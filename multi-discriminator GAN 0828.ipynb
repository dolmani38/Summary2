{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "korean_frame_token_0_1.0_gamma_10.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dolmani38/Summary2/blob/main/multi-discriminator%20GAN%200828.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkQCxNatSIOk"
      },
      "source": [
        "# Multi-Discriminator GAN\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZjIW9VwyjDf"
      },
      "source": [
        "ABSTRACT\n",
        "\n",
        "----\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c20I_OEErmP9"
      },
      "source": [
        "# Related works\n",
        "\n",
        "두개 이상의 discriminator를 사용하는 GAN 연구에 대하여 알아본다.\n",
        "\n",
        "어떤 목적으로 복수의 discriminator를 사용하고 그 효과는 무엇인지 알아본다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uFOIbzcFagq"
      },
      "source": [
        "## 0. N개의 discriminator를 활용한 연구 \n",
        "\n",
        "Generative adversarial networks (Goodfellow et al. (2014))\n",
        "\n",
        "Generator를 multi로 한 연구들...\n",
        "\n",
        "1) Q. Hoang, T. Dinh Nguyen, T. Le, and D. Phung, “Multi-Generator Generative Adversarial Nets,” ArXiv e-prints, Aug. 2017.\n",
        "\n",
        "2) Multi-Agent Diverse Generative Adversarial Networks\n",
        "\n",
        "Federated learning의 한 지류가 될수도 있을 것...\n",
        "\n",
        "H. B. McMahan, E. Moore, D. Ramage, and B. A. y Arcas, “Federated learning of deep networks using model averaging,” CoRR, vol. abs/1602.05629, 2016."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fa-0-i84rqoX"
      },
      "source": [
        "## 1. Automatic Image Colorization based on Multi-Discriminators Generative Adversarial Networks [품질향상]\n",
        "\n",
        "GAN은 흑백의 이미지를 입력하여 Color화 된 이미지를 생성해 낼 수 있다.\n",
        "본 논문은 두개의 discriminator를 이용하여 더 produces\n",
        "more realistic quality results.\n",
        "\n",
        "Different from conventional GAN network architecture,\n",
        "Park et al. [13] (S.-J. Park, H. Son, S. Cho, K.-S. Hong, and S. Lee, “Srfeat: Single image super-resolution with feature discrimination,” in Proceedings of the European Conference on Computer Vision, 2018, pp. 439–455.) introduce architecture based on combination of one generator associated with two discriminators. For colorization task, we propose an extended model, illustrated in Fig.1, which uses two discriminators: <font color='red'><b>an image discriminator Di and a feature discriminator Df</b> </font>. The first one discriminates real images (RGB) from colorized images by inspecting their pixel values, while the second discriminates real images from colorized ones by inspecting their feature maps, noted respectively\n",
        "VGG(y) and VGG(G(x)) .\n",
        "\n",
        "본 논문의 Proposed Loss functions 중 GAN에 대한 Loss은 다음과 같다.\n",
        "\n",
        "$$ L_{M-dis}(G,D_i,D_f) = \\lambda_iL_{GAN}(G,D_i) + \\lambda_fL_{GAN}(G,D_f)  $$\n",
        "where lambda_i and lambda_f denote a defined weighting factors\n",
        "\n",
        "실험에 있어서도 lambda_i and lambda_f 의 값을 특정 값을 설정하여 실험 하였다.\n",
        "그 값은 최적의 값이 였을까??"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxfz7tKoDcZQ"
      },
      "source": [
        "## 2. UMLE: Unsupervised Multi-discriminator Network for Low Light Enhancement [품질 향상]\n",
        "\n",
        "Low-light image enhancement, such as recovering color and texture details from low-light images, is a complex and vital task. For automated driving, low-light scenarios will have serious implications for vision-based applications. To address this problem, we propose a real-time unsupervised generative adversarial network (GAN) containing  <font color='red'><b>multiple discriminators, i.e. a multi-scale discriminator, a texture discriminator, and a color discriminator.</b></font>\n",
        "\n",
        "본 논문에서 loss function 은 Adversarial loss + Cycle loss + Color loss + Preserving Loss + Reconstruction loss 로 구성된다.\n",
        "\n",
        "$$ L_{all} = \\omega_1L_{adv}+\\omega_2L_{cyc}+\\omega_3L_{color}+\\omega_4L_{pre}+\\omega_5L_{idt}$$ \n",
        "\n",
        "하지만 각각의 omega는 huristic하게 특정 지었다. 최적화된 값인가??"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jbt0ApbS8V_Q"
      },
      "source": [
        "## 3. GENERATIVE MULTI-ADVERSARIAL NETWORKS [품질 향상+mode collapse]\n",
        "\n",
        "N개의 복수 discriminator를 사용하여 안정적으로 더 빠르게 GAN 학습을 할 수 있다. 또한 mode collapse에도 robust 한 특성을 보인다.\n",
        "\n",
        "본 논문에서는 loss function을 three classical Pythagorean means 을 응용하여 정의하였다.\n",
        "\n",
        "$$ AM_{soft}(V, \\lambda) = \\sum_{i}^N \\omega_iV_i $$\n",
        "$$ GM_{soft}(V, \\lambda) = -exp(\\sum_{i}^N \\omega_ilog(-V_i)) $$\n",
        "$$ HM_{soft}(V, \\lambda) = (\\sum_{i}^N \\omega_iV_i^{-1})^{-1} $$\n",
        "\n",
        "하지만, 논문에서는 omega에 대하여 다루지 않았다.\n",
        "저 omega는 어떻게 최적화 할 수 있겠는가?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5qpgtDUySyC"
      },
      "source": [
        "## 4. Dual Discriminator Generative Adversarial Nets [mode collapse]\n",
        "\n",
        "GAN에서 발생하는 치명적인 mode collapse (https://developers.google.com/machine-learning/gan/problems) 현상을 개선하기 위해 두개의 discriminator를 사용한다. - dual discriminator generative adversarial network (D2GAN)\n",
        "\n",
        "it combines <font color='red'><b>the Kullback-Leibler (KL) and reverse KL divergences</b></font> into a unified objective function, thus it exploits the complementary statistical properties from these divergences to effectively diversify the estimated density in capturing multi-modes.\n",
        "\n",
        "본 논문에서 제안하는 D2GAN의 목적함수는 다음과 같다.\n",
        "\n",
        "$$ \\min_{G} \\max_{D_1,D_2} J (G,D_1,D_2) = \\alpha \\times E_{x \\sim P_{data}} [logD_1 (x)] + E_{z \\sim P_z} [-D_1 (G(z))] + E_{x \\sim P_{data}}[-D_2 (x)] + \\beta \\times E_{z \\sim P_z} [logD_2 (G(z))] $$\n",
        "\n",
        "여기서 alpha, beta는 hyperparameter로서, 본 논문의 실험에서는 다양한 값을 대입하여 각각의 성능을 확인하였다.\n",
        "\n",
        "이렇게 값을 찾아야만 하는가?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBQHO9hOBho-"
      },
      "source": [
        "## 5. MD-GAN: Multi-Discriminator Generative Adversarial Networks for Distributed Datasets [성능 향상]\n",
        "\n",
        "we address the problem of distributing GANs so that they are able to train over datasets that are spread on multiple workers. MD-GAN is exposed as the first solution for this problem: we propose a novel learning procedure for GANs\n",
        "so that they fit this distributed setup. We then compare the performance of MD-GAN to an adapted version of Federated Learning to GANs, using the MNIST and CIFAR10 datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPUM8QvQCWzi"
      },
      "source": [
        "## 6. ParallelWasserstein Generative Adversarial Nets with Multiple Discriminators [성능 향상]\n",
        "\n",
        "In this paper, we solve the computation cost problem by speeding up the Wasserstein GANs from a welldesigned communication efficient parallel architecture. 그리고 이것을 Multiple Discriminators 로 구성하였다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjztFvs812EB"
      },
      "source": [
        "## Proposed methods\n",
        "\n",
        "ref : https://realpython.com/python-ai-neural-network/\n",
        "\n",
        "colab 수식입력 : \n",
        "\n",
        "https://wikidocs.net/1679\n",
        "\n",
        "https://en.wikipedia.org/wiki/Help:Displaying_a_formula#Formatting_using_TeX\n",
        "\n",
        "Original GAN의 목적함수\n",
        "$$ \\min_{G}\\max_{D} V(D,G) = E_{x\\sim p_{data}(x)}[logD(x)] + E_{z\\sim p_{z}(z)}[log(1-D(G(z)))] $$\n",
        "\n",
        "Multi-Discriminator GAN은 discriminator가 각 목적에 의하여 여러개 (N개) 있다.\n",
        "MDGAN의 목적함수\n",
        "\n",
        "$$ \\min_{G}\\max_{D_{i\\sim N}} V(D_{i\\sim N},G) = \\sum_{i=1}^N \\{E_{x\\sim p_{data}(x)}[logD_i(x)] + E_{z\\sim p_{z}(z)}[log(1-D_i(G(z)))]\\} $$\n",
        "\n",
        "여기서\n",
        "\n",
        "$$ L(D_i,G) =  E_{x\\sim p_{data}(x)}[logD_i(x)] + E_{z\\sim p_{z}(z)}[log(1-D_i(G(z)))] $$\n",
        "\n",
        "이라하고 단순화 하면\n",
        "\n",
        "$$ \\min_{G}\\max_{D_{i\\sim N}} V(D_{i\\sim N},G) = \\sum_{i=1}^N L(D_i,G) $$\n",
        "\n",
        "와 같이 된다.\n",
        "\n",
        "문제점은 GAN의 특성상, 특정 Discriminator가 학습에 있어 지배적으로 loss 함수에 영향을 미치게 되어 각각의 Discriminator가 골고루 학습에 참여하지 못하고 의도하지 않은 결과를 만들게 된다. 이러한 문제점을 극복하기 위해 다음의 두가지 제안을 한다.\n",
        "\n",
        "1) 목적함수에 각 Loss 에 대한 표준편차 (standard-deviation) 를 반영하여 각 Discriminator에 대한 Loss가 상호 유사한 수준을 유지하면 학습이 진행되도록 한다.\n",
        "\n",
        "$$ \\min_{G}\\max_{D_{i\\sim N}} V(D_{i\\sim N},G) = \\sum_{i=1}^N L(D_i,G) + \\sigma(L(D_i,G))$$\n",
        "\n",
        "2) 각 discriminator에 의한 loss를 제어하기 위해, adaptive discriminant factor (ADF) 를 적용하고, 학습의 진행 과정에서 이를 최적화 한다. \n",
        "\n",
        "$$ \\min_{G}\\max_{D_{i\\sim N}} V(\\lambda_{i\\sim N},D_{i\\sim N},G) = \\sum_{i=1}^N \\lambda_iL(D_i,G)$$\n",
        "\n",
        "3) 1)의 제안에 2)의 제안을 추가한다.\n",
        "\n",
        "$$ \\min_{G}\\max_{D_{i\\sim N}} V(\\lambda_{i\\sim N},D_{i\\sim N},G) = \\sum_{i=1}^N \\lambda_iL(D_i,G) + \\sigma(L(D_i,G))$$\n",
        "\n",
        "\n",
        "여기서\n",
        "\n",
        "$$ \\lambda_i = adaptive\\ discriminant \\ factor \\ for \\ discriminator \\ i  $$\n",
        "\n",
        "중요한 것은, 학습과정에서 L_i을 작게 (학습의 방향)하기 위해서는 lambda_i는 역으로 커져야 한다. 그래야, 전체 Loss function에서 비중이 증대되어 더 적극적인 학습이 이루어 지게 된다. 따라서, lambda_i의 최적화 방향은 기존의 gradient decent와 반대 방향이 되어야 한다.\n",
        "\n",
        "$$ \\lambda_i^{t+1} = \\lambda_i^t + \\gamma \\nabla V(\\lambda_{i\\sim N}^t,D_{i\\sim N},G)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K87VNBbeRLFF"
      },
      "source": [
        "#4. Implementation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQZeBAf8NxAR"
      },
      "source": [
        "## 4.1 기본 설정..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAdXzWGuKSBT",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef7ad518-96d5-490c-ac53-bc2c53d50388"
      },
      "source": [
        "if True:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "newO0mBXKVnE",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "187b1a14-897e-481e-99c4-993bfe6ceaf8"
      },
      "source": [
        "#!pip install keybert\n",
        "!pip3 install transformers\n",
        "!pip3 install sentence-transformers\n",
        "\n",
        "#!pip install sentence-transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.9.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (5.4.1)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.12)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.7/dist-packages (2.0.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.10.0+cu102)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.9.0+cu102)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.62.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.1.96)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.19.5)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.2.5)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.9.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.0.12)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.22.2.post1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers) (3.7.4.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.0.45)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.12)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (4.6.4)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.10.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (21.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (5.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2021.5.30)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.0.1)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers) (7.1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmIxp0FnKXif",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61bbe206-c624-4d52-8aae-1199e58f1027"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# set seeds for reproducability\n",
        "from numpy.random import seed\n",
        "#seed(1)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string, os \n",
        "\n",
        "import urllib.request\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3J0n_lhKcgm",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e50ea6dd-340c-4511-c14b-a9d3ac07e5ba"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ue_4ZfdRKfdX",
        "trusted": true
      },
      "source": [
        "# Print iterations progress\n",
        "class ProgressBar:\n",
        "\n",
        "    def __init__(self,total=20, prefix = '', suffix = '', decimals = 1, length = 20, fill = '|', printEnd = \"\\r\"):\n",
        "        self.total = total\n",
        "        self.prefix = prefix\n",
        "        self.suffix = suffix\n",
        "        self.decimals = decimals\n",
        "        self.length = length\n",
        "        self.fill = fill\n",
        "        self.printEnd = printEnd\n",
        "        self.ite = 0\n",
        "        self.back_filledLength = 0\n",
        "\n",
        "    def printProgress(self,iteration, text):\n",
        "        self.ite += iteration\n",
        "        percent = (\"{0:.\" + str(self.decimals) + \"f}\").format(100 * (self.ite / float(self.total)))\n",
        "        filledLength = int(self.length * self.ite // self.total)\n",
        "        bar = self.fill * filledLength + '.' * (self.length - filledLength)\n",
        "        if filledLength > self.back_filledLength or percent == 100:\n",
        "            print(f'\\r{self.prefix} |{bar}| {percent}% {self.suffix}  {text}', end=\"\", flush=True)\n",
        "            # Print New Line on Complete\n",
        "            if self.ite == self.total: \n",
        "                print()\n",
        "        self.back_filledLength = filledLength    "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNHI0G6JKc5h",
        "trusted": true
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Zsv-LVkKmfL"
      },
      "source": [
        "##4.2 Grammar Discriminator Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VQdGLciKc_y",
        "trusted": true
      },
      "source": [
        "from transformers import BertTokenizer, BertTokenizerFast,AutoTokenizer, BertForSequenceClassification, AdamW, BertConfig, get_linear_schedule_with_warmup\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset, random_split\n",
        "\n",
        "import time\n",
        "import random\n",
        "import datetime\n",
        "\n",
        "# 간단한 전처리\n",
        "def clean_text(txt):\n",
        "    txt = txt.replace('\\n',' ')\n",
        "    txt = txt.replace('\\r',' ')    \n",
        "    txt = txt.replace('=','')\n",
        "    txt = txt.replace('\\\"','')   \n",
        "    txt = txt.replace('\\'','')\n",
        "    #txt = txt.replace(',','')\n",
        "    txt = txt.replace('..','')\n",
        "    txt = txt.replace('...','')\n",
        "    txt = txt.replace(' .','.')\n",
        "    txt = txt.replace('.','. ')\n",
        "    txt = txt.replace('  ',' ')\n",
        "    txt = txt.replace('  ',' ')    \n",
        "    txt = txt.replace('  ',' ')   \n",
        "    txt = txt.replace('  ',' ')           \n",
        "    txt = txt.replace('  ',' ')\n",
        "    txt = txt.replace('  ',' ')    \n",
        "    txt = txt.replace('  ',' ')   \n",
        "    txt = txt.replace('  ',' ')             \n",
        "    return txt.strip()\n",
        "\n",
        "def shuffling(txt):\n",
        "    txt_list = txt.split(' ')\n",
        "    random.shuffle(txt_list)\n",
        "    return ' '.join(txt_list)\n",
        "\n",
        "def collect_training_dataset_for_grammar_discriminator(sentences_dataset):\n",
        "\n",
        "    sentences = []\n",
        "    labels = []\n",
        "\n",
        "    for txtss in sentences_dataset:\n",
        "        txtss = clean_text(txtss)\n",
        "        txts = txtss.strip().split('.')\n",
        "        for txt in txts:  \n",
        "            txt = txt.strip()\n",
        "            if len(txt) > 10:\n",
        "                #ko_grammar_dataset.append([txt,1])\n",
        "                txt = txt.replace('.','')\n",
        "                tf = random.choice([True,False])\n",
        "                # 정상 또는 비정상 둘중에 하나만 데이터셋에 추가\n",
        "                if (tf):\n",
        "                    sentences.append(txt) # '.'의 위치를 보고 True, False를 판단 하기 땜에...\n",
        "                    labels.append(1)\n",
        "                else:\n",
        "                    sentences.append(shuffling(txt))\n",
        "                    labels.append(0)\n",
        "\n",
        "    return sentences,labels\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
        "\n",
        "class Grammar_Discriminator:\n",
        "\n",
        "\n",
        "    def __init__(self, pretraoned_kobert_model_name='kykim/bert-kor-base', input_dir=None):\n",
        "\n",
        "        if input_dir is None:\n",
        "            self.tokenizer = BertTokenizerFast.from_pretrained(pretraoned_kobert_model_name)\n",
        "            self.discriminator = BertForSequenceClassification.from_pretrained(\n",
        "                                    pretraoned_kobert_model_name, # Use the 12-layer BERT model, with an uncased vocab.\n",
        "                                    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                                                    # You can increase this for multi-class tasks.   \n",
        "                                    output_attentions = False, # Whether the model returns attentions weights.\n",
        "                                    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        "                                )            \n",
        "        else:\n",
        "            self.__load_model(input_dir)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def set_dataset(self, sentences,labels):\n",
        "        # Print the original sentence.\n",
        "        print(' Original: ', sentences[0])\n",
        "\n",
        "        # Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "        input_ids = []\n",
        "        attention_masks = []\n",
        "\n",
        "        # For every sentence...\n",
        "        for sent in sentences:\n",
        "            # `encode_plus` will:\n",
        "            #   (1) Tokenize the sentence.\n",
        "            #   (2) Prepend the `[CLS]` token to the start.\n",
        "            #   (3) Append the `[SEP]` token to the end.\n",
        "            #   (4) Map tokens to their IDs.\n",
        "            #   (5) Pad or truncate the sentence to `max_length`\n",
        "            #   (6) Create attention masks for [PAD] tokens.\n",
        "            encoded_dict = self.tokenizer.encode_plus(\n",
        "                                sent,                      # Sentence to encode.\n",
        "                                add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                                max_length = 64,           # Pad & truncate all sentences.\n",
        "                                pad_to_max_length = True,\n",
        "                                return_attention_mask = True,   # Construct attn. masks.\n",
        "                                return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                                truncation = True,\n",
        "                        )\n",
        "            \n",
        "            # Add the encoded sentence to the list.    \n",
        "            input_ids.append(encoded_dict['input_ids'])\n",
        "            \n",
        "            # And its attention mask (simply differentiates padding from non-padding).\n",
        "            attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "        # Convert the lists into tensors.\n",
        "        input_ids = torch.cat(input_ids, dim=0)\n",
        "        attention_masks = torch.cat(attention_masks, dim=0)\n",
        "        labels = torch.tensor(labels)\n",
        "\n",
        "        # Print sentence 0, now as a list of IDs.\n",
        "        print('Original: ', sentences[0])\n",
        "        print('Token IDs:', input_ids[0])\n",
        "\n",
        "        # Training & Validation Split\n",
        "        # Divide up our training set to use 90% for training and 10% for validation.\n",
        "\n",
        "        # Combine the training inputs into a TensorDataset.\n",
        "        dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "        # Create a 90-10 train-validation split.\n",
        "\n",
        "        # Calculate the number of samples to include in each set.\n",
        "        train_size = int(0.9 * len(dataset))\n",
        "        val_size = len(dataset) - train_size\n",
        "\n",
        "        # Divide the dataset by randomly selecting samples.\n",
        "        train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "        print('{:>5,} training samples'.format(train_size))\n",
        "        print('{:>5,} validation samples'.format(val_size))\n",
        "\n",
        "        # The DataLoader needs to know our batch size for training, so we specify it \n",
        "        # here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "        # size of 16 or 32.\n",
        "        self.batch_size = 32\n",
        "\n",
        "        # Create the DataLoaders for our training and validation sets.\n",
        "        # We'll take training samples in random order. \n",
        "        self.train_dataloader = DataLoader(\n",
        "                    train_dataset,  # The training samples.\n",
        "                    sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "                    batch_size = self.batch_size # Trains with this batch size.\n",
        "                )\n",
        "\n",
        "        # For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "        self.validation_dataloader = DataLoader(\n",
        "                    val_dataset, # The validation samples.\n",
        "                    sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "                    batch_size = self.batch_size # Evaluate with this batch size.\n",
        "                )        \n",
        "\n",
        "\n",
        "\n",
        "    def train(self,epochs=4):\n",
        "        # Tell pytorch to run this model on the GPU.\n",
        "        self.discriminator.cuda()\n",
        "\n",
        "        # Get all of the model's parameters as a list of tuples.\n",
        "        params = list(self.discriminator.named_parameters())\n",
        "\n",
        "        print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "        print('==== Embedding Layer ====\\n')\n",
        "\n",
        "        for p in params[0:5]:\n",
        "            print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "        print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "        for p in params[5:21]:\n",
        "            print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "        print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "        for p in params[-4:]:\n",
        "            print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))  \n",
        "\n",
        "        # Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "        # I believe the 'W' stands for 'Weight Decay fix\"\n",
        "        self.optimizer = AdamW(self.discriminator.parameters(),\n",
        "                        lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                        eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                        )\n",
        "\n",
        "        # Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "        # We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "        # training data.\n",
        "        #epochs = 2\n",
        "\n",
        "        # Total number of training steps is [number of batches] x [number of epochs]. \n",
        "        # (Note that this is not the same as the number of training samples).\n",
        "        total_steps = len(self.train_dataloader) * epochs\n",
        "\n",
        "        # Create the learning rate scheduler.\n",
        "        scheduler = get_linear_schedule_with_warmup(self.optimizer, \n",
        "                                                    num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                                    num_training_steps = total_steps)\n",
        "            \n",
        "        # This training code is based on the `run_glue.py` script here:\n",
        "        # https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "        # Set the seed value all over the place to make this reproducible.\n",
        "        seed_val = 42\n",
        "\n",
        "        random.seed(seed_val)\n",
        "        np.random.seed(seed_val)\n",
        "        torch.manual_seed(seed_val)\n",
        "        torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "        # We'll store a number of quantities such as training and validation loss, \n",
        "        # validation accuracy, and timings.\n",
        "        training_stats = []\n",
        "\n",
        "        # Measure the total training time for the whole run.\n",
        "        total_t0 = time.time()\n",
        "\n",
        "        # For each epoch...\n",
        "        for epoch_i in range(0, epochs):\n",
        "            \n",
        "            # ========================================\n",
        "            #               Training\n",
        "            # ========================================\n",
        "            \n",
        "            # Perform one full pass over the training set.\n",
        "\n",
        "            print(\"\")\n",
        "            print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "            print('Training...')\n",
        "\n",
        "            # Measure how long the training epoch takes.\n",
        "            t0 = time.time()\n",
        "\n",
        "            # Reset the total loss for this epoch.\n",
        "            total_train_loss = 0\n",
        "\n",
        "            # Put the model into training mode. Don't be mislead--the call to \n",
        "            # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "            # `dropout` and `batchnorm` layers behave differently during training\n",
        "            # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "            self.discriminator.train()\n",
        "\n",
        "            # For each batch of training data...\n",
        "            for step, batch in enumerate(self.train_dataloader):\n",
        "\n",
        "                # Progress update every 40 batches.\n",
        "                if step % 40 == 0 and not step == 0:\n",
        "                    # Calculate elapsed time in minutes.\n",
        "                    elapsed = format_time(time.time() - t0)\n",
        "                    \n",
        "                    # Report progress.\n",
        "                    print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(self.train_dataloader), elapsed))\n",
        "\n",
        "                # Unpack this training batch from our dataloader. \n",
        "                #\n",
        "                # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "                # `to` method.\n",
        "                #\n",
        "                # `batch` contains three pytorch tensors:\n",
        "                #   [0]: input ids \n",
        "                #   [1]: attention masks\n",
        "                #   [2]: labels \n",
        "                b_input_ids = batch[0].to(device)\n",
        "                b_input_mask = batch[1].to(device)\n",
        "                b_labels = batch[2].to(device)\n",
        "\n",
        "                # Always clear any previously calculated gradients before performing a\n",
        "                # backward pass. PyTorch doesn't do this automatically because \n",
        "                # accumulating the gradients is \"convenient while training RNNs\". \n",
        "                # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "                self.discriminator.zero_grad()        \n",
        "\n",
        "                # Perform a forward pass (evaluate the model on this training batch).\n",
        "                # The documentation for this `model` function is here: \n",
        "                # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "                # It returns different numbers of parameters depending on what arguments\n",
        "                # arge given and what flags are set. For our useage here, it returns\n",
        "                # the loss (because we provided labels) and the \"logits\"--the model\n",
        "                # outputs prior to activation.\n",
        "                outputs = self.discriminator(b_input_ids, \n",
        "                                    token_type_ids=None, \n",
        "                                    attention_mask=b_input_mask, \n",
        "                                    labels=b_labels)\n",
        "                loss, logits = outputs.loss, outputs.logits\n",
        "                # Accumulate the training loss over all of the batches so that we can\n",
        "                # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "                # single value; the `.item()` function just returns the Python value \n",
        "                # from the tensor.\n",
        "                total_train_loss += loss.item()\n",
        "\n",
        "                # Perform a backward pass to calculate the gradients.\n",
        "                loss.backward()\n",
        "\n",
        "                # Clip the norm of the gradients to 1.0.\n",
        "                # This is to help prevent the \"exploding gradients\" problem.\n",
        "                torch.nn.utils.clip_grad_norm_(self.discriminator.parameters(), 1.0)\n",
        "\n",
        "                # Update parameters and take a step using the computed gradient.\n",
        "                # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "                # modified based on their gradients, the learning rate, etc.\n",
        "                self.optimizer.step()\n",
        "\n",
        "                # Update the learning rate.\n",
        "                scheduler.step()\n",
        "\n",
        "            # Calculate the average loss over all of the batches.\n",
        "            avg_train_loss = total_train_loss / len(self.train_dataloader)            \n",
        "            \n",
        "            # Measure how long this epoch took.\n",
        "            training_time = format_time(time.time() - t0)\n",
        "\n",
        "            print(\"\")\n",
        "            print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "            print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "                \n",
        "            # ========================================\n",
        "            #               Validation\n",
        "            # ========================================\n",
        "            # After the completion of each training epoch, measure our performance on\n",
        "            # our validation set.\n",
        "\n",
        "            print(\"\")\n",
        "            print(\"Running Validation...\")\n",
        "\n",
        "            t0 = time.time()\n",
        "\n",
        "            # Put the model in evaluation mode--the dropout layers behave differently\n",
        "            # during evaluation.\n",
        "            self.discriminator.eval()\n",
        "\n",
        "            # Tracking variables \n",
        "            total_eval_accuracy = 0\n",
        "            total_eval_loss = 0\n",
        "            nb_eval_steps = 0\n",
        "\n",
        "            # Evaluate data for one epoch\n",
        "            for batch in self.validation_dataloader:\n",
        "                \n",
        "                # Unpack this training batch from our dataloader. \n",
        "                #\n",
        "                # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "                # the `to` method.\n",
        "                #\n",
        "                # `batch` contains three pytorch tensors:\n",
        "                #   [0]: input ids \n",
        "                #   [1]: attention masks\n",
        "                #   [2]: labels \n",
        "                b_input_ids = batch[0].to(device)\n",
        "                b_input_mask = batch[1].to(device)\n",
        "                b_labels = batch[2].to(device)\n",
        "                \n",
        "                # Tell pytorch not to bother with constructing the compute graph during\n",
        "                # the forward pass, since this is only needed for backprop (training).\n",
        "                with torch.no_grad():        \n",
        "\n",
        "                    # Forward pass, calculate logit predictions.\n",
        "                    # token_type_ids is the same as the \"segment ids\", which \n",
        "                    # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "                    # The documentation for this `model` function is here: \n",
        "                    # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "                    # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "                    # values prior to applying an activation function like the softmax.\n",
        "                    outputs = self.discriminator(b_input_ids, \n",
        "                                        token_type_ids=None, \n",
        "                                        attention_mask=b_input_mask,\n",
        "                                        labels=b_labels)\n",
        "                loss, logits = outputs.loss, outputs.logits\n",
        "                # Accumulate the validation loss.\n",
        "                total_eval_loss += loss.item()\n",
        "\n",
        "                # Move logits and labels to CPU\n",
        "                logits = logits.detach().cpu().numpy()\n",
        "                label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "                # Calculate the accuracy for this batch of test sentences, and\n",
        "                # accumulate it over all batches.\n",
        "                total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "                \n",
        "\n",
        "            # Report the final accuracy for this validation run.\n",
        "            avg_val_accuracy = total_eval_accuracy / len(self.validation_dataloader)\n",
        "            print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "            # Calculate the average loss over all of the batches.\n",
        "            avg_val_loss = total_eval_loss / len(self.validation_dataloader)\n",
        "            \n",
        "            # Measure how long the validation run took.\n",
        "            validation_time = format_time(time.time() - t0)\n",
        "            \n",
        "            print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "            print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "            # Record all statistics from this epoch.\n",
        "            training_stats.append(\n",
        "                {\n",
        "                    'epoch': epoch_i + 1,\n",
        "                    'Training Loss': avg_train_loss,\n",
        "                    'Valid. Loss': avg_val_loss,\n",
        "                    'Valid. Accur.': avg_val_accuracy,\n",
        "                    'Training Time': training_time,\n",
        "                    'Validation Time': validation_time\n",
        "                }\n",
        "            )\n",
        "\n",
        "        print(\"\")\n",
        "        print(\"Training complete!\")\n",
        "\n",
        "        print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n",
        "            \n",
        "\n",
        "        return training_stats\n",
        "\n",
        "    def save_model(self, output_dir = './model_save/'):\n",
        "        # Create output directory if needed\n",
        "        if not os.path.exists(output_dir):\n",
        "            os.makedirs(output_dir)\n",
        "\n",
        "        print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "        # Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "        # They can then be reloaded using `from_pretrained()`\n",
        "        model_to_save = self.discriminator.module if hasattr(self.discriminator, 'module') else self.discriminator  # Take care of distributed/parallel training\n",
        "        model_to_save.save_pretrained(output_dir)\n",
        "        self.tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "        # Good practice: save your training arguments together with the trained model\n",
        "        # torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n",
        "\n",
        "    def __load_model(self, input_dir = './drive/MyDrive/Colab Notebooks/summary/en_grammar_check_model'):\n",
        "        print('Loading BERT tokenizer...')\n",
        "        self.tokenizer = BertTokenizerFast.from_pretrained(input_dir)\n",
        "        self.discriminator = BertForSequenceClassification.from_pretrained(input_dir)\n",
        "\n",
        "    def transfer_learning(self, sentences, train_for = True):\n",
        "        \n",
        "        input_ids = []\n",
        "        attention_masks = []\n",
        "\n",
        "        # For every sentence...\n",
        "        for sent in sentences:\n",
        "            # `encode_plus` will:\n",
        "            #   (1) Tokenize the sentence.\n",
        "            #   (2) Prepend the `[CLS]` token to the start.\n",
        "            #   (3) Append the `[SEP]` token to the end.\n",
        "            #   (4) Map tokens to their IDs.\n",
        "            #   (5) Pad or truncate the sentence to `max_length`\n",
        "            #   (6) Create attention masks for [PAD] tokens.\n",
        "            encoded_dict = self.tokenizer.encode_plus(\n",
        "                                sent,                      # Sentence to encode.\n",
        "                                add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                                max_length = 64,           # Pad & truncate all sentences.\n",
        "                                pad_to_max_length = True,\n",
        "                                return_attention_mask = True,   # Construct attn. masks.\n",
        "                                return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                                truncation = True,\n",
        "                        )\n",
        "            # Add the encoded sentence to the list.    \n",
        "            input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "            # And its attention mask (simply differentiates padding from non-padding).\n",
        "            attention_masks.append(encoded_dict['attention_mask'])\n",
        "        \n",
        "        if train_for:\n",
        "            b_labels = torch.ones(len(sentences),dtype=torch.long).to(device)\n",
        "        else:\n",
        "            b_labels = torch.zeros(len(sentences),dtype=torch.long).to(device)\n",
        "        #print(b_labels)\n",
        "        # Convert the lists into tensors.\n",
        "        input_ids = torch.cat(input_ids, dim=0).to(device)\n",
        "        attention_masks = torch.cat(attention_masks, dim=0).to(device)    \n",
        "        #if str(discriminator1.device) == 'cpu':\n",
        "        #    pass\n",
        "        #else:\n",
        "        #    input_ids = input_ids.to(device)\n",
        "        #    attention_masks = attention_masks.to(device)        \n",
        "\n",
        "        outputs = self.discriminator(input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=attention_masks, \n",
        "                                labels=b_labels)\n",
        "\n",
        "        #print(outputs)\n",
        "        #return torch.sigmoid(outputs[0][:,1])\n",
        "        #return outputs[0][:,1]\n",
        "        return outputs['loss'], outputs['logits']\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjqloLeQpyxz"
      },
      "source": [
        "# 문법 학습을 위한 데이터셋 구성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "id": "p-dd_3RRp2Qz",
        "outputId": "65c33d63-f2a1-4f70-c48e-16af1d8fdbb6"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/summary/korean_news_corpus.csv')\n",
        "df"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>contents</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>문 대통령 변창흠 국토장관 사의표명 사실상 수용</td>\n",
              "      <td>정만호 국민소통수석이 12일 오후 청와대 춘추관 대브리핑룸에서 변창흠 국토부 장관 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>계급장 수여하는 문 대통령</td>\n",
              "      <td>(아산뉴스1) 이광호 기자 문재인 대통령이 12일 오후 충남 아산시 경찰대학에서 열...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>계급장 수여하는 문 대통령</td>\n",
              "      <td>(아산뉴스1) 이광호 기자 문재인 대통령이 12일 오후 충남 아산시 경찰대학에서 열...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>수상자 메달 걸어주는 문 대통령</td>\n",
              "      <td>(아산뉴스1) 이광호 기자 문재인 대통령이 12일 오후 충남 아산시 경찰대학에서 열...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>정몽구 서울아산병원에 50억 쾌척</td>\n",
              "      <td>인재 양성·소외 계층 지원 등 계획 “부친 질병·가난 악순환 끊기 원해 국내 최고 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140559</th>\n",
              "      <td>[건축과도시] 북한산을 캔버스 삼아. 미술관 또 하나의 작품이 되다</td>\n",
              "      <td>&lt;은평구 진관동 사비나 미술관&gt; 서울시 은평구 진관동에 자리잡은 사비나미술관. 삼각...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140560</th>\n",
              "      <td>조선후기 문인 김조순 별장 그린 옥호정도 첫 공개</td>\n",
              "      <td>국립중앙박물관 서화실 개편해 32점 새롭게 전시 옥호정도[국립중앙박물관 제공연합뉴스...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140561</th>\n",
              "      <td>안성 청룡사 대웅전에서 목재 곡자 발견</td>\n",
              "      <td>문화재청(청장 정재숙)의 국고보조와 기술지도로 안성시에서 시행하고 있는 안성 청룡사...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140562</th>\n",
              "      <td>156년전 ㄱ자 곡자 찾았다 안성 청룡사 기둥 밑에서</td>\n",
              "      <td>안성 청룡사 대웅전에서 발견된 곡자 【서울뉴시스】 이수지 기자 안성 청룡사 대웅전에...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140563</th>\n",
              "      <td>[김중기의 필름통] 새 영화 도굴 나인스 게이트 앙상블</td>\n",
              "      <td>영화 도굴 스틸컷 ◆도굴 감독: 박정배 출연: 이제훈 조우진 신혜선 도굴을 소재로 ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>140564 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        title                                           contents\n",
              "0                  문 대통령 변창흠 국토장관 사의표명 사실상 수용  정만호 국민소통수석이 12일 오후 청와대 춘추관 대브리핑룸에서 변창흠 국토부 장관 ...\n",
              "1                              계급장 수여하는 문 대통령  (아산뉴스1) 이광호 기자 문재인 대통령이 12일 오후 충남 아산시 경찰대학에서 열...\n",
              "2                              계급장 수여하는 문 대통령  (아산뉴스1) 이광호 기자 문재인 대통령이 12일 오후 충남 아산시 경찰대학에서 열...\n",
              "3                           수상자 메달 걸어주는 문 대통령  (아산뉴스1) 이광호 기자 문재인 대통령이 12일 오후 충남 아산시 경찰대학에서 열...\n",
              "4                          정몽구 서울아산병원에 50억 쾌척  인재 양성·소외 계층 지원 등 계획 “부친 질병·가난 악순환 끊기 원해 국내 최고 ...\n",
              "...                                       ...                                                ...\n",
              "140559  [건축과도시] 북한산을 캔버스 삼아. 미술관 또 하나의 작품이 되다  <은평구 진관동 사비나 미술관> 서울시 은평구 진관동에 자리잡은 사비나미술관. 삼각...\n",
              "140560            조선후기 문인 김조순 별장 그린 옥호정도 첫 공개  국립중앙박물관 서화실 개편해 32점 새롭게 전시 옥호정도[국립중앙박물관 제공연합뉴스...\n",
              "140561                  안성 청룡사 대웅전에서 목재 곡자 발견  문화재청(청장 정재숙)의 국고보조와 기술지도로 안성시에서 시행하고 있는 안성 청룡사...\n",
              "140562          156년전 ㄱ자 곡자 찾았다 안성 청룡사 기둥 밑에서  안성 청룡사 대웅전에서 발견된 곡자 【서울뉴시스】 이수지 기자 안성 청룡사 대웅전에...\n",
              "140563         [김중기의 필름통] 새 영화 도굴 나인스 게이트 앙상블  영화 도굴 스틸컷 ◆도굴 감독: 박정배 출연: 이제훈 조우진 신혜선 도굴을 소재로 ...\n",
              "\n",
              "[140564 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9ouEN_yp4uG",
        "outputId": "f6019fa3-d16d-4af4-9f8b-26b275bd2a32"
      },
      "source": [
        "df = df.dropna(axis=0)\n",
        "df['contents'].count()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "140536"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "-e484q4qqA74",
        "outputId": "1acf5260-413a-4af5-ea20-b3aae248df35"
      },
      "source": [
        "import re\n",
        "import sys\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "# 간단한 전처리\n",
        "def clean_text(txt):\n",
        "    txt = txt.replace('\\n',' ')\n",
        "    txt = txt.replace('\\r',' ')    \n",
        "    txt = txt.replace('=','')\n",
        "    txt = txt.replace('\\\"','')   \n",
        "    txt = txt.replace('\\'','')\n",
        "    txt = txt.replace('”','')\n",
        "    txt = txt.replace('“','')\n",
        "    txt = txt.replace('’','')\n",
        "    #txt = txt.replace(',','')\n",
        "    txt = txt.replace('..','')\n",
        "    txt = txt.replace('...','')\n",
        "    #txt = txt.replace('.','. ')\n",
        "    txt = txt.replace('.','. ')\n",
        "    txt = txt.replace('  ',' ')\n",
        "    txt = txt.replace('  ',' ')    \n",
        "    txt = txt.replace('  ',' ')   \n",
        "    txt = txt.replace('  ',' ')           \n",
        "    txt = txt.replace('  ',' ')\n",
        "    txt = txt.replace('  ',' ')    \n",
        "    txt = txt.replace('  ',' ')   \n",
        "    txt = txt.replace('  ',' ')             \n",
        "    return txt.strip()\n",
        "    \n",
        "# 검사...\n",
        "pattens = [\"[34569][0-9]{3}[\\;.\\;-\\; ][0-9]{4}[\\;.\\;-\\; ][0-9]{4}[\\;.\\;-\\; ][0-9]{4}\",\n",
        "           \"[0-9]{2,3}[\\:\\s\\;.\\;,\\;-;)][0-9]{3,4}[\\:\\s\\;.\\;,\\;-][0-9]{4}\",\n",
        "           \"[0-9]{1}[0-9]{1}[\\W]?[0-1]{1}[0-9]{1}[\\W]?[0-3]{1}[\\W]?[0-9]{1}[\\W]?[1-4]{1}[\\W]?[0-9]{1}[\\W]?[0-9]{1}[\\W]?[0-9]{1}[\\W]?[0-9]{1}[\\W]?[0-9]{1}[\\W]?[0-9]{1}\",\n",
        "           \"[0-9]{2}[\\:\\s\\;.\\;,\\;-][0-9]{2}[\\:\\s\\;.\\;,\\;-][0-9]{6}|[0-9]{3}[\\:\\s\\;.\\;,\\;-]([0-9]{5,6}[\\:\\s\\;.\\;,\\;-][0-9]{3}|[0-9]{6}[\\:\\s\\;.\\;,\\;-][0-9]{5}|[0-9]{2,3}[\\:\\s\\;.\\;,\\;-][0-9]{6}|[0-9]{2}[\\:\\s\\;.\\;,\\;-][0-9]{7}|[0-9]{2}[\\:\\s\\;.\\;,\\;-][0-9]{4,6}[\\:\\s\\;.\\;,\\;-][0-9]|[0-9]{5}[\\:\\s\\;.\\;,\\;-][0-9]{3}[\\:\\s\\;.\\;,\\;-][0-9]{2}|[0-9]{2}[\\:\\s\\;.\\;,\\;-][0-9]{5}[\\:\\s\\;.\\;,\\;-][0-9]{3}|[0-9]{4}[\\:\\s\\;.\\;,\\;-][0-9]{4}[\\:\\s\\;.\\;,\\;-][0-9]{3}|[0-9]{6}[\\:\\s\\;.\\;,\\;-][0-9]{2}[\\:\\s\\;.\\;,\\;-][0-9]{3}|[0-9]{2}[\\:\\s\\;.\\;,\\;-][0-9]{2}[\\:\\s\\;.\\;,\\;-][0-9]{7})|[0-9]{4}[\\:\\s\\;.\\;,\\;-]([0-9]{3}[\\:\\s\\;.\\;,\\;-][0-9]{6}|[0-9]{2}[\\:\\s\\;.\\;,\\;-][0-9]{6}[\\:\\s\\;.\\;,\\;-][0-9])|[0-9]{5}[\\:\\s\\;.\\;,\\;-][0-9]{2}[\\:\\s\\;.\\;,\\;-][0-9]{6}|[0-9]{6}[\\:\\s\\;.\\;,\\;-][0-9]{2}[\\:\\s\\;.\\;,\\;-][0-9]{5,6}\"\n",
        "           ]\n",
        "\n",
        "filters = []\n",
        "for p in pattens:\n",
        "    filters.append(re.compile(p))\n",
        "\n",
        "sentences = []\n",
        "df = df.dropna(axis=0)\n",
        "cnt = df['contents'].count()\n",
        "#print('Total row count:',cnt)\n",
        "i=0\n",
        "for raw_text in df['contents']:\n",
        "    i=i+1\n",
        "    try:\n",
        "        if i%100 == 0:\n",
        "            percent = (\"{0:.2f}\").format(100 * (i / float(cnt)))\n",
        "            print(f'\\r {percent}% {i}/{str(cnt)}', end=\"\", flush=True)\n",
        "\n",
        "        docs = nltk.sent_tokenize(clean_text(raw_text))\n",
        "        for txt in docs:\n",
        "            if txt.find('▶') > -1 or txt.find('@') > -1 or txt.find('ⓒ') > -1: \n",
        "                pass\n",
        "            else:\n",
        "                txt = txt.strip()\n",
        "                if any(chr.isdigit() for chr in txt) :\n",
        "                    pass\n",
        "                else:\n",
        "                    sentences.append(txt)\n",
        "    except KeyboardInterrupt as ki:\n",
        "        raise ki        \n",
        "    except:\n",
        "        pass #print(\"Unexpected error:\", sys.exc_info()[0])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            " 3.91% 5500/140536"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mnormalize_resource_url\u001b[0;34m(resource_url)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_resource_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36msplit_resource_url\u001b[0;34m(resource_url)\u001b[0m\n\u001b[1;32m    140\u001b[0m     \"\"\"\n\u001b[0;32m--> 141\u001b[0;31m     \u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresource_url\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m':'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'nltk'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-b09b8dcf4c1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m                     \u001b[0msentences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mki\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mki\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mpass\u001b[0m \u001b[0;31m#print(\"Unexpected error:\", sys.exc_info()[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-b09b8dcf4c1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'\\r {percent}% {i}/{str(cnt)}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflush\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mdocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtxt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtxt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'▶'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtxt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'@'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtxt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ⓒ'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \"\"\"\n\u001b[0;32m---> 94\u001b[0;31m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tokenizers/punkt/{0}.pickle'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[1;32m    800\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0monly\u001b[0m \u001b[0mused\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m     \"\"\"\n\u001b[0;32m--> 802\u001b[0;31m     \u001b[0mresource_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize_resource_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    803\u001b[0m     \u001b[0mresource_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_py3_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mnormalize_resource_url\u001b[0;34m(resource_url)\u001b[0m\n\u001b[1;32m    184\u001b[0m     \"\"\"\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_resource_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;31m# the resource url has no protocol, use the nltk protocol by default\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pM9ZrtFcqEn0"
      },
      "source": [
        "import re\n",
        "import sys\n",
        "import io\n",
        "\n",
        "#텍스트 정제(전처리)\n",
        "def cleanText(readData):\n",
        "    #텍스트에 포함되어 있는 특수 문자 제거\n",
        "    text = re.sub('[-=+,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》◆◇●🎧○▲\\t―△━▷]', '', readData)\n",
        "    return text.lower()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piBg9aJkqHH-"
      },
      "source": [
        "c_sentences = []\n",
        "for sentence in sentences:\n",
        "    s = cleanText(sentence)\n",
        "    c = len(s.split())\n",
        "    if c >= 3 and c < 10 and s.find('재배포') < 0 and s.find('기자') < 0  and s.find('유투브') < 0 and s.find('www') < 0 and s.find('com') < 0 and s.find('접속하기') < 0 and s.find('http') < 0 and s.find('뉴스') < 0 and s.find('일보') < 0 :\n",
        "        if s.endswith(('다','요')):\n",
        "            c_sentences.append(s.strip())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ljb_u8pcqJxe"
      },
      "source": [
        "len(c_sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TscPqOMtqKdB"
      },
      "source": [
        "c_sentences[:100]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51dbd376qMyB"
      },
      "source": [
        "ko_sentences_dataset = c_sentences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nk93tR2Nuk8t"
      },
      "source": [
        "# 문법 discriminator의 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7Zf2oRMMXmH",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee6b87eb-d6a9-4a6f-c11c-e036542f71cd"
      },
      "source": [
        "use_pretrained_model = True\n",
        "\n",
        "if use_pretrained_model:\n",
        "    #g_discriminator = Grammar_Discriminator(input_dir = '/content/drive/MyDrive/Colab Notebooks/summary/model_save')\n",
        "    g_discriminator = Grammar_Discriminator(input_dir = '/content/drive/MyDrive/Colab Notebooks/summary/ko_grammar_model3')\n",
        "else:\n",
        "    sentences,labels = collect_training_dataset_for_grammar_discriminator(ko_sentences_dataset)\n",
        "    print(len(sentences))\n",
        "    g_discriminator = Grammar_Discriminator()\n",
        "    g_discriminator.set_dataset(sentences,labels)\n",
        "    g_discriminator.train(epochs=1)\n",
        "    g_discriminator.save_model(output_dir='/content/drive/MyDrive/Colab Notebooks/summary/ko_grammar_model3')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKRx8zA0uY-B"
      },
      "source": [
        "if False: ## 추가적인 fine-tuning\n",
        "    g_discriminator.train(epochs=10)\n",
        "    g_discriminator.save_model(output_dir='/content/drive/MyDrive/Colab Notebooks/summary/ko_grammar_model3')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-kyzdkT-G2m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b00284df-8bb1-4b19-cf5a-ff8b964a5fd5"
      },
      "source": [
        "txt = ['최근 날씨가 포근해지면서 산을 찾는 사람들도 늘고 있는데요','서비스를 음원 플랫폼 스포티파이가 국내 론칭한다']\n",
        "g_discriminator.discriminator.to(device)\n",
        "g_discriminator.transfer_learning(txt)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(4.3092, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor([[-4.0743,  4.2727],\n",
              "         [ 4.2365, -4.3814]], device='cuda:0', grad_fn=<AddmmBackward>))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d96kaCAHKuUc"
      },
      "source": [
        "##4.3 Static similarity discriminator class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZDpXe7XKxeg",
        "trusted": true
      },
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import BertTokenizer\n",
        "from scipy.signal import find_peaks\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.misc import electrocardiogram\n",
        "import scipy\n",
        "\n",
        "\n",
        "class Similarity_Discriminator:\n",
        "    '''\n",
        "    _instance = None\n",
        "    _embedder = None\n",
        "    def __new__(cls,pre_trained_model_name='stsb-roberta-large'):\n",
        "        if cls._instance is None:\n",
        "            print('Creating Similarity_Discriminator object')\n",
        "            cls._instance = super(Similarity_Discriminator, cls).__new__(cls)\n",
        "            # Put any initialization here.\n",
        "            cls._embedder = SentenceTransformer(pre_trained_model_name)\n",
        "        return cls._instance\n",
        "\n",
        "    '''\n",
        "\n",
        "    def __init__(self,pre_trained_model_name='xlm-r-large-en-ko-nli-ststb'):\n",
        "        print('Creating Similarity_Discriminator object')\n",
        "        # Put any initialization here.\n",
        "        self._embedder = SentenceTransformer(pre_trained_model_name)  \n",
        "        #self.cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
        "\n",
        "    def encode(self,texts):\n",
        "        return self._embedder.encode(texts,show_progress_bar=False)\n",
        "\n",
        "    def similarity(self, query_text, org_text_emb):\n",
        "        queries = nltk.sent_tokenize(query_text)\n",
        "        query_embeddings = self._embedder.encode(queries,show_progress_bar=False)\n",
        "        #query_embeddings = self._embedder.encode(queries,show_progress_bar=False)\n",
        "        #print(queries)\n",
        "        #print(org_text_emb)\n",
        "        \n",
        "        if len(query_embeddings) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        cos_scores = scipy.spatial.distance.cdist(query_embeddings, org_text_emb, \"cosine\")\n",
        "        similarity_score = 1.0 - np.mean(np.min(cos_scores,axis=0))\n",
        "        '''\n",
        "        for query, query_embedding in zip(queries, query_embeddings):\n",
        "            distances = scipy.spatial.distance.cdist([query_embedding], [org_text_emb], \"cosine\")[0]\n",
        "            results = zip(range(len(distances)), distances)\n",
        "            for idx, distance in results:\n",
        "                scores.append(1-distance)\n",
        "        '''\n",
        "        return similarity_score  \n",
        " "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sQZ36GuMumP"
      },
      "source": [
        "###4.3.1 한국어 문장 유사도 pre-trained model 적용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9Miao14Muww",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1eccb667-a7ef-459c-8bc5-78ba6e5e1fe5"
      },
      "source": [
        "s_discriminator = Similarity_Discriminator()\n",
        "#s_discriminator = Similarity_Discriminator()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating Similarity_Discriminator object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xnk9GsQ0K1t1"
      },
      "source": [
        "# 4.4 Document source class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhvXMrSO-CiD"
      },
      "source": [
        "## 두 문장을 합치는 rule 변환기... --> 이거... ML로 나중에 바꿔야..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_W1Wqq26MjQ"
      },
      "source": [
        "combine_matching_table = {}\n",
        "\n",
        "combine_matching_table['어요.'] = '고'\n",
        "combine_matching_table['지요.'] = '고'\n",
        "combine_matching_table['답니다.'] = '고'\n",
        "combine_matching_table['보거라.'] = '봐,'\n",
        "combine_matching_table['간단다.'] = '가니,'\n",
        "combine_matching_table['돼.'] = '되,'\n",
        "combine_matching_table['해.'] = '하며,'\n",
        "combine_matching_table['다.'] = '고'\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giRiIsfR6DV6"
      },
      "source": [
        "def combine_sentence(txt):\n",
        "    for c in combine_matching_table.keys():\n",
        "        if txt.endswith(c):\n",
        "            txt = txt.replace(c,combine_matching_table[c])\n",
        "    return txt"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwhMHwwefy-N"
      },
      "source": [
        "\n",
        "conjunction_table = ['그러던','그래서','그러나','그런데','그리고','그랬더니','그러니까','하지만','그래서']"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnBm6RCvNIWG"
      },
      "source": [
        "## 4.4.2 source class 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsJKbtc2K4xN",
        "trusted": true
      },
      "source": [
        "\n",
        "\n",
        "class Source:\n",
        "\n",
        "    def __init__(self,org_text):\n",
        "        self.org_text = org_text\n",
        "\n",
        "    def __crean_text(self, txt):\n",
        "        txt = txt.replace('\\n',' ')\n",
        "        txt = txt.replace('\\r',' ')    \n",
        "        txt = txt.replace('=','')\n",
        "        txt = txt.replace('\\\"','')   \n",
        "        txt = txt.replace('\\'','')\n",
        "        txt = txt.replace(',','')\n",
        "        txt = txt.replace('..','')\n",
        "        txt = txt.replace('...','')\n",
        "        txt = txt.replace(' .','.')\n",
        "        txt = txt.replace('.','. ')\n",
        "        txt = txt.replace('  ',' ')\n",
        "        txt = txt.replace('  ',' ')    \n",
        "        txt = txt.replace('  ',' ')   \n",
        "        txt = txt.replace('  ',' ')           \n",
        "        txt = txt.replace('  ',' ')\n",
        "        txt = txt.replace('  ',' ')    \n",
        "        txt = txt.replace('  ',' ')   \n",
        "        txt = txt.replace('  ',' ')           \n",
        "        return txt.strip()\n",
        "\n",
        "    def set_key_rate(self,s_discriminator):\n",
        "        #self.full_text = self.__crean_text(self.full_text.strip())\n",
        "        self.org_text = self.__crean_text(self.org_text.strip())\n",
        "        print('-'*50)\n",
        "        print(self.org_text)\n",
        "        print('-'*50)\n",
        "        self.org_sentences = np.array(nltk.sent_tokenize(self.org_text))\n",
        "        for i,sents in enumerate(self.org_sentences):\n",
        "            for cj in conjunction_table: \n",
        "                if sents.startswith(cj):\n",
        "                    self.org_sentences[i] = sents[len(cj):].strip()\n",
        "\n",
        "        #self.full_sentences = np.array(nltk.sent_tokenize(self.full_text))\n",
        "        \n",
        "        #self.org_term_set = (' ' + self.org_text + ' ').split(' ')\n",
        "        self.org_term_set = (' '.join(self.org_sentences)).strip().split(' ')\n",
        "        self.org_source_length = len(self.org_term_set)\n",
        "        self.term_table = {}\n",
        "        self.seps = []\n",
        "        #morp_table = {}\n",
        "\n",
        "        for index, word in zip(range(len(self.org_term_set)),self.org_term_set):\n",
        "            self.term_table[index] = word\n",
        "            if word.endswith(('.','?')):\n",
        "                self.seps.append(index)\n",
        "                if self.org_source_length - 1 == index:\n",
        "                    pass\n",
        "                else:\n",
        "                    self.term_table[index] = combine_sentence(word)\n",
        "\n",
        "        #print(self.term_table.values())\n",
        "        #print('------------------------------------------------------------------')\n",
        "\n",
        "        self.s_discriminator = s_discriminator\n",
        "        # 원문의 embedding...\n",
        "        self.org_text_emb = self.s_discriminator.encode(self.org_sentences)\n",
        "        #self.full_text_emb = self.s_discriminator.encode(self.full_sentences)\n",
        "        #top_n = int(len(self.term_table) * comp_rate)\n",
        "        #print('top_n',top_n)\n",
        "        #self.story_peaks = [i+1 for i in range(top_n)]\n",
        "\n",
        "    def get_org_sample(self, num):\n",
        "        return self.org_sentences[np.random.choice(len(self.org_sentences), num)]\n",
        "\n",
        "    def get_source_embedded_code(self):\n",
        "        return self.org_text_emb\n",
        "\n",
        "    def get_random_text(self,rate=0.7):\n",
        "        cnt = int(len(self.term_table) * rate)\n",
        "        a = list(self.term_table.keys())\n",
        "        b = np.random.choice(a, cnt)\n",
        "        c = [fruit for fruit in a if fruit not in b]\n",
        "        txt = []\n",
        "        for i in c:\n",
        "            txt.append(self.term_table[i])\n",
        "        return ' '.join(txt).strip(), hash(tuple(b))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UAeFBYMMxKY",
        "outputId": "fe457ce2-6555-4671-82f8-d4b2fa4f38e1"
      },
      "source": [
        "txt = \"\"\"\n",
        "황금마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼어요. \n",
        "그러니까 반드시 밤 열두시가 되기 전에 돌아와야 해요.\n",
        "\"\"\"\n",
        "s = Source(txt)\n",
        "s.set_key_rate(s_discriminator)\n",
        "s.get_random_text()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------------------\n",
            "황금마차는 호박으로 흰말은 생쥐로 마부는 도마뱀으로 변하게 돼어요. 그러니까 반드시 밤 열두시가 되기 전에 돌아와야 해요.\n",
            "--------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('생쥐로 마부는 변하게 반드시 되기 돌아와야 해요.', 1751478749107674013)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XY59mdNK8ub"
      },
      "source": [
        "# 4.5 Generator class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5CLF3WcK6lp",
        "trusted": true
      },
      "source": [
        "from functools import reduce\n",
        "\n",
        "\n",
        "# custom weights initialization called on netG and netD\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Linear') != -1:\n",
        "        m.weight.data.normal_(0.0, 0.06)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        m.weight.data.normal_(0.0, 0.05)\n",
        "        m.bias.data.fill_(0)\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    \"\"\"\n",
        "        Simple Generator w/ MLP\n",
        "    \"\"\"\n",
        "    '''\n",
        "    def __init__(self, input_size=1024):\n",
        "        super(Generator, self).__init__()\n",
        "        self.layer = nn.Sequential(\n",
        "            nn.Linear(input_size, input_size*2),\n",
        "            nn.BatchNorm1d(input_size*2),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(input_size*2, input_size*3),\n",
        "            nn.BatchNorm1d(input_size*3),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(input_size*3, input_size*3),\n",
        "            nn.BatchNorm1d(input_size*3),\n",
        "            nn.LeakyReLU(0.2),            \n",
        "            nn.Linear(input_size*3, input_size*2),\n",
        "            nn.BatchNorm1d(input_size*2),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(input_size*2, input_size),\n",
        "            #nn.BatchNorm1d(term_length*4),\n",
        "            nn.Tanh() # -1 ~ 1\n",
        "        )\n",
        "    '''\n",
        "    \n",
        "    def __init__(self, input_size=1024):\n",
        "        super(Generator, self).__init__()\n",
        "        l1 = nn.Linear(input_size, input_size*4)\n",
        "        l1.weight.data.normal_(0.0, 0.03)\n",
        "        bn = nn.BatchNorm1d(input_size*4)\n",
        "        bn.weight.data.normal_(0.0, 0.05)\n",
        "        bn.bias.data.fill_(0)        \n",
        "        l2 = nn.Linear(input_size*4, input_size)\n",
        "        l2.weight.data.normal_(0.01, 0.05)\n",
        "        self.layer = nn.Sequential(\n",
        "            l1,\n",
        "            bn,\n",
        "            nn.LeakyReLU(0.2),\n",
        "            l2,\n",
        "            #nn.BatchNorm1d(term_length*4),\n",
        "            nn.Tanh() # -1 ~ 1\n",
        "        )\n",
        "\n",
        "    def forward(self, x, bias):\n",
        "        #biased_noise = torch.randn(N,_NOISE_DIM)\n",
        "        # stroy peak에 해당하는 term에게 평균값에 해당하는 bias를 추가 한다.\n",
        "                 \n",
        "        y_ = self.layer(x)\n",
        "        y = torch.add(y_,bias)\n",
        "        #y = nn.Sigmoid()(y)\n",
        "\n",
        "        return y, y_\n"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Co1MnRG8a4Vq"
      },
      "source": [
        "# multi-discriminator에 대한 Adaptive discriminant factor 를 구하기 위한 학습\n",
        "\n",
        "ref : https://realpython.com/python-ai-neural-network/\n",
        "\n",
        "colab 수식입력 : \n",
        "\n",
        "https://wikidocs.net/1679\n",
        "\n",
        "https://en.wikipedia.org/wiki/Help:Displaying_a_formula#Formatting_using_TeX\n",
        "\n",
        "Original GAN의 목적함수\n",
        "$$ \\min_{G}\\max_{D} V(D,G) = E_{x\\sim p_{data}(x)}[logD(x)] + E_{z\\sim p_{z}(z)}[log(1-D(G(z)))] $$\n",
        "\n",
        "Multi-Discriminator GAN은 discriminator가 각 목적에 의하여 여러개 (N개) 있다.\n",
        "MDGAN의 목적함수\n",
        "\n",
        "$$ \\min_{G}\\max_{D_{i\\sim N}} V(D_{i\\sim N},G) = \\sum_{i=1}^N \\{E_{x\\sim p_{data}(x)}[logD_i(x)] + E_{z\\sim p_{z}(z)}[log(1-D_i(G(z)))]\\} $$\n",
        "\n",
        "여기서\n",
        "\n",
        "$$ L(D_i,G) =  E_{x\\sim p_{data}(x)}[logD_i(x)] + E_{z\\sim p_{z}(z)}[log(1-D_i(G(z)))] $$\n",
        "\n",
        "이라하고 단순화 하면\n",
        "\n",
        "$$ \\min_{G}\\max_{D_{i\\sim N}} V(D_{i\\sim N},G) = \\sum_{i=1}^N L(D_i,G) $$\n",
        "\n",
        "와 같이 된다.\n",
        "\n",
        "문제점은 GAN의 특성상, 특정 Discriminator가 학습에 있어 지배적으로 loss 함수에 영향을 미치게 되어 각각의 Discriminator가 골고루 학습에 참여하지 못하고 의도하지 않은 결과를 만들게 된다. 이러한 문제점을 극복하기 위해 다음의 두가지 제안을 한다.\n",
        "\n",
        "1) 목적함수에 각 Loss 에 대한 표준편차 (standard-deviation) 를 반영하여 각 Discriminator에 대한 Loss가 상호 유사한 수준을 유지하면 학습이 진행되도록 한다.\n",
        "\n",
        "$$ \\min_{G}\\max_{D_{i\\sim N}} V(D_{i\\sim N},G) = \\sum_{i=1}^N L(D_i,G) + STD_{i \\sim N}(L(D_i,G))$$\n",
        "\n",
        "2) 1)의 제안에 추가하여, 각 discriminator에 의한 loss를 제어하기 위해, adaptive discriminant factor (ADF) 를 적용하고, 학습의 진행 과정에서 이를 최적화 한다. \n",
        "\n",
        "$$ \\min_{G}\\max_{D_{i\\sim N}} V(D_{i\\sim N},G) = \\sum_{i=1}^N f_iL(D_i,G) + STD_{i \\sim N}(L(D_i,G))$$\n",
        "\n",
        "여서서 \n",
        "\n",
        "fi = adaptive discriminant factor for discriminator i \n",
        "\n",
        "중요한 것은, 학습과정에서 Li을 작게 (학습의 방향)하기 위해서는 fi는 역으로 커져야 한다. 그래야, 전체 Loss function에서 비중이 증대되어 더 적극적인 학습이 이루어 지게 된다. 따라서, fi의 최적화 방향은 기존의 gradient decent와 반대 방향이 되어야 한다.\n",
        "\n",
        "$$ f_i^{t+1} = f_i^t + \\alpha \\frac{\\partial V}{\\partial f_i}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLVVmQdxLBHZ"
      },
      "source": [
        "##4.6 Summarizer class (GAN training)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0RQOPpQgUTE"
      },
      "source": [
        "# 학습기..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nd8GTS7HKz1H",
        "trusted": true
      },
      "source": [
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "from scipy.special import expit\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "class SAM_Summarizer:\n",
        "\n",
        "    def __init__(self,g_discriminator,s_discriminator):\n",
        "        self.g_discriminator = g_discriminator\n",
        "        #self.c_discriminator = c_discriminator\n",
        "        self.s_discriminator = s_discriminator\n",
        "        self.m = nn.Sigmoid()\n",
        "\n",
        "    def ready(self,source):\n",
        "        self.source = source  \n",
        "        #self.source.analysis_frame_terms(self.s_discriminator)\n",
        "        self.generator = Generator(input_size=self.source.org_source_length)\n",
        "        #self.generator.apply(weights_init)\n",
        "        return self\n",
        "\n",
        "    def summarize(self,epochs=10,batch_size=1,learning_rate=2e-4, display = False):\n",
        "        history = self.__train(epochs,batch_size,learning_rate,display)\n",
        "        if display:\n",
        "            plt.figure(figsize=(12, 6))\n",
        "            plt.plot(history['gen_g_loss'],label='grammar loss')\n",
        "            plt.plot(history['gen_l_loss'],label='compression loss')\n",
        "            plt.plot(history['gen_s_loss'],label='similarity loss')\n",
        "\n",
        "            plt.plot(history['total loss'],label='total loss')\n",
        "            plt.plot(history['losses std'],label='standard deviation of losses')\n",
        "            \n",
        "            #if 'dis_loss' in history:\n",
        "            #    plt.plot(history['dis_loss'],label='discriminator grammar loss')\n",
        "            plt.legend()\n",
        "            plt.show()\n",
        "\n",
        "        return history\n",
        "\n",
        "    # text의 생성 for torch\n",
        "    def __text_gen2(self, p_txt, gen_length):\n",
        "        gtext = []\n",
        "        sorted_noise, i = torch.sort(p_txt, descending=True)\n",
        "        order, i = torch.sort(i[:gen_length], descending=False)\n",
        "        #print(len(order))\n",
        "        #print(gen_length)\n",
        "        assert len(order) == gen_length\n",
        "        order = order.cpu().detach().numpy()\n",
        "        for k in order:\n",
        "            gtext.append((self.source.term_table[k],k))\n",
        "        return gtext\n",
        "\n",
        "    def __text_gen3(self, p_txt):\n",
        "        gtext = []\n",
        "\n",
        "        for order,p in enumerate(p_txt):\n",
        "            if p > 0.0:\n",
        "                gtext.append(self.source.term_table[order])\n",
        "        return gtext\n",
        "\n",
        "    def __text_gen4(self, p_txt):\n",
        "        gtext = \"\"\n",
        "        indexs = []\n",
        "        for order,p in enumerate(p_txt):\n",
        "            if p > 0.0:\n",
        "                gtext += self.source.term_table[order] + ' '\n",
        "                indexs.append(order)\n",
        "        return gtext.strip(),indexs\n",
        "\n",
        "\n",
        "    def __discrete_gradient(self,weights,use_gpu=False, verbose=0):\n",
        "        fake_gen_out = torch.zeros(weights.shape).to(device)\n",
        "        #fake_com_out = torch.zeros(weights.shape).to(device)\n",
        "        fake_sim_out = torch.zeros(weights.shape).to(device)\n",
        "        fake_len_out = torch.zeros(weights.shape).to(device) # * 0.2\n",
        "\n",
        "        #real_text = self.source.get_org_sample(weights.shape[0])\n",
        "        fake_outs = []\n",
        "        #real_outs = []\n",
        "        apply_order = []\n",
        "        for i, noise in enumerate(weights):\n",
        "            #gtext = self.__text_gen2(noise,gen_length)\n",
        "            gtext,tk = self.__text_gen4(noise)\n",
        "            fake_outs.append(gtext)\n",
        "            apply_order.append((i,tk))\n",
        "  \n",
        "        D_z_loss, fake_gmr_out=self.g_discriminator.transfer_learning(fake_outs,train_for = False)\n",
        "\n",
        "        o_sim_out = []\n",
        "        o_len_out = []\n",
        "        for fake_text in fake_outs:\n",
        "            o_sim_out.append(self.s_discriminator.similarity(fake_text,self.source.org_text_emb))\n",
        "\n",
        "            l = ((1 - len(fake_text.split(' '))/self.source.org_source_length)-0.5) * 2\n",
        "\n",
        "            o_len_out.append(l)\n",
        "            #print(1 - len(fake_text.split(' '))/self.source.org_source_length)\n",
        "            #o_len_out.append(-len(fake_text.split(' '))/self.source.org_source_length)\n",
        "        \n",
        "        \n",
        "        for j, (i,tk) in enumerate(apply_order):\n",
        "\n",
        "            try:\n",
        "                '''\n",
        "                a = torch.tanh( fake_gmr_out[j,1])\n",
        "                if a > 0 :\n",
        "                    fake_gen_out[:] = -0.5\n",
        "                    fake_gen_out[i,tk] = a\n",
        "                else:\n",
        "                    fake_gen_out[:] = 0.5\n",
        "                    fake_gen_out[i,tk] = a\n",
        "                '''\n",
        "                fake_gen_out[i,tk] = torch.tanh( fake_gmr_out[j,1])\n",
        "                fake_sim_out[i,tk] = o_sim_out[j]\n",
        "                fake_len_out[:] = o_len_out[j]\n",
        "                fake_len_out[i,tk] = 0 #torch.tensor(fake_text_len/self.source.org_source_length).to(device)\n",
        "                #fake_len_out[:] = o_len_out[j] #torch.tensor(fake_text_len/self.source.org_source_length).to(device)\n",
        "                #print(o_len_out[j])\n",
        "            except Exception as ex:\n",
        "                print(j,i,tk)\n",
        "                print(fake_gmr_out)\n",
        "                raise ex\n",
        "\n",
        "        return fake_gen_out, fake_sim_out, fake_len_out #fake_com_out, fake_sim_out #, D_z_loss, D_x_loss\n",
        "\n",
        "\n",
        "    def __train(self, epochs=10,batch_size=10,learning_rate=2e-4,display = False):\n",
        "        # In the Deepmind paper they use RMSProp however then Adam optimizer\n",
        "        # improves training time\n",
        "        #generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "        # This method returns a helper function to compute cross entropy loss\n",
        "        #cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "        # Set the seed value all over the place to make this reproducible.\n",
        "        seed_val = int(random.random()*100)\n",
        "\n",
        "        random.seed(seed_val)\n",
        "        np.random.seed(seed_val)\n",
        "        torch.manual_seed(seed_val)\n",
        "        torch.cuda.manual_seed_all(seed_val)\n",
        "        \n",
        "        criterion = nn.BCELoss()\n",
        "        #D_opt = torch.optim.Adam(D.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "        G_opt = AdamW(self.generator.parameters(),\n",
        "                        lr = 2e-3, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                        eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                        )\n",
        "        # Create the learning rate scheduler.\n",
        "        scheduler = get_linear_schedule_with_warmup(G_opt, \n",
        "                                                    num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                                    num_training_steps = epochs)\n",
        "        \n",
        "        #gen_length = len(self.source.story_peaks) + int(len(self.source.story_peaks)*self.frame_expansion_ratio)\n",
        "        pb = ProgressBar(epochs,prefix='Train...')\n",
        "        gen_gmr_loss_history = []\n",
        "        gen_len_loss_history = []\n",
        "        gen_sim_loss_history = []\n",
        "        dis_loss_history = []    \n",
        "        total_loss_history = []\n",
        "        losses_std_history = []\n",
        "\n",
        "        #model 들은 cuda로 보낸다.\n",
        "        self.g_discriminator.discriminator.to(device)\n",
        "        self.g_discriminator.discriminator.eval() # 학습하지 않는다...\n",
        "        #self.c_discriminator.discriminator.to(device)\n",
        "        #self.c_discriminator.discriminator.eval() # 학습하지 않는다...\n",
        "\n",
        "        self.generator.to(device)       \n",
        "        self.generator.train()\n",
        "\n",
        "        #self.bias_w = init_bias\n",
        "        initial_bias = 0\n",
        "        G_s_loss = torch.tensor(0)\n",
        "        #G_c_loss = torch.tensor(0)\n",
        "        G_g_loss = torch.tensor(0)\n",
        "\n",
        "\n",
        "        dfs = torch.tensor([ 1.0, 1.0, 1.0], device=device, dtype=torch.float, requires_grad=True)\n",
        "\n",
        "        for i in range(epochs):\n",
        "   \n",
        "            if True:\n",
        "                noise = torch.randn(batch_size,self.source.org_source_length).to(device) \n",
        "                bias = torch.zeros_like(noise).to(device)\n",
        "                #if i < epochs/4:\n",
        "                #bias = torch.randn(batch_size,self.source.org_source_length).to(device) / 4 \n",
        "                #else:\n",
        "                \n",
        "                #bias = torch.randn(batch_size,self.source.org_source_length).to(device) \n",
        "                sw, sw0 = self.generator(noise,bias)\n",
        "                with torch.no_grad():                \n",
        "                    fake_gmr_out, fake_sim_out, fake_len_out = self.__discrete_gradient(sw)\n",
        "\n",
        "                #print(fake_len_out)\n",
        "\n",
        "                sw1 = sw * fake_sim_out\n",
        "                G_s_loss = -torch.mean(sw1) \n",
        "                sw2 = sw * fake_gmr_out\n",
        "                G_g_loss = -torch.mean(sw2) \n",
        "                sw3 = sw * fake_len_out\n",
        "                G_l_loss = -torch.mean(sw3)\n",
        "\n",
        "                dsc_loss = torch.stack([G_g_loss,G_s_loss,G_l_loss])\n",
        "\n",
        "                G_loss = torch.dot(dfs,dsc_loss) + torch.std(dsc_loss)\n",
        "                #G_loss = G_g_loss + G_s_loss\n",
        "\n",
        "                self.generator.zero_grad()\n",
        "                G_loss.backward()\n",
        "                #print('backward:')\n",
        "                G_opt.step()\n",
        "                scheduler.step()\n",
        "                '''\n",
        "                learning_rate = 0.1\n",
        "                with torch.no_grad():\n",
        "                    dfs += learning_rate * dfs.grad\n",
        "                    dfs.grad = None                    \n",
        "                    dfs[dfs < 0] = 0.1                \n",
        "                '''\n",
        "\n",
        "            gen_gmr_loss_history.append(G_g_loss.cpu().detach().numpy())\n",
        "            #gen_com_loss_history.append(G_c_loss.cpu().detach().numpy())\n",
        "            gen_sim_loss_history.append(G_s_loss.cpu().detach().numpy())\n",
        "            #dis_loss_history.append(D_loss.cpu().detach().numpy())\n",
        "            gen_len_loss_history.append(G_l_loss.cpu().detach().numpy())\n",
        "\n",
        "            #pb.printProgress(+1,f'{i+1}/{epochs} epochs, beta:{dfs} Generator / grammar loss:{G_g_loss}  similarity loss:{G_s_loss}') #,   Discriminator grammar_loss:{D_loss}        ')\n",
        "            #pb.printProgress(+1,'{}/{} epochs, beta:{}, grammar loss:{:.4f}  similarity loss:{:.4f} length loss:{:.4f}'.format(i+1,epochs,dfs,G_g_loss,G_s_loss,G_l_loss)) #,   Discriminator grammar_loss:{D_loss}        ')\n",
        "            pb.printProgress(+1,'{}/{} epochs,grammar loss:{:.4f}  similarity loss:{:.4f} length loss:{:.4f}'.format(i+1,epochs,G_g_loss,G_s_loss,G_l_loss)) #,   Discriminator grammar_loss:{D_loss}        ')\n",
        "            \n",
        "            total_loss_history.append(torch.sum(dsc_loss).item())\n",
        "            losses_std_history.append(torch.std(dsc_loss).item())\n",
        "\n",
        "            \n",
        "        self.generator.eval()\n",
        "        #self.g_discriminator.discriminator.eval()\n",
        "        if display:\n",
        "            plt.figure(figsize=(12, 6))\n",
        "            xs = np.arange(self.source.org_source_length)\n",
        "            plt.bar(xs+0.0,sw0[0].cpu().detach().numpy(),label='before activation weights',width=0.2)\n",
        "            plt.bar(xs+0.2,sw[0].cpu().detach().numpy(),label='after activation weights',width=0.2)\n",
        "            plt.bar(xs+0.4,bias[0].cpu().detach().numpy(),label='bias weights',width=0.2)         \n",
        "            plt.legend()        \n",
        "            plt.show()\n",
        "\n",
        "        return  {'gen_g_loss':gen_gmr_loss_history,'gen_s_loss':gen_sim_loss_history,'gen_l_loss':gen_len_loss_history,'total loss':total_loss_history,'losses std':losses_std_history} #,'dis_loss':dis_loss_history }\n",
        "\n",
        "    def get_summary(self, count):\n",
        "        #texts = []\n",
        "        self.generator.cpu()\n",
        "        self.generator.eval()\n",
        "        #gen_length = len(self.source.story_peaks) + int(len(self.source.story_peaks)*self.frame_expansion_ratio)\n",
        "        noise = torch.randn(count,self.source.org_source_length)\n",
        "        bias = torch.zeros_like(noise)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            sw,sw0 = self.generator(noise,bias)\n",
        "            #sw,sw0 = self.generator(noise)\n",
        "\n",
        "        max_score = 0\n",
        "        max_sim = 0\n",
        "        comp_rate = 0\n",
        "        best_text = \"\"\n",
        "\n",
        "        for p_txt in sw:\n",
        "            gtext = self.__text_gen3(p_txt)\n",
        "            text = ' '.join(gtext)\n",
        "            #print('>>',text)\n",
        "            sim_score = self.s_discriminator.similarity(text,self.source.org_text_emb)\n",
        "            if sim_score > max_sim:\n",
        "                best_text = text.strip()\n",
        "                loss, out=self.g_discriminator.transfer_learning([text],train_for = False)\n",
        "                max_score = out[0,1].item()\n",
        "                comp_rate = 1 - len(best_text.split(' '))/self.source.org_source_length\n",
        "                max_sim = sim_score\n",
        "            #texts.append([text.strip(),out,sim_score])\n",
        "        return best_text, max_score, max_sim, comp_rate\n",
        "\n",
        "    def get_samples(self,count):\n",
        "        self.generator.cpu()\n",
        "        self.generator.eval()\n",
        "        noise = torch.randn(count,self.source.org_source_length)\n",
        "        bias = torch.zeros_like(noise)\n",
        "        with torch.no_grad():\n",
        "            sw,sw0 = self.generator(noise,bias)\n",
        "        samples = []\n",
        "        max_g = 0\n",
        "        for p_txt in sw:\n",
        "            gtext = self.__text_gen3(p_txt)\n",
        "            text = ' '.join(gtext).strip()\n",
        "            #print(text)\n",
        "            loss, out=self.g_discriminator.transfer_learning([text],train_for = False)\n",
        "            sim_score = self.s_discriminator.similarity(text,self.source.org_text_emb)    \n",
        "            comp_rate = 1 - len(text.split(' '))/self.source.org_source_length\n",
        "            samples.append((text,out[0,1].item(),sim_score,comp_rate))\n",
        "            if max_g < out[0,1].item():\n",
        "                max_g = out[0,1].item()\n",
        "        return samples, max_g\n"
      ],
      "execution_count": 340,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCdfO9iuLH6D"
      },
      "source": [
        "#5. Experiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_eAwIPLb4aj"
      },
      "source": [
        "## 비교 대상 요약 알고리즘 준비"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhcoXuPMGy09"
      },
      "source": [
        "def sam_wgan4(text, epochs=50, batch_size=32,display=False, retry = True):\n",
        "    source = Source(text)\n",
        "    source.set_key_rate(s_discriminator)\n",
        "    summarizer = SAM_Summarizer(g_discriminator,s_discriminator)\n",
        "    summarizer.ready(source)\n",
        "    hist = summarizer.summarize(epochs,batch_size=2,learning_rate=5e-3,display=display)\n",
        "    samples, max_g = summarizer.get_samples(batch_size)\n",
        "    #print(samples)\n",
        "    if retry and max_g < 3.0:\n",
        "        print('max g',max_g)\n",
        "        return sam_wgan4(text, epochs+10, batch_size,display=display)\n",
        "    return samples"
      ],
      "execution_count": 348,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2FstAHWGQ8KR",
        "outputId": "edd3589e-2126-458d-853a-72ea346d3909"
      },
      "source": [
        "txt = \"\"\"\n",
        "옛날 어느 집에 귀여운 여자 아기가 태어났어요.\n",
        "아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요.\n",
        "\"\"\"\n",
        "sam_wgan4(txt,epochs=50,display= True,retry = False)"
      ],
      "execution_count": 350,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서 예쁘고 마음씨 고운 소녀가 되었어요.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   50/50 epochs,grammar loss:-0.1713  similarity loss:-0.1380 length loss:0.0037\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtEAAAFlCAYAAAAterT5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3zrV33/8ddXe8uSLG/72r6503fm3kwCBH5AICSsAknpSIA2jEL7a39taYGuMEqhixZaRtmzlFECpKyGQHbuyL3J3cu+13tJ1t46vz+OLNs3d+baln3v5/l4fB/fKelYlq23js4wlFIIIYQQQgghLpyp1gUQQgghhBBiuZEQLYQQQgghxEWSEC2EEEIIIcRFkhAthBBCCCHERZIQLYQQQgghxEWSEC2EEEIIIcRFstS6AM9FfX296uzsrHUxhBBCCCHEZWzXrl0TSqnwmc4tyxDd2dnJzp07a10MIYQQQghxGTMM4+TZzklzDiGEEEIIIS6ShGghhBBCCCEukoRoIYQQQgghLpKEaCGEEEIIIS6ShGghhBBCCCEukoRoIYQQQgghLpKEaCGEEEIIIS6ShGghhBBCCCEu0ryEaMMwXm4YxmHDMI4ZhvFnZzj/AsMwdhuGUTQM4/WnnbvLMIyjleWu+SiPEEIIIYQQC+mSQ7RhGGbgk8ArgPXArxuGsf60y04BdwNfP+22QeCvgOuAa4G/MgwjcKllEkIIIYQQYiHNR030tcAxpdQJpVQe+Cbw6tkXKKX6lFJPA+XTbnsL8DOlVEQpFQV+Brx8HsokhBBCCCHEgpmPEN0K9M/aH6gcW+jbCiGEEEJcMWLjaaZG0yilal0UAVhqXYALZRjGPcA9AB0dHTUujRBCCCHE4shnizx5Xy9P/6IfpcATsNO2Lkj72gCtawK4/fZaF/GKNB8hehBon7XfVjl2obe9+bTbPnimC5VSnwE+A7B9+3b5CCaEEEKIy17fMxP88huHSUZzbHh+K6E2DwOHIvTuGefQo8MABFvctK8N0rY2QMvqOmyOZVNHuqzNx7O8A1hlGEYXOhTfCbzpAm/7E+DDszoTvgz483kokxBCCCHEspWK5Xj4W0c5tmuMYIub1/3xBppX+gHY8IJWymXFRH+CgUNR+g9G2PfQIHsf6MdkMmjs8tG6NkD72iCNXT5MZuOCH1cpyGeKZJMFsqkCmWSBbDJfWReqx7PJQvVYqVjGajdjc1r02mHG6pjZtjksWE9be4MO/GEndrcFw7jw8i0lxny0qzEM41bgnwEz8Hml1IcMw7gX2KmUus8wjGuA7wEBIAuMKKV6Krd9C/Deyl19SCn1hfM93vbt29XOnTsvudxCCCGEEEuJKisOPDLEY987TjFfZvutnWx9WQdmy7m7sRULJUaOx+g/FGXgUJTxk3Hmu+m0yWLgdFtxeGw4PFacHisOtxWz1UQhWySfK1HIlshni+SzJQrZIoVciXy2RKlw+tgSms1pwVevA7U/7MRX78QXduKvd+IJOjCZahuwDcPYpZTafsZzy7FxuoRoIYQQQtRSLl0gPpElPpkhPpElMZnFYjXRuiZA81X+59SkIjKc4sGvHWL4WIzW1XXc/BtrqWt0PafyZVMFho5MMTGYvOjb2p0WHB7rnKDs8Fix2s3Puda4VCrPBOxMUT93Exni4xliExli4xkSk1nKpZlcajIZeEM6YLesrmPbyzuf02NfinOFaGk0I4QQQggxS7lUplgok4zkqiE5PpkhMb2ezJJLF+fcxuYwUyyUeepnp2aaVKwJ0LYmQGO3D4vVfNbHKxXK7PpxH7t+chKrzcyLf3sta29ovqRmDg63le6tYbq3hp/zfcwns9mE2W3C4bYCUN/mfdY15bIiGc0SH9fPeWxch+v4RIbIcGqxi3xeEqKFEEIIcVkoFcqkYjlSsTypqRypWI50LEdqKk82VaBYKFMulilVF0WpMHtfH1PlZ39Lb7Ga8IYc+OqdNHX78YWc+Or1vjfkwO6yUCyUGTkWY+BwlIHDUXb9Tx877+/DbDXRvNJfDdUNK7yYzLp5xtDRKA9+7TDRkTSrrmnkpjeswuWzLfZTtySYTIZ+XkPOWhflgkiIFkIIIcSSVy6VSUZzxMb01//JaJZULE+6Epang/LpTGYDt9+Ow2PFbDFhthpYHZVtiwmz1TSzbTHmHPME7NWQ7PLZzlszbLWZaV8fpH19EIBcpsjQ0SkGD+lQ/cT3T/AEYHWYaVmlR9E4umMUb8jB7e/eTEdPaCGeOrFAJEQLIYQQYkkoFcskJrNMjaWrX+XHxvTX+fGJzJz2sobJwOWz4fbb8NU7aV5Zh7vOhstvx11nx+23466z4XBZMWrUOc3utNC1qZ6uTfUAZBJ5Bo9MMXA4yuDhKPHxDFtf2sE1t3VhtZ+9uYdYmiRECyGEEGJelMuKbLJAPqNHZSjkKqM05M68FCvrbKpAbDxDMpKdM6KE1W7G3+Ak1Oqme0t4ZgSHsBN3nb3mIzdcLKfXxlXbGrhqWwOgn6/l9jOIGRKihRBCCHFWxXyJdDxPJlEgnciTSeQr+5Vj1W09ljAXMOiXYTL0WMJ2c3V84aZuP/7rmvA3OPGHXfjDTpxe67IdQ/hCSIBe3iRECyGEEALQ00tP9CcYO6mX8VMJpkbTZ7zW6jDj8tpwem34w06aV/pxVvYdbks1IFvtlW2HGatNHzNZjMs6HIsrg4RoIYQQYplQSpGO55kcTDI5mCI6ksJi02HW5bPh9Om1y2fD5bVhtp59go5CrsR4f4LxkwnGTsUZP5kgOpqu1iR7AnbCHV5WX9uIu86uA7PPhtNrxeW1YbFJG15xZZMQLYQQQixBhXyJ6HCKiYEkkcEUE4NJJgeTZJMzI1A4vVZKhTL5bOmM92FzWnS49lqrwbqQKzF2KkF0OFVtf+z22wiv8LHqmkbCHV4aVviu2GHWhLhQEqKFEEKIRVAulZ/duS5b0lMl54oUsqU5tcyxsXQ15FpsJoLNbro21xNq9VQWN06PDrrFfEm3V45X2i3Hdbvl2duRoRQD8Sgmi4mGFV66t4ZpWOGjocOLu85ew2dGiOVJQrQQQghxCZRSpGN5YuNppsbmDsuWTRaqgblULJ//zgzw1zsJtXpYtb2BUJuHUIsHX9h5zk5oFpt5WU1SIcTlQEK0EEIIcR5KqcpEH+lqSNbjGOv9Yn4mIJtMBt56B/6wk2CLe1YHOzM2h2XOfrXDXWXb7rZilbbGQiwLEqKFEEKIM8hligwcinDqQIRT+ydJRnLVcyaLgb/eib/BRdvaoB6/uDI0mzdor07pLIS4fEmIFkIIIQBVVoz3Jzi1P8KpA5OMnIijygqrw0zbmgBbX7qCYLMLf4NrWU70IYSYXxKihRBCLEtKKcplRalQplxSmC0mLFbTRU3xnI7n6T8wyakDEfoPRsgk9MgX4Q4vW1/WwYqeII3dfsxSsyyEOI2EaCGEEEuCUorR3jjHdo8RGUxSKiqKhTKlYpnSWdbqDLPjmS0mLDYdqM02M1abCbN1Zj19LjqSZvxUAtBDxbWvC9LRE6J9XVCGdxNCnJeEaCGEEDWjlGK0L86xXWMc3z1GMpLDZDGob/VgtZtxuCyYrSbMFtOz1harCbPFwGwxYzIblIplioUyxXxpZp3X61JBn8sm89Vz7jo71726m471QcLt3ouqwRZCCAnRQgghFtV0cD6+a4xj08HZbNCxPsj1r+qmc3MYu1PenoQQS5v8lxJCCLHglFKM9SU4tnuM47vGSESymMwG7euDXPeqbro21WN3WWtdTCGEuGASooUQQsyLUrFMJlEgk9Az5E2vk9Ecfc9MkJjMYjLp4Hzt7V10bqrH4ZbgLIRYniRECyGEeBalFPlsiVyqQLay5FLF6nZmekrpRKEamHPp4hnvy2I10bI6wDWv7KJrswRnIcTlQUK0EEJcIYqFEqmpPKmpHKmpHMmpHKlYjmyiQDZdqARmHZRz6SKqfIahLyrsLgtOrw2Xz0ao1Y3LG8Dps1WP6bUVp9eG1W7GMKTTnhDi8iIhWgghLgPlUpn4ZJbYeIZUtBKQZ4flqRzZZOFZt7PYTDi9NhxuKw63BU/QgcNlxe624HBbsbv0cbvbisNlxeGxYndZMFtk3GQhxJVNQrQQQiwTSikyiQJTo+nqEh1NExtLExvPUC7NrTl2eq246+x4A3aauv146my46+zVxVNnx+a0SC2xEEI8BxKihRCixsqlsm5/nC6SzxTJZfQ6nymSiGSZGkszNZJmaixDPjPT7thkMahrcBFoctO1OUxdoxN/gwtPwI7bb5faYiGEWEASooUQYoFlUwVO7ptk4GCEdKIwJyjnMkWKudI5b+8J2KlrdLH62kbqGl3UNboINLrwBB2YZIIQIYSoCQnRQgixABKRLL17J+jdO87QkSnKZYXTa8UTcGB3WXD5XdidFmxOC3aXBZtj1rbTUj3n8umOeUIIIZYWCdFCCDEPlFJEhlKc2DNO794Jxk8lAAg0udjy0g66ttTTuMInU0sLIcRlYl5CtGEYLwc+DpiB/1BKfeS083bgy8A2YBK4QynVZxhGJ3AQOFy59HGl1Nvno0xCCLHQymXFyPEpTuzRNc7xiSwY0NTl44bXrqRrcz2BJnetiymEEGIBXHKINgzDDHwSeCkwAOwwDOM+pdSBWZe9FYgqpa4yDONO4O+AOyrnjiultlxqOYQQYqEVciXGT8UZ7U0w2hdn8EiUbLKAyWLQvjbI1besoHNTPW6/vdZFFUIIscDmoyb6WuCYUuoEgGEY3wReDcwO0a8G/rqy/W3gE4aMqSSEWMLKpTKR4TSjvTHG+uKM9iWIDCVRlVHkvCEHHT1BujaF6egJYnNI6zghhLiSzMd//Vagf9b+AHDd2a5RShUNw4gBocq5LsMwngLiwPuVUg/NQ5mEEFewQq5EJpGvBN6ZsZOnAzBnmIivXFJEhlOM9sYY7YszfipBMV8GwO620Njpo2tLJ42dPhpW+HD5bAv+cwghhFi6al11Mgx0KKUmDcPYBvy3YRg9Sqn46RcahnEPcA9AR0fHIhdTCLFUTE84koxmSUxmSUQqS2U7GcmRTT17Zr4LZbaYCHd4WH9Tiw7MnT78YadMSCKEEGKO+QjRg0D7rP22yrEzXTNgGIYF8AOTSikF5ACUUrsMwzgOrAZ2nv4gSqnPAJ8B2L59+xnqkYQQl5tcusDgkSkGD0eJjqRIRHIkI1mKhfKc66x2M96QA0/AQWOXH2/Qjstnq46EMSf+niEMG4a+qK7BRajVI5OUCCGEOK/5CNE7gFWGYXShw/KdwJtOu+Y+4C7gMeD1wANKKWUYRhiIKKVKhmF0A6uAE/NQJiHEMlQslBg+HmPgUJSBQ1HGT8ZRCiw2E8EWD6FWD50bQ9XA7A058Ab1uMtSUyyEEGIxXXKIrrRxfhfwE/QQd59XSu03DONeYKdS6j7gc8BXDMM4BkTQQRvgBcC9hmEUgDLwdqVU5FLLJIRYHsplxfjJBP2HIgwcijJyPEapWMZkMmjs8rHt1k7a1wZo7PJL7bAQQoglxVBq+bWM2L59u9q581ktPoQQS1w2VSAylGK8P8Hg4SiDR6bIZ4oAhFo9tK0L0LYmQMuqOhntQgghRM0ZhrFLKbX9TOfkXUoIMe9ymSKRoRSRoSSR4ZTeHk6RjuWr1/jqHVy1rYG2tQFaVwdktAshhBDLioRoIcQ5qbKiVCxTLJQp5suUiiWKeb1fKpQpFkokozkiwymilbCcjOaqt7fYTASb3XSsCxJocRNq8RBsceMNOmr4UwkhhBCXRkK0EFe4cqnM5GCKkRMxRk7EGD+VIJcu6uCcL1Mqls9/J4DZaiLQ5KJldR3BZrfuCFgJy9OjZAghhBCXCwnRQlxh0vE8o70xRk7EGTkRY+xkvDqpiMtvo7HTh9Nrw2I1YbaaZq3NWGwz27PPubw2fGEnJgnLQgghrhASooW4jBULJaLDaV3LXAnO8fEMACaTQX27h/XPa6Gp209jt0/XGstQcUIIIcR5SYgWYhkrlcokI1nik1kSE1nikxkSk1niE1kSkxlSszryuXw2mrr99Dxfh+aGDi8Wm7mGpRdCCCGWLwnRQixhhXyJZGUq60R01vTWk1niExlSUzlmj1JpmAw8ATu+kIP2nhC+kIO6BheNXT68IallFkIIIeaLhGghaqRcVqRjeZKVcDwdlJORmf1sqjD3RgZ46ux4Qw5aVwfw1jvwhRz4Qs7KLH52TGaZlEQIIYRYaBKihVgASimyyQLJaE4H4qgOxcloVh+LZklP5SmX5052ZHWY8Qb1VNaNXX68Qbue3rqydgfsmCUkCyGEEDUnIVqI50iVFYlIVo+PPJImOpwiPpnRYXkqR6kwd2g4k8XAU6fDcMuqOh2OA3Y8ldDsCTqwO+VPUgghhFgO5B1biPMol8rExjNEh9NERlJEp0PzSKo6NByA02vFH3YS7vDStbm+UoPswFOpRXZ6rDJeshBCCHGZkBAtrnhKKfKZou60F8npjnsRPbpFdCTN1Giacmmm2YUnYCfQ7KbnplYCzS4CzW6CTW4cHmsNfwohhBBCLCYJ0eKypJSqTEldppjX01RnkgUSEd3cIjGZ1aNdVAJzIVuac3uTxcAbdBBocrNiQ4hgs5tAs5tAkwubQ/5shBBCiCudpAGx5CmlR7GYGk0zNZYmNpYhNpEhnylSzJcpFnRIng7LxUKJYqEM6uz3aXdZ8IYc+OqdtK4JVDvzTTe/cHlt0vRCCCGEEGclIVosCUopMokCsbE0U2OZyrqyPZ6hmJupKTZbTPjqHdhdViw2Ew6PXltsZizWytpmqm5bbXqK6ung7A06pDZZCCGEEJdEkoRYVKVSmdhYhqmRNNHR6Q56ut1xPlOsXmcyGXjr9UQhbasD+Buc1DW48Dc68QQcmKSWWAghxJWmkAGzDUwy2+xSICFaLIhcujArIM+E5fh4Zs7YyO46O4EmF6uvbdQhuRKWvfUOGQ9ZCCGEmDZ5HL5wK9jccMuHYPXLQWahrSkJ0WLeJKM5Dj46xKHHR4iPZ6rHTWYDf4OLYIublVvD1Q56dQ0ubDIushBCCHFu0ZPwpduhXNC10N+4E1a+GG75W2hYW+vSXbEkwYhLUi6VOblvkgOPDHPymQmUgra1AXqe30KgyU2g0YWv3iFTUQshhBDPRXxIB+h8Eu76ITSsgx3/AQ/+Lfz7jXDN78DNfwauYK1LesWREH0ZK+RLZJMFsqnKkiyQSxWwOS2EO7z4G1zPuW1xfCLDwUeHOfjIEKlYHpfPxtZbVrD+ec34w655/kmEEEKIK1ByDL70KkhH4Le/D82b9PHr3wEb3wi/+BDs+Cw88y140ftg25vBLNFusRhKnWMcsCVq+/btaufOnbUuxoJQSumxjXMlCtNLvqT3888+XsiVyKVmB+Vidfv0aadPZ7GZqG/zEu7wUt/uIdzhJdjsxmw5c61xqVimd+8EBx4Zov9gBIAVPSHW39TCio0hacMshBBCzJd0BL54G0R74Te/AytuPPN1o/vhx38Gvb+C8Dp4+Yd1Uw8xLwzD2KWU2n7GcxKiF1epVCYZyRKf0BN9xCcyxGetM4n8Occ3Pp3JZGB3W3C4rTg8VuwuvXa4rThmHdf7ejuTKDB+KsFEf4Lx/gQT/UkKlSHkTBaDUItHh+p2HbCtdjOHHx/h0OPDZBIFPAE7625sZt3zWvAGHQv0TAkhrmhKSacpceXKxnQN9NhBeNN/wsoXnft6peDQj+Cn74NoH6y5FV72QQitXPiypiahlANv82X5Nysheh7s+9Ug+345gNl6hrGIZ+3PPm+2GKTjeR2QJ7LEJzOkojlmP+WGycAbtOMNOfHVO3D77VjtZj2+sd2E1W7BYjNhtZtnHa8sNjMmi4FxiS9aVVbExjOM9ycYP5WoBOwk2VRhTjk7N+pa546ekAwxJ8TFUgomjgJK9663usDmAYut1iVbOpJjsPebsOdr+rly+MFZB466M6+dgZltVz2E14Jpkb4RK5chF4fsFGSmZtaZ6Mx2Lg6eJv0VfPPm+QkZpSKMH4LBXTC0W4es9mvh6rugftX8/Gzi4pWK+vdu84D1EiuXckn46utgcDfc+TVYfcuF37aQhcf/DR76ByjmdLOPF/wJOHyXVqbp+x4/BGMHdO339Do5qs97m6HtGv16bLsGmrdc+nOxBEiIngfHdo1x5MkRSoUyhXxp7pTShXJ1prxy8bTn0wC3344v5MBb78BXCcu+kBNvvQNPnX1JdrpTSpGM5hg/lSAdz9O1uR63317rYgmxvCgFQ0/B/u/B/v+G2KlnX2OyVEK1G2yuWduVfbtPh0VnYCY4nr7YPMu3BqhUhKM/hae+Ckd/AuUitF2rv7rOJZ4dUqfXqvTs+/K2QM9roOe10Lp9fgJ1qQinHoMjP4aTj0ImMhOQ1TmazJmsOrikI1S/XnTV6zA9HaqbNkGg6+zlVAqmTurAPLhbL8N7oJDW5x1+qF+tX2PlIqx4ng7T618FVuel/+ygg9jYAV0Wk2XWYj5t/7RjZuvijGWslK61TU/q5zo9qX9H6clZS2W/mNV/K3ZvZT297Z21PX3cp5/DXGLm9tX7jjz7vrNTujyOOrju7XDd255bR79CBr72Bjj5CLzhi7D+1c/teUmMwP9+APZ8Fcx28DTq8rjrwRWqLEH9mqzuVxZnHcT6YfTATFAe3Q+R4zOvebMdwmugcQM0rtdjVw/sgP4n9WsW9N9A8yb999x+jQ7W/vZl979KQvQiKpdVJWDroO302DBbl15IFkIsEKVgdB/s+64Oz9FeHSpWvhjW3qbDcT6lg1A+Cfl0ZT+l16fvT7+Jl3Jnf0yTZW6trNUJFqdeTy/VfcezzznqwNMA7gb9xroY4Wf8iH6D3/tNXZPlboDNd8LW39Rvzuei1LMD9lS//jr72M+glAdf26xAve3i3rizcTj2czj8PzrgZ6d0SGi/DrxNZ68Zd9TNfNixuvRj5hI6gAzvheGn9Xr8oA69oMNa00YdqJs369sO7ZmpaU5P6uvMdn2+dVtluRqC3foxEqOw9+uw+8sQOaHD9aY7Ydtd0Nhzcb+XchlGn4ETD+rl5GNQzJzvVmdmmMFi18+d2TazffrabNOhu1zSH47KJR3WZu+Xi5XtcmVd1L+nTGTmuTydyTo3MFocM39T+YSu8c0lzv23dTqLY1YAnQ6dlW1nAPoegkM/1B+Et78ZbngX+Jov7L6LOfjmm+DY/8JrPw2b77jwcp3N4G7Y9x1ITVRC/8RM+M8nL+w+Ap3Q0KNfS43r9Xaw++wdGJNjM4F6YIcuw/RryNNUCdTX6g99zZuXfEdICdHzIZfUf+QWqY0VYtEUMpUAsqfyN1h5s63WdFn1urptqczmVakFrF+zeP+gxw7OBOfJozpAdL9Qh7i1t1368FOFjG4qkInONBuYXrJTc88VszqkF7L6dsWMXhcyZ67Bnc0w6dopTwO4w6etG8ATngnbrtDF1XjmEvr5eeqr0P+Efo5Wv1wH51Uv1b/HS5WN6fC7/3s6jJQL4O+YCdQtW88cqKf6dW3z4fuh9yF9O2dQl2/NK3SbVLv30ssHldrdgzpQj1SC9ci+WWHV0MOYtV6tA3PL1TrAnO/5KZfh5MOw60tw8D79YaJ1m66d3vBruob1TKJ9M6G591czwT28Frpvho4b9O+5XJy1lKBUmLtf3S7oGvxSTv+spbxeivm5x4o5fR+lytpk1q+JOWvTTA336ccc/pkAO2epHLN7L+zDU6mgX5u5hA6W0+G6kNL3MTso2y5g9KnRA/DwP8G+b+tyb/kNeN4fQLDr3GX4r7t1AL/947Dt7vM/zqUqZPWHkGrAroTrTER/WGzcoF8DZ3vdXKhSQf8fnx2so736nM0LK26AzudD5006VC+x2RglRM+Hh/9ZDyXTtAnatuuvCtu2609oy+yrCSHOKpfQY5L6WuYvMFyofBpGntGBeXivro0bP3T+0HcuVpcOTW3b9VeJbdeCt3H+yjxxVIe1fd/VtYuGSdeubHgdrHuV/up0qSkVZgXs9Ew4T41BclzXCk9vz14Xs2e+P6urEjCCZ66dm64BPHy/fq4Kad0EYetvwaY75vf3cbrMlH7cfd+FE7/QAa9uhQ7TPa8FlA7ch+/Xrz2A0Codmtfcqtt2LtYberkEk8d0iGnacOl/f+mIruXf/SX9d2Tz6CC97S7dhKT3lzPBOdqnb+Nt1qG5+2boeuGF16CKM4v0wiMf1238yyX9/N/0h7o2d7ZyCb57jw7dL/87uP7ttSnvYkqOQd/Duua+72GYOKKP2326Kdd0qG7aWPNQLSF6HuT7Hiey87s0Jfbp9mfTbdJcoUqgvgbaKl+zOfyLWjYhLphSOjBFTuh/8JETukYgckIvqfGZawOduiaiaWOl3VuPDiDz0c40l5wJzEOV0DxxeKa9nTusO6W0bKm0Id2s/9ama75KBV2TNb1druyXpmvBCrp2ZXCXrvUY3quPg66VnA7V7dfqn+9M3zBNP1dTpyA2oNsITvXrds2xAb2dngAMXVM3HZwXMhTWynTzidS4fvNLjc9qdxqZqb2aXZs13UZ0ms2rn6Otv6Wf/8WufEhHdHOP/d/TwXH6w5lhgvbrK8H5FZdf5zyldO3f7i/pDxOzm2bYfTqsdN+sl/pVUim0EOLD8NgnYOcXdO322tvgpj/SmaFchvverZs2veSvdci+EiVG5obqyWP6uMOvKyY6b9If7Jo2LHrRFjxEG4bxcuDjgBn4D6XUR047bwe+DGwDJoE7lFJ9lXN/DrwVKAG/r5T6yfkerxYh+kM/OsCXHjvJ13/nOra3+3Rj+8GdMFBZJg5XrjR0LUvbdh2og9360723Sb8Y5B/Uc1PMz7TnSo3rGiZfq57utJYfWpTSb86JIf2PspQ/SztUp66Ns7rmv3mBUvpDXTaml8zUzHZ2Stcszg7M2djc2/tadc1UsEu/Xn2tOjiOPqO/Yo6coNoxyuattIvr0f/MGjfqWhWrS3e0Sk3MhKzZS3JMn0tVajVnl8HTVAnLlcDcsmX+h0oqZPXX5gM7KstOHYpBN/9o3qy/Mi/l9fHpkFxIzb0fi/5J8xwAACAASURBVBPq2nXnmLp2PSbr+lfpmnsx1/RoBelJ/ftu7NHtwZeC1CQc+R/9VftVLwV3qNYlWhzZmG4fm47oQNKydcm3R72spCPwxKfhiU/pv43um3XTqGe+BS98D7zovbUu4dIRH54Vqh/S70MrboI3/2jRi7KgIdowDDNwBHgpMADsAH5dKXVg1jXvBDYppd5uGMadwGuVUncYhrEe+AZwLdAC/BxYrdS5v7+tRYiOpvK87t8fZSqd53vvfB6d9ae9GWSmdCeQgUrN1+DOmXZl06wuHaa9LZV1k37z9TZVgnazroGzua+MsF3I6KYD8aHKV8jjlbZZE5XAVQld6YlnB7/ZvC06TDes1+23GtbpjkmX+nVoqaDLNV3GxDDEB/Ufd3xoVnC+iE4poN+4rS4dqi0O/Sb2rF7uZ+sBb54JzLPDcrlw9sczzFDXMROSA5V1sBsCK87fpjWf0u03R56p9NLep9e5+PQD6CB6tufBGZzVpra+0q62QdcAN2/Wr/9aiA/PDdVDT+nnohqSO8DfNhOY/R26acKV8LcphFg4uYSulX7sE/o95sZ3w0s/IP9bziU2qD94XGxH2Xmw0CH6BuCvlVK3VPb/HEAp9bezrvlJ5ZrHDMOwACNAGPiz2dfOvu5cj1mr0Tn6JlK87t8fxe+08t133EjAfY7xXZWa+Ro4MVxZRirha2Tm2JnaGRpmHQAdPrD7K2vf2ddWZ6WXs70SzE5f2yphza6/ildKd+jIpyqjA6TOvV3MVsa0PcPwWzZP5Zx7ZrE4IRc7LWyetiSG9FflZ/rZXaFK2KrXHZzc4dP263Xtc2xAh7uxg7o96viRuV9V+ttnQnXDOn2/2bguWzauw2cuXjk2e105n088u3wWh/6w42upfACavd2in+vpDlxzOnelK/uzOngVM/rc6Z115uyfvpQqoyn49UgA1XF0/XOPVUcLqGwvRO331CkdqEf26Rpb93QHtHDldxbWz/l8dBZbDDK5hxBiMU1/Q9Z2jfzvWcLOFaLn4521FeiftT8AXHe2a5RSRcMwYkCocvzx027beqYHMQzjHuAegI6Ojnko9sXrrHfz2d/exq9/9gnu+cpOvvLW63BYz9Lg3TB0LV9gxdnvUCn9ySo+K2Snxs8c7GIDMBab2T/X+KTnYrbNDBt0Mbcp5Z/b41UZOlT5WvRzsuKGSgBt1Z1XpmvhHXUX3ua2sWfuIPTlkh6fshqsD8HYId3b/Ey1pGbbaR9K/OBZOfPBxeGf+eZgOig7A/LPDua+vte+stalmR/yexVCLCarQ/fLEMvWsmkMpZT6DPAZ0DXRtSrHthVB/vGNm3nX15/iT779NB+/Y8tzn73PMGYmSzi9t+65KFUZ6zKuvxYqZnXN8rPWs7anhxUqZGYmd7B5ZtUge+bWJk/vW1061JZLMzXThfSs7dlj2yZnztl9leBZCcmepoWfmc1knmmmMDvYlYqVtsDxuYH5MphJSQghhBC1MR8hehBon7XfVjl2pmsGKs05/OgOhhdy2yWjGI1iCQS4bVMLpyJpPvrjw3QEnfzJLWsXtyCGUZlR6RLHbrwYJnOldnYepg5dbGbL5dfjXgghhBA1NR9T6e0AVhmG0WUYhg24E7jvtGvuA+6qbL8eeEDpxtj3AXcahmE3DKMLWAU8OQ9lmncTn/oUJ25/FcWobsf7jheu5M5r2vnkL47zrR3957m1EEIIIYS4nFxyiFZKFYF3AT8BDgLfUkrtNwzjXsMwXlW57HNAyDCMY8AfMdOhcD/wLeAA8GPg9843MketeF70IkqxGCN/9dcopTAMgw+8ZgPPX1XPe7/3DA8fnah1EYUQQgghxCKRyVYuwsRnP8v4P/wjLR/7KP7bbwcgkS3whk89xmA0w7ffcSNrmhZ5ljchhBBCCLEgzjU6x3w057hihN7yFpxbtzLygQ9SGBkBwOuw8vm7r8FpM/OWL+5gLH6WqXGFEEIIIcRlQ0L0RTDMZlo+8reoQoHh976P6Vr8ljonn7/7GqLpPG/90k7S+WKNSyqEEEIIIRaShOiLZFuxgsb3/CmpRx8l+o1vVI9vaPXzr7++lf1DMX7/G3solZdfMxkhhBBCCHFhJERfoNltx+vuuAP3TTcx9tGPke/rqx7/P+sa+avbe/j5wVE++KMDZ7iX5WcskeW/dvbLhwIhhBBCiFmWzWQrtfa5fZ/j8/s+T9ARJGAP0Harkzt3l9j17rs5+qG7CbhDBB1BrlkT4M7rvXzh0aOsCLq4+3ldtS76c9Y7keK3PvcEA9EMJyfT/PEta2pdJCGEEEKIJUFG57hAjw49yoP9DxLNRolmo0RyEVY+OcRbvh3j6y808d83PrtSX5VseGw+WrwhAg4/frsfn82Hz+7DZ/NV92evQ44QDkvtZ9J7emCKN39hBwq4uqOOnx8c4z9+ezsvWd9Y66IJIYQQQiyKc43OISH6EiilGPzDPyLx859j/8I/E1sRJJKNEM1GGUtN8v1njnAyOoHFmqXBX8LlzJMqJojlYhTKhTPep4FBi6eFLn8XXf4uuv3d1XXAEViUn+uho+O87Su7CLptfPkt19JS5+T1n3qUk5Npfvjum1gRci9KOYQQQgghaklC9AIqRqOceNWrsNQF6PzOtzHZbHPOHxqJ82+/OM4Pnx7CYjZxx/Z27nlBF/U+E/FcnHg+TiwXq65H0iP0xnrpi/XRG+slW5oZMq/OXlcN1bMDdounBZMxP83bv79nkD/+r72sDHv48luupcGna8X7I2lu+9eHaalz8t133IjTZp6XxxNCCCGEWKokRC+w5C9/Sf/b3k7od3+Hhv/3/854Td9Eik/98jjf2T2AUvCara284+aVrAx7znq/ZVVmODVMb6yXE1Mn6I1X1rFeorlo9TqnxUmXv4uV/pV013Wz0r+SlXUrafW0YjZdeNj9/MO93PvDA1zXFeSzd23H57DOOf+Lw2O85Ys7eN3WNv7+DZswDOOC71sIIYQQYrmREL0Ihv/iL5n69rdZ8dWv4Nq27azXDU1l+MyvTvDNHafIFcvcuqGZd75oJT0t/ot6vGg2qsN17ATHp45X16Pp0eo1drO9WmO9sm5lNWSHnWGsZitWkxWTYUIpxUd/cph/f/A4L+9p4p/v3ILDeubw/U8/O8LH//coH3rtBn7juhUXVWYhhBBCiOVEQvQiKCVT9L7mNWAYdP/39zC5z91ueCKZ4/MP9/KVx06SyBV50Zow73rxVWxbEbykciTyCXpjvRyfOq6X2HFOTJ1gKDV0xuvNhhmlzJRKJuwWG3VOB1aTDtgWkwWryYrX5mVb4zZubLmR9cEefvfLT/HY8Un+6+03sLm97pLKK4QQQgixVEmIXiTpnTs5+Vu/Td0b30jz3/z1Bd0mlinwlcf6+NzDvUTTBVY3euiqd9MecNEedNEedNIecNEWcF1SO+R0IU1vrJdjU8eYyk1RKBdI53P88Jl+TkYSbO3w0tPqpqiKFEoFCuWZZSIzwcHJgygUXpuXq8PX8sT+esy51dz/e68h6LadvwBCCCGEEMuMhOhFNPqxjxH53Odp/8yn8bzgBRd8u3S+yDee7Ofho+P0RzP0R9LkiuU519R77NVQPb3uCLroDnto9Nkvqo3yVDrPW764gz39U9z76g385vXnbpoxlZ3i8ZHHeWzoMR4ZfKTabMSuGnnt2hfzvNYbubbpWlxW1wWXQQghhBBiKZMQvYjKuRx9r389pakY3T+4D3Pdc2vuoJRiPJmjP5JhIJqmP5KmP5KhP5rmVCTNcCw7ZxZBr93CygYPqxo8XFVZVjV4aQs4MZnmhuuhqQy//fknORVJ8y93buHlG5ovumy9sV4+8fiP+J/jv8Th7aOoclhMFraEt3Bjy41sqN9At7+bBleDdEAUQgghxLIkIXqRZQ8coPeNd+B72cto/cd/WJDHKJbKDMeynIqkOT6e5OhokmNjSY6OJZlI5qrX2S0mVoanQ7WHljonf//TwySzRT5713au7w5dUjn+9Nt7+dauPt7zGjtZy0EeG3qMg5GD1fNuq5suX2VIvrpuvV3XRbu3HavJeo57FkIIIYSoLQnRNTDxqU8x/s8fJ/T2txF+5zsxbIvXbngqnefYWLK6HK2sB6cyAIS9dr705mtZ3+K75MfKFkr82r8/Sn8kzQ/f/Xw6Qi4i2QhHo0ero4dMr8fSY9XbWQwL7b52unw6XHf6OunwddDubSfkCEnttRBCCCFqTkJ0DahikeH3vY/Y9+/DvmoVzR/+EM6NG2taplSuSO9EivaAC79r/mqBT02mue1fH6It4OK777zxrMPjpQopemO9c8J1b6yXU/FTFFWxep3T4qTd2067t50Obwdt3rZqwG5yNV3U2NdCCCGEEM+VhOgaSjzwC0b+5m8ojo8TvPtuwu9+Fyans9bFmncPHBrlLV/cyeu3tfGx11/cRCyFcoHBxCD9if45y6nEKQYSA3OmSLeYLLR52mj3trOhfgPbG7ezMbwRp+Xye06FEEIIUVsSomuslEgw9vf/wNR//ifWFR003/sB3NddW+tizbt//Olh/uWBY3z4tRt503Ud83KfpXKJsfTYnGDdn+inL97HsegxFAqLycLG+o1sa9zGtsZtbG3Yitt67nG6hRBCCCHOR0L0EpF6/AmG//IvKZw6Rd0dd9DwJ3+M2XP2ab+Xm1JZcfcXnuSJExHee+taNrb5Wd3oxetYmA6E8XycPWN72Dm6k12juzgwcYCiKmIyTKwLrmNb4za2N27n6sar8dsvbkZIIYQQQggJ0UtIOZNh/F/+lciXvoSloYGmv/4rvDffXOtinVXuRC+Jn/yY4FvfiukCOkdGU3ne8OnHODaWrB5rrXOytsnLmsqytslHd9iN1Wya17KmC2n2ju9l1+gudo3u4unxp8mX8wCsCqxiY/1G2r3ttHnaaPPqJiE+m086MQohhBDijCREL0GZp59m+H3vJ3f0KL7bb6fxvX+OJRCodbHmyDyzj/577qEUjRL+g9+n/h3vuKDblcuKwakMh0cSHB5NcGgkweGROCfGUxQrY1tbzQYrwx5WN+pgva7ZS0+LnwbvxU0acy65Uo59E/vYNbqLnSM7ORI9wmR2cs41XquXNm/bzDIdsD3tNHmaZBg+IYQQ4gomIXqJUvk8E5/+DBOf+Qxmj4fG978P3623Loma0dQTTzLwjndgDgSwdXWRfvJJuu/7PrbOzud8n7liiRPjKQ6PzATrwyMJhmLZ6jX1Hhvrmn30tPjpafHR0+KjM+R+1oQxz1W6kGYgOcBAQi/9if7q/mBycE4nRpNhIuwM0+hupMnVRJNbL42uxup2yBGS0UKEEEKIy5SE6CUue/gIw+9/P9lnnsF1/fX4X/NqvC95Sc3aSyceeIDB//uHWDva6fjc58AwOHHrK3Fu2kj75z437yE/lilweCTB/qEY+4fiHBiKc3QsQaGkX5sum7kSrKcXP6saPdgt8xteS+US45lxHawrAXs0PcpoapSR9AgjqRFypdyc21gMC2FXWIdqVxNd/i7Wh9bTU99DvbN+XssnhBBCiMUlIXoZUKUSka98hciXv0xxaBjDbsfzwhfie+Ur8bzwBZgcjkUpR+z732fove/D0dND+6c/VW1iEvn61xm99wO0fOxj+G+/bcHLkSuWODqa5MBQnP1DMQ4M63CdypcAsJgMelr9bF8R4JrOANtWBAl77QtaJqUUsVysGqhnh+vpZTA5iEL/TTW4GugJ9ehQXVmHnJc2Q6QQQgghFo+E6GVElctk9uwlfv/9xH/8Y0oTE5jcbrwv+T/4br0V9403YlgXpp1u5MtfYfTDH8Z1/fW0feITmD0zw8SpUom+X38ThcFBVt7/I8z+xR/tolxWnIyk2T8UY99gnN0no+wdmCJXLAOwIuRi+4og2zt1sO6u98xbM5ALlS6kORg5yP6J/RyIHGD/xH764n3V883u5mqong7WdY66RS2jEEIIIS6MhOhlShWLpJ98ktj995P46c8ox+OY6+rw3nILvltvxXXNdgzTpY9woZRi4pP/xsQnPoH3pS+h5e//HpP92bW62YMH6X39G6j7tV+j+d6/ueTHnQ/5Ypl9QzF29kXY2Rdl18kokyk9Ikedy8q2jgDbO3Ww3tjqP+tsigspmU9yMHKQA5MHquH6ZPxk9Xy3v5utDVu5uvFqrm64mlZP65JoFy+EEEJc6RYsRBuGEQT+E+gE+oA3KqWiZ7juLuD9ld0PKqW+VDn+INAMZCrnXqaUGjvf414pIXq2cj5P6uFHiP/oRyQeeACVyWBpaMD3ilfgu+02HBt6nlPwUuUyo3/7EaJf+Qr+176W5g/ci2GxnPX60b/7KJEvfIEVX/8arquvvpQfaUEopeidSLHzZFQH65NRToynADAMaA+4uKrBo5ewh5UNbq4Ke+d1GvQLEc/HOTh5kGcmnmH36G72jO0hUUgA0OBsYGvjVrY2bGVb4zZW1a2SzotCCCFEDSxkiP4oEFFKfcQwjD8DAkqp95x2TRDYCWwHFLAL2KaUilZC9B8rpS4qEV+JIXq2cjpN8sEHif3oflK/+hWqUMDW1YXv9tvw3347tvb2C7ofVSgw/P73E/v+fQTvuouG9/zpeWu2y6kUx2+/HbPbQ9d3v7NgTUvm02Qyx66TUfYPxTk+nuTYWJITEynylWYgAPUeO1c1uKvh+qoGL6saPfM65N65lFWZY1PHeGr0KXaN7WL36G5G06MAuK1utoS3VGurV9Wtwm/3S221EEIIscAWMkQfBm5WSg0bhtEMPKiUWnPaNb9eueZtlf1PV677hoToS1eKxYj/9KfE7/sB6R07AHBu2YLvVbfje8Urzjr2dDmXY/AP/4jkAw8Q/r9/QOhtb7vgUJZ44BcMvPOdhP/fH1H/u787bz/LYiqVFQPRNMfGkjNLJWAnssXqdQ1eO5vb69hSWTa1+RdsBsbTDSeH2T22m92ju9k9tptjU8eq57w2L+3e9jMuDa4GTMb8TmQjhBBCXIkWMkRPKaXqKtsGEJ3en3XNHwMOpdQHK/t/AWSUUn9fCdEhoAR8B93U47wFkhB9ZoWhIWI/+hHx+35A7uhRsFjwPO95+F51O94XvxiT0wlAKZlk4J2/R3rHDhr/4v0E3/Smi36sgXe/m+RDD9P9wx9ga2ub7x+lZpRSjCdyHBtLcng0wdMDMfb2T3FiYqZJyMqwh81tdWzpqGNLWx1rm73zPvvimcRyMfaO76Uv1sepxKnqMHxDySGKaib420y26oyM7d52uvxdbApv4qq6q7CYzt5URwghhBBzXVKINgzj50DTGU69D/jS7NBsGEZUKTWn6vM8IbpVKTVoGIYXHaK/qpT68lnKcQ9wD0BHR8e2kydPnukyUZE9fJj4D35A7Ac/pDg6isnlwvvSl+C95RYmPvlvZA8fpuUjH8F/2yuf0/0XRkb02NHbttH+mU9f9k0LptJ5nh6Isad/ir39U+zpn6p2YLRbTPS0+NjcXsf2FUGu7w4S8izscHuzFctFRlIjc4L17CVT1F0OnBYnPaEeNoU36aV+E2FXeNHKKYQQQiw3S7Y5x2nX3Q1sV0q963yPKzXRF06Vy6R37CT2g/tI/OSnlBMJDLud1o//M96bb76k+458+cuMfvhvaf2nf8T3ilfMT4GXCaUUA9EMewem2HNqir0DUzwzGCNb0O2s1zZ5ub47xA0rQ1zfFVr0jotzypkc4JnxZ3h64mmeGX+GA5EDFMu65rrZ3VwN1JvCm1gXWofdvHgfAIQQQoilbCFD9MeAyVkdC4NKqT897ZogujPh9FAOu4FtQByoU0pNGIZhBb4B/Fwp9anzPa6E6OemnMuReughrC0tONavv+T7U6USfW+8g8LYKCvvvx+z1zsPpVy+CqUyzwzGeOz4JI8dn2TnyQjZQhnDgJ4WHzd0h7hxZT3XdAXx2GvXrCJXynEocoinx5+uLkOpIQAsJgvrguvYUL+hunT6OqWNtRBCiCvSQoboEPAtoAM4iR7iLmIYxnbg7Uqp36lc9xbgvZWbfUgp9QXDMNzArwArYAZ+DvyRUqp0vseVEL10ZPbtp++NbyRw5500/eVf1Lo4S0quWGLPqSkeO6FD9VOnpsiXyphNBhtb/dywMsQN3SE2t9fhd9Z2lJPx9DhPT8yE6gOTB0gX0wB4rB7Wh9ZXQ/XG+o00uhov+yY8QgghhEy2IhbUyIc+TPSrX6XzP7+Jc9OmWhdnycoWSuw6GdU11Scm2ds/RbGs//5Wht1saQ8semfFsymVS/TGetk3uY99E3o5HD1cbQYScoTm1FavD60n6AjWrLxCCCHEQpAQLRZUKZnkxCtvwxwM0vVf3zrnZC1iRipX5KlTU+zpj7Kn0llxIjnTWXFDq786tN6W9jraAs6a1v7mS3kORw7PCda9sV4U+n9I2BlmdWA1q4OrWR1YzZrAGjr9nVhNS38scSGEEOJMJESLBRf/6U8Z/P0/oOE97yH05rtrXZxlabqz4nSg3tM/xb7BGLnKpDD1Hhtb2utY3+xjdZOXNY1eOuvdNa2xTuaT7J/cz6HIIY5Ej3AkeoTjU8cplAsAWE1WVtat1OF61hJyhmpWZiGEEOJCSYgWC04pxcA7f4/U44+z8kc/xNrSUusiXRYKpTKHhhPs6Y/yVGV4vd6JFJVWIFjNBt31HlY3eVndUFk3eukIujCbalNrXSgX6Iv1cSR6hMPRwxyJHuFo5ChjmbHqNWFnmE3hTWwJb2FLwxbWh9ZjM9tqUl4hhBDibCREi0VRGBzk+G23477+etr+7ZPS8WyBZAsljo8nOTKa4MhokiMjCY6MJeiPZKrX2C0mrmrwsKbRy/oWHzetqmdNo7emv5NINsLR6FEORw5zKHKIPeN76E/0A7rGuifUw5aGLWwJb2Fzw2bqnfU1K6sQQggBEqLFIpr83OcZ+9jHCPzGb+C+6Xk4t2w569TjYn6lckWOjlXC9UiCI2M6YI/Es4Cewvymq+q5aZVeGryOGpcYJjIT7B3fy56xPewZ28P+yf3VpiDt3vZqTfXm8GauqrsKs8lc4xILIYS4kkiIFotGFQoM/OEfknzwl1DUIznYurpwbt2Kc+sWXFu3YuvuxjDJuMOLZWgqw8PHJnjo6ASPHJsgUplpcW2Tl+evquemVWGu7QzitNU+oOZLeQ5MHtChenwPT409RSQbAfSMi2uDa1kfWs/60Hp6Qj10+jolWAshhFgwEqLFoitnMmT37SP91B4yTz1FZs8eStEoACafD+eWzbi2btXheuNGTG53jUt8ZSiXFQeG4zx0dIKHjo6zsy9KvlTGZjFxTWeAm64K8/xV9axv9mGqUZvq2ZRSDCQG2DO+h30T+zgweYDD0cNzpjKfHazXB9fT5e+SYC2EEGJeSIgWNaeUonDy5EyofuopcseOgVJgMmFfuwbX9u24rrkG1/bt0gRkkWTyJZ7si/DQkXEePjbBoZEEAHUuq55h8ap6blwZorvevWTauE+PYX0gcoADk3o5FDk0J1ivCaxhfWg9a4NrWRdax0r/SqxmGWpPCCHExZEQLZakUjxOZu/TZJ56ivTu3WT27EFldftd+6pVuK6ZFarD4RqX9sowFs/y8LEJHj0+yaPHJhiK6d9Hk8/BjStD3LBSB+vWOmeNSzpXqVyiL95XDdUHJg9wMHKwGqytJitX1V3FutA6HayD61gdWI3L6qpxyYUQQixlEqLFsqDyeTL79pHesZP0jh1kdu+mnNZTT9s6O3WgvlaHamtzc41Le/lTSnFyMs2jxyd55PgEjx2frLan7gy5uGFlfTVY13vsNS7ts5VVmVPxUxyKHOJA5ACHJg9xKHKIaE43KzIwWOFbwbrQOtYFdbjuqe/BZ/PVuORCCCGWCgnRYllSxSLZAweqoTq9axflhG5uYG1vJ/TWt1L3xjdIJ8VFUi4rjowleOTYJI8dn+CJExESOd15dFWDh20rAlzdEeDqFQFWhpdO84/ZlFKMpkc5FDnEwcmDHIwc5FDkEMOp4eo1Xf4uNtVvYlN4E5vDm1lZtxKLSWbhFEKIK5GEaHFZUKUSuSNHSO/YQfzHPyGzezeua66h6d6/wd7VVeviXXGKpTLPDMZ49PgkO/oi7D4ZJZ7VobrOZWVre50O1isCbG6rw21fukF0KjvFwchB9k3s4+nxp3l64uk5o4L0hHrYFJ4J1jKGtRBCXBkkRIvLjlKK2He+w+jffRSVy1H/rncRevPdGFbpPFYr5bLixESSXSej7D45xa5TUY6NJQEwGbCu2cfVHQG2rdBLe3DptkdWSjGQHNCBurIcih6iWNYfElrcLWwMb2RDaAOrg3oqcwnWQghx+ZEQLS5bhbExRj/wQRI/+xn2deto/uAHcPb01LpYoiKWLrC7P8pTJ6PsOhVlz6kpUvkSoNtVv3B1mJvXNHB9d2hJjFN9LrlSjoOTB6s11U+PPz2nGUjQEWR1YDVrAmuqwbrb3y3TmQshxDImIVpc9uI//SkjH/gApUiU4N13EX7XuzA5l9YIEgJKZcXhkQQ7+iL88sg4jx6fIFvQ41Rf1xWshOowK8OeJdmm+nTTU5kfiR6pLsenjpMr5QAwG2a6/F2sCqxidUAH63ZvO62eVgnXQgixDEiIFleEUjzO2Mc+xtR/fRtrRwfN996L+/rral0scQ7ZQkkH6sPj/PLIOEcrzT9a65y8cE2YF64Oc+PKEF7H8mmmUywXOZU4pUN15Eg1ZA+lhqrXGBiEXWHaPG20edto9bTOrD1thF1hTIZ0mBVCiFqTEC2uKKnHn2D4L/+SwqlT1L3h9TT8yZ9g9smwZcvBQDTNr45M8MsjYzxybJJkrojFZLC9M8BNV9VzXXeITW1+7Jal3fTjTBL5BMemjjGQGGAgOcBAYoDB5CADiQHG0mMoZv4X20w2WjwttHpbWRtYy/Pbns/mveCkKQAAIABJREFU8GYZJUQIIRaZhGhxxSlnMkx88pNMfuGLmIMBmv7iL/C97GW1Lpa4CPlimd2novzyyDgPHh7n4HAcALvFxLYVAa7rCnFdd5At7XU4rMsvVM+WL+UZTg3PCdbTQfto9ChFVcRr9XJj643c1HoTN7XeJB0Zhfj/7N15fFT1vf/x15nJbJlJJjOThCwQkiBrCAYICCKyK4qCtraibKLWn977w2u916J1ubQXr1brTwVtqaVurYperaLiclVAsAVll31NQhJClkkymck22/f3x4QIyiIQmCR8no/HeZwzZ5vPxEje+eZ7vl8hzgMJ0eKC1bh9O2UPPUzzzp1Y8gdjHT6c2MGDsQwYgC62/Y4OIX6opt7PN4XVfH2gmrUH3Ow8XIdSYIzRMbBbApdkuxiW7WRQhqPDh+qjef1e1patZXXJalaXrqaqsQqAfq5+jEwfyciuI+nv6o9e13k+sxBCtBcSosUFTQUCVL/6Kp4PPqR5925QCvR6zP36ETtoEJbBg4gdNIiYRGnZ60g8DYGWUO3m64Jqth/yEFZg1Ou4uJudS7JcDM1yMqi7A1s7HqP6dCil2FW9i9Wlq1ldsppvq74lrMIkmBIYkT6CkekjuTTtUhxmR7RLFUKITkFCtBAtQl4vjZs307BhA40bNtL47beo5shICsbu3bEMHkzs4EFYBg3CmJnZIUaIEBF1TQHWH2mpLqhmW6mHUFih0yAnzc6QTCdDsxzkZzrb5TTlZ6K2qZZ/HvonX5V+xVelX7VOad7V1vWY6cz7uvpK9w8hhDgDEqKFOIGw30/T9u00btxIw4aNNG7YQMjjAUDvdGLJy8MyYACWvIsx989Fb7NGuWLxY/mag2w6WMO6gmq+Kaxm08FamoNhALKTrAzNdLYEayddHZYO/wtTKBxih3sHa8vWsrN6JzvdOynxlbQeT7Ik0cfZhz7OPvRz9aOPsw/ptvQO/7mFEOJckhAtxI+kwmH8BQXHtFT7CwoiBzUNU8+eWC6+GEvexVgGDMDYoweaToYi6wj8wcg05d8UVLOusJr1hdWt05SnxJsZkuXk0h4uLrsosV3Ppng6vH4vu6p3sat6FzvdO9lZvZMCTwEhFZnwJs4YR19nX3o7e9PH2Yfejt5k27Mx6DvOkIJCCHEuSYgW4iyEamtp3LqVxs1baPz2Wxq3bCFcFxkpQmezYRmQi/niSKiOHTJUWqs7iHBYsbs8MvHLNwWRpcIb6dqTlWjlsosSuaxnIsN7uIjvQONUn0pTsIm9NXvZWb2zNWDvqdnTOkFMjC6GHvYe9Hb2prejJVw7e2M32aNcuRBCnH8SooVoQyocxl9YROOWLTR+u4XGLVto3r0HQiF08fE4Z83EOWOGjE3dwSil2FfhY/XeKr7aV8XaA24a/CH0Oo28bglcdlEiI3smktctgRh95/rrQzAc5GDdQXbX7GZX9S521+xmd/Xu1pFAALrEdqGPsw+9HL1au4RIdxAhRGcnIVqIcyzc0EDjt99S/epf8S1fji4uDueMGThnzkCfkBDt8sQZODJO9Vd7q1i9r4pvS2pRCuJMMQzr4WJkz0Qu7ZFIjyRrpw2SVY1V7KneEwnVLcH66O4gdpOdfs5+9HNFlpzEHNKsaZ326yGEuPBIiBbiPGrasYOqPy7C+9ln6KxWHDOm45w1ixiHDDvWkdU2+Pnnfjer91axem8lJTWNANgtBgZlJDAow8Gg7g4u7pbQaYbUO57mUDN7a/ayw72jdTkyIQxIsBZCdC4SooWIgqbduyNh+tNP0VksOKZNwzn7FmKczmiXJs6SUooidwNfF7jZWFTLxoM17K3wAaDToFeXOAZ1dzAow8Hg7g4yXbGdOkT+mGDd29Gbno6e9HL0omdCT3ok9CDW0Dke4BRCdF7nLERrmuYE3gQygULg50qpmuOc9wkwDPhKKXXNUfuzgCWAC9gAzFBK+U/1vhKiRUfSvHcvVX9cRN3HH6NZLDhumorr1luJcbmiXZpoQ57GAJuLa9lYVMPGgzVsPliLtzkSIp1WIwO7JTCou4PeXeK4KNlGN2csel3nDdb+kJ+9NXvZ7t7eGqr31u6lMRhpwdfQ6BrXNRKqHT3pmdCTno6eZMRlyOyLQoh241yG6CeAaqXU45qm3Q84lFJzj3PeOCAW+D/fC9FvAX9XSi3RNG0RsEUp9cdTva+EaNERNe/fT9WiP1G3bBma0Yhj6lRct91KTFJStEsT50A4rNhb4WPjwZrWYL2/sr71uDFGR3ailYuSbfRMjgTrnl1sZLqsGGM614OLR4RVmFJvKXtq97CnZk8kWNfs5aD3IGEVGcPbrDeTnZBNZnwmXWK7kBSbRFJsUmTbEtk26TvHZDlCiPbvXIbo3cBopVSZpmmpwEqlVO8TnDsa+I8jIVqL/G2zEkhRSgU1TRsOzFNKXXmq95UQLTqy5oIC3Iv+hOfDD9H0euw/uR7XrbdizMiIdmniHKtrCrCvwse+ch/7Kn3sLfeyr9JHSU0jR/4p1us0ujtjuSjZxkXJNvIzHYzsmYShk40IcrSmYBP7PfvZU72HvbWRYF3sLaaioYJAOPCD8+0mO0mWJJJjk1vXKdYUchJz6O3oTYyu8/ZJF0KcX+cyRNcqpRJatjWg5sjr45w7mmNDdCKwVil1UcvrbsDHSqn+J7j+DuAOgIyMjMFFRUVnXLcQ7YG/qAj34sV43luKCoWIn3glrttvx9yvX7RLE+dZoz/E/kpfJGBX+Nhb4WVfhY8idwPBsMJpNXLNgFSm5KUzKCOhU/evPppSCk+zh4rGCiobKqloqKCyMbKuaGjZ11iBu9HdOmKIJcbCxUkXMyh5EAO7DGRA4gDpey2EOGNnFaI1TfscSDnOoQeBV44OzZqm1SiljjsEwdmG6KNJS7ToTAIVFdS8+io1bywhXF+PdcQIXL+4ndhLLrlgwpI4vuZgiNV7qnh3cymf7yinORimuyuWKXnpXJeXRnaSLdoltguhcIjyhnK2VG5hY/lGNlVsYk/NHhQKvaanr7MvA7sMZFDyIPKS80i0JEa7ZCFEByHdOYToAEJ1ddQseZPqV18lVFWFOTcX1+23Ezd+HJpeHrS60HmbAnyy7TDvbS7ln/vdKAUXd0vg+rw0rrk4jUSb9BM+mtfvbQ3VGys2sq1qW+usjN3juzMoeRA5rhyyE7LJtmfjNDvll1YhxA+cyxD9JOA+6sFCp1LqVyc4dzRHheiWff8DvHPUg4XfKqX+cKr3lRAtOrNwczOe95bi/stfCBw8iDEzE+dtt2KfMgWd0Rjt8kQ7cNjTxAdbDvHuplJ2lNWh12mM7JnI9QPTmdCvC7FG6RP8ff6Qnx3uHWyq2MTGikhrtafZ03rcbrKTbc/+bmkJ1ynWFHRa5+2PLoQ4uXMZol3AW0AGUERkiLtqTdPygTuVUre3nLca6APYADdwm1LqU03TsokMcecENgHTlVLNp3pfCdHiQqBCIbyffYb7hT/TtGMHMUlJOGfNJP7ayRi6JEe7PNFO7D7s5b3NpSzdVMohTxNmg45BGQ6GZDoZmuVkYEaChOrjUEpR3lDOgdoDHPBElv21+ynwFFDT/N1IrZYYC1n2rGMCdpY9i25x3TDoDVH8BEKI80EmWxGiA1NK0bBmDe7Fi6n/5xoADBkZxA7JJzZ/CLFDhmDsmh7lKkW0hcOKdYXVfLztMOsKq9lRVodSEKPT6J9uZ2iWkyGZToZkOkiIlb9onEx1U3VruC7wFLQG7PKG8tZz9JqebnHdyLRnkmXPIis+K7K2Z2E32aNYvRCiLUmIFqKTaNqzh/p//pOGdetpXL+ekCfy5+iYtFRi8/OJHTKE2Px8jJmZ0r/zAlfXFGBDUQ3rCqpZV1jNlmIP/lBkLOZeXWytoXpolpNUuyXK1XYM9YF6CusKKfAUHLMU1RUdMxSf0+xsDdT9XP0Y3GUwWfFZ8v+kEB2QhGghOiEVDtO8dx8N69fRsG49DevXE6qqAkCflNgaqq3DhmPKzopytSLamgIhthTXsq6wmm8KIxPA+FpmVExPsJCf6SC/u4PB3Z30Tonr1LMptrVQOMQh3yEK6o4N1/s9+1v7XTvNTgYmR0YIGdxlML2dMp61EB2BhGghLgBKKfwFhd+F6nXrCB4+DICpTx/s10wi/uqrMaSlRblS0R4EQ2F2lnn5prCaDUXVrC+socIbeSQlzhRDXkYC+d2d5Gc6yOuWgNUkge90KaUoqitiY8VGNpRvYEP5Bkp9pQDExsSSl5zHoORBDOoyiNzEXMwx5ihXLIT4PgnRQlyAlFIESkvxrVhJ3Ycf0rhlCwCWwYOxXzOJuIkTiXEcd1h3cQFSSlFS08j6lkC9oaiG3eVelAKdBn1T4yMt1S39qqULyJkpry8/JlTvq90HgEFnoH9if3JcOSTFJuE0O3GZXbgsLlxmF06LE4NOHmQU4nyTEC2EwF9cTN2yZXg+/BD/vv0QE4P10uHYr7kG29hx6G3WaJco2pm6pgCbDtayobCa9UU1bC6upcEfmRkwwxnLsGwnl2S5GNbDRXqChOoz4Wn2RIbdK9/IhooN7K3ZS2Ow8bjn2k32Y4O12UmiJZGLEi4iJzGH5FgZtUeItiYhWgjRSilF85491H34IZ5lywgeKkMzm7GNGY39mmuwjhwp41GL4wqGwuw67OXrgmq+PuDmm8JqahsiD9R1dVgYlu3ikiwnw7JddHPKVNtnqiHQgLvRjbupZWn8bl3dVH3M2hvwtl6XbEmmX2I/clw5kSUxB6fZGcVPIkTHJyFaCHFcKhymcfNm6j78kLqPPyFUU4MuPp7Ef7kL54wZMlOiOKlwWLG73MvXB9ysPVDN1wVualpCdXqChUuynQzLcrWEaouMTnEONAQa2FOzh+3u7Wyv2s429zYKPYUoIj/bU62prYG6nysSsGUIPiF+PAnRQohTUoEA9WvXUv3qX6lfvRrzxQNImz8fU8+e0S5NdBDhsGJvhY+1B9x8XRAJ1tX1fgCS4kwM7JbAwAwHAzMSGNDVLpPAnCM+v4+d1TvZ4d7B9qrtbHdv56D3YOtxl9mFw+zAYXaQYErAYXKQYI6s7SZ75NhR+ywx8guQuHBJiBZC/GhKKeo+XEb5o48Sqq8n8a47Sbz9djTp4iFOk1KKfS2hetPBWjYV11JQVQ+AXqfRJyWOgRkJDOzmYFB3B5muWAlr54in2RMJ1e7tlHhLqG2upaaphtrm2tYlrMLHvdakN9Etrhvd47uTEZ9BZnwmGXEZZNozcZld8t9MdGoSooUQpy3odlP+6H9T99FHmHr3JnX+fCy5/aNdlujgquv9bC6uiYTqg7VsLq5tHa86IdbQ2lqdkxZPN2csXR0WabE+D8IqjNfvbQ3WRwfsqsYqDnoPUlRXRLG3mGA42Hqd1WCNBOr4TDLiM+ge353u8d1Js6XhMDnQ66RLmOjYJEQLIc6Yd/lyDs/7DcGqKpyzbyFpzhx0ZhnPVrSNUDjSWr3pYCRYbzxYw94K3zHnuKxGujpj6eaw0NURSzdny9phIS3BgtkgQe18CYaDlNWXcbDuIIV1hRTVFbVul9WXHdOardN0rSOIuCwuEs2JJFq+W1wWF0mWJBItiVgNVmnRFu2ShGghxFkJ1dVR8eST1P7P2xi7dyd1/n8RO2RItMsSnZSnMcC+Ch8lNQ2U1DRSUtNAcXVkXVrbSCB07M+tLvEmMpyxDM92MaZPMhd3TUAnMy6ed/6QnxJvCYV1hZQ3lFPVWIW70U1VY1Xr4m50E1TBH1xrNVjp4+zT+vBjjiuHjPgMdJouCp9EiO9IiBZCtIn6NWsoe/gRAiUlJNw0leR//3f0Nlu0yxIXkFBYUeFtag3VR9b7Kn1sKa4lrCIt16N6JTGmTzKX90zCHiuTlLQXYRWmrrkuEqqbvgvWJd4SdlbvZFf1LppDkZkzbQYbfV196efsR05iJFh3i+smLdbivJIQLYRoM+GGBiqffZbqV/9KTEoKqb+Zh+3yy6NdlhDU1PtZtbeSFbsqWLmnktqGAHqdxuAMB2P6JDOmTxK9u8RJCGvHguEg+2v3tz4EucO9g93Vu/GHI6O8xBni6OfqRz9XP9Jt6bgskUlnnGYnLosLm8Em/31Fm5IQLYRoc42bN3PooYfw79uPbdQo4q++Ctvo0ejtMgatiL5QWLG5uIYVuypZvquCHWV1QGT86tG9kxjTO5lhPVzYTPLQYnsXCAfYX7u/dbi+He4d7K7ZfcwDjkcYdIbWQN0arltmeTw6bDvNThxmh0ylLk5JQrQQ4pwI+/24//xnat/6H4Ll5ZGpxIcOJW7CeGzjxmFIlmmIRftw2NPEit0VrNhVwVf7qmjwh9A0yE60kptup3+6ndx0OznpdgnWHUAgHKC2qRZ3k5vqxurIuqm69XV103eLu9Hd2pL9ffHG+GMC9pGQ7TJHlhRbCl1tXYk3xksL9wVKQrQQ4pxS4TBNW7fi/fxzvP/7Gf6iItA0LBdfTNyECcRNGI8xIyPaZQoBQHMwxLqCGjYU1bC11MPW0lrK6yL9cCVYdz5KKeoD9a1B+0joPjpwtx5rqsbT7PnBPWwGG+m29MgSF1l3tXUl3ZZOmi2NWINMc99ZSYgWQpw3Sin8+/ZR99lneD//nOYdOwEw9e7dGqhNvXpJq45oVyq8TWwr9bC1pI6tpbVsLfWcMFjnpNnplxaP3SJdATqjQDhATVMNVY1VlPnKKPGVUOorjSzeyLop1HTMNU6zk662rjjMDmJ0Md8tWgwGvYEYLfLaoDMcc9yoM2I1WokzxhFviCfOGIfNaIu8NsZj1MskV9EmIVoIETX+kpJIC/Vnn9O4cSMohSEjg7hx44gbPw5LXh6aXsb5Fe3PyYI1QIYzlv7p8eSk2clJi6d/up1EmymKFYvzQSmFu8l9TKgu9ZVS4ivB0+whGA4SDAcJhAOt20EV/G47HCSkQj/qvUx6EzbDd6E6zhhHgjmhdXztREvid9uxicQZ5MHZtiYhWgjRLgSrqvB+sRzv55/TsHYtKhBA73RiGzuGuHHjsA4fLhO5iHatytfM9kN1bCv1sP2Qh+2H6ihyN7Qe7xJvon9apAtITlo8QzKdOK3SmiiOFVZhQuEQ/rAfr9+Lz+/DG/Di9Xup89dFXvsjr4/s9/q91DXXUdNcQ2VD5XH7eZv0pmMmtDkyqU2CKYF4Yzx2kx270U68KR670U6cMe6sZpUMhAP4Q370mh5zTOf8t1tCtBCi3Qn5fNSvXo338y/wffklYZ8PLTYW24gRxI0fh23UKPQJCdEuU4hT8jQG2HGorjVUbyv1sL/SR1iBToNBGQ7G9k1mXJ8u9OoiQ7CJs6eUwhvwUtUQGWu7srGydUKb1u2GyHadv+6k94ozxEVCdUvAjjPGoVA0BZtoDjW3Lke/PrJ9dIu63WQnJTaFFOt3S5fYLpHt2BS6WLt0yO4pEqKFEO2a8vup/2Yd3i8+x/fFcoIVFaDXEztkSKTbx7ixGNLSol2mED9aoz/EjjIPX+6pYvmucraVfjfE3ri+yYztk8ywbJdMWS7OuUA4QF1zHR6/h7rmOur8dXiaPXiaPd9ttxw7stZrekwxJsx6M0a9EbPejCnGhElvat02682R1zFm/CE/5Q3lHK4/HFkaDh/3AU2n2UmKNYXk2GRMehM6TYde0x+zPrIcs1+no3tcd37a66fn/esnIVoI0WGocJimbdvwfv4F3uVf4N+3H4DYoUNx/eIXWC8bIS15osM5MsTeFzsr+Me+KhoDISwGPZf1TGRcn2TG9EmmS3zn/HO4uDA1BBp+EKzL6yOvKxorCIQCkW4tKnTM+shy9OtQOMSQlCEsmrDovH8OCdFCiA6ruaAA7/9+Rs3rrxMsL8fUty+u228j/sor0WJk2DHR8TQFQqw54GbFrkioLq1tBKB/ejyX9kikq8NCqt1Cqt1Mit2My2qUXxyFiBIJ0UKIDk/5/Xg+XIZ78WL8Bw5g6NYN1223Yr/uOnkYUXRYSin2lPv4Ylc5y3dWsLm4lmD42J/LRr2OlJZAnWY3k9ISsFPtZtISLPTsYsMUI91ChDgXJEQLIToNFQ7jW76cqj//maYt36J3uXDOnInjpqno4+OjXZ4QZyUcVlTVN1NW20SZp4kyTyOHPd9tl3maKK9rIhD67me32aBjcHcHw7NdDO/hYkDXBAx6XRQ/hRCdh4RoIUSno5SiYd063H9eTP3q1eisVhKm3ohz5iwMXWS6cdF5HQnahz1NFFc3sq6wmrUH3Ow67AUg1qgnP9PJsGwnw7Nd5KbbiZFQLcQZkRAthOjUmnbuxL34L9R9/DGaXo/9uik4b70VU1ZWtEsT4ryprvfz9QE3aw64WXvAzZ5yHwA2UwxDMh0Ma2mp7pcaL6FaiB/pnIVoTdOcwJtAJlAI/FwpVXOc8z4BhgFfKaWuOWr/y8Ao4Mg4KLcopTaf6n0lRAshjsdfXEz1Sy9R+87fUcEgrttvJ/Ff7kJnklnkxIWnytfM2pZAvWa/m/2V9UBk7GqXzURyXGRJijORHGcmOd5Eks1EcnzkdVKcSYbgExe8cxminwCqlVKPa5p2P+BQSs09znnjgFjg/xwnRH+olHr7dN5XQrQQ4mSCVVVUPPX/8Lz7LsbsbFLnzyd20MBolyVEVFV4m1h7oJp95V4qvM1UeJup9DZT4W2iyucnFP5hHogzx5ASb6ZnFxt9U+LpmxpPn9Q40hMsMmKIuCCcyxC9GxitlCrTNC0VWKmU6n2Cc0cD/yEhWghxvvhWf0XZfz5CsOwwjunTSb7n39BZrdEuS4h2JxRWVNf7W0P1kYBd6W3mUG0ju8u9x0xvHm+OoU9qPH1T4uibGgnXvbrEYTFKy7XoXM5liK5VSiW0bGtAzZHXxzl3NMcP0cOBZuAL4H6lVPMJrr8DuAMgIyNjcFFR0RnXLYS4cIR89VQ+/TQ1r7+OIS2NlN/+BtuIEdEuS4gOx9ccZPdhLzvL6lqX3Ye91PsjUz/rNMhMtNI3NZ4eiVZSEyykJVhITzCTardgNcm47qLjOasQrWna50DKcQ49CLxydGjWNK1GKeU4wX1G88MQnQocBozAC8B+pdRvT/5xpCVaCHH6GjZsoOyhh/EXFGD/yU/oMvdX6O32aJclRIcWDiuKaxpaQnVLwD5cR2lNI9/vHZIQayDNHgnWaQnmlnUkZGc4rSTFybMLov05WYg+5a+FSqnxJ7lxuaZpqUd156g4ncKUUmUtm82apr0E/MfpXC+EED9W7ODBZL33LlXP/wH3X/6Cb/UqUh55hPgJE6JdmhAdlk6n0d1lpbvLysT+qa37g6Ew5S1dQQ7VNlLasj5U20RJTQPfFLipawoec6+sRCvDsp0My3ZxSZaLFLtMoiTat7P928r7wCzg8Zb10tO5+KgArgHXAdvOsh4hhDghnclE8r2/JH7ilRx68CFK59xN3cSJpDz0IDGJidEuT4hOI0avIz3BQnqC5YTneJsClHmaKK1tZH+Fj7UHqln2bRlvfFMMHBuqh2W76BIvoVq0L2fbJ9oFvAVkAEVEhrir1jQtH7hTKXV7y3mrgT6ADXADtymlPtU0bTmQBGjA5pZrfKd6X+nOIYQ4WyoQwP3iS1Q9/zyaxUKXB+7HPmWKjDggRBSFwoqdZXUtQ/NV83WBG29Li7WEahENMtmKEEKcQPOBA5Q9+BCNmzZhzM7GPmUK9snXYkhNPfXFQohz6mShOs4cQ6rdTJd4M6l2MynxZlLslmP2JcQa5BdjcVYkRAshxEmocBjP0vepfedtGtdvAE0jdtgl2KdMIX7CBBkWT4h24kio/rqgmuLqBso8jRz2NHG4LjIs3/cjjSlGR8rRQbslbEe2I4E70WZCr5OgLY5PQrQQQvxI/uJiPO+/j2fp+wQOHkSLjSV+wgTs100hduhQNL2MgytEexQMhan0NVPmaYoE65ZwfWS7rK6Rck8z/lD4mOv0Oo3kOBMpdvOxLdt2C9mJVrKTrMQaZXi+C5WEaCGEOE1KKRo3bcLz7nvUffIJYa+XmJQU7JMnY79uCqbs7GiXKIQ4TUpFJpUp+17ILvM0cbiusXW7oWXs6yPSEyz0SLZxUZKNi5K/W5xWY5Q+iThfJEQLIcRZCDc14Vuxgtr33qP+q39AKIQ5NxfbqFHoHQno4+PRx8eji4tHb49HFxcXeW2WB5+E6GiUUnibgxyqbeRAZT37Knzsr/S1rpsC37VkO61GLkqyRQJ2so2UeDMGvYYhRodJr8MQo8Og12HU6zDGaJHtln0GvQ5TjA6zQf661Z5JiBZCiDYSrKzEs2wZnveW0rxr10nP1YxGdC0BWx8Xh97hwHrpcOKuvBJDly7nqWIhRFsJhxWltY3sq/SxvyISrPdV+NhX6aO2IXBG9zQbdDhjjSTEGnFajSTEGlrWRpyxBhxWI47YlsVqICnOhClGgvf5IiFaCCHOgbDfT7iujlCdl7C3jlBdZDlmn6eOkNdLuM5D4HA5/gMHQNOwDB5E/MSriLtiAobk5Gh/FCHEWXL7mnHX+/EHw/hDYQLBMIGQwh8K4Q8qAqEw/mCYQCiyNAcjS22Dn5qGADX1fmqObDf48TQGfvCg5BFJcSbSEix0TbCQ7rCQZjeT7oglLcFM14RY4i0xMipJG5EQLYQQ7UTzgQPUffIJ3o8/oXnv3shIIPn5xF99FXETJsikL0IIIDISiacxQHW9vzVoV9c3U17XTGlNI4c8jZTWRGaDbA4e+7Ck1agn3RGZ7CbFbiHJZsRlM+GyGXFZTSS2vE6wGNCdxcgkobCiMRBCr2lYjJ2zdVxCtBBCtEPN+/ZR9/En1H38caSFWqcjduhQ4idOJO6KCcQ4ndEuUQjRzimlcNf7I8G6ZYr1kqO2D3uaqG7wH7dVW6/TcMQaW0J1JGA7rUaUUtT7QzT6QzT4gzT4QzQGQpH1UfuODu8+VsBaAAAgAElEQVRd4k2RKeCdsWQmWunuiiXTFVnHmQ3n8SvStiRECyFEO6aUonnvXryffELdRx/jLywEvR7rJUNxTJ9O3Nix0S5RCNGBhcKKmgY/bp+/tdvJkXXV9/f5/Oh0GrFGfcsSg6V1W4/FEPPddsu6ORCmqLqBInc9he4GKr3Nx7y/y2o8KlRbyXBZsBj06DSNGL2GXqdDr2nodd8tMd/btppiSDvJNPLnioRoIYToIJRSNO/eHWmh/ugjAsXF2G/4KSkPPCCTvgghOoT65iAHjwrVRe56Cqsi60OepjO656U9XLz+i2FtXOmpSYgWQogOSAUCVD73PO4XXsCYkUHaU09h6Z8T7bKEEOKMNQVClNY24g+GCYUVobAi2LL+7nWYsFIEQy37lMIZa+TSi87/MyMSooUQogOr//obDs2dS9DtJvmef8M5ezaaThftsoQQotM7WYiWf4WFEKKds14ylOz33iVuzBgqnvw9B2+7jUB5RbTLEkKIC5qEaCGE6AD0CQmkP/sMqfP/i8bNWyiYMgXvF19EuywhhLhgSYgWQogOQtM0Em64gax33sGQlkbJv/5fyubNI9zYGO3ShBDigiMhWgghOhhTdhaZS97Aedut1C55k4IbfkbTKaYgF0II0bYkRAshRAekGY10ue8+Ml78C+G6Ogp/9nOqX3kFFQ6f+mIhhBBnTUK0EEJ0YNZLLyXr/aVYR46k/LHHKf7FHdIqLYQQ54GEaCGE6OBiHA66Pv8cKf/5CI2bNlFw3fUcvOMOGtatoyMOYyqEEB2BhGghhOgENE3DcdNNXLRiOUn33EPTtu0UzZhJ0U03412+XLp5CCFEG5PJVoQQohMKNzVR+/e/U/2XFwmUlmK8qAeu227HPulqNKMx2uUJIUSHIJOtCCHEBUZnNuO8+WZ6fPoJaU8+iabTU/bAA+y7ciLVr7xCuL4+2iUKIUSHJi3RQghxAVBKUb9qFe4/L6Zh/Xr0djuO6dNxTJ9GjMMR7fKEEKJdOllLtIRoIYS4wDRs3IR78WJ8y5ejWSw4brwR1+23EZOYGO3ShBCiXZEQLYQQ4gea9+6l6s9/pu7DZWgmE46bb8J1223EOJ3RLk0IIdoF6RMthBDiB0w9e5L+xBNkf/ghcePHU/3iS+wbP4GKp/4fwZqaaJcnhBDtmoRoIYS4wJmys0h/8gmyP/yAuNGjcS9ezP5x46l45hlCtbXRLk8IIdqlswrRmqY5NU37TNO0vS3rHzydomlanqZpazRN265p2reapt141LEsTdO+1jRtn6Zpb2qaJuMuCSFElJh69CD9/z1F9vtLsV5+Oe5Ff2Lf+AlULlhIqK4u2uUJIUS7crYt0fcDXyilegJftLz+vgZgplIqB5gIPKNpWkLLsd8BTyulLgJqgNvOsh4hhBBnydSzJ12feZqspe9hHT6cqj/8gX3jxlP53POEvN5olyeEEO3CWT1YqGnabmC0UqpM07RUYKVSqvcprtkC3ADsAyqBFKVUUNO04cA8pdSVp3pfebBQCCHOn6adO6l87nl8X3yBLj4e162zcc6Ygc5qjXZpQghxTp3LBwu7KKXKWrYPA11OUchQwAjsB1xArVIq2HK4BEg/y3qEEEK0MXPfvnR7/jky33mb2EGDqHzmWfZNuILqV18l3Nwc7fKEECIqThmiNU37XNO0bcdZphx9noo0aZ+wWbulpfqvwGylVPh0C9U07Q5N09Zrmra+srLydC8XQghxliw5OXRb9Ecyl7yBqWdPyv/7MfZPvIrat99GBYOnvoEQQnQi56U7h6Zp8cBK4L+VUm+37NOQ7hxCCNFh1a9ZQ8XTz9D07bcYMzNJ+re7ibvySjSdDPwkhOgczmV3jveBWS3bs4Clx3lzI/Au8OqRAA2tLdcriPSPPuH1Qggh2ifr8OFkvrmErs8tRDPEUPrLeym44QZ8q1bRESfyEkKI03G2IfpxYIKmaXuB8S2v0TQtX9O0xS3n/By4HLhF07TNLUtey7G5wL2apu0j0kf6L2dZjxBCiPNI0zTixo8n6733SPvd44TrvBTf8X8omj6Dhg0bol2eEEKcMzLttxBCiDaj/H5q33mHqj/8kWBlJdbLR5J8zz2Y+/WLdmlCCHHaTtadQ0K0EEKINhdubKTmtdeo+vNiwh4P6PVoev1x1jo03Q+PxSQnYbt8FLbRozBlZUX74wghLlASooUQQkRFyOvF8/e/E6yugXAIFQy1rlU4BMeswxAKooIh/AUFNO/dC4Cxe3dso0dhGz2a2MGD0Ywyua0Q4vyQEC2EEKLD8ZeU4vtyJb4vv6Rh7dcovx+d1Yp1xAhso0djG3U5MS5XtMsUQnRiEqKFEEJ0aOGGBurXrsW38kt8K1cSrKgATcM8IBfbqFHEjR2LuU+faJcphOhkLogQHQgEKCkpoampKUpVCXHmzGYzXbt2xWAwRLsUIdo9pRTNO3fi+/JLvCtX0vTtVlAK56yZJP/qV5F+1UII0QZOFqJjzncx50pJSQlxcXFkZmYSmcdFiI5BKYXb7aakpIQseYBKiFPSNA1zv36Y+/Uj8a67CLrdVD3/B6pfeRV/aSnpTz6JzmKJdplCiE6u00wr1dTUhMvlkgAtOhxN03C5XPJXFCHOUIzLRcojD9Pl1w/g+2I5RTNnEaysjHZZQohOrtOEaEACtOiw5HtXiLPnnDmTrs8tpHnfPgpvnErzvn3RLkkI0Yl1qhAtzt7o0aORhzaFEB1V3LhxdH/1VcJ+P4U33Uz92rXRLkkI0UlJiD7PgsFgtEtopZQiHA5HuwwhhGhTltz+ZL25BENKFw7e/gtq//5utEsSQnRCEqLb0H/913/Ru3dvLrvsMm666SZ+//vfA5HW3XvuuYf8/HyeffZZPvjgAy655BIGDhzI+PHjKS8vB2DevHnMmjWLkSNH0r17d/7+97/zq1/9itzcXCZOnEggEAAgMzOTBx54gLy8PPLz89m4cSNXXnklPXr0YNGiRQD4fD7GjRvHoEGDyM3NZenSpQAUFhbSu3dvZs6cSf/+/SkuLj7h53njjTfIzc2lf//+zJ07F4BQKMQtt9xC//79yc3N5emnnwZgwYIF9OvXjwEDBjB16tRz8wUWQogfyZCeTvfXXsM6dAhlv/41Fc8+S0ccjUoI0X51mtE5jvabD7az41Bdm96zX1o8/3ltzgmPr1u3jnfeeYctW7YQCAQYNGgQgwcPbj3u9/tbu0nU1NSwdu1aNE1j8eLFPPHEEzz11FMA7N+/nxUrVrBjxw6GDx/OO++8wxNPPMH111/PsmXLuO666wDIyMhg8+bN/PKXv+SWW27hH//4B01NTfTv358777wTs9nMu+++S3x8PFVVVQwbNozJkycDsHfvXl555RWGDRt2ws9z6NAh5s6dy4YNG3A4HFxxxRW89957dOvWjdLSUrZt2wZAbW0tAI8//jgFBQWYTKbWfUIIEU36+Hi6/elPlM2bh/uPiwgUl5D634+ikxkPhRBtoFOG6Gj4xz/+wZQpUzCbzZjNZq699tpjjt94442t2yUlJdx4442UlZXh9/uPGdbsqquuwmAwkJubSygUYuLEiQDk5uZSWFjYet6RQJybm4vP5yMuLo64uLjWEGu1Wvn1r3/NqlWr0Ol0lJaWtrZ4d+/e/aQBGiK/FIwePZqkpCQApk2bxqpVq3j44Yc5cOAAc+bMYdKkSVxxxRUADBgwgGnTpnHddde1Bn0hhIg2zWAgdf58jN26UfnMswQOl9F14UJiHI5olyaE6OA6ZYg+WYtxtFit1tbtOXPmcO+99zJ58mRWrlzJvHnzWo+ZTCYAdDodBoOhddQGnU53TH/qo887sn30ea+99hqVlZVs2LABg8FAZmZm6xBqR9dyuhwOB1u2bOHTTz9l0aJFvPXWW7z44ossW7aMVatW8cEHH/Doo4+ydetWYmI65beXEKKD0TSNxDvvxNC1G2UPPEDRTTfT7YU/YczIiHZpQogOTPpEt5ERI0bwwQcf0NTUhM/n48MPPzzhuR6Ph/T0dABeeeWVc1KPx+MhOTkZg8HAihUrKCoqOq3rhw4dypdffklVVRWhUIg33niDUaNGUVVVRTgc5qc//Snz589n48aNhMNhiouLGTNmDL/73e/weDz4fL5z8rmEEOJM2a+ZRMZLLxKqqaHwxqlU/+016j76CN/q1TRs2kTz3r0EDh8m5POh5KFrIcQpSFNhGxkyZAiTJ09mwIABdOnShdzcXOx2+3HPnTdvHj/72c9wOByMHTuWgoKCNq9n2rRpXHvtteTm5pKfn0+fPn1O6/rU1FQef/xxxowZg1KKSZMmMWXKFLZs2cLs2bNbR/V47LHHCIVCTJ8+HY/Hg1KKu+++m4SEhDb/TEIIcbZi8/PpvuQNSu68i/L58098oqahs1rRxcWht1nR2eLQu5xYh16C7fKRGLp3l/HdhbjAaR3xaeX8/Hz1/bGMd+7cSd++faNUUYTP58Nms9HQ0MDll1/OCy+8wKBBg6Jak+g42sP3sBAXChUMEqyqIuz1EvL5CLcsIa+XsK+esK9lv7dlv89L4NAhAkUHATB064Zt5EisIy/Deskl6GJjo/yJhBDngqZpG5RS+cc7Ji3RbeiOO+5gx44dNDU1MWvWLAnQQgjRTmkxMRhSUiAl5bSu8xcX41u9mvpVq6l9911qXn8dzWAgdkg+1pGXYxt5GcYePaSVWogLgLREC9FOyPewEB1L2O+ncf16fKu/wrd6Ff59+wGISUvFdtlIbJePxDpyJLqjHv4WQnQs0hIthBBCtDGd0Yj10kuxXnopXeb+isChQ/hWf0X9V6upW7aM2rfewtTzItKeegpzr17RLlcI0cZkdA4hhBCiDRjS0nDc+HO6LlxIrzX/pOtzCwnW1FL4s59Ts2SJzJgoRCcjIVoIIYRoY5rRSNz48WS/9y6xQ4ZweN5vKP23ewh5PNEuTQjRRiRECyGEEOdITGIi3V74E8n33Yd3+XIOXHc9DRs2RLssIUQbkBAtADh06BA33HBDm9xr9OjRfP/BTyGEuFBpOh2u224l843ISB5FM2ZS+Yc/oEKhaJcmhDgLEqI7gaOnAz9TaWlpvP32221QjRBCiOOx5OaS9fd3iJ80iaoFCzk4+1YC5eXRLksIcYYkRLehV199lQEDBnDxxRczY8YMAAoLCxk7diwDBgxg3LhxHDwYGaj/lltu4a677mLYsGFkZ2ezcuVKbr31Vvr27cstt9zSek+bzcYvf/lLcnJyGDduHJWVlUCktfeee+4hPz+fZ599lg0bNjBq1CgGDx7MlVdeSVlZGQALFiygX79+DBgwgKlTpwLw5ZdfkpeXR15eHgMHDsTr9VJYWEj//v0BaGpqYvbs2eTm5jJw4EBWrFgBwMsvv8xPfvITJk6cSM+ePfnVr351yq/JG2+8QW5uLv3792fu3LkAhEIhbrnlFvr3709ubi5PP/30CWsVQojORG+zkfbE70h97DEat22jYPIUvMuXR7ssIcQZ6JxD3H18Pxze2rb3TMmFqx4/4eHt27czf/58/vnPf5KYmEh1dTUAc+bMYdasWcyaNYsXX3yRu+++m/feew+Ampoa1qxZw/vvv8/kyZP5xz/+weLFixkyZAibN28mLy+P+vp68vPzefrpp/ntb3/Lb37zG5577jkA/H4/69evJxAIMGrUKJYuXUpSUhJvvvkmDz74IC+++CKPP/44BQUFmEwmamtrAfj973/P888/z4gRI/D5fJjN5mM+y/PPP4+maWzdupVdu3ZxxRVXsGfPHgA2b97Mpk2bMJlM9O7dmzlz5tCtW7fjfk0OHTrE3Llz2bBhAw6HgyuuuIL33nuPbt26UVpayrZt2wBa6zperUII0dlomkbC9ddhybuY0n//d0r+5V9xTJtG8q/ukzGlhehApCW6jSxfvpyf/exnJCYmAuB0OgFYs2YNN998MwAzZszgq6++ar3m2muvRdM0cnNz6dKlC7m5ueh0OnJycigsLARAp9Nx4403AjB9+vRjrj+yf/fu3Wzbto0JEyaQl5fH/PnzKSkpAWDAgAFMmzaNv/3tb8TERH5nGjFiBPfeey8LFiygtra2df8RX331FdOnTwegT58+dO/evTVEjxs3Drvdjtlspl+/fhQVFZ3wa7Ju3TpGjx5NUlISMTExTJs2jVWrVpGdnc2BAweYM2cOn3zyCfHx8SesVQghOitTVhaZS5bgnDWTmtdeo/DGqTRs2kTzgQM079tH0+49NO3aReP27TRu3Urjli00bNxEw/r11H/zDfVr19Kwbh0qEIj2RxHignRWSUXTNCfwJpAJFAI/V0rVfO+cPOCPQDwQAh5VSr3ZcuxlYBRwZMyfW5RSm8+mJuCkLcbtiamlxUGn07VuH3l9on7OR08la7VaAVBKkZOTw5o1a35w/rJly1i1ahUffPABjz76KFu3buX+++9n0qRJfPTRR4wYMYJPP/30B63Rp6oZQK/Xn1F/bIfDwZYtW/j0009ZtGgRb731Fi+++OJxa5UwLYTozHRGI10eeIDY4cMpe+DXFN1082nfI3bIELouXIA+IeEcVCiEOJGzTSj3A18opR7XNO3+ltdzv3dOAzBTKbVX07Q0YIOmaZ8qpY78vf4+pVSHf6Jt7NixXH/99dx77724XC6qq6txOp1ceumlLFmyhBkzZvDaa68xcuTI07pvOBzm7bffZurUqbz++utcdtllPzind+/eVFZWsmbNGoYPH04gEGDPnj307duX4uJixowZw2WXXcaSJUvw+Xy43W5yc3PJzc1l3bp17Nq1i7y8vNb7jRw5ktdee42xY8eyZ88eDh48SO/evdm4ceNp1T506FDuvvtuqqqqcDgcvPHGG8yZM4eqqiqMRiM//elP6d27N9OnTyccDh+31gT5oSCEuADEjR6N5YP3qV+zFjQNTaeBTg86DU2vB50OTacDnR5NrwNdZPHv30/5fz9G4Y1T6fanRRgzM6P9UYS4YJxtiJ4CjG7ZfgVYyfdCtFJqz1HbhzRNqwCSgE7V6TUnJ4cHH3yQUaNGodfrGThwIC+//DILFy5k9uzZPPnkkyQlJfHSSy+d1n2tVivffPMN8+fPJzk5mTfffPMH5xiNRt5++23uvvtuPB4PwWCQe+65h169ejF9+nQ8Hg9KKe6++24SEhJ4+OGHWbFiRWvXkauuuqr1QUSAf/mXf+Guu+4iNzeXmJgYXn755WNaoH+s1NRUHn/8ccaMGYNSikmTJjFlyhS2bNnC7NmzCYfDADz22GOEQqHj1iqEEBeKmMRE7Ndec1rXWIcOxdS7NyX/+n8pvHEq6QsXYB069BxVKIQ4mnY205BqmlarlEpo2daAmiOvT3D+UCJhO0cpFW7pzjEcaAa+AO5XSjWf4No7gDsAMjIyBn+/L+7OnTvp27fvGX+W9spms+Hz+aJdhjgPOuv3sBDi3PMfPEjxnXfhLy4m9be/JeH666JdkhCdgqZpG5RS+cc7dsoHCzVN+1zTtG3HWaYcfZ6KpPETJnJN01KBvwKzlVLhlt0PAH2AIYCTH3YFOfr+Lyil8pVS+UlJSacqWwghhLhgGDMyyHzjdWIHD6bsgQeoeOYZVDh86guFEGfslN05lFLjT3RM07RyTdNSlVJlLSG54gTnxQPLgAeVUmuPuveRPgTNmqa9BPzHaVV/AZBWaCGEED+G3m4n488vcPi3v8W96E/4i4pIe+wxdD/ywXEhxOk52yHu3gdmtWzPApZ+/wRN04zAu8Cr33+AsCV4H+kKch2w7SzrEUIIIS5YmsFAym9/S/J99+H95FOKZs0iWFUV7bKE6JTONkQ/DkzQNG0vML7lNZqm5WuatrjlnJ8DlwO3aJq2uWU5MhTEa5qmbQW2AonA/LOsRwghhLigaZqG67ZbSV/wLM2791D48xtp2rPn1BcKIU7LWT1YGC35+flq/fr1x+yTh7JERyffw0KItta4bTsld91FuKGB9GeewTbyh8OkCiFO7GQPFspMFkIIIUQnZemfQ+b/vEXxnXdRfOedpDz0II6bbmo9rgIBgtXVBKuqCLndBCurCLrdBKsqCVW5CbrdhBsasA4fTvykqzH16nXMpF9CXMgkRJ9jt99+O/feey/9+vX7UeevX7+eV199lQULFvDyyy+zfv16nnvuuR/9fkdfv3LlSoxGI5deeumPvn7evHnYbDb+4z/kGU8hhOgMDCkpdP/b3zj07//O4d/8ltp33yPcUE+oyk2o9vhTNuhiY9EnJhLjcqGZjLj/8hfcL7yA8aIexF99Nfarr5aJXcQFT0L0ObZ48eJTn3SU/Px88vOP+1eDUwoGg8dcv3LlSmw222mFaCGEEJ2P3mal6x+ep3LhQhq+/gZTVhb6/HxiEpOISXShd7mISUyMLC4XutjYY64Put14//d/8SxbRtWChVQtWIg5J4f4q68m/uqrMKSmRumTCRE9Z/tgoWhRX1/PpEmTuPjii+nfv3/rzIKjR4/mSP9tm83GfffdR05ODuPHj+ebb75h9OjRZGdn8/777wOR4HvNNT+cseqDDz7gkksuYeDAgYwfP57y8nIg0nI8Y8YMRowYwYwZM1qvLywsZNGiRTz99NPk5eWxevVqsrKyCAQCANTV1R3z+ng2b97MsGHDGDBgANdffz01NTUALFiwgH79+jFgwACmTp0KwJdffkleXh55eXkMHDgQr9fbRl9ZIYQQbUHT60m+5x4y33idrgsXkjpvHkn/919xTJ1K/IQJxA4ciLFbtx8EaIAYlwvHTTeR+be/cdHKFSTPnQuaRsWTT7JvzFgKp02n+rXXZCQQcUHplC3Rv/vmd+yq3tWm9+zj7MPcoSecC4ZPPvmEtLQ0li1bBoDH4/nBOfX19YwdO5Ynn3yS66+/noceeojPPvuMHTt2MGvWLCZPnnzC+1922WWsXbsWTdNYvHgxTzzxBE899RQAO3bs4KuvvsJisbBy5UoAMjMzufPOO4/pmjF69GiWLVvGddddx5IlS/jJT36CwWA44XvOnDmThQsXMmrUKB555BF+85vf8Mwzz/D4449TUFCAyWSituVPgb///e95/vnnGTFiBD6fD7OMSyqEEJ2SISUF1+xbcM2+BX9REXUff0zdso8o/6/5lD/631iHDcM2Zgyx+YMjfaj1+miXLMQ5IS3RbSQ3N5fPPvuMuXPnsnr1aux2+w/OMRqNTJw4sfX8UaNGYTAYyM3NpbCw8KT3Lykp4corryQ3N5cnn3yS7du3tx6bPHkyFovllDXefvvtvPTSSwC89NJLzJ49+4TnejweamtrGTVqFACzZs1i1apVAAwYMIBp06bxt7/9jZiYyO9hI0aM4N5772XBggXU1ta27hdCCNF5Gbt3J/HOO8n+4H2y3l+K645f4C8pofzRRym4/ifsuWQYB++4g6pFf6Jh/XrCzc3RLlmINtMpk87JWozPlV69erFx40Y++ugjHnroIcaNG8cjjzxyzDkGg6H1qWadTofJZGrdDgaDJ73/nDlzuPfee5k8eTIrV65k3rx5rcesVuuPqnHEiBEUFhaycuVKQqEQ/fv3P41P+J1ly5axatUqPvjgAx599FG2bt3K/fffz6RJk/joo48YMWIEn376KX369Dmj+wshhOh4zL16Ye7Vi+R77iFQWkrDhg00rN9Aw4YNVK5aDUQmgzEPGEDs4MHEDh6EZdAg9HFxUa5ciDPTKUN0NBw6dAin08n06dNJSEg47QcKT8Xj8ZCeng7AK6+88qOuiYuLo66u7ph9M2fO5Oabb+bhhx8+6bV2ux2Hw8Hq1asZOXIkf/3rXxk1ahThcJji4mLGjBnDZZddxpIlS/D5fLjdbnJzc8nNzWXdunXs2rVLQrQQQlygDOnp2NPTsbd0UwzW1NC4cWNrqHa/+CLuF14ATcPUuzfWSy4h4cafY8rOjnLlQvx4EqLbyNatW7nvvvvQ6XQYDAb++Mc/tun9582bx89+9jMcDgdjx46loKDglNdce+213HDDDSxdupSFCxcycuRIpk2bxkMPPcRNR40TeiKvvPIKd955Jw0NDWRnZ/PSSy8RCoWYPn06Ho8HpRR33303CQkJPPzww6xYsQKdTkdOTg5XXXVVW3xsIYQQnUCMw0HcuHHEjRsHQLihgcZvv20J1eupef11ql95BevlI3HOmoX10ktlPGrR7smMhReYt99+m6VLl/LXv/412qWI75HvYSHEhSrodlOzZAk1bywhVFWFqedFOGbOxH7ttejkQXURRSebsVAeLLyAzJkzh/vvv/+UXTmEEEKI8ynG5SLpX/+Vi5Z/Qepjj4E+hsMPP8K+MWOpePZZAhUV0S5RiB/4/+3deVxV1drA8d/icGR0QETEQNBSUUZFcLqoaHkt7S0tp6zQUkvNJl/Kei2za91e82ZZltdbqZWWU73e1OqWeS92NQcIhxRxCBVRQRQVAZme949z5DoHCaGH5/v5nA97WHuvtfc6bB+Wa6+lLdFKXSf0O6yUUjYiQv7GTRyfP5+8NWvA2Zn6d9xOw/h4XCs4A7BSVeFqLdHaJ1oppZRS1xVjDB4dY/DoGENRejrHP1lA7uefc3L533Hv0IGGw+Nx79QZi2fFRqdSqjpoEK2UUkqp61adoCCaTPoffB4fT+7SZRz/5GMyHhsPgFP9+lj9/P7zaeqHs58fVr+mtmUfH53sRVUbDaKVUkopdd2z1KuH90MjaPjgA+StXUvR3r0UZx6m+LDtk5+cTNnFswVbLFh9fXH286NOUCDuUR1wj4mhjv9NNXMRyqFoEK2UUkqpG4ZxdqZuXBzExV2yrzTvDCVH7IF15mGKD2dSYl/O+241J5d9DoBzUz88omNwj4nGPSYGq7//dT+knhQXkz3zbawB/jQYOPC6L29toEF0FcnNzWXhwoWMHTv2qunS09NZt24d991336+m69evHyJ0wGkAABfsSURBVNu3b6/QdqWUUqq2s3h6YLnlFlxuueWSfVJWxtnde8jftIn8jRvJS0zk5PLlADg3aYJ7dDTuMdF4REdjDQy8roLUsjNnyHjyKc6stc38WJCUTJMpL+nwfzVMg+gqkpuby7vvvluhIHrhwoW/GkQrpZRSquoYJydcW7fCtXUrGt4/DBGhaO9ezmzcSP6mTZxZt45TX34JgLOPD+4xMbhFRuIWHoZLcDBOLi41Uu6S48c5+MijFP78M02mTKEkO5tj77xD4e40/Ge+rV1TapAG0VVk4sSJ7N27l8jISG677TamTZvGM888w1dffYUxhkmTJjF48GAmTpzIzp07iYyMJD4+nv79+/PAAw9w5swZAN555x26dOlSoTwLCwsZM2YMmzdvxtnZmTfeeIO4uDh+/vlnRowYQVFREWVlZSxbtoymTZsyaNAgMjIyKC0t5YUXXmDw4MHVeUuUUkqp65YxBhd7q3XD++6zBdW//EL+RltLdf6mTZxaudKW2GrFtXVr3MLDcQ0Pwy08nDpBQRin6p1uoyjjEAcffpjiI0fwf3tm+YyPriFtyXzmWdLvvZeb3vgLHhWMG1TVcsgg+sirr3J2Z2qVntOlTTBNnn/+ivtfe+01tm/fTkpKCgDLli0jJSWFLVu2cOzYMaKjo+nWrRuvvfYa06dPZ8WKFQDk5+fz7bff4urqyu7duxk6dCgXj4F9JbNmzcIYw7Zt20hNTaV3796kpaUxe/ZsnnjiCYYNG0ZRURGlpaWsWrWKpk2bstL+QDh58csXSimlVC1mjMGlRQtcWrTAa4itkan46FEKtm6lcOs2CrZu5eTy5ZxYuBAAJ09PXMNCcQsLxy08DNewcKy+jausPIWpqRwYNQopKqbZ3A9xb9++fF/duDiaL1lMxvjxHBg5isZPP0XDhx++rrqg1AYOGURfD3744QeGDh2KxWLB19eX7t27s2nTJurVq3dBuuLiYh577DFSUlKwWCykpaVVKo/x423D/AQHBxMYGEhaWhqdO3fmlVdeISMjgwEDBtCyZUvCwsKYMGECzz77LP369SM2NrZKr1cppZRyNFZfX6y33Ua9224DQEpLKfrlFwq2bqNgmy24zvnwQygpAcClTRt8xo/HM67HNQW0ZzZsJGPcOJw8PQn85ENcWra8JE2doCCCPvuMzEmTyJr+Fwq2bcfvlVd07OzfkUMG0VdrMb7ezJgxA19fX7Zs2UJZWRmuVfCSwH333UfHjh1ZuXIld9xxB3/961/p2bMnycnJrFq1ikmTJtGrVy9efPHFKrgCpZRSqnYwFkt5F5AGA/oDUFZYSOHOnRSkbOHEZ5+SMXYsrhHhNH7qKTw6dap0Hqe+/obMhASszZrR7P2/YfXzu2JaJw8PbnrjDY6HhpH1l79wdu8e/N9+G5fmzX/zNaqKq97OPLVI3bp1OX36dPl6bGwsixYtorS0lOzsbBITE4mJibkk3cmTJ/Hz88PJyYmPP/6Y0tLSCucZGxvLggULAEhLS+PAgQO0bt2affv20aJFCx5//HHuuusutm7dSmZmJu7u7tx///0kJCSQnJxcdRevlFJK1VJOrq64t2uH94jh3LxiBU3+9DIlR7M4MHwE+4ePoMDezbMiji9cyKGnnsI1NJSgBZ9cNYA+xxiD98MP0eyD9yk9lkP6wEGc/v77a7kkVUEaRFcRb29vunbtSmhoKAkJCfTv35/w8HAiIiLo2bMn06ZNo0mTJoSHh2OxWIiIiGDGjBmMHTuW+fPnExERQWpqKh4eFf9vmLFjx1JWVkZYWBiDBw9m3rx5uLi4sHjxYkJDQ4mMjGT79u08+OCDbNu2jZiYGCIjI5kyZQqTJk2qxruhlFJK1T7GasVr4EBu/uZrfJ9/jrNpaaQPGcrBMWMp3LXriseJCFlvvcXRl/+EZ48eNPvwAywNGlQqb4/OnWm+bCl1AgPJGDuO7JlvI2Vl13pJ6iqMiNR0GSqtQ4cOcvHLdzt37qRNmzY1VCKlrp1+h5VSyrGUnTnD8Y8/IeeDDyjLy6Pe7bfTaPxjF3S3kJISjkyZQu6SpdS/9x78XnoJ4/zbe9uWFRZyZMrLnPziCzy6d+Om11/HctH7WFWprKgISkpwcnevtjxqkjEmSUQ6XG6fQ/aJVkoppZSqaU4eHjR69BG8hg4h58O5HP/oI0598w31+9+Nz9ixWBo25NDTE8j7/nu8xzyKz+OPX/MIG06urvi9+gpu4WEcefXP7Ot3Jx6xf8C9fRTuUe2veSIZKSqiYPt28jds4MyGjRT89BMYQ4OBA/F+aESFuqA4Cm2JVuo6od9hpZRybCXHjnFszhxyP/0MAKu/P0Xp6fhO+h8aDhtW5fnl//QTOX97n4KkJErtQ9tavL1xb98et/btcY9qj2ubNhir9YrnkJISCnfs4MyGDeRv2Eh+UhJSUACAS3AwHh1jKD11mpNffgnGUP+/7sR75EiHebnxai3R1xxEG2MaAouAICAdGCQiJy5KEwh8ga0PthV4W0Rm2/dFAfMAN2AV8IT8SqE0iFaOSL/DSilVOxRnZnLsvfc4/Y9vaTJlCvX6/LFa85OyMttEMklJFCQlk5+cTPHBgwAYNzfcwsNxj2qPW/so3MLDKDp40BYwb9hAflISZXl5ALi0vAX3mI64d4zBPToaZy+vC64p58O55C5ZghQVUfePf6TR6FG4tm1brddW3ao7iJ4GHBeR14wxEwEvEXn2ojR17HmdNcZ4AtuBLiKSaYzZCDwObMAWRM8Uka+ulqcG0coR6XdYKaXU76U4K4uC5J/IT7YF1oU7d8JFLyLWCQrCvWNHPDrG4B4Tg3OjRr963pKcHI7P/4gTCxdSlpeHR2wsjR4ZjXuHy8ah173qDqJ3AT1E5LAxxg/4p4i0vkp6b+AnoBMgwBoRCbbvG2o/1yNXy1ODaOWI9DuslFKqppTmnaFw6xYKtm7DelNT3GNisPr6/vbznT7NiYWfcnz+fEqPH8ctKopGo0fh0a3bDTWzYnW/WOgrIofty0eAy95xY0wAsBK4BUiwt0J3ADLOS5YB3FQFZVJKKaWUUhVk8fTAo0sXPLp0qZrz1a1Lo0dG0/DBB8hd9jk5H3zAwUcexSU4mEajR+HZsydOVTDBXE2q0DjRxpjvjDHbL/O56/x09r7Ml23aFpGDIhKOLYiON8ZU6s8bY8xoY8xmY8zm7Ozsyhxao958803y8/Or7HxBQUEcO3bsNx8/b948HnvssWrNp8uv/ALm5uby7rvvlq9nZmZy7733/qa8Kmrt2rWEhIQQGRlJgf2FiHM8PT2rNW+llFKqtnJyc6Ph/cO45Zuv8Xv1VeTsWQ49PYG0jp04MHIUOfPmcXbPHm7EgS4qFESLyK0iEnqZz3LgqL0bB/afWb9yrkxsfaJjgUOA/3m7/e3bLnfcHBHpICIdfHx8KlLs60JVB9GVVZkZEKvKunXrrrr/4iC6adOmLF26tFrLtGDBAp577jlSUlJwc3Or1ryUUkopdSFTpw4NBvSnxYovCfjb32gweBDFmZlkvfa/7Ot3J3t69iJz0iROff11+Ugi17uqmLHw70C8fTkeWH5xAmOMvzHGzb7sBfwB2GXvBnLKGNPJ2DrIPHi5428EZ86coW/fvkRERBAaGsqiRYuYOXMmmZmZxMXFERcXB8CYMWPo0KEDISEhTJ48ufz4oKAgJk+eTPv27QkLCyM1NRWAnJwcevfuTUhICCNHjrzgL7W7776bqKgoQkJCmDNnTvl2T09PJkyYQEREBOvXr2fu3Lm0atWKmJgY/v3vf1+2/FfL55NPPimf7fCRRx6htLSU2bNnk5CQUJ7m/Bbucy27eXl59OrVq/yali+3Ve3EiRPZu3cvkZGRJCQkkJ6eTmhoKACFhYWMGDGCsLAw2rVrx5o1a8rPP2DAAPr06UPLli155plnLnsdq1evpl27doSFhfHQQw9x9uxZ3n//fRYvXswLL7zAsKsMISQiJCQkEBoaSlhYGIsWLQLg8OHDdOvWjcjISEJDQ1m7di2lpaUMHz68PO2MGTMA2Lt3L3369CEqKorY2NjyelyyZAmhoaFERETQrVu3K5ZBKaWUcmTGYsEz9g80ef55bl61kltWf0eTl6fgFhbG6W/+waEnnyKtcxfShwwl+51ZFKSkIDXQIFghInJNH8AbWA3sBr4DGtq3dwDety/fBmwFtth/jj7v+A7YWqb3Au9gf9nxap+oqCi52I4dO8qXExftks+nJ1XpJ3HRrkvyPN/SpUtl5MiR5eu5ubkiIhIYGCjZ2dnl23NyckREpKSkRLp37y5btmwpTzdz5kwREZk1a5Y8/PDDIiIyfvx4mTJlioiIrFixQoDy8507V35+voSEhMixY8dEbDdVFi1aJCIimZmZEhAQIFlZWXL27Fnp0qWLjBs37pLyXymfHTt2SL9+/aSoqEhERMaMGSPz58+XrKwsufnmm8uP79Onj6xdu1ZERDw8PEREpLi4WE6ePCkiItnZ2XLzzTdLWVmZ/PLLLxISElJ+7Pnr06dPlxEjRoiIyM6dOyUgIEAKCgpk7ty50rx5c8nNzZWCggJp1qyZHDhw4IJrKCgoEH9/f9m1y1ZXDzzwgMyYMUNEROLj42XJkiWXqbn/lHfp0qVy6623SklJiRw5ckQCAgIkMzNTpk+fLlOnTi2vt1OnTsnmzZvl1ltvLT/HiRMnRESkZ8+ekpaWJiIiP/74o8TFxYmISGhoqGRkZFyQ9mLnf4eVUkqp2qasuFjOJCVJ1ltvyb6Bg2RHcBvZ0TpYUmM6yuGX/1QjZQI2yxXi0Wt+sVBEcoBel9m+GRhpX/4WCL/C8ZuB0GstR00LCwtjwoQJPPvss/Tr14/Y2NjLplu8eDFz5syhpKSEw4cPs2PHDsLDbbdmwIABAERFRfH5558DkJiYWL7ct29fvM4bk3HmzJl88cUXABw8eJDdu3fj7e2NxWLhnnvuAWDDhg306NGDc11gBg8eTFpa2iXlulI+q1evJikpiejoaAAKCgpo3LgxPj4+tGjRgh9//JGWLVuSmppK165dLziniPD888+TmJiIk5MThw4d4ujRo1e9jz/88APjx48HIDg4mMDAwPLy9urVi/r16wPQtm1b9u/fT0BAQPmxu3btonnz5rRq1QqA+Ph4Zs2axZNPPnnVPM/Pe+jQoVgsFnx9fenevTubNm0iOjqahx56iOLiYu6++24iIyNp0aIF+/btY/z48fTt25fevXuTl5fHunXrGDhwYPk5z549C0DXrl0ZPnw4gwYNKq9npZRSSv2HcXbGvX173Nu3x+fxxyk5cYL89evJ++HfOLldfy8hOuS037GDWv3uebZq1Yrk5GRWrVrFpEmT6NWrFy+++OIFaX755RemT5/Opk2b8PLyYvjw4RQWFpbvd3FxAcBisVBSUnLV/P75z3/y3XffsX79etzd3enRo0f5uVxdXbFYLFVyXSJCfHw8f/7zny/ZN2TIEBYvXkxwcDD9+/e/ZMiaBQsWkJ2dTVJSElarlaCgoAuut7LO3R+o2D2qKt26dSMxMZGVK1cyfPhwnn76aR588EG2bNnCN998w+zZs1m8eDFvvvkmDRo0ICUl5ZJzzJ49mw0bNrBy5UqioqJISkrC29v7dym/UkopdSNy9vKi3h13UO+OO2q6KJdVFX2iFbYRJtzd3bn//vtJSEggOTkZgLp163L69GkATp06hYeHB/Xr1+fo0aN89dVV55QBbAHcwoULAfjqq684ccI2GeTJkyfx8vLC3d2d1NRUfvzxx8se37FjR/71r3+Rk5NDcXExS5YsqVQ+vXr1YunSpWRl2d4XPX78OPv37wegf//+LF++nE8//ZQhQ4Zccs6TJ0/SuHFjrFYra9asKT/u/HtysdjYWBYsWABAWloaBw4coHXrKw47foHWrVuTnp7Onj17APj444/p3r17hY49l/eiRYsoLS0lOzubxMREYmJi2L9/P76+vowaNYqRI0eSnJzMsWPHKCsr45577mHq1KkkJydTr149mjdvXn6PRYQtW7YAtr7SHTt25OWXX8bHx4eD9pmilFJKKXVjcsiW6Jqwbds2EhIScHJywmq18t577wEwevRo+vTpQ9OmTVmzZg3t2rUjODiYgICAS7o/XM7kyZMZOnQoISEhdOnShWbNmgHQp08fZs+eTZs2bWjdujWdOnW67PF+fn689NJLdO7cmQYNGhAZGVmpfNq2bcvUqVPp3bs3ZWVlWK1WZs2aRWBgIF5eXrRp04YdO3YQExNzyTmHDRvGnXfeSVhYGB06dCA4OBgAb29vunbtSmhoKLfffjvjxo0rP2bs2LGMGTOGsLAwnJ2dmTdv3gUt0Ffj6urK3LlzGThwICUlJURHR/Poo49W6Fiw/VGwfv16IiIiMMYwbdo0mjRpwvz583n99dexWq14enry0UcfcejQIUaMGEGZfXancy31CxYsYMyYMUydOpXi4mKGDBlCREQECQkJ7N69GxGhV69eREREVLhcSimllLr+XPOMhTVBZyxUjki/w0oppdT15WozFmp3DqWUUkoppSpJg2illFJKKaUqSYNopZRSSimlKsmhgugbsX+3UqDfXaWUUupG4zBBtKurKzk5ORqMqBuOiJCTk4Or6/U3kLxSSimlLs9hhrjz9/cnIyOD7Ozsmi6KUpXm6uqKv79/TRdDKaWUUhXkMEG01WqlefPmNV0MpZRSSilVCzhMdw6llFJKKaV+LxpEK6WUUkopVUkaRCullFJKKVVJN+S038aYbGB/DWTdCDhWA/mqmqH1XftondcuWt+1i9Z37VJV9R0oIj6X23FDBtE1xRiz+UrzpyvHo/Vd+2id1y5a37WL1nft8nvUt3bnUEoppZRSqpI0iFZKKaWUUqqSNIiunDk1XQD1u9L6rn20zmsXre/aReu7dqn2+tY+0UoppZRSSlWStkQrpZRSSilVSRpEV5Axpo8xZpcxZo8xZmJNl0dVLWPMh8aYLGPM9vO2NTTGfGuM2W3/6VWTZVRVxxgTYIxZY4zZYYz52RjzhH271rkDMsa4GmM2GmO22Ot7in17c2PMBvtzfZExpk5Nl1VVHWOMxRjzkzFmhX1d69uBGWPSjTHbjDEpxpjN9m3V+kzXILoCjDEWYBZwO9AWGGqMaVuzpVJVbB7Q56JtE4HVItISWG1fV46hBJggIm2BTsA4+++01rljOgv0FJEIIBLoY4zpBPwvMENEbgFOAA/XYBlV1XsC2Hneuta344sTkcjzhrar1me6BtEVEwPsEZF9IlIEfAbcVcNlUlVIRBKB4xdtvguYb1+eD9z9uxZKVRsROSwiyfbl09j+ob0JrXOHJDZ59lWr/SNAT2CpfbvWtwMxxvgDfYH37esGre/aqFqf6RpEV8xNwMHz1jPs25Rj8xWRw/blI4BvTRZGVQ9jTBDQDtiA1rnDsv/XfgqQBXwL7AVyRaTEnkSf647lTeAZoMy+7o3Wt6MT4B/GmCRjzGj7tmp9pjtX5cmUclQiIsYYHcrGwRhjPIFlwJMicsrWWGWjde5YRKQUiDTGNAC+AIJruEiqmhhj+gFZIpJkjOlR0+VRv5s/iMghY0xj4FtjTOr5O6vjma4t0RVzCAg4b93fvk05tqPGGD8A+8+sGi6PqkLGGCu2AHqBiHxu36x17uBEJBdYA3QGGhhjzjUm6XPdcXQF/ssYk46t+2VP4C20vh2aiByy/8zC9odyDNX8TNcgumI2AS3tb/bWAYYAf6/hMqnq93cg3r4cDyyvwbKoKmTvH/kBsFNE3jhvl9a5AzLG+NhboDHGuAG3YesHvwa4155M69tBiMhzIuIvIkHY/r3+XkSGofXtsIwxHsaYuueWgd7Adqr5ma6TrVSQMeYObH2sLMCHIvJKDRdJVSFjzKdAD6ARcBSYDPwfsBhoBuwHBonIxS8fqhuQMeYPwFpgG//pM/k8tn7RWucOxhgTju2lIgu2xqPFIvKyMaYFtpbKhsBPwP0icrbmSqqqmr07x3+LSD+tb8dlr9sv7KvOwEIRecUY4001PtM1iFZKKaWUUqqStDuHUkoppZRSlaRBtFJKKaWUUpWkQbRSSimllFKVpEG0UkoppZRSlaRBtFJKKaWUUpWkQbRSSimllFKVpEG0UkoppZRSlaRBtFJKKaWUUpX0/yuqSLFheaamAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('옛날 귀여운 여자 태어났고 무럭무럭 자라서 마음씨 고운 소녀가 되었어요.',\n",
              "  4.159156799316406,\n",
              "  0.8053343781928117,\n",
              "  0.33333333333333337),\n",
              " ('옛날 귀여운 여자 태어났고 무럭무럭 자라서 마음씨 고운 소녀가 되었어요.',\n",
              "  4.159156799316406,\n",
              "  0.8053343781928117,\n",
              "  0.33333333333333337),\n",
              " ('옛날 귀여운 여자 태어났고 무럭무럭 자라서 마음씨 고운 소녀가 되었어요.',\n",
              "  4.159156799316406,\n",
              "  0.8053343781928117,\n",
              "  0.33333333333333337),\n",
              " ('옛날 귀여운 여자 태어났고 무럭무럭 자라서 마음씨 고운 소녀가 되었어요.',\n",
              "  4.159156799316406,\n",
              "  0.8053343781928117,\n",
              "  0.33333333333333337),\n",
              " ('옛날 귀여운 여자 태어났고 무럭무럭 자라서 마음씨 고운 소녀가 되었어요.',\n",
              "  4.159156799316406,\n",
              "  0.8053343781928117,\n",
              "  0.33333333333333337),\n",
              " ('옛날 귀여운 여자 태어났고 무럭무럭 자라서 마음씨 고운 소녀가 되었어요.',\n",
              "  4.159156799316406,\n",
              "  0.8053343781928117,\n",
              "  0.33333333333333337),\n",
              " ('옛날 귀여운 여자 태어났고 무럭무럭 자라서 마음씨 고운 소녀가 되었어요.',\n",
              "  4.159156799316406,\n",
              "  0.8053343781928117,\n",
              "  0.33333333333333337),\n",
              " ('옛날 귀여운 여자 태어났고 무럭무럭 자라서 마음씨 고운 소녀가 되었어요.',\n",
              "  4.159156799316406,\n",
              "  0.8053343781928117,\n",
              "  0.33333333333333337),\n",
              " ('옛날 귀여운 여자 태어났고 무럭무럭 자라서 마음씨 고운 소녀가 되었어요.',\n",
              "  4.159156799316406,\n",
              "  0.8053343781928117,\n",
              "  0.33333333333333337),\n",
              " ('옛날 귀여운 여자 태어났고 무럭무럭 자라서 마음씨 고운 소녀가 되었어요.',\n",
              "  4.159156799316406,\n",
              "  0.8053343781928117,\n",
              "  0.33333333333333337),\n",
              " ('옛날 귀여운 여자 태어났고 무럭무럭 자라서 마음씨 고운 소녀가 되었어요.',\n",
              "  4.159156799316406,\n",
              "  0.8053343781928117,\n",
              "  0.33333333333333337),\n",
              " ('옛날 귀여운 여자 태어났고 무럭무럭 자라서 마음씨 고운 소녀가 되었어요.',\n",
              "  4.159156799316406,\n",
              "  0.8053343781928117,\n",
              "  0.33333333333333337),\n",
              " ('옛날 귀여운 여자 태어났고 무럭무럭 자라서 마음씨 고운 소녀가 되었어요.',\n",
              "  4.159156799316406,\n",
              "  0.8053343781928117,\n",
              "  0.33333333333333337),\n",
              " ('옛날 귀여운 여자 태어났고 무럭무럭 자라서 마음씨 고운 소녀가 되었어요.',\n",
              "  4.159156799316406,\n",
              "  0.8053343781928117,\n",
              "  0.33333333333333337),\n",
              " ('옛날 귀여운 여자 태어났고 무럭무럭 자라서 마음씨 고운 소녀가 되었어요.',\n",
              "  4.159156799316406,\n",
              "  0.8053343781928117,\n",
              "  0.33333333333333337),\n",
              " ('옛날 귀여운 여자 태어났고 무럭무럭 자라서 마음씨 고운 소녀가 되었어요.',\n",
              "  4.159156799316406,\n",
              "  0.8053343781928117,\n",
              "  0.33333333333333337),\n",
              " ('옛날 귀여운 여자 태어났고 무럭무럭 자라서 마음씨 고운 소녀가 되었어요.',\n",
              "  4.159156799316406,\n",
              "  0.8053343781928117,\n",
              "  0.33333333333333337),\n",
              " ('옛날 귀여운 여자 태어났고 무럭무럭 자라서 마음씨 고운 소녀가 되었어요.',\n",
              "  4.159156799316406,\n",
              "  0.8053343781928117,\n",
              "  0.33333333333333337),\n",
              " ('옛날 귀여운 여자 태어났고 무럭무럭 자라서 마음씨 고운 소녀가 되었어요.',\n",
              "  4.159156799316406,\n",
              "  0.8053343781928117,\n",
              "  0.33333333333333337),\n",
              " ('옛날 귀여운 여자 태어났고 무럭무럭 자라서 마음씨 고운 소녀가 되었어요.',\n",
              "  4.159156799316406,\n",
              "  0.8053343781928117,\n",
              "  0.33333333333333337),\n",
              " ('옛날 귀여운 여자 태어났고 무럭무럭 자라서 마음씨 고운 소녀가 되었어요.',\n",
              "  4.159156799316406,\n",
              "  0.8053343781928117,\n",
              "  0.33333333333333337),\n",
              " ('옛날 귀여운 여자 태어났고 무럭무럭 자라서 마음씨 고운 소녀가 되었어요.',\n",
              "  4.159156799316406,\n",
              "  0.8053343781928117,\n",
              "  0.33333333333333337),\n",
              " ('옛날 귀여운 여자 태어났고 무럭무럭 자라서 마음씨 고운 소녀가 되었어요.',\n",
              "  4.159156799316406,\n",
              "  0.8053343781928117,\n",
              "  0.33333333333333337),\n",
              " ('옛날 귀여운 여자 태어났고 무럭무럭 자라서 마음씨 고운 소녀가 되었어요.',\n",
              "  4.159156799316406,\n",
              "  0.8053343781928117,\n",
              "  0.33333333333333337),\n",
              " ('옛날 귀여운 여자 태어났고 무럭무럭 자라서 마음씨 고운 소녀가 되었어요.',\n",
              "  4.159156799316406,\n",
              "  0.8053343781928117,\n",
              "  0.33333333333333337),\n",
              " ('옛날 귀여운 여자 태어났고 무럭무럭 자라서 마음씨 고운 소녀가 되었어요.',\n",
              "  4.159156799316406,\n",
              "  0.8053343781928117,\n",
              "  0.33333333333333337),\n",
              " ('옛날 귀여운 여자 태어났고 무럭무럭 자라서 마음씨 고운 소녀가 되었어요.',\n",
              "  4.159156799316406,\n",
              "  0.8053343781928117,\n",
              "  0.33333333333333337),\n",
              " ('옛날 귀여운 여자 태어났고 무럭무럭 자라서 마음씨 고운 소녀가 되었어요.',\n",
              "  4.159156799316406,\n",
              "  0.8053343781928117,\n",
              "  0.33333333333333337),\n",
              " ('옛날 귀여운 여자 태어났고 무럭무럭 자라서 마음씨 고운 소녀가 되었어요.',\n",
              "  4.159156799316406,\n",
              "  0.8053343781928117,\n",
              "  0.33333333333333337),\n",
              " ('옛날 귀여운 여자 태어났고 무럭무럭 자라서 마음씨 고운 소녀가 되었어요.',\n",
              "  4.159156799316406,\n",
              "  0.8053343781928117,\n",
              "  0.33333333333333337),\n",
              " ('옛날 귀여운 여자 태어났고 무럭무럭 자라서 마음씨 고운 소녀가 되었어요.',\n",
              "  4.159156799316406,\n",
              "  0.8053343781928117,\n",
              "  0.33333333333333337),\n",
              " ('옛날 귀여운 여자 태어났고 무럭무럭 자라서 마음씨 고운 소녀가 되었어요.',\n",
              "  4.159156799316406,\n",
              "  0.8053343781928117,\n",
              "  0.33333333333333337)]"
            ]
          },
          "metadata": {},
          "execution_count": 350
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "0S301yeelEvG"
      },
      "source": [
        "full_text = \"\"\"\n",
        "옛날 어느 집에 귀여운 여자 아기가 태어났어요.\n",
        "아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요.\n",
        "그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요.\n",
        "소녀의 아버지는 홀로 남은 소녀가 걱정되었어요.\n",
        "그래서 얼마 지나서 새어머니를 맞이했어요.\n",
        "새어머니는 소녀보다 나이가 위인 두명의 딸을 데리고 왔어요.\n",
        "그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요.\n",
        "새어머니는 소녀가 자기 딸들보다 예쁘고 착한게 못마땅했어요.\n",
        "그런데 이번에는 아버지마저 돌아가셨어요.\n",
        "소녀는 쓸고, 닦고, 하녀처럼 하루 종일 집안일을 도맡아 했어요.\n",
        "집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했어요.\n",
        "그러던 어느날, 왕궁에서 무도회가 열렸어요.\n",
        "신데렐라의 집에도 무도회 초대장이 왔어요.\n",
        "새어머니는 언니들을 데리고 무도회장으로 떠났어요.\n",
        "신데렐라도 무도회에 가고 싶었어요.\n",
        "혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요.\n",
        "그때 어디선가 마법사 할머니가 나타났어요.\n",
        "신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요.\n",
        "할머니는 소녀를 무도회에 보내줄테니 호박 한개와 생쥐 두마리, 도마뱀을 가지고 오라 했어요.\n",
        "마법사 할머니가 이것들을 보면서 주문을 외웠어요.\n",
        "그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금마차로 변했어요.\n",
        "이번에는 생쥐와 도마뱀을 건드렸어요.\n",
        "그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했어요.\n",
        "신데렐라의 낡은 옷은 구슬 장식이 반짝이는 예쁜 드레스로 바뀌었어요.\n",
        "할머니는 신데렐라에게 반짝반짝 빛나는 유리구두를 신겨 주었어요.\n",
        "그리고 밤 열두시가 되면 모든게 처음대로 돌아간다고 알려주었어요.\n",
        "황금마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼어요. \n",
        "그러니까 반드시 밤 열두시가 되기 전에 돌아와야 해요.\n",
        "신데렐라는 황금마차를 타고 왕궁 무도회장으로 가서 멋진 왕자님을 만났어요.\n",
        "왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요.\n",
        "왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고 신데렐라하고만 춤을 추었어요.\n",
        "신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요.\n",
        "어느덧 시간이 흘러 열두시가 되었어요. \n",
        "벽시계의 열두시를 알리는 종소리에 신데렐라는 화들짝 놀랐어요.\n",
        "신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리구두 한짝이 벗겨졌어요.\n",
        "하지만 구두를 주울 시간이 없었어요.\n",
        "신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리구두 한짝을 주웠어요.\n",
        "왕자님은 유리구두를 가지고 임금님께 가서 말했어요.\n",
        "이 유리구두의 주인과 결혼하겠어요.\n",
        "그래서 신하들은 유리구두의 주인을 찾아 온 나라를 돌아다녔어요.\n",
        "드디어 신데렐라의 집에까지 신하들이 도착했어요.\n",
        "언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리구두는 너무 작았어요.\n",
        "그때 신데렐라가 조용히 다가와 자기도 한번 신어보게 해달라고 부탁했어요.\n",
        "신데렐라는 신하에게서 받은 유리구두를 신었어요.\n",
        "유리구두는 신데렐라의 발에 꼭 맞았어요.\n",
        "신하들은 신데렐라를 왕궁으로 데리고 갔어요.\n",
        "그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
        "\"\"\""
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "h7mVuIMzsEdN",
        "outputId": "079448de-276a-441d-98e3-d9852c37471d"
      },
      "source": [
        "txt = \"\"\"\n",
        "옛날 어느 집에 귀여운 여자 아기가 태어났어요.\n",
        "아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요.\n",
        "\"\"\"\n",
        "hist,st = sam_wgan4(txt.strip(),display= True)\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-794dfb92ee0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0m아기는\u001b[0m \u001b[0m무럭무럭\u001b[0m \u001b[0m자라서\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m예쁘고\u001b[0m \u001b[0m마음씨\u001b[0m \u001b[0m고운\u001b[0m \u001b[0m소녀가\u001b[0m \u001b[0m되었어요\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \"\"\"\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mhist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msam_wgan4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: sam_wgan4() got an unexpected keyword argument 'display'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKZ6xV0W7cEw"
      },
      "source": [
        "# EncoderDecoderModel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1LCjLMi7bAh"
      },
      "source": [
        "pre_trained_kobert_model_name='kykim/bert-kor-base'\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_Ue51tr7rwm"
      },
      "source": [
        "from transformers import EncoderDecoderModel, BertTokenizerFast\n",
        "import torch\n",
        "\n",
        "tokenizer = BertTokenizerFast.from_pretrained(pre_trained_kobert_model_name)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERrGJOdd_zSM",
        "outputId": "9801c661-5df8-4b2d-84cb-bcac250f16b5"
      },
      "source": [
        "op = tokenizer('옛날 어느 집에 귀여운 여자 아기가 태어났어요.[SEP]아기는 무럭무럭 자라서 예쁘고 마음씨 고운 소녀가 되었어요.', return_tensors=\"pt\",padding=\"max_length\", truncation=True, max_length=64)\n",
        "print(op)\n",
        "print(\"Tokens (str)      : {}\".format([tokenizer.convert_ids_to_tokens(s) for s in op['input_ids'].tolist()[0]]))\n",
        "print(\"Tokens (int)      : {}\".format(op['input_ids'].tolist()[0]))\n",
        "print(\"Tokens (attn_mask): {}\\n\".format(op['attention_mask'].tolist()[0]))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'input_ids': tensor([[    2, 17463, 14385, 14662, 15886, 14891, 17818, 33791, 13972,  2016,\n",
            "             3, 35244,  4215,  8669,  8035,  8669, 19206,  8044, 17364, 14125,\n",
            "          8472, 26268, 18857,  8048, 17292,  2016,     3,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
            "Tokens (str)      : ['[CLS]', '옛날', '어느', '집에', '귀여운', '여자', '아기가', '태어났', '##어요', '.', '[SEP]', '아기는', '무', '##럭', '##무', '##럭', '자라', '##서', '예쁘고', '마음', '##씨', '고운', '소녀', '##가', '되었어요', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
            "Tokens (int)      : [2, 17463, 14385, 14662, 15886, 14891, 17818, 33791, 13972, 2016, 3, 35244, 4215, 8669, 8035, 8669, 19206, 8044, 17364, 14125, 8472, 26268, 18857, 8048, 17292, 2016, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Tokens (attn_mask): [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abW0juJN7zmE"
      },
      "source": [
        "## dataset 만들기...???"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8RRUZz027yPs",
        "outputId": "1e3608af-cdfd-49a5-b1db-d2dddd4da1a1"
      },
      "source": [
        "\n",
        "encoder_max_length = 64\n",
        "decoder_max_length = 64\n",
        "batch_size = 16 #4 # 64, 128\n",
        "dataset_iterator = []\n",
        "batch_counter = 0\n",
        "\n",
        "\n",
        "org_sentences = np.array(nltk.sent_tokenize(full_text.strip()))\n",
        "summary_text = []\n",
        "for i in range(0,len(org_sentences),2):\n",
        "    txt = org_sentences[i]\n",
        "    txt2 = txt\n",
        "    if i < len(org_sentences)-1:\n",
        "        txt = txt +'[SEP]'+ org_sentences[i+1]\n",
        "        txt2 += org_sentences[i+1]\n",
        "\n",
        "    #text,g,s = sam_wgan3(txt2)\n",
        "    #print(text,g,s)\n",
        "    source = Source(txt2)\n",
        "    source.set_key_rate(s_discriminator)\n",
        "\n",
        "    batch = {}\n",
        "    batch['input_ids'] = []\n",
        "    batch['attention_mask'] = []\n",
        "    batch['decoder_input_ids'] = []\n",
        "    batch['decoder_attention_mask'] = []\n",
        "    batch['labels'] = []\n",
        "    batch['reward'] = []\n",
        "    batch['combine_text'] = []\n",
        "\n",
        "    percent = (\"{0:.2f}\").format(100 * ((i+2) / float(len(org_sentences))))\n",
        "    print(f'{percent}% {i+2}/{str(len(org_sentences))}')\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        text,h = source.get_random_text(0.5)\n",
        "        loss, out= g_discriminator.transfer_learning([text],train_for = False)\n",
        "        g = out[0,1].item()\n",
        "        s = s_discriminator.similarity(text,source.org_text_emb)\n",
        "\n",
        "        inputs = g_discriminator.tokenizer(txt, padding=\"max_length\", truncation=True, max_length=encoder_max_length)\n",
        "        outputs = g_discriminator.tokenizer(text, padding=\"max_length\", truncation=True, max_length=decoder_max_length)\n",
        "\n",
        "        rwd = (g + (s-0.5)*10 + 5)/10 * 5 - 3\n",
        "\n",
        "        batch[\"input_ids\"].append(inputs.input_ids)\n",
        "        batch[\"attention_mask\"].append(inputs.attention_mask)\n",
        "        batch[\"decoder_input_ids\"].append(outputs.input_ids)\n",
        "        batch[\"decoder_attention_mask\"].append(outputs.attention_mask)\n",
        "        batch[\"labels\"].append(outputs.input_ids.copy())\n",
        "        batch[\"reward\"].append(rwd)\n",
        "        batch['combine_text'].append(text)\n",
        "\n",
        "    dataset_iterator.append(batch)\n",
        "\n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서 예쁘고 마음씨 고운 소녀가 되었어요.\n",
            "--------------------------------------------------\n",
            "4.26% 2/47\n",
            "--------------------------------------------------\n",
            "그러던 어느날 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요.\n",
            "--------------------------------------------------\n",
            "8.51% 4/47\n",
            "--------------------------------------------------\n",
            "그래서 얼마 지나서 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두명의 딸을 데리고 왔어요.\n",
            "--------------------------------------------------\n",
            "12.77% 6/47\n",
            "--------------------------------------------------\n",
            "그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한게 못마땅했어요.\n",
            "--------------------------------------------------\n",
            "17.02% 8/47\n",
            "--------------------------------------------------\n",
            "그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 쓸고 닦고 하녀처럼 하루 종일 집안일을 도맡아 했어요.\n",
            "--------------------------------------------------\n",
            "21.28% 10/47\n",
            "--------------------------------------------------\n",
            "집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했어요. 그러던 어느날 왕궁에서 무도회가 열렸어요.\n",
            "--------------------------------------------------\n",
            "25.53% 12/47\n",
            "--------------------------------------------------\n",
            "신데렐라의 집에도 무도회 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요.\n",
            "--------------------------------------------------\n",
            "29.79% 14/47\n",
            "--------------------------------------------------\n",
            "신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요.\n",
            "--------------------------------------------------\n",
            "34.04% 16/47\n",
            "--------------------------------------------------\n",
            "그때 어디선가 마법사 할머니가 나타났어요. 신데렐라가 고개를 들어보니 마법사 할머니가 빙그레 웃고 있었어요.\n",
            "--------------------------------------------------\n",
            "38.30% 18/47\n",
            "--------------------------------------------------\n",
            "할머니는 소녀를 무도회에 보내줄테니 호박 한개와 생쥐 두마리 도마뱀을 가지고 오라 했어요. 마법사 할머니가 이것들을 보면서 주문을 외웠어요.\n",
            "--------------------------------------------------\n",
            "42.55% 20/47\n",
            "--------------------------------------------------\n",
            "그리고 지팡이로 호박을 건드리자 호박이 화려한 황금마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요.\n",
            "--------------------------------------------------\n",
            "46.81% 22/47\n",
            "--------------------------------------------------\n",
            "그랬더니 생쥐는 흰말로 도마뱀은 멋진 마부로 변했어요. 신데렐라의 낡은 옷은 구슬 장식이 반짝이는 예쁜 드레스로 바뀌었어요.\n",
            "--------------------------------------------------\n",
            "51.06% 24/47\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-a6a83f3b278b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mg_discriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransfer_learning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_for\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms_discriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morg_text_emb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg_discriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"max_length\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_max_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-fe99af6fcd77>\u001b[0m in \u001b[0;36msimilarity\u001b[0;34m(self, query_text, org_text_emb)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morg_text_emb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mqueries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mquery_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_embedder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;31m#query_embeddings = self._embedder.encode(queries,show_progress_bar=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m#print(queries)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m                 \u001b[0mout_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0moutput_value\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'token_embeddings'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sentence_transformers/models/Transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mtrans_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'token_type_ids'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'token_type_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0moutput_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrans_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0moutput_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    852\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 854\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    855\u001b[0m         )\n\u001b[1;32m    856\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    527\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m                 )\n\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    412\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself_attn_past_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         )\n\u001b[1;32m    416\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    342\u001b[0m             \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m         )\n\u001b[1;32m    346\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mkey_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m             \u001b[0mvalue_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mquery_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmixed_query_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1845\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cL0pg5TF-gVC",
        "outputId": "ad941bcd-8a38-46a2-e974-51d44fd8a04f"
      },
      "source": [
        "from transformers import EncoderDecoderModel, BertTokenizerFast\n",
        "\n",
        "try:\n",
        "    del model\n",
        "    print('delete model')\n",
        "except Exception as ex:\n",
        "    pass\n",
        "\n",
        "\n",
        "model = EncoderDecoderModel.from_encoder_decoder_pretrained(pre_trained_kobert_model_name, pre_trained_kobert_model_name) # initialize Bert2Bert from pre-trained checkpoints\n",
        "\n",
        "model.config.decoder_start_token_id = tokenizer.cls_token_id\n",
        "model.config.eos_token_id = tokenizer.sep_token_id\n",
        "model.config.pad_token_id = tokenizer.pad_token_id\n",
        "model.config.vocab_size = model.config.encoder.vocab_size\n",
        "\n",
        "model.config.max_length = 142\n",
        "model.config.min_length = 56\n",
        "model.config.no_repeat_ngram_size = 3\n",
        "model.config.early_stopping = True\n",
        "model.config.length_penalty = 2.0\n",
        "model.config.num_beams = 4\n",
        "\n",
        "N_EPOCHS = 100"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "delete model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertLMHeadModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertLMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertLMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertLMHeadModel were not initialized from the model checkpoint at kykim/bert-kor-base and are newly initialized: ['bert.encoder.layer.1.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.5.crossattention.output.dense.bias', 'bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.10.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.9.crossattention.self.key.bias', 'bert.encoder.layer.6.crossattention.output.dense.weight', 'bert.encoder.layer.5.crossattention.self.key.bias', 'bert.encoder.layer.6.crossattention.self.query.weight', 'bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.11.crossattention.self.key.bias', 'bert.encoder.layer.9.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.1.crossattention.self.value.bias', 'bert.encoder.layer.3.crossattention.self.value.weight', 'bert.encoder.layer.1.crossattention.self.key.bias', 'bert.encoder.layer.8.crossattention.output.dense.bias', 'bert.encoder.layer.4.crossattention.self.value.weight', 'bert.encoder.layer.3.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.7.crossattention.self.query.weight', 'bert.encoder.layer.7.crossattention.self.query.bias', 'bert.encoder.layer.9.crossattention.self.query.weight', 'bert.encoder.layer.3.crossattention.self.key.bias', 'bert.encoder.layer.6.crossattention.self.key.weight', 'bert.encoder.layer.7.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.10.crossattention.self.query.bias', 'bert.encoder.layer.1.crossattention.self.query.bias', 'bert.encoder.layer.11.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.9.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.5.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.11.crossattention.self.key.weight', 'bert.encoder.layer.3.crossattention.self.query.weight', 'bert.encoder.layer.9.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.9.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.output.dense.weight', 'bert.encoder.layer.7.crossattention.self.key.bias', 'bert.encoder.layer.9.crossattention.self.value.weight', 'bert.encoder.layer.3.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.5.crossattention.self.query.weight', 'bert.encoder.layer.8.crossattention.self.value.weight', 'bert.encoder.layer.8.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.self.value.weight', 'bert.encoder.layer.8.crossattention.self.value.bias', 'bert.encoder.layer.4.crossattention.output.dense.weight', 'bert.encoder.layer.4.crossattention.self.value.bias', 'bert.encoder.layer.10.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.self.query.weight', 'bert.encoder.layer.11.crossattention.output.dense.weight', 'bert.encoder.layer.5.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.6.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.output.dense.bias', 'bert.encoder.layer.3.crossattention.output.dense.weight', 'bert.encoder.layer.9.crossattention.self.query.bias', 'bert.encoder.layer.11.crossattention.self.value.bias', 'bert.encoder.layer.3.crossattention.self.value.bias', 'bert.encoder.layer.7.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.output.dense.bias', 'bert.encoder.layer.5.crossattention.self.key.weight', 'bert.encoder.layer.4.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.output.dense.bias', 'bert.encoder.layer.5.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.output.dense.bias', 'bert.encoder.layer.11.crossattention.self.query.weight', 'bert.encoder.layer.8.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.11.crossattention.self.query.bias', 'bert.encoder.layer.1.crossattention.self.value.weight', 'bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.3.crossattention.self.query.bias', 'bert.encoder.layer.8.crossattention.self.key.weight', 'bert.encoder.layer.5.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.output.dense.weight', 'bert.encoder.layer.11.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.self.key.weight', 'bert.encoder.layer.10.crossattention.self.value.bias', 'bert.encoder.layer.7.crossattention.output.dense.bias', 'bert.encoder.layer.11.crossattention.self.value.weight', 'bert.encoder.layer.5.crossattention.self.value.bias', 'bert.encoder.layer.11.crossattention.output.dense.bias', 'bert.encoder.layer.7.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.self.query.bias', 'bert.encoder.layer.9.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.8.crossattention.self.query.weight', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.3.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.self.value.bias', 'bert.encoder.layer.10.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.self.key.bias', 'bert.encoder.layer.5.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.4.crossattention.self.query.bias', 'bert.encoder.layer.9.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.3.crossattention.output.dense.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PU0yl7rY_Fut"
      },
      "source": [
        "from transformers import BertTokenizer, AutoTokenizer, BertForSequenceClassification, AdamW, BertConfig, get_linear_schedule_with_warmup\n",
        "\n",
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n",
        "        \n",
        "criterion = nn.CrossEntropyLoss(ignore_index = tokenizer.pad_token_id)"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xUyXy2FE6X4"
      },
      "source": [
        "def train2(model, iterator, optimizer, criterion, scheduler,clip):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    optimizer.zero_grad()\n",
        "    for i, batch in enumerate(iterator):\n",
        "\n",
        "        input_ids = torch.tensor(batch[\"input_ids\"]).to(device)\n",
        "        attention_mask = torch.tensor(batch[\"attention_mask\"]).to(device)\n",
        "        decoder_input_ids= torch.tensor(batch[\"decoder_input_ids\"]).to(device)\n",
        "        decoder_attention_mask= torch.tensor(batch[\"decoder_attention_mask\"]).to(device)\n",
        "        labels= torch.tensor(batch[\"labels\"]).to(device)\n",
        "\n",
        "            \n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask,\n",
        "                        decoder_input_ids=decoder_input_ids, \n",
        "                        decoder_attention_mask=decoder_attention_mask,\n",
        "                        labels=labels)\n",
        "\n",
        "        loss = outputs.loss #* b_rewards\n",
        "        loss.backward()\n",
        "        ##print('loss',loss)\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "\n",
        "        scheduler.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        ##print('epoch_loss',epoch_loss)\n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhNcMCKA_Tel"
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZAmw1Lf_VtA"
      },
      "source": [
        "def generate_summary(text):\n",
        "    # cut off at BERT max length 512\n",
        "    inputs = tokenizer(text, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n",
        "    input_ids = inputs.input_ids.to(device)\n",
        "    attention_mask = inputs.attention_mask.to(device)\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    outputs = model.generate(input_ids, attention_mask=attention_mask).cpu().detach().numpy()[0]\n",
        "    o=[]\n",
        "    for token in outputs:\n",
        "        if token == tokenizer.pad_token_id:\n",
        "            break\n",
        "        o.append(token)\n",
        "    output_str = tokenizer.batch_decode([o], skip_special_tokens=True)[0]\n",
        "\n",
        "    return output_str"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYZtPeMY_aFW",
        "outputId": "cb0cc0e0-2415-4954-ec7e-f4d316876ed5"
      },
      "source": [
        "\n",
        "\n",
        "documents = []\n",
        "documents.append(full_text)\n",
        "\n",
        "encoder_max_length = 64\n",
        "decoder_max_length = 64\n",
        "batch_size = 32 #4 # 64, 128\n",
        "\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "model.to(device)\n",
        "\n",
        "for doc in documents:\n",
        "    dataset_iterator = []\n",
        "    org_sentences = np.array(nltk.sent_tokenize(doc.strip()))\n",
        "    for i in range(len(org_sentences)):\n",
        "        txt = org_sentences[i]\n",
        "        txt2 = txt\n",
        "        if i < len(org_sentences)-1:\n",
        "            txt +=  '[SEP]' + org_sentences[i+1]\n",
        "            txt2 += org_sentences[i+1]\n",
        "\n",
        "        batch = {}\n",
        "        batch['input_ids'] = []\n",
        "        batch['attention_mask'] = []\n",
        "        batch['decoder_input_ids'] = []\n",
        "        batch['decoder_attention_mask'] = []\n",
        "        batch['labels'] = []\n",
        "        samples = sam_wgan4(txt2,epochs=100,batch_size=batch_size)\n",
        "        for (text,g,s,l) in samples:\n",
        "            inputs = g_discriminator.tokenizer(txt, padding=\"max_length\", truncation=True, max_length=encoder_max_length)\n",
        "            outputs = g_discriminator.tokenizer(text, padding=\"max_length\", truncation=True, max_length=decoder_max_length)\n",
        "            batch[\"input_ids\"].append(inputs.input_ids)\n",
        "            batch[\"attention_mask\"].append(inputs.attention_mask)\n",
        "            batch[\"decoder_input_ids\"].append(outputs.input_ids)\n",
        "            batch[\"decoder_attention_mask\"].append(outputs.attention_mask)\n",
        "            batch[\"labels\"].append(outputs.input_ids.copy())\n",
        "        dataset_iterator.append(batch)\n",
        "\n",
        "    # Total number of training steps is [number of batches] x [number of epochs]. \n",
        "    # (Note that this is not the same as the number of training samples).\n",
        "    total_steps = len(dataset_iterator) * N_EPOCHS\n",
        "\n",
        "    # Create the learning rate scheduler.\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                                num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                                num_training_steps = total_steps)\n",
        "\n",
        "    for epoch in range(N_EPOCHS):\n",
        "        \n",
        "        start_time = time.time()\n",
        "        train_loss = train2(model, dataset_iterator, optimizer, criterion, scheduler,CLIP)\n",
        "        end_time = time.time()\n",
        "        \n",
        "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "        \n",
        "        #if valid_loss < best_valid_loss:\n",
        "        #    best_valid_loss = valid_loss\n",
        "        #    torch.save(model.state_dict(), 'tut6-model.pt')\n",
        "        \n",
        "        print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "        print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "        #print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n",
        "        print(generate_summary('옛날 어느 집에 귀여운 여자 아기가 태어났어요.[SEP]아기는 무럭무럭 자라서 예쁘고 마음씨 고운 소녀가 되었어요.'))\n",
        "\n",
        "    model.save_pretrained(\"/content/drive/MyDrive/GAN_ENDE/model\")"
      ],
      "execution_count": 351,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서 예쁘고 마음씨 고운 소녀가 되었어요.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   100/100 epochs,grammar loss:-0.0116  similarity loss:-0.0097 length loss:0.0013\n",
            "--------------------------------------------------\n",
            "아기는 무럭무럭 자라서 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   100/100 epochs,grammar loss:-0.4985  similarity loss:-0.3520 length loss:0.0458\n",
            "--------------------------------------------------\n",
            "그러던 어느날 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   100/100 epochs,grammar loss:-0.5181  similarity loss:-0.4308 length loss:0.0825\n",
            "--------------------------------------------------\n",
            "소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 지나서 새어머니를 맞이했어요.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   100/100 epochs,grammar loss:-0.0015  similarity loss:-0.0086 length loss:-0.0011\n",
            "--------------------------------------------------\n",
            "그래서 얼마 지나서 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두명의 딸을 데리고 왔어요.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   100/100 epochs,grammar loss:-0.0260  similarity loss:-0.0230 length loss:-0.0007\n",
            "--------------------------------------------------\n",
            "새어머니는 소녀보다 나이가 위인 두명의 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   100/100 epochs,grammar loss:-0.4471  similarity loss:-0.3382 length loss:0.0282\n",
            "--------------------------------------------------\n",
            "그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한게 못마땅했어요.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   100/100 epochs,grammar loss:-0.0609  similarity loss:-0.0550 length loss:0.0104\n",
            "--------------------------------------------------\n",
            "새어머니는 소녀가 자기 딸들보다 예쁘고 착한게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   100/100 epochs,grammar loss:-0.1691  similarity loss:-0.1018 length loss:0.0130\n",
            "--------------------------------------------------\n",
            "그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 쓸고 닦고 하녀처럼 하루 종일 집안일을 도맡아 했어요.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   100/100 epochs,grammar loss:-0.2323  similarity loss:-0.1209 length loss:-0.0003\n",
            "--------------------------------------------------\n",
            "소녀는 쓸고 닦고 하녀처럼 하루 종일 집안일을 도맡아 했어요. 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했어요.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   100/100 epochs,grammar loss:-0.4353  similarity loss:-0.3171 length loss:0.0239\n",
            "--------------------------------------------------\n",
            "집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했어요. 그러던 어느날 왕궁에서 무도회가 열렸어요.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   100/100 epochs,grammar loss:-0.4656  similarity loss:-0.2707 length loss:0.0477\n",
            "--------------------------------------------------\n",
            "그러던 어느날 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 무도회 초대장이 왔어요.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   100/100 epochs,grammar loss:-0.3082  similarity loss:-0.2199 length loss:-0.0069\n",
            "max g 1.611590027809143\n",
            "--------------------------------------------------\n",
            "그러던 어느날 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 무도회 초대장이 왔어요.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   110/110 epochs,grammar loss:-0.1878  similarity loss:-0.1516 length loss:0.0426\n",
            "--------------------------------------------------\n",
            "신데렐라의 집에도 무도회 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   100/100 epochs,grammar loss:-0.0237  similarity loss:-0.0203 length loss:0.0090\n",
            "--------------------------------------------------\n",
            "새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   100/100 epochs,grammar loss:-0.1515  similarity loss:-0.1208 length loss:0.0080\n",
            "max g 2.4321460723876953\n",
            "--------------------------------------------------\n",
            "새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   110/110 epochs,grammar loss:-0.0955  similarity loss:-0.0762 length loss:0.0051\n",
            "max g 2.4321460723876953\n",
            "--------------------------------------------------\n",
            "새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   120/120 epochs,grammar loss:-0.2436  similarity loss:-0.1922 length loss:0.0063\n",
            "--------------------------------------------------\n",
            "신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   100/100 epochs,grammar loss:-0.1383  similarity loss:-0.1041 length loss:-0.0088\n",
            "max g 2.644831418991089\n",
            "--------------------------------------------------\n",
            "신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   110/110 epochs,grammar loss:-0.1004  similarity loss:-0.0833 length loss:-0.0000\n",
            "max g 1.4790774583816528\n",
            "--------------------------------------------------\n",
            "신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   120/120 epochs,grammar loss:-0.2337  similarity loss:-0.1171 length loss:0.0093\n",
            "--------------------------------------------------\n",
            "혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 그때 어디선가 마법사 할머니가 나타났어요.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   100/100 epochs,grammar loss:0.0040  similarity loss:-0.0025 length loss:0.0063\n",
            "max g 0.7204656600952148\n",
            "--------------------------------------------------\n",
            "혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 그때 어디선가 마법사 할머니가 나타났어요.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   110/110 epochs,grammar loss:-0.2526  similarity loss:-0.2988 length loss:-0.0012\n",
            "max g 0.6598734855651855\n",
            "--------------------------------------------------\n",
            "혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 그때 어디선가 마법사 할머니가 나타났어요.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   120/120 epochs,grammar loss:-0.1100  similarity loss:-0.0874 length loss:0.0010\n",
            "max g 1.2010704278945923\n",
            "--------------------------------------------------\n",
            "혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 그때 어디선가 마법사 할머니가 나타났어요.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   130/130 epochs,grammar loss:-0.1915  similarity loss:-0.1282 length loss:-0.0018\n",
            "max g 2.5954794883728027\n",
            "--------------------------------------------------\n",
            "혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 그때 어디선가 마법사 할머니가 나타났어요.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   140/140 epochs,grammar loss:-0.0246  similarity loss:-0.0174 length loss:0.0022\n",
            "--------------------------------------------------\n",
            "그때 어디선가 마법사 할머니가 나타났어요. 신데렐라가 고개를 들어보니 마법사 할머니가 빙그레 웃고 있었어요.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   100/100 epochs,grammar loss:-0.3081  similarity loss:-0.2547 length loss:0.0655\n",
            "--------------------------------------------------\n",
            "신데렐라가 고개를 들어보니 마법사 할머니가 빙그레 웃고 있었어요. 할머니는 소녀를 무도회에 보내줄테니 호박 한개와 생쥐 두마리 도마뱀을 가지고 오라 했어요.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   100/100 epochs,grammar loss:-0.5228  similarity loss:-0.3932 length loss:0.0063\n",
            "--------------------------------------------------\n",
            "할머니는 소녀를 무도회에 보내줄테니 호박 한개와 생쥐 두마리 도마뱀을 가지고 오라 했어요. 마법사 할머니가 이것들을 보면서 주문을 외웠어요.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   100/100 epochs,grammar loss:-0.5226  similarity loss:-0.3706 length loss:0.0034\n",
            "--------------------------------------------------\n",
            "마법사 할머니가 이것들을 보면서 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자 호박이 화려한 황금마차로 변했어요.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   100/100 epochs,grammar loss:-0.1150  similarity loss:-0.0805 length loss:-0.0006\n",
            "max g 1.897260069847107\n",
            "--------------------------------------------------\n",
            "마법사 할머니가 이것들을 보면서 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자 호박이 화려한 황금마차로 변했어요.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   110/110 epochs,grammar loss:-0.3288  similarity loss:-0.1968 length loss:-0.0061\n",
            "--------------------------------------------------\n",
            "그리고 지팡이로 호박을 건드리자 호박이 화려한 황금마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   100/100 epochs,grammar loss:-0.3082  similarity loss:-0.2052 length loss:-0.0065\n",
            "--------------------------------------------------\n",
            "이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로 도마뱀은 멋진 마부로 변했어요.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   100/100 epochs,grammar loss:-0.1579  similarity loss:-0.1313 length loss:0.0171\n",
            "--------------------------------------------------\n",
            "그랬더니 생쥐는 흰말로 도마뱀은 멋진 마부로 변했어요. 신데렐라의 낡은 옷은 구슬 장식이 반짝이는 예쁜 드레스로 바뀌었어요.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   100/100 epochs,grammar loss:-0.0830  similarity loss:-0.0608 length loss:-0.0029\n",
            "--------------------------------------------------\n",
            "신데렐라의 낡은 옷은 구슬 장식이 반짝이는 예쁜 드레스로 바뀌었어요. 할머니는 신데렐라에게 반짝반짝 빛나는 유리구두를 신겨 주었어요.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   100/100 epochs,grammar loss:-0.5638  similarity loss:-0.5149 length loss:0.1241\n",
            "--------------------------------------------------\n",
            "할머니는 신데렐라에게 반짝반짝 빛나는 유리구두를 신겨 주었어요. 그리고 밤 열두시가 되면 모든게 처음대로 돌아간다고 알려주었어요.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   100/100 epochs,grammar loss:-0.4901  similarity loss:-0.3099 length loss:0.0804\n",
            "--------------------------------------------------\n",
            "그리고 밤 열두시가 되면 모든게 처음대로 돌아간다고 알려주었어요. 황금마차는 호박으로 흰말은 생쥐로 마부는 도마뱀으로 변하게 돼어요.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   100/100 epochs,grammar loss:-0.3455  similarity loss:-0.1833 length loss:0.0234\n",
            "--------------------------------------------------\n",
            "황금마차는 호박으로 흰말은 생쥐로 마부는 도마뱀으로 변하게 돼어요. 그러니까 반드시 밤 열두시가 되기 전에 돌아와야 해요.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   100/100 epochs,grammar loss:-0.1239  similarity loss:-0.0669 length loss:0.0025\n",
            "--------------------------------------------------\n",
            "그러니까 반드시 밤 열두시가 되기 전에 돌아와야 해요. 신데렐라는 황금마차를 타고 왕궁 무도회장으로 가서 멋진 왕자님을 만났어요.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   100/100 epochs,grammar loss:-0.5088  similarity loss:-0.3092 length loss:0.0383\n",
            "--------------------------------------------------\n",
            "신데렐라는 황금마차를 타고 왕궁 무도회장으로 가서 멋진 왕자님을 만났어요. 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   100/100 epochs,grammar loss:-0.4734  similarity loss:-0.4252 length loss:0.0390\n",
            "--------------------------------------------------\n",
            "왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고 신데렐라하고만 춤을 추었어요.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   100/100 epochs,grammar loss:-0.2176  similarity loss:-0.1843 length loss:0.0065\n",
            "--------------------------------------------------\n",
            "왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고 신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   100/100 epochs,grammar loss:-0.5809  similarity loss:-0.5344 length loss:0.0637\n",
            "--------------------------------------------------\n",
            "신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 어느덧 시간이 흘러 열두시가 되었어요.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   100/100 epochs,grammar loss:-0.3463  similarity loss:-0.2216 length loss:0.0241\n",
            "--------------------------------------------------\n",
            "어느덧 시간이 흘러 열두시가 되었어요. 벽시계의 열두시를 알리는 종소리에 신데렐라는 화들짝 놀랐어요.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   100/100 epochs,grammar loss:-0.0364  similarity loss:-0.0264 length loss:0.0058\n",
            "--------------------------------------------------\n",
            "벽시계의 열두시를 알리는 종소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데 유리구두 한짝이 벗겨졌어요.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   100/100 epochs,grammar loss:-0.1415  similarity loss:-0.1722 length loss:0.0078\n",
            "max g 0.8139598965644836\n",
            "--------------------------------------------------\n",
            "벽시계의 열두시를 알리는 종소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데 유리구두 한짝이 벗겨졌어요.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   110/110 epochs,grammar loss:-0.3529  similarity loss:-0.3068 length loss:0.0077\n",
            "--------------------------------------------------\n",
            "신데렐라가 허둥지둥 왕궁을 빠져나가는데 유리구두 한짝이 벗겨졌어요. 하지만 구두를 주울 시간이 없었어요.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   100/100 epochs,grammar loss:0.0001  similarity loss:-0.0041 length loss:-0.0006\n",
            "--------------------------------------------------\n",
            "하지만 구두를 주울 시간이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리구두 한짝을 주웠어요.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   100/100 epochs,grammar loss:-0.0401  similarity loss:-0.0291 length loss:0.0060\n",
            "--------------------------------------------------\n",
            "신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리구두 한짝을 주웠어요. 왕자님은 유리구두를 가지고 임금님께 가서 말했어요.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   100/100 epochs,grammar loss:-0.4395  similarity loss:-0.3677 length loss:-0.0048\n",
            "--------------------------------------------------\n",
            "왕자님은 유리구두를 가지고 임금님께 가서 말했어요. 이 유리구두의 주인과 결혼하겠어요.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   100/100 epochs,grammar loss:0.0035  similarity loss:-0.0030 length loss:-0.0010\n",
            "--------------------------------------------------\n",
            "이 유리구두의 주인과 결혼하겠어요. 그래서 신하들은 유리구두의 주인을 찾아 온 나라를 돌아다녔어요.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   100/100 epochs,grammar loss:-0.1142  similarity loss:-0.0757 length loss:0.0048\n",
            "--------------------------------------------------\n",
            "그래서 신하들은 유리구두의 주인을 찾아 온 나라를 돌아다녔어요. 드디어 신데렐라의 집에까지 신하들이 도착했어요.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   100/100 epochs,grammar loss:-0.2082  similarity loss:-0.1676 length loss:0.0176\n",
            "--------------------------------------------------\n",
            "드디어 신데렐라의 집에까지 신하들이 도착했어요. 언니들은 발을 오므려도 보고 구두를 늘려도 보았지만 한눈에 보기에도 유리구두는 너무 작았어요.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   100/100 epochs,grammar loss:-0.5153  similarity loss:-0.4006 length loss:0.0240\n",
            "--------------------------------------------------\n",
            "언니들은 발을 오므려도 보고 구두를 늘려도 보았지만 한눈에 보기에도 유리구두는 너무 작았어요. 그때 신데렐라가 조용히 다가와 자기도 한번 신어보게 해달라고 부탁했어요.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   100/100 epochs,grammar loss:-0.0832  similarity loss:-0.0669 length loss:0.0076\n",
            "--------------------------------------------------\n",
            "그때 신데렐라가 조용히 다가와 자기도 한번 신어보게 해달라고 부탁했어요. 신데렐라는 신하에게서 받은 유리구두를 신었어요.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   100/100 epochs,grammar loss:-0.3295  similarity loss:-0.2827 length loss:0.0705\n",
            "--------------------------------------------------\n",
            "신데렐라는 신하에게서 받은 유리구두를 신었어요. 유리구두는 신데렐라의 발에 꼭 맞았어요.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   100/100 epochs,grammar loss:-0.3509  similarity loss:-0.3190 length loss:0.1003\n",
            "--------------------------------------------------\n",
            "유리구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   100/100 epochs,grammar loss:-0.0267  similarity loss:-0.0179 length loss:0.0002\n",
            "--------------------------------------------------\n",
            "신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   100/100 epochs,grammar loss:-0.0355  similarity loss:-0.0310 length loss:-0.0024\n",
            "--------------------------------------------------\n",
            "그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   100/100 epochs,grammar loss:-0.1158  similarity loss:-0.1097 length loss:0.0069\n",
            "Epoch: 01 | Time: 0m 26s\n",
            "\tTrain Loss: 0.293 | Train PPL:   1.340\n",
            "옛날 어느 집에 귀여운 아기가 무럭무럭 자라서 예쁘고 마음씨 고운 소녀가 되었어요. 집에 귀여운 여자 태어났고 아기는 자라서 마음씨 소녀가 어느 집에 아기가 아기는 무럭 무럭 되었어요. 아기가 자라서 소녀가 집에 귀여운 귀여운 여자 아기가 아기는 태어났고 자라서 고운 아기가 태어났어요. 집에 태어났고 예쁘고 고운 아기가 아기는 아기는 예쁘고 고운 소녀는 되었어요.\n",
            "Epoch: 02 | Time: 0m 26s\n",
            "\tTrain Loss: 0.119 | Train PPL:   1.127\n",
            "옛날 어느 집에 귀여운 아기가 무럭무럭 자라서 마음씨 고운 소녀가 되었고 어느날 왕궁에서 무도회가 열렸어요. 되었어요. 귀여운 여자 아기가 아기는 고운 아기가 아기는 자라서 고운 소녀보다 나이가 위인 여자 데리고 갔어요.\n",
            "Epoch: 03 | Time: 0m 26s\n",
            "\tTrain Loss: 0.062 | Train PPL:   1.063\n",
            "옛날 어느 집에 귀여운 여자 아기가 마음씨 고운 소녀가 되었고 어느날 어머니가 병이들어 그만 세상을 떠나고 말았어요.었어요.했어요. 여자 아기가 예쁘고 착한게 못마땅했어요. 돌아가셨어요. 귀여운 여자 여자 아기가 아기는 무럭무럭 되었어요.았어요.\n",
            "Epoch: 04 | Time: 0m 26s\n",
            "\tTrain Loss: 0.061 | Train PPL:   1.063\n",
            "어느 집에 귀여운 여자 아기가 자라서 마음씨 고운 소녀가 되었고 어느날 소녀의 어머니가 병이들어 그만 떠나고 말았어요. 유리구두 한짝이 벗겨졌어요. 시간이 흘러 열두시가 되었고 소녀가 걱정되었어요. 아기가 아기는 무럭무럭 자라서 소녀가 되었어요.\n",
            "Epoch: 05 | Time: 0m 26s\n",
            "\tTrain Loss: 0.039 | Train PPL:   1.040\n",
            "옛날 어느 귀여운 여자 아기가 아기는 마음씨 고운 고운 소녀가 되었어요. 드레스로 바뀌었어요. 귀여운 여자 여자 아기가 귀여운 여자 아기는 무럭무럭 예쁘고 고운 고운 고운 아가씨가 아기는 아기는 고운 고운 옷은 고운 고운 쳐다보니 고운 고운 여자 아기가 여자 아기가 되었어요.\n",
            "Epoch: 06 | Time: 0m 26s\n",
            "\tTrain Loss: 0.041 | Train PPL:   1.042\n",
            "어느 집에 귀여운 여자 아기가 아기는 무럭무럭 예쁘고 마음씨 고운 어느 집에 아기가 태어났고 신데렐라가 힘들어 난롯가에 앉아서 잠시 도맡아 했어요.\n",
            "Epoch: 07 | Time: 0m 26s\n",
            "\tTrain Loss: 0.036 | Train PPL:   1.037\n",
            "옛날 어느 귀여운 여자 아기가 아기는 자라서 마음씨 고운 소녀가 되었고 어느날 소녀의 어머니가 병이들어 그만 떠나고 말았어요. 아기가 아기는 무럭무럭 자라서 고운 나이가 아기는 자라 되었어요.\n",
            "Epoch: 08 | Time: 0m 26s\n",
            "\tTrain Loss: 0.042 | Train PPL:   1.043\n",
            "어느 집에 귀여운 여자 자라서 마음씨 고운 소녀가 되었고 어느날 소녀의 여자 아기가 병이들어 그만 떠나고 말았어요. 여자 아기가 자라서 소녀가 되었어요. 귀여운 여자 태어났어요. 집에도 무도회 초대장이 왔고 새어머니는 소녀가 자라서 예쁘고 착한게 돼어요.\n",
            "Epoch: 09 | Time: 0m 26s\n",
            "\tTrain Loss: 0.043 | Train PPL:   1.044\n",
            "옛날 어느 귀여운 여자 아기가 아기는 자라서 마음씨 고운 소녀를 아기가 아기는 무럭무럭 소녀가 되었어요. 여자 아기가 자라서 고운 소녀가 되었고 어느날 소녀를 했어요.마차를 타고 왕궁 무도회장으로 가서 멋진 왕자님을 왕자님을 만났어요.기 전에 돌아와야 해요.\n",
            "Epoch: 10 | Time: 0m 26s\n",
            "\tTrain Loss: 0.052 | Train PPL:   1.054\n",
            "옛날 어느 집에 귀여운 여자 아기가 자라서 마음씨 고운 소녀가 되었어요. 귀여운 여자 여자 아기가 아기는 무럭무럭 자라서 예쁘고 마음씨 마음씨 소녀가 어느 집에 여자 아기가 고운 소녀 여자 아기가 마음씨씨 고운 여자 아기가 여자 아기가 무럭궁에서 귀여운 여자 귀여운 여자 데리고 무도회회가 되었어요.\n",
            "Epoch: 11 | Time: 0m 26s\n",
            "\tTrain Loss: 0.024 | Train PPL:   1.025\n",
            "어느 집에 귀여운 여자 아기가 아기는 자라서 고운 되었어요.가 되었어요. 아기가 아기는 무럭무럭 예쁘고 착한게서 마음씨 고운 소녀가 되었고 어느날 왕궁에서 유리구두를 했어요.회회회회가 열렸어요.\n",
            "Epoch: 12 | Time: 0m 26s\n",
            "\tTrain Loss: 0.055 | Train PPL:   1.056\n",
            "어느 집에 귀여운 여자 아기가 아기는 자라서 마음씨 고운 소녀가 되었어요. 집안일이 힘들어 지칠때면 앉아서 잠시 잠시 했고 왕궁을 빠져나가는데 유리구두 한짝이 힘들어 난롯가에 앉아서 잠시 했고 어느 집에도 무도회 초대약한 심약한 심술쟁이들이었어요.\n",
            "Epoch: 13 | Time: 0m 26s\n",
            "\tTrain Loss: 0.031 | Train PPL:   1.031\n",
            "옛날 어느 집에 귀여운 여자 아기가 마음씨 고운 소녀가 되었고 어느날 소녀의 집에도 무도회 초대장이 왔어요. 귀여운 여자 데리고 무도회장으로 가서 멋진 왕자님을 만났어요. 여자 왔어요. 되었어요. 자라서 마음회 왔어요.가 되었어요. 놀랐어요.\n",
            "Epoch: 14 | Time: 0m 26s\n",
            "\tTrain Loss: 0.049 | Train PPL:   1.050\n",
            "어느 집에 귀여운 여자 아기가 자라서 마음씨 고운 소녀가 되었고 어느날 소녀의 어머니가 병이들어 그만 떠나고 왕궁을 어느 귀여운 여자 아기는 자라서 고운 소녀 아기가 아기는 고운 소녀 마음술 고운 소녀보다 나이가 아기는 고운 여자 아기가 아기는 무럭무럭 자라서 예쁘고 착한 소녀가 되었어요.\n",
            "Epoch: 15 | Time: 0m 26s\n",
            "\tTrain Loss: 0.030 | Train PPL:   1.030\n",
            "옛날 어느 집에 귀여운 여자 아기가 마음씨 고운 소녀가 되었어요. 옛날 구슬 장식이 반짝이는 예쁜 드레스로 바뀌었고 할머니는 신데렐라에게 반짝반짝 빛나는 유리구두를 신겨 주었어요. 집에도 무도회장에 앉아서 잠시 했어요. 귀여운 소녀가 걱정되었어요.\n",
            "Epoch: 16 | Time: 0m 26s\n",
            "\tTrain Loss: 0.044 | Train PPL:   1.045\n",
            "옛날 어느 귀여운 여자 아기가 자라서 마음씨 고운 소녀가 되었어요. 여자 아기가 아기는 자라서 예쁘고 착한게 못마땅했어요. 귀여운 여자 태어났어요. 옛날 옛날 어느 집에도 무도회장으로 가서 멋진 왕자님을 왕자님도 고운 여자 아기가 고운 여자 아기는 고운 여자 데리고 왔어요.\n",
            "Epoch: 17 | Time: 0m 26s\n",
            "\tTrain Loss: 0.025 | Train PPL:   1.025\n",
            "옛날 어느 집에 귀여운 여자 아기가 마음씨 고운 소녀가 되었고 어느날 소녀는 소녀가 허둥지둥 왕궁을 빠져나가는데 유리구두 한짝이 벗겨졌고 구두를 늘려도 보았지만 한눈에 보기에도 유리구두는 너무 그때 신데렐라가 딸들보다 예쁘고 착한게 못마땅했어요.\n",
            "Epoch: 18 | Time: 0m 26s\n",
            "\tTrain Loss: 0.022 | Train PPL:   1.023\n",
            "옛날 어느 귀여운 여자 아기가 아기는 자라서 마음씨 고운 소녀가 되었어요. 옛날 어머니가 병이들어 그만 떠나고 말았어요. 여자 아기가 자라서 예쁘고 착한게 못마땅했어요. 어느 집에도 무도회장으로 가서 멋진 왕자님을 왕자님도 아름다운 마음을 빼았겼어요.\n",
            "Epoch: 19 | Time: 0m 26s\n",
            "\tTrain Loss: 0.041 | Train PPL:   1.042\n",
            "어느 집에 귀여운 여자 아기가 자라서 마음씨 고운 소녀가 되었고 어느날 소녀가 되었어요. 떠나고 말았어요. 도맡아 했어요. 없었어요. 시작했어요. 했어요. 되었어요.. 타고 왕궁 무도회장으로 가서 멋진 왕자님을 왕자님도 아름다운 마음을 빼았겼어요.\n",
            "Epoch: 20 | Time: 0m 26s\n",
            "\tTrain Loss: 0.027 | Train PPL:   1.028\n",
            "어느 집에 귀여운 여자 아기가 아기는 자라서 마음씨 고운 소녀가 되었고 어느날 소녀가 되었어요.훌쩍 울기 전에 돌아와야 해요. 여자 아기가 자라서 예쁘고 착한게 못마땅했어요. 유리구두 한짝이 여자 떠나고 말았어요. 소녀가 벗겨졌어요.\n",
            "Epoch: 21 | Time: 0m 26s\n",
            "\tTrain Loss: 0.051 | Train PPL:   1.052\n",
            "어느 집에 귀여운 여자 아기가 자라서 마음씨 고운 소녀가 되었어요.\n",
            "Epoch: 22 | Time: 0m 26s\n",
            "\tTrain Loss: 0.024 | Train PPL:   1.024\n",
            "옛날 어느 귀여운 여자 아기가 아기는 자라서 마음씨 고운 되었고 어느날 소녀가 되었어요.\n",
            "Epoch: 23 | Time: 0m 26s\n",
            "\tTrain Loss: 0.041 | Train PPL:   1.042\n",
            "옛날 어느 귀여운 여자 아기가 자라서 마음씨 고운 소녀가 되었어요. 소녀가되었어요. 어느 집에도 한눈에 보기에도 유리구두 한짝이 벗겨졌어요. 이번에는 생쥐 두마리 도마뱀은 멋진 심술쟁이들이었어요. 여자 아기가 아기는 무럭무럭 자라서 고운 되었어요.\n",
            "Epoch: 24 | Time: 0m 26s\n",
            "\tTrain Loss: 0.031 | Train PPL:   1.031\n",
            "옛날 어느 집에 귀여운 여자 아기가 자라서 마음씨 고운 소녀가 소녀가 되었어요. 어느 집에도 무도회 초대장이 왔어요. 옛날 집에 귀여운 심술쟁이들이었어요. 소녀보다 예쁘고 착한게 못마땅했어요. 여자 아기가 아기는 무럭무럭 자라서 예쁘고 고운 되었어요.\n",
            "Epoch: 25 | Time: 0m 26s\n",
            "\tTrain Loss: 0.026 | Train PPL:   1.026\n",
            "옛날 어느 귀여운 여자 아기가 자라서 마음씨 고운 소녀가 되었어요. 어느 집에도 무도회 초대장이 왔어요. 옛날 집에도 고운 되었어요. 되었어요. 했어요. 여자 아기가 아기는 무럭무럭 예쁘고 착한게 못마땅했어요. 귀여운 여자 아기는 자라서 예쁘고 착한이 되었어요.\n",
            "Epoch: 26 | Time: 0m 26s\n",
            "\tTrain Loss: 0.025 | Train PPL:   1.026\n",
            "옛날 어느 귀여운 여자 아기가 아기는 자라서 마음씨 고운 소녀가 되었어요. 어느 집에 앉아서 잠시 했어요. 옛날 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀가 되었고 어느날 소녀가 딸들보다 데리고 왔어요. 여자 아기가 마음씨시가 되었어요. 되었어요.\n",
            "Epoch: 27 | Time: 0m 26s\n",
            "\tTrain Loss: 0.037 | Train PPL:   1.038\n",
            "옛날 어느 귀여운 여자 아기가 자라서 마음씨 고운 소녀가 되었어요. 어느 집에도 무도회 초대장이 왔어요. 옛날 집에도 한눈에 보기에도 유리구두의 주인을 찾아 나라를 돌아다녔어요. 여자 아기가 아기는 무럭무럭 예쁘고 착한게 못마땅했어요.\n",
            "Epoch: 28 | Time: 0m 26s\n",
            "\tTrain Loss: 0.018 | Train PPL:   1.018\n",
            "옛날 집에 귀여운 여자 아기가 마음씨 고운 소녀가 되었어요. 어느 집에 아기가 아기는 무럭무럭 자라서 마음씨 마음씨 소녀가 되기 전에 돌아와야 해요. 옛날 어느 집에도 무도회장으로 가서 멋진 왕자님을 왕자님은 층계에서 유리구두 한짝이 주웠어요.\n",
            "Epoch: 29 | Time: 0m 26s\n",
            "\tTrain Loss: 0.025 | Train PPL:   1.026\n",
            "옛날 어느 귀여운 여자 아기가 자라서 마음씨 고운 소녀가 되었어요. 어느 집에 아기가 아기는 무럭무럭 예쁘고 착한게서 유리구두 한짝이 고약한 심술쟁이처럼 하루 종일 집안일을 도맡아 했어요. 여자 아기가 아기는 자라서 고운 소녀보다 나이가 위인 딸을 데리고 왔어요.\n",
            "Epoch: 30 | Time: 0m 26s\n",
            "\tTrain Loss: 0.032 | Train PPL:   1.033\n",
            "옛날 어느 귀여운 여자 아기가 아기는 자라서 마음씨 고운 소녀가 되었어요. 어느 집에 아기가 아기는 무럭무럭 소녀가 되기 전에 돌아와야 해요. 옛날 되었어요.시가 되었고 어느날 집에도 무도회장으로 가서 멋진 왕자님을 만났어요. 여자 아기가 마음씨 되었어요.\n",
            "Epoch: 31 | Time: 0m 26s\n",
            "\tTrain Loss: 0.028 | Train PPL:   1.029\n",
            "옛날 어느 귀여운 여자 아기가 자라서 마음씨 고운 소녀가 얼마 지나서 새어머니는 소녀가 자기 딸들보다 예쁘고 착한게서 유리구두 한짝이 고약한 심술쟁이들이었고 소녀가 딸들보다 나이가 데리고 무도회장으로 멋진 왕자님을 왕자님도 아름다운 소녀가 되었어요.\n",
            "Epoch: 32 | Time: 0m 26s\n",
            "\tTrain Loss: 0.027 | Train PPL:   1.027\n",
            "옛날 집에 아기가 자라서 마음씨 고운 소녀가 되었고 어느날 소녀의 집에 귀여운 여자 아기가 아기는 자라서 예쁘고 착한이 고약한 심술쟁이들이었어요. 옛날 소녀가 되었어요. 어느 집에도 무도회장으로 가서 멋진 왕자님을 왕자님도 아름다운 심술때면 앉아서 잠시 했어요.\n",
            "Epoch: 33 | Time: 0m 26s\n",
            "\tTrain Loss: 0.035 | Train PPL:   1.035\n",
            "옛날 어느 귀여운 여자 아기가 아기는 자라서 마음씨 고운 소녀가 되었어요. 어느 귀여운 심술쟁이들이었어요. 여자 아기가 자라서 예쁘고 착한게 못마 고운 소녀보다 나이가 아기는 무럭무럭 자라서 귀여운 소녀가되었어요. 귀여운 소녀보다 되었어요.\n",
            "Epoch: 34 | Time: 0m 26s\n",
            "\tTrain Loss: 0.025 | Train PPL:   1.025\n",
            "옛날 어느 집에 여자 아기가 자라서 마음씨 고운 소녀가 되기 전에 돌아와야 신데렐라는 황금마차를 타고 왕궁 무도회장으로 가서 멋진 왕자님을 왕자님도 아름다운 심술쟁이들이었어요. 옛날 집에도 한눈에 보기에도 유리구두 한짝이 벗겨졌어요.\n",
            "Epoch: 35 | Time: 0m 26s\n",
            "\tTrain Loss: 0.032 | Train PPL:   1.033\n",
            "옛날 어느 귀여운 여자 아기가 자라서 마음씨 고운 소녀가 되었어요. 어느 집에 귀여운게서 유리구두 한짝이 벗겨졌고 얼마 지나서 새어머니의 주인을 맞이했어요. 귀여운 여자 왔어요. 여자 맞이하겠어요. 집에도 무도회장으로 가서 멋진 왕자님을 왔어요.\n",
            "Epoch: 36 | Time: 0m 26s\n",
            "\tTrain Loss: 0.019 | Train PPL:   1.019\n",
            "옛날 어느 집에 여자 아기가 마음씨 고운 소녀가 되었어요. 어느 집에 귀여운 여자 아기가 아기는 자라서 마음씨 고약한 심술쟁이들이었어요. 옛날 집에 아기가 마음소리에 신데렐라의 주인과 시간 가는 소녀가 걱정되었어요. 귀여운 쳐다보지도 않고 춤을 추었어요.\n",
            "Epoch: 37 | Time: 0m 26s\n",
            "\tTrain Loss: 0.019 | Train PPL:   1.019\n",
            "옛날 어느 집에 귀여운 여자 아기가 마음씨 고운 소녀가 어느 집에 아기가 아기는 무럭무럭 예쁘고 착한게서 유리구두 한짝으로 변하게 못마땅했어요. 어느 집에 여자 아기가 아기는 자라서 마음씨씨 고운 심술쟁이들이었어요. 되었어요.\n",
            "Epoch: 38 | Time: 0m 26s\n",
            "\tTrain Loss: 0.021 | Train PPL:   1.021\n",
            "옛날 어느 귀여운 여자 아기가 아기는 자라서 마음씨 고운 소녀가 되기 전에 돌아와야 신데렐라는 황금마차를 타고 왕궁 무도회장으로 가서 멋진 왕자님을 만났어요. 어느 집에 귀여운 심술쟁이들이었어요. 여자 아기가 무럭무럭 자라서 멋진 왕자님은 층계에서 유리구두 한짝이\n",
            "Epoch: 39 | Time: 0m 26s\n",
            "\tTrain Loss: 0.035 | Train PPL:   1.036\n",
            "옛날 어느 귀여운 여자 아기가 아기는 자라서 마음씨 고운 소녀가 되었어요. 어느 집에 아기가 아기는 무럭무럭 자라서 소녀가 되기 전에 돌아와야 신데렐라의 주인을 찾아 나라를 돌아다녔어요. 귀여운 심술쟁이들이었어요. 옛날.\n",
            "Epoch: 40 | Time: 0m 26s\n",
            "\tTrain Loss: 0.017 | Train PPL:   1.017\n",
            "옛날 집에 귀여운 여자 아기가 마음씨 고운 소녀가 되었어요. 옛날 어느 집에 아기가 아기는 무럭무럭 예쁘고 착한게 못마땅했어요. 어느 집에 여자 아기가 아기는 자라서 고운 되었어요. 아기가 아기는 무도회장으로 가서 멋진 왕자님을 만났어요. 여자 아기가 앉아서 잠시 했어요.\n",
            "Epoch: 41 | Time: 0m 26s\n",
            "\tTrain Loss: 0.042 | Train PPL:   1.043\n",
            "옛날 어느 귀여운 여자 아기가 자라서 마음씨 고운 소녀가 되기 전에 돌아와야 신데렐라는 황금마차를 타고 왕궁 무도회장으로 가서 멋진 왕자님을 만났고 왕자님을 왕자님도 아름다운 심술쟁이들이 도착했어요. 옛날 집에서 열두시가 되었어요.\n",
            "Epoch: 42 | Time: 0m 26s\n",
            "\tTrain Loss: 0.032 | Train PPL:   1.033\n",
            "옛날 어느 귀여운 여자 아기가 자라서 마음씨 고운 소녀가 되기 전에 돌아와야 신데렐라는 황금마차를 타고 왕궁 무도회장으로 가서 멋진 왕자님을 만났어요. 옛날 집에서 유리구두 한짝이 벗겨졌어요. 어느 집에도 무도회 초대장이 왔어요.\n",
            "Epoch: 43 | Time: 0m 26s\n",
            "\tTrain Loss: 0.031 | Train PPL:   1.032\n",
            "옛날 어느 귀여운 여자 아기가 자라서 마음씨 고운 소녀가 되었어요. 어느 집에 귀여운 다른 쳐다보지도 않고 이것들을 보면서 구두를 늘려도 한눈에 보기에도 했어요. 여자 늘려도 보았지만 한눈에 보기에도 너무 그때 어머니가 이것들을 한눈에 보기에도 전에 돌아와야 해요. 옛날 되었어요.\n",
            "Epoch: 44 | Time: 0m 26s\n",
            "\tTrain Loss: 0.036 | Train PPL:   1.036\n",
            "옛날 어느 집에 귀여운 여자 아기가 자라서 마음씨 고운 소녀가 되었어요. 옛날 집에 아기가 아기는 무럭무럭 예쁘고 착한게서 유리구두 한짝이 고약한 심술쟁이들이었고 황금마차를 타고 왕궁 무도회장으로 가서 멋진 왕자님을 왕자님을 만났어요.\n",
            "Epoch: 45 | Time: 0m 26s\n",
            "\tTrain Loss: 0.016 | Train PPL:   1.016\n",
            "옛날 어느 귀여운 여자 마음씨 고운 소녀가 되었어요. 어느 집에 귀여운 여자 아기는 자라서 마음씨 아름다운 심술쟁이들이었어요. 옛날 집에도 무도회 초대장이 왔고 새어머니는 언니들을 데리고 무도회장으로 가서 멋진 왕자님을 왕자님도 아름다운 마음을씨 고운 되었어요.\n",
            "Epoch: 46 | Time: 0m 26s\n",
            "\tTrain Loss: 0.022 | Train PPL:   1.022\n",
            "옛날 어느 귀여운 여자 아기가 자라서 마음씨 고운 소녀가 되었어요. 옛날 집에 귀여운 여자 여자 아기가 무럭무럭 예쁘고 착한게서 유리구두 한짝이 주울 여자 아기가 아기는 자라서 예쁘고 착한일이 힘들어 난롯가에 앉아서 잠시 했어요. 여자 아기가 힘들어 지칠이 되었어요.\n",
            "Epoch: 47 | Time: 0m 26s\n",
            "\tTrain Loss: 0.025 | Train PPL:   1.026\n",
            "어느 집에 귀여운 여자 마음씨 고운 소녀가 되었어요. 어느 귀여운 심술 고운 소녀보다 나이가 위인 딸을 데리고 무도회장으로 가서 멋진 왕자님을 왕자님도 아름다운 마음을 빼았겼어요. 옛날 어느 집에도 무도회가 열두시가 되기 전에 돌아와야 해요.\n",
            "Epoch: 48 | Time: 0m 26s\n",
            "\tTrain Loss: 0.017 | Train PPL:   1.017\n",
            "옛날 어느 귀여운 여자 아기가 자라서 마음씨 고운 소녀가 되기 전에 돌아와야 신데렐라는 황금마차를 타고 왕궁 무도회장으로 가서 멋진 왕자님을 만났고 왕자님을 왕자님도 아름다운 마음을 빼았겼어요. 옛날 집에 귀여운 다른 쳐다보지도 않고 춤을 추었어요.\n",
            "Epoch: 49 | Time: 0m 26s\n",
            "\tTrain Loss: 0.019 | Train PPL:   1.020\n",
            "어느 집에 귀여운 여자 아기가 아기는 자라서 마음씨 고운 소녀가 되었고 어느날 소녀의 주인을 찾아 나라를 떠나고 말았어요. 옛날 어느 집에 모인 여자 아기가 마음소리에 모인 다른 쳐다보지도 않고 신데렐라의 어머니가 병이들어 그만 세상을 아기가 이것들을 무도회 초대장이 왔어요.\n",
            "Epoch: 50 | Time: 0m 26s\n",
            "\tTrain Loss: 0.015 | Train PPL:   1.015\n",
            "옛날 어느 귀여운 여자 아기가 자라서 마음씨 고운 소녀가 되었어요. 옛날 집에 귀여운 여자 아기는 자라서 고운 소녀보다 데리고 무도회장으로 가서 멋진 왕자님을 왕자님을 만났고 왕자님도 아름다운 마음을씨 고운 무도회장에 모인 다른 쳐다보지도 않고 신데렐라하고만 춤을 추었어요.\n",
            "Epoch: 51 | Time: 0m 26s\n",
            "\tTrain Loss: 0.025 | Train PPL:   1.026\n",
            "어느 집에 귀여운 여자 아기가 아기는 자라서 마음씨 고운 소녀가 되었고 어느날 소녀의 집에 귀여운 다른 쳐다보지도 않고 신데렐라하고만 춤을 추느라 시간 가는 줄도 몰랐어요. 옛날 어느 집에 모인 여자 아기가 아기가 아기는 무럭무럭 자라서 아기가 아기는 고운 되었어요.\n",
            "Epoch: 52 | Time: 0m 26s\n",
            "\tTrain Loss: 0.016 | Train PPL:   1.016\n",
            "옛날 어느 귀여운 여자 아기가 자라서 마음씨 고운 소녀가 옛날 어느 집에 귀여운 여자 태어났고 신데렐라가 어느 여자 아기가 마음씨 아름다운 소녀가 어느 집에 여자 아기가 무럭무럭 예쁘고 착한게 못마땅했고 밤 되면 모든게 처음대로 돌아간다고 알려주었어요.\n",
            "Epoch: 53 | Time: 0m 26s\n",
            "\tTrain Loss: 0.011 | Train PPL:   1.011\n",
            "옛날 집에 귀여운 여자 아기가 아기는 자라서 마음씨 고운 소녀가 되기 전에 돌아와야 해요. 어느 집에 모인 여자 아기가 아기가 아기는 무럭무럭 예쁘고 착한게 못마땅했고 밤 되기 전에 집에 아기가 마음씨 초대장이 새어머니는 소녀가 되었어요.\n",
            "Epoch: 54 | Time: 0m 26s\n",
            "\tTrain Loss: 0.013 | Train PPL:   1.013\n",
            "옛날 어느 귀여운 여자 아기가 자라서 마음씨 고운 소녀가 되기 전에 돌아와야 신데렐라는 황금마차를 타고 왕궁 무도회장으로 왕자님을 가서 멋진 왕자님을 왕자님도 아름다운 마음을 빼았겼어요. 어느 집에 귀여운 여자 아기는 무럭무럭 예쁘고 착한게 못마땅했어요.\n",
            "Epoch: 55 | Time: 0m 26s\n",
            "\tTrain Loss: 0.023 | Train PPL:   1.023\n",
            "옛날 어느 귀여운 여자 아기가 자라서 마음씨 고운 소녀가 되었고 어느날 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 어느 집에 귀여운 여자 아기는 무럭무럭 예쁘고 착한게 못마땅했고 왕궁을 무도회장으로 가서 멋진 왕자님을 왕자님도 아름다운 소녀가 되었어요.\n",
            "Epoch: 56 | Time: 0m 26s\n",
            "\tTrain Loss: 0.016 | Train PPL:   1.016\n",
            "옛날 어느 귀여운 여자 아기가 자라서 마음씨 고운 소녀가 되었고 새어머니는 소녀가 자기 딸들보다 예쁘고 착한게 못마 고운 소녀보다 나이가 위인 딸을 데리고 무도회장으로 가서 멋진 왕자님을 왕자님도 아름다운 소녀가 되기 전에 돌아와야 신데렐라가 되었어요.\n",
            "Epoch: 57 | Time: 0m 26s\n",
            "\tTrain Loss: 0.018 | Train PPL:   1.018\n",
            "옛날 어느 귀여운 여자 아기가 아기는 자라서 마음씨 고운 소녀가 되기 전에 돌아와야 해요. 어느 집에 귀여운 여자 아기는 자라도 무도회장으로 가서 멋진 왕자님을 왕자님도 아름다운 소녀가 되었어요. 귀여운 여자 태어났고 왕자님은 층계에서 유리구두 한짝이 되었어요.\n",
            "Epoch: 58 | Time: 0m 26s\n",
            "\tTrain Loss: 0.020 | Train PPL:   1.020\n",
            "옛날 어느 집에 귀여운 여자 아기가 마음씨 고운 소녀가 되었고 어느날 소녀의 여자 아기가 아기는 자라서 마음씨 소녀가 되기 전에 돌아와야 신데렐라가 되었어요. 어느 집에 여자 아기가 자라서 예쁘고 착한게 못마땅했어요. 옛날 집에 아기가 아기는 무럭무럭 되었어요.\n",
            "Epoch: 59 | Time: 0m 26s\n",
            "\tTrain Loss: 0.013 | Train PPL:   1.013\n",
            "옛날 어느 귀여운 여자 아기가 자라서 마음씨 고운 소녀가 되었고 어느날 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 옛날 집에 여자 아기가 아기는 자라서 자라서 마음을 빼았겼어요. 여자 아기가 무럭무럭 예쁘고 착한게 못마머니는 소녀가 되었어요.\n",
            "Epoch: 60 | Time: 0m 26s\n",
            "\tTrain Loss: 0.016 | Train PPL:   1.016\n",
            "어느 집에 귀여운 여자 아기가 마음씨 고운 소녀가 되었고 어느날 소녀의 주인과 추느라 시간도 무도회장으로 왕자님은 층계에서 유리구두 한짝이 고약한 심술쟁이들이었고 왕궁을 건드리자 호박이 화려한 황금마차를 타고 왕궁에서 열두시가 되었어요.\n",
            "Epoch: 61 | Time: 0m 26s\n",
            "\tTrain Loss: 0.011 | Train PPL:   1.011\n",
            "옛날 집에 귀여운 여자 태어났고 자라서 마음씨 고운 소녀가 되었어요. 옛날 어느 귀여운 여자 아기가 아기는 자라서 고운 나이가 위인 딸을 데리고 무도회장으로 가서 멋진 소녀가 되기 전에 돌아와야 해요. 소녀가 되었고 어느날 소녀가 걱정되었어요 옛날 옛날 집에도 무도회 왔어요.\n",
            "Epoch: 62 | Time: 0m 26s\n",
            "\tTrain Loss: 0.019 | Train PPL:   1.019\n",
            "옛날 어느 집에 귀여운 여자 아기가 아기는 자라서 마음씨 고운 소녀가 되었고 어느날 소녀의 어머니가 병이들어 그만 세상을 아기가 아기는 무럭무럭 자라서 새어머니는 소녀가 걱정되었고 어느날 집에도 무도회장으로 가서 멋진 왕자님을 왕자님도 아름다운 소녀가 되었어요.\n",
            "Epoch: 63 | Time: 0m 26s\n",
            "\tTrain Loss: 0.014 | Train PPL:   1.015\n",
            "옛날 어느 귀여운 여자 아기가 자라서 마음씨 고운 소녀가 되었고 어느날 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 옛날 집에 귀여운 여자 자라서 고운 소녀보다 나이가 자라서 새어머니는 소녀가 걱정되었고 어느날 소녀가 되기 전에 돌아와야 해요.\n",
            "Epoch: 64 | Time: 0m 26s\n",
            "\tTrain Loss: 0.012 | Train PPL:   1.012\n",
            "옛날 어느 귀여운 여자 아기가 자라서 마음씨 고운 소녀가 되었고 새어머니는 소녀가 자기 딸들보다 나이가 위인 여자 아기가 아기는 자라서 예쁘고 착한게 못마 그만 세상을 떠나고 말았어요. 옛날 집에 귀여운 여자 태어났어요. 어느 집에 여자 아기가 무럭무럭 소녀가 되었어요.\n",
            "Epoch: 65 | Time: 0m 26s\n",
            "\tTrain Loss: 0.010 | Train PPL:   1.010\n",
            "어느 집에 귀여운 여자 아기는 자라서 고운 소녀가 되기 전에 돌아와야 신데렐라는 왕자님과 추느라 시간 가는 소녀가 걱정되었고 얼마 지나서 새어머니는 소녀가 되었고 종소리에 모인 여자 아기가 자라서 마음씨 고운 소녀보다 나이가 위인 딸을 데리고 왔어요.\n",
            "Epoch: 66 | Time: 0m 26s\n",
            "\tTrain Loss: 0.011 | Train PPL:   1.011\n",
            "옛날 어느 귀여운 여자 아기가 자라서 마음씨 고운 소녀가 되었고 새어머니는 소녀가 자기 딸들보다 데리고 무도회장으로 가서 멋진 여자 아기가 무럭무럭 예쁘고 착한게 못마 그만 세상을 아기가 아기는 자라서 멋진 마부는 도마뱀으로 변하게 돼어요.\n",
            "Epoch: 67 | Time: 0m 26s\n",
            "\tTrain Loss: 0.012 | Train PPL:   1.013\n",
            "옛날 어느 귀여운 여자 아기가 자라서 마음씨 고운 소녀가 되기 전에 돌아와야 신데렐라는 왕자님과 추느라 시간 줄도 몰랐어요. 어느 여자 아기가 아기는 무럭무럭 예쁘고 착한게서 유리구두를 신겨줄테니 호박으로 가서 멋진 왕자님을 만났어요.\n",
            "Epoch: 68 | Time: 0m 26s\n",
            "\tTrain Loss: 0.011 | Train PPL:   1.011\n",
            "옛날 어느 귀여운 여자 아기가 자라서 마음씨 고운 소녀가 되기 전에 돌아와야 해요. 어느 집에 귀여운 여자 아기는 자라서 마음을씨 고운 되었어요. 옛날 집에 여자 아기가 아기는 무럭무럭 예쁘고 착한게 못마 그만 세상을 떠나고 말았어요. 소녀가 되었어요.\n",
            "Epoch: 69 | Time: 0m 26s\n",
            "\tTrain Loss: 0.010 | Train PPL:   1.010\n",
            "옛날 어느 귀여운 여자 아기가 자라서 마음씨 고운 소녀가 되기 전에 돌아와야 신데렐라는 왕자님과 추느라 시간 가는 줄도 몰랐고 왕자님과 생쥐 두마리 도마뱀으로 변하게 못마땅했어요. 여자 아기가 아기는 무럭무럭 예쁘고 착한게 돼어요.\n",
            "Epoch: 70 | Time: 0m 26s\n",
            "\tTrain Loss: 0.010 | Train PPL:   1.010\n",
            "옛날 어느 집에 귀여운 여자 아기가 마음씨 고운 소녀가 되기 전에 돌아와야 신데렐라는 황금마차를 타고 왕궁 무도회장으로 가서 멋진 왕자님을 만났어요. 어느 집에 아기가 자라서 멋진 왕자님도 아름다운 마음을 빼았겼어요. 옛날 집에 귀여운 심술쟁이들이었어요.\n",
            "Epoch: 71 | Time: 0m 26s\n",
            "\tTrain Loss: 0.010 | Train PPL:   1.010\n",
            "옛날 어느 집에 귀여운 여자 아기가 자라서 마음씨 고운 소녀가 되기 전에 돌아와야 신데렐라는 황금마차를 타고 왕궁 무도회장으로 가서 멋진 왕자님을 왕자님도 아름다운 심술쟁이들이었어요. 옛날 집에도 무도회 초대장이 되었어요. 어느 집에 여자 아기가 마음았어요.\n",
            "Epoch: 72 | Time: 0m 26s\n",
            "\tTrain Loss: 0.009 | Train PPL:   1.010\n",
            "어느 집에 귀여운 여자 아기가 마음씨 고운 소녀가 되었고 어느날 어머니가 병이들어 그만 세상을 떠나고 말았어요. 집에도 무도회장으로 가서 멋진 마부는 밤 되면 모든게 처음대로 돌아간다고 알려주었어요. 옛날 집에까지 집에 귀여운 다른 쳐다보지도 않고 신데렐라가 되었어요.\n",
            "Epoch: 73 | Time: 0m 26s\n",
            "\tTrain Loss: 0.010 | Train PPL:   1.010\n",
            "옛날 어느 귀여운 여자 아기가 아기는 자라서 마음씨 고운 소녀가 되었고 어느날 소녀의 어머니가 병이들어 그만 무도회장으로 변하게 돼어요. 여자 아기가 무럭무럭 소녀가 되었어요. 어느 집에 귀여운 다른 쳐다보지도 않고 신데렐라가 되었어요 옛날 집에도 무도회 초대장이 되었어요.\n",
            "Epoch: 74 | Time: 0m 26s\n",
            "\tTrain Loss: 0.010 | Train PPL:   1.010\n",
            "옛날 어느 귀여운 여자 아기가 자라서 마음씨 고운 소녀가 되기 전에 돌아와야 신데렐라는 왕자님과 추느라 시간 가는 줄도 몰랐고 집에도 무도회장으로 가서 멋진 마부는 도마뱀으로 변하게 돼고 왕자님을 만났어요. 여자 아기가 아기는 자라서 멋진 왕자님도 아름다운 소녀가 되었어요.\n",
            "Epoch: 75 | Time: 0m 26s\n",
            "\tTrain Loss: 0.009 | Train PPL:   1.009\n",
            "옛날 어느 귀여운 여자 아기가 자라서 마음씨 고운 소녀가 되었고 어느날 집에 여자 아기가 아기는 무럭무럭 예쁘고 착한게 못마 그만 세상을 떠나고 말았어요. 어느 집에 귀여운 여자 아기는 자라서 예쁘고 착한가 되었어요. 옛날 집에 귀여운 다른 쳐다보지도 않고 무도회장으로 변했어요.\n",
            "Epoch: 76 | Time: 0m 26s\n",
            "\tTrain Loss: 0.009 | Train PPL:   1.009\n",
            "옛날 어느 귀여운 여자 아기가 자라서 마음씨 고운 소녀가 되기 전에 돌아와야 신데렐라는 황금마차를 타고 왕궁 무도회장으로 가서 멋진 왕자님을 만났어요. 어느 집에 여자 아기가 아기는 자라서 멋진 왕자님도 아름다운 마음을 빼았겼어요. 옛날 집에 귀여운 여자 태어났어요.\n",
            "Epoch: 77 | Time: 0m 26s\n",
            "\tTrain Loss: 0.009 | Train PPL:   1.009\n",
            "옛날 어느 귀여운 여자 아기가 자라서 마음씨 고운 소녀가 되었고 어느날 소녀의 집에 귀여운 여자 아기는 자라서 예쁘고 착한게 못마 그만 세상을 떠나고 말았어요. 어느 집에 여자 아기가 아기는 무럭무럭 예쁘고 착한가 되었어요. 옛날 집에 귀여운 다른 쳐다보지도 않고 추었어요.\n",
            "Epoch: 78 | Time: 0m 26s\n",
            "\tTrain Loss: 0.009 | Train PPL:   1.009\n",
            "옛날 어느 귀여운 여자 아기가 아기는 자라서 마음씨 고운 소녀가 되기 전에 돌아와야 해요. 옛날 집에 귀여운 여자 태어났어요 어느 집에 여자 아기가 자라서 예쁘고 착한게 못마땅했고 왕궁 무도회장으로 가서 멋진 마부는 도마뱀으로 변하게 돼어요.\n",
            "Epoch: 79 | Time: 0m 26s\n",
            "\tTrain Loss: 0.009 | Train PPL:   1.009\n",
            "어느 집에 귀여운 여자 아기가 아기는 자라서 마음씨 고운 소녀가 되기 전에 돌아와야 소녀가 되었고 어느날 어머니가 병이들어 그만 세상을 떠나고 말았어요. 집에도 무도회장으로 가서 멋진 왕자님을 왕자님도 아름다운 소녀가 되었어요. 옛날 어느 집에 모인 다른 쳐다보지도 않고 왕궁에서 열두시가 되었어요.\n",
            "Epoch: 80 | Time: 0m 26s\n",
            "\tTrain Loss: 0.009 | Train PPL:   1.009\n",
            "옛날 어느 귀여운 여자 아기가 자라서 마음씨 고운 소녀가 되기 전에 돌아와야 신데렐라는 황금마차를 타고 왕궁 무도회장으로 가서 멋진 왕자님을 만났고 왕자님도 아름다운 소녀가 되었어요. 어느 집에 귀여운 여자 아기는 자라서 멋진 마부는 도마뱀으로 변하게 되었어요.\n",
            "Epoch: 81 | Time: 0m 26s\n",
            "\tTrain Loss: 0.009 | Train PPL:   1.009\n",
            "옛날 어느 귀여운 여자 아기가 아기는 자라서 마음씨 고운 소녀가 되기 전에 돌아와야 신데렐라가 되었고 어느날 어머니가 병이들어 그만 무도회장으로 가서 멋진 왕자님을 왕자님도 아름다운 소녀가 되었어요. 어느 집에 귀여운 여자 아기는 자라도 무도회장에 모인 다른 쳐다보지도 않고 왕궁에서 열렸어요.\n",
            "Epoch: 82 | Time: 0m 26s\n",
            "\tTrain Loss: 0.009 | Train PPL:   1.009\n",
            "옛날 어느 귀여운 여자 아기가 자라서 마음씨 고운 소녀가 되기 전에 돌아와야 신데렐라는 황금마차를 타고 왕궁 무도회장으로 가서 멋진 왕자님을 만났고 왕자님도 아름다운 소녀가 되었어요. 옛날 집에도 무도회장에 모인 다른 쳐다보지도 않고 왕궁으로 멋진 심술쟁이들이었어요.\n",
            "Epoch: 83 | Time: 0m 26s\n",
            "\tTrain Loss: 0.009 | Train PPL:   1.009\n",
            "옛날 어느 귀여운 여자 아기가 자라서 마음씨 고운 소녀가 되었어요. 어느 집에 귀여운 여자 자라서 예쁘고 착한게 못마 그만 세상을 떠나고 말았어요. 옛날 집에 여자 아기가 아기는 자라도 무도회장으로 가서 멋진 왕자님을 왕자님도 아름다운 마음을 빼았겼어요.\n",
            "Epoch: 84 | Time: 0m 26s\n",
            "\tTrain Loss: 0.009 | Train PPL:   1.009\n",
            "옛날 어느 귀여운 여자 아기가 자라서 마음씨 고운 소녀가 되기 전에 돌아와야 신데렐라는 황금마차를 타고 왕궁 무도회장으로 가서 멋진 왕자님을 왕자님도 아름다운 심술쟁이들이었어요. 어느 집에 귀여운 심술 고운 소녀보다 나이가 위인 딸을 데리고 왔어요.\n",
            "Epoch: 85 | Time: 0m 26s\n",
            "\tTrain Loss: 0.009 | Train PPL:   1.009\n",
            "옛날 어느 귀여운 여자 아기가 자라서 마음씨 고운 소녀가 되기 전에 돌아와야 신데렐라는 황금마차를 타고 왕궁 무도회장으로 가서 멋진 왕자님을 왕자님도 아름다운 심술쟁이들이었어요. 어느 집에 귀여운 심술 고운 소녀보다 나이가 위인 딸을 데리고 왔어요.\n",
            "Epoch: 86 | Time: 0m 26s\n",
            "\tTrain Loss: 0.009 | Train PPL:   1.009\n",
            "옛날 어느 귀여운 여자 아기가 자라서 마음씨 고운 소녀가 되기 전에 돌아와야 신데렐라는 황금마차를 타고 왕궁 무도회장으로 가서 멋진 왕자님을 왕자님도 아름다운 심술쟁이들이었어요. 어느 집에 귀여운 심술 고운 소녀보다 나이가 위인 딸을 데리고 왔어요.\n",
            "Epoch: 87 | Time: 0m 26s\n",
            "\tTrain Loss: 0.009 | Train PPL:   1.009\n",
            "옛날 어느 귀여운 여자 아기가 자라서 마음씨 고운 소녀가 되기 전에 돌아와야 신데렐라는 황금마차를 타고 왕궁 무도회장으로 가서 멋진 왕자님을 왕자님도 아름다운 심술쟁이들이었어요. 어느 집에 귀여운 심술 예쁜 드레스로 변하게 돼어요.\n",
            "Epoch: 88 | Time: 0m 26s\n",
            "\tTrain Loss: 0.009 | Train PPL:   1.009\n",
            "옛날 어느 귀여운 여자 아기가 자라서 마음씨 고운 소녀가 되기 전에 돌아와야 신데렐라는 황금마차를 타고 왕궁 무도회장으로 가서 멋진 왕자님을 왕자님도 아름다운 심술쟁이들이었어요. 어느 집에 귀여운 심술 예쁜 드레스로 바뀌었어요. 되었어요.\n",
            "Epoch: 89 | Time: 0m 26s\n",
            "\tTrain Loss: 0.009 | Train PPL:   1.009\n",
            "옛날 어느 귀여운 여자 아기가 자라서 마음씨 고운 소녀가 되기 전에 돌아와야 신데렐라는 황금마차를 타고 왕궁 무도회장으로 가서 멋진 왕자님을 왕자님도 아름다운 심술쟁이들이었어요. 어느 집에 귀여운 심술 고운 소녀보다 나이가 위인 딸을 데리고 왔어요.\n",
            "Epoch: 90 | Time: 0m 26s\n",
            "\tTrain Loss: 0.009 | Train PPL:   1.009\n",
            "옛날 어느 귀여운 여자 아기가 자라서 마음씨 고운 소녀가 되기 전에 돌아와야 신데렐라는 황금마차를 타고 왕궁 무도회장으로 가서 멋진 왕자님을 만났어요. 어느 집에 여자 아기가 아기는 자라서 멋진 마부는 도마뱀으로 변하게 돼어요.\n",
            "Epoch: 91 | Time: 0m 26s\n",
            "\tTrain Loss: 0.009 | Train PPL:   1.009\n",
            "옛날 어느 귀여운 여자 아기가 자라서 마음씨 고운 소녀가 되었어요. 어느 집에 귀여운 여자 자라서 예쁘고 착한게 못마머니는 왕자님을 데리고 무도회장으로 가서 멋진 마부는 도마뱀으로 변하게 못마땅했어요. 옛날 집에 귀여운 다른 쳐다보지도 않고 왕궁에서 열두시가 되었어요.\n",
            "Epoch: 92 | Time: 0m 26s\n",
            "\tTrain Loss: 0.009 | Train PPL:   1.009\n",
            "옛날 어느 귀여운 여자 아기가 자라서 마음씨 고운 소녀가 되었어요. 어느 집에 귀여운 여자 자라서 예쁘고 착한게 못마땅했어요. 여자 아기가 아기는 자라서 마음을 빼았겼어요. 옛날 집에 아기가 아기는 무럭무럭 예쁘고 착한이 고약한 심술쟁이들이었어요.\n",
            "Epoch: 93 | Time: 0m 26s\n",
            "\tTrain Loss: 0.009 | Train PPL:   1.009\n",
            "옛날 어느 귀여운 여자 아기가 자라서 마음씨 고운 소녀가 되기 전에 돌아와야 신데렐라는 황금마차를 타고 왕궁 무도회장으로 가서 멋진 왕자님을 왕자님도 아름다운 심술쟁이들이었어요. 어느 집에 귀여운 심술 고운 소녀보다 나이가 위인 딸을 데리고 왔어요.\n",
            "Epoch: 94 | Time: 0m 26s\n",
            "\tTrain Loss: 0.009 | Train PPL:   1.009\n",
            "옛날 어느 귀여운 여자 아기가 자라서 마음씨 고운 소녀가 되기 전에 돌아와야 신데렐라는 황금마차를 타고 왕궁 무도회장으로 왕자님을 왕자님도 아름다운 심술쟁이들이었고 황금마차는 호박으로 가서 멋진 왕자님을 만났어요. 어느 집에도 무도회 초대장이 왔어요.\n",
            "Epoch: 95 | Time: 0m 26s\n",
            "\tTrain Loss: 0.009 | Train PPL:   1.009\n",
            "옛날 어느 귀여운 여자 아기가 자라서 마음씨 고운 소녀가 되기 전에 돌아와야 신데렐라는 황금마차를 타고 왕궁 무도회장으로 왕자님을 왕자님도 아름다운 심술쟁이들이었고 집에도 무도회장에 모인 다른 쳐다보지도 않고 집에 귀여운 다른 쳐다보니 마법사 할머니가 빙그레 웃고 있었어요.\n",
            "Epoch: 96 | Time: 0m 26s\n",
            "\tTrain Loss: 0.009 | Train PPL:   1.009\n",
            "옛날 어느 귀여운 여자 아기가 자라서 마음씨 고운 소녀가 되기 전에 돌아와야 신데렐라는 황금마차를 타고 왕궁 무도회장으로 왕자님을 왕자님도 아름다운 심술쟁이들이었고 집에도 무도회장에 모인 다른 쳐다보지도 않고 추느라 시간 가는 줄도 몰랐어요.\n",
            "Epoch: 97 | Time: 0m 26s\n",
            "\tTrain Loss: 0.009 | Train PPL:   1.009\n",
            "옛날 어느 귀여운 여자 아기가 자라서 마음씨 고운 소녀가 되기 전에 돌아와야 신데렐라는 황금마차를 타고 왕궁 무도회장으로 가서 멋진 왕자님을 왕자님도 아름다운 심술쟁이들이었어요. 옛날 집에도 무도회장에 모인 다른 쳐다보지도 않고 왕궁에서 열두시가 되었어요.\n",
            "Epoch: 98 | Time: 0m 26s\n",
            "\tTrain Loss: 0.009 | Train PPL:   1.009\n",
            "옛날 어느 귀여운 여자 아기가 자라서 마음씨 고운 소녀가 되기 전에 돌아와야 신데렐라는 황금마차를 타고 왕궁 무도회장으로 가서 멋진 왕자님을 만났고 왕자님도 아름다운 소녀가 되었어요. 옛날 집에도 무도회 초대장이 왔어요. 어느 집에 귀여운 다른 쳐다보지도 않고마차를 왔어요.\n",
            "Epoch: 99 | Time: 0m 26s\n",
            "\tTrain Loss: 0.009 | Train PPL:   1.009\n",
            "옛날 어느 귀여운 여자 아기가 자라서 마음씨 고운 소녀가 되기 전에 돌아와야 신데렐라는 황금마차를 타고 왕궁 무도회장으로 가서 멋진 왕자님을 만났고 왕자님도 아름다운 마음을 빼았겼어요. 드레스로 바뀌었어요 어느 집에 모인 다른 쳐다보지도 않고 왕궁에서 열두시가 되었어요.\n",
            "Epoch: 100 | Time: 0m 26s\n",
            "\tTrain Loss: 0.009 | Train PPL:   1.009\n",
            "옛날 어느 귀여운 여자 아기가 자라서 마음씨 고운 소녀가 되기 전에 돌아와야 신데렐라는 황금마차를 타고 왕궁 무도회장으로 가서 멋진 왕자님을 만났고 왕자님도 아름다운 마음을 빼았겼어요. 드레스로 바뀌었어요. 옛날 집에 귀여운 여자 아기는 무럭무럭 예쁘고 착한게 못마땅했어요.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTSvu8EnFD3_",
        "outputId": "cdb24741-da01-408f-9cbd-d65262f6b907"
      },
      "source": [
        "print(generate_summary('옛날 어느 집에 귀여운 여자 아기가 태어났어요.[SEP]아기는 무럭무럭 자라서 예쁘고 마음씨 고운 소녀가 되었어요.'))"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "옛날 어느 집에 귀여운 아기가 무럭무럭 자라서 예쁘고 마음씨 고운 소녀가 되었고 어느날 소녀의 어머니가 병이들어 그만 떠나고 말았어요. 여자 아기는 무럭궁에서 무도회장으로 가서 멋진 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 되었어요.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "humjKhgOoBKX"
      },
      "source": [
        "model.save_pretrained(\"/content/drive/MyDrive/GAN_ENDE/model\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}