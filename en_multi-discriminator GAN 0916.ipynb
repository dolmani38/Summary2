{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "korean_frame_token_0_1.0_gamma_10.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2725c384f0c5402f8e2e355a8d032c27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_841e791180cd4f06810c9fc2ee4b7ef7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e4616ecb441f45f582820181bafcca7c",
              "IPY_MODEL_af73e478e6714728952cae89bd429782",
              "IPY_MODEL_aec90660de0d465d9cf92e176176b3ec"
            ]
          }
        },
        "841e791180cd4f06810c9fc2ee4b7ef7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e4616ecb441f45f582820181bafcca7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d05d9f35970548faa2eb9ec1bf671aa6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ee227a8ffea04f0084dc4838fb5fe616"
          }
        },
        "af73e478e6714728952cae89bd429782": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_db0294e213aa4c86bae60f94aeb40513",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 571,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 571,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fcc1b445088b48a9950955a529a06dbb"
          }
        },
        "aec90660de0d465d9cf92e176176b3ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_babecf53b500436dba413ad8ecfcd86c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 571/571 [00:00&lt;00:00, 14.2kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_24f3badcdde646e7b9be6c0b260df980"
          }
        },
        "d05d9f35970548faa2eb9ec1bf671aa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ee227a8ffea04f0084dc4838fb5fe616": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "db0294e213aa4c86bae60f94aeb40513": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fcc1b445088b48a9950955a529a06dbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "babecf53b500436dba413ad8ecfcd86c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "24f3badcdde646e7b9be6c0b260df980": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "567c452d0dda422c918b9411143e0b85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a588624c12b345df964352327718ff99",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_124a61bb9d8b48bda4d9c187dfe991cc",
              "IPY_MODEL_c1b6672cbf0d4d529d04110b02cec482",
              "IPY_MODEL_91b4bb94c11e4e3e90d198c1f018b0c3"
            ]
          }
        },
        "a588624c12b345df964352327718ff99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "124a61bb9d8b48bda4d9c187dfe991cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5899d4b33b2f4ba0aca6a903bb844d45",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4deb448f6c304585839610a6061e80d1"
          }
        },
        "c1b6672cbf0d4d529d04110b02cec482": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ddd6b1e63ff04c8ea1d1e4b3191d2b25",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1344997306,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1344997306,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_094dba517d4549308c9eab2879fd7830"
          }
        },
        "91b4bb94c11e4e3e90d198c1f018b0c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d2ef8f4df6e64caa99980ba45d00aac1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.34G/1.34G [00:27&lt;00:00, 47.6MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_826da1d4aef4498b9448fed1d8be5466"
          }
        },
        "5899d4b33b2f4ba0aca6a903bb844d45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4deb448f6c304585839610a6061e80d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ddd6b1e63ff04c8ea1d1e4b3191d2b25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "094dba517d4549308c9eab2879fd7830": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d2ef8f4df6e64caa99980ba45d00aac1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "826da1d4aef4498b9448fed1d8be5466": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f850723df11b41c99b34012ef670e056": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f55d3a93f6b84ec2afee4a393fe3c8d9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ad0464ca6170476b8f1081e784fa6aa4",
              "IPY_MODEL_9bc3e18b752745e29cbef985a2dc2659",
              "IPY_MODEL_5021647bd3664c338c028302ccf6a4b0"
            ]
          }
        },
        "f55d3a93f6b84ec2afee4a393fe3c8d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ad0464ca6170476b8f1081e784fa6aa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_689c4681ff4445f0a7ce12cd9c615d3b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7c0975e55ca247aea5793ff3b3316bc5"
          }
        },
        "9bc3e18b752745e29cbef985a2dc2659": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c87f658ecf7f4c3493cef3ba4fa4c746",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a91ceb8a986d4c808333b86b301b7b99"
          }
        },
        "5021647bd3664c338c028302ccf6a4b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f3e2da4627c54ca1bd6728fece19be42",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 843kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_60f4bf0e200a4d9388c28520e72f728b"
          }
        },
        "689c4681ff4445f0a7ce12cd9c615d3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7c0975e55ca247aea5793ff3b3316bc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c87f658ecf7f4c3493cef3ba4fa4c746": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a91ceb8a986d4c808333b86b301b7b99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f3e2da4627c54ca1bd6728fece19be42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "60f4bf0e200a4d9388c28520e72f728b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "631df6a9d8a2470da71920cc0f4bfb43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8de5037a89e443098cc9f5689b76e338",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e41755b0bce94913baed72b97dc09dde",
              "IPY_MODEL_553e9c929a2a4a2c9a322937a52b5858",
              "IPY_MODEL_ede5fa1f45e24f1fa67308eda7065db6"
            ]
          }
        },
        "8de5037a89e443098cc9f5689b76e338": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e41755b0bce94913baed72b97dc09dde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ac065fcace8042eeaba38867ac6015d5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_277fc75bc5cd49e08d183b04dfeeb263"
          }
        },
        "553e9c929a2a4a2c9a322937a52b5858": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_eaa7f05e2dfb47648cc22c800d2d5967",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c017c1a913aa405db460ac19bcdcd0a5"
          }
        },
        "ede5fa1f45e24f1fa67308eda7065db6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_edad20eb7f9b4a4587c273edee9e291f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 808B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_68d7eb154f534df6bdbd0ef724826851"
          }
        },
        "ac065fcace8042eeaba38867ac6015d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "277fc75bc5cd49e08d183b04dfeeb263": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eaa7f05e2dfb47648cc22c800d2d5967": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c017c1a913aa405db460ac19bcdcd0a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "edad20eb7f9b4a4587c273edee9e291f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "68d7eb154f534df6bdbd0ef724826851": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1d6ba2826e86487992e46568ff427917": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c5894f88f0a64bd7892a5feb8b408306",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d4ac5a7546d44f128a40e1003de8c78a",
              "IPY_MODEL_5cc8f1cd1a164a6ba631c509b469ce99",
              "IPY_MODEL_8228681ab7694daf8a3efd57e5b24127"
            ]
          }
        },
        "c5894f88f0a64bd7892a5feb8b408306": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d4ac5a7546d44f128a40e1003de8c78a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c2da357f3794465887383f4d10699c71",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_84548e5edf894a079ccb063110bd9362"
          }
        },
        "5cc8f1cd1a164a6ba631c509b469ce99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_dbf869a2638f47668812cab82815e17d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d19407a17c954f4cb126915bb926a7ae"
          }
        },
        "8228681ab7694daf8a3efd57e5b24127": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_76959845dd1441b7a7db9b2febb19fe2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:00&lt;00:00, 1.18MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dcebf80dd97f4aad87ffe8c60a543096"
          }
        },
        "c2da357f3794465887383f4d10699c71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "84548e5edf894a079ccb063110bd9362": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dbf869a2638f47668812cab82815e17d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d19407a17c954f4cb126915bb926a7ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "76959845dd1441b7a7db9b2febb19fe2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dcebf80dd97f4aad87ffe8c60a543096": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dolmani38/Summary2/blob/main/en_multi-discriminator%20GAN%200916.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkQCxNatSIOk"
      },
      "source": [
        "# English Multi-Discriminator GAN\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZjIW9VwyjDf"
      },
      "source": [
        "ABSTRACT\n",
        "\n",
        "----\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K87VNBbeRLFF"
      },
      "source": [
        "#4. Implementation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQZeBAf8NxAR"
      },
      "source": [
        "## 4.1 기본 설정..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAdXzWGuKSBT",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "970656fc-14d7-48e6-8080-aabfd1e8b14c"
      },
      "source": [
        "if True:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "newO0mBXKVnE",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02b2b1ac-8827-4866-c1cf-b71e77744a05"
      },
      "source": [
        "#!pip install keybert\n",
        "!pip3 install transformers\n",
        "!pip3 install sentence-transformers\n",
        "\n",
        "#!pip install sentence-transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.10.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (5.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.17)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.4)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.7/dist-packages (2.0.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.10.0+cu102)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.2.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.62.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.22.2.post1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.10.2)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.0.17)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.9.0+cu102)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.1.96)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers) (3.7.4.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (4.6.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.0.45)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (5.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.12)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.10.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (21.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.0.1)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmIxp0FnKXif",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e75e2ca-af93-4421-fbda-4adc710061d7"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# set seeds for reproducability\n",
        "from numpy.random import seed\n",
        "#seed(1)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string, os \n",
        "\n",
        "import urllib.request\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3J0n_lhKcgm",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b104c35-d00a-4f34-f826-d6efe8dc76a3"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ue_4ZfdRKfdX",
        "trusted": true
      },
      "source": [
        "# Print iterations progress\n",
        "class ProgressBar:\n",
        "\n",
        "    def __init__(self,total=20, prefix = '', suffix = '', decimals = 1, length = 20, fill = '|', printEnd = \"\\r\"):\n",
        "        self.total = total\n",
        "        self.prefix = prefix\n",
        "        self.suffix = suffix\n",
        "        self.decimals = decimals\n",
        "        self.length = length\n",
        "        self.fill = fill\n",
        "        self.printEnd = printEnd\n",
        "        self.ite = 0\n",
        "        self.back_filledLength = 0\n",
        "\n",
        "    def printProgress(self,iteration, text):\n",
        "        self.ite += iteration\n",
        "        percent = (\"{0:.\" + str(self.decimals) + \"f}\").format(100 * (self.ite / float(self.total)))\n",
        "        filledLength = int(self.length * self.ite // self.total)\n",
        "        bar = self.fill * filledLength + '.' * (self.length - filledLength)\n",
        "        if filledLength > self.back_filledLength or percent == 100:\n",
        "            print(f'\\r{self.prefix} |{bar}| {percent}% {self.suffix}  {text}', end=\"\", flush=True)\n",
        "            # Print New Line on Complete\n",
        "            if self.ite == self.total: \n",
        "                print()\n",
        "        self.back_filledLength = filledLength    "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNHI0G6JKc5h",
        "trusted": true
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Zsv-LVkKmfL"
      },
      "source": [
        "##4.2 Grammar Discriminator Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VQdGLciKc_y",
        "trusted": true
      },
      "source": [
        "from transformers import BertTokenizer, BertTokenizerFast,AutoTokenizer, BertForSequenceClassification, AdamW, BertConfig, get_linear_schedule_with_warmup\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset, random_split\n",
        "\n",
        "import time\n",
        "import random\n",
        "import datetime\n",
        "import pickle\n",
        "\n",
        "# 간단한 전처리\n",
        "def clean_text(txt):\n",
        "    txt = txt.replace('\\n',' ')\n",
        "    txt = txt.replace('\\r',' ')    \n",
        "    txt = txt.replace('=','')\n",
        "    txt = txt.replace('\\\"','')   \n",
        "    txt = txt.replace('\\'','')\n",
        "    #txt = txt.replace(',','')\n",
        "    txt = txt.replace('..','')\n",
        "    txt = txt.replace('...','')\n",
        "    txt = txt.replace(' .','.')\n",
        "    txt = txt.replace('.','. ')\n",
        "    txt = txt.replace('  ',' ')\n",
        "    txt = txt.replace('  ',' ')    \n",
        "    txt = txt.replace('  ',' ')   \n",
        "    txt = txt.replace('  ',' ')           \n",
        "    txt = txt.replace('  ',' ')\n",
        "    txt = txt.replace('  ',' ')    \n",
        "    txt = txt.replace('  ',' ')   \n",
        "    txt = txt.replace('  ',' ')             \n",
        "    return txt.strip()\n",
        "\n",
        "def shuffling(txt):\n",
        "    txt_list = txt.split(' ')\n",
        "    random.shuffle(txt_list)\n",
        "    return ' '.join(txt_list)\n",
        "\n",
        "def collect_training_dataset_for_grammar_discriminator(sentences_dataset):\n",
        "\n",
        "    sentences = []\n",
        "    labels = []\n",
        "\n",
        "    for txtss in sentences_dataset:\n",
        "        txtss = clean_text(txtss)\n",
        "        txts = txtss.strip().split('.')\n",
        "        for txt in txts:  \n",
        "            txt = txt.strip()\n",
        "            if len(txt) > 10:\n",
        "                #ko_grammar_dataset.append([txt,1])\n",
        "                txt = txt.replace('.','')\n",
        "                tf = random.choice([True,False])\n",
        "                # 정상 또는 비정상 둘중에 하나만 데이터셋에 추가\n",
        "                if (tf):\n",
        "                    sentences.append(txt) # '.'의 위치를 보고 True, False를 판단 하기 땜에...\n",
        "                    labels.append(1)\n",
        "                else:\n",
        "                    sentences.append(shuffling(txt))\n",
        "                    labels.append(0)\n",
        "\n",
        "    return sentences,labels\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
        "\n",
        "class Grammar_Discriminator:\n",
        "\n",
        "\n",
        "    def __init__(self, pretraoned_kobert_model_name='bert-base-v2', input_dir=None):\n",
        "\n",
        "        if input_dir is None:\n",
        "            self.tokenizer = BertTokenizerFast.from_pretrained(pretraoned_kobert_model_name)\n",
        "            self.discriminator = BertForSequenceClassification.from_pretrained(\n",
        "                                    pretraoned_kobert_model_name, # Use the 12-layer BERT model, with an uncased vocab.\n",
        "                                    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                                                    # You can increase this for multi-class tasks.   \n",
        "                                    output_attentions = False, # Whether the model returns attentions weights.\n",
        "                                    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        "                                )            \n",
        "        else:\n",
        "            self.__load_model(input_dir)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def set_dataset(self, sentences,labels):\n",
        "        # Print the original sentence.\n",
        "        print(' Original: ', sentences[0])\n",
        "\n",
        "        # Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "        input_ids = []\n",
        "        attention_masks = []\n",
        "\n",
        "        # For every sentence...\n",
        "        for i, sent in enumerate(sentences):\n",
        "            print(f'\\r Tokenize {i+1}/{len(sentences)}', end=\"\", flush=True)            \n",
        "            # `encode_plus` will:\n",
        "            #   (1) Tokenize the sentence.\n",
        "            #   (2) Prepend the `[CLS]` token to the start.\n",
        "            #   (3) Append the `[SEP]` token to the end.\n",
        "            #   (4) Map tokens to their IDs.\n",
        "            #   (5) Pad or truncate the sentence to `max_length`\n",
        "            #   (6) Create attention masks for [PAD] tokens.\n",
        "            encoded_dict = self.tokenizer.encode_plus(\n",
        "                                sent,                      # Sentence to encode.\n",
        "                                add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                                max_length = 64,           # Pad & truncate all sentences.\n",
        "                                pad_to_max_length = True,\n",
        "                                return_attention_mask = True,   # Construct attn. masks.\n",
        "                                return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                                truncation = True,\n",
        "                        )\n",
        "            \n",
        "            # Add the encoded sentence to the list.    \n",
        "            input_ids.append(encoded_dict['input_ids'])\n",
        "            \n",
        "            # And its attention mask (simply differentiates padding from non-padding).\n",
        "            attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "        # Convert the lists into tensors.\n",
        "        input_ids = torch.cat(input_ids, dim=0)\n",
        "        attention_masks = torch.cat(attention_masks, dim=0)\n",
        "        labels = torch.tensor(labels)\n",
        "\n",
        "        # Print sentence 0, now as a list of IDs.\n",
        "        print('Original: ', sentences[0])\n",
        "        print('Token IDs:', input_ids[0])\n",
        "\n",
        "        # Training & Validation Split\n",
        "        # Divide up our training set to use 90% for training and 10% for validation.\n",
        "\n",
        "        # Combine the training inputs into a TensorDataset.\n",
        "        dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "        # Create a 90-10 train-validation split.\n",
        "\n",
        "        # Calculate the number of samples to include in each set.\n",
        "        train_size = int(0.9 * len(dataset))\n",
        "        val_size = len(dataset) - train_size\n",
        "\n",
        "        # Divide the dataset by randomly selecting samples.\n",
        "        train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "        print('{:>5,} training samples'.format(train_size))\n",
        "        print('{:>5,} validation samples'.format(val_size))\n",
        "\n",
        "        # The DataLoader needs to know our batch size for training, so we specify it \n",
        "        # here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "        # size of 16 or 32.\n",
        "        self.batch_size = 32\n",
        "\n",
        "        # Create the DataLoaders for our training and validation sets.\n",
        "        # We'll take training samples in random order. \n",
        "        self.train_dataloader = DataLoader(\n",
        "                    train_dataset,  # The training samples.\n",
        "                    sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "                    batch_size = self.batch_size # Trains with this batch size.\n",
        "                )\n",
        "\n",
        "        # For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "        self.validation_dataloader = DataLoader(\n",
        "                    val_dataset, # The validation samples.\n",
        "                    sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "                    batch_size = self.batch_size # Evaluate with this batch size.\n",
        "                )        \n",
        "\n",
        "\n",
        "    def train(self,epochs=4):\n",
        "        # Tell pytorch to run this model on the GPU.\n",
        "        self.discriminator.cuda()\n",
        "\n",
        "        # Get all of the model's parameters as a list of tuples.\n",
        "        params = list(self.discriminator.named_parameters())\n",
        "\n",
        "        print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "        print('==== Embedding Layer ====\\n')\n",
        "\n",
        "        for p in params[0:5]:\n",
        "            print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "        print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "        for p in params[5:21]:\n",
        "            print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "        print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "        for p in params[-4:]:\n",
        "            print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))  \n",
        "\n",
        "        # Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "        # I believe the 'W' stands for 'Weight Decay fix\"\n",
        "        self.optimizer = AdamW(self.discriminator.parameters(),\n",
        "                        lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                        eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                        )\n",
        "\n",
        "        # Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "        # We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "        # training data.\n",
        "        #epochs = 2\n",
        "\n",
        "        # Total number of training steps is [number of batches] x [number of epochs]. \n",
        "        # (Note that this is not the same as the number of training samples).\n",
        "        total_steps = len(self.train_dataloader) * epochs\n",
        "\n",
        "        # Create the learning rate scheduler.\n",
        "        scheduler = get_linear_schedule_with_warmup(self.optimizer, \n",
        "                                                    num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                                    num_training_steps = total_steps)\n",
        "            \n",
        "        # This training code is based on the `run_glue.py` script here:\n",
        "        # https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "        # Set the seed value all over the place to make this reproducible.\n",
        "        seed_val = 42\n",
        "\n",
        "        random.seed(seed_val)\n",
        "        np.random.seed(seed_val)\n",
        "        torch.manual_seed(seed_val)\n",
        "        torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "        # We'll store a number of quantities such as training and validation loss, \n",
        "        # validation accuracy, and timings.\n",
        "        training_stats = []\n",
        "\n",
        "        # Measure the total training time for the whole run.\n",
        "        total_t0 = time.time()\n",
        "\n",
        "        # For each epoch...\n",
        "        for epoch_i in range(0, epochs):\n",
        "            \n",
        "            # ========================================\n",
        "            #               Training\n",
        "            # ========================================\n",
        "            \n",
        "            # Perform one full pass over the training set.\n",
        "\n",
        "            print(\"\")\n",
        "            print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "            print('Training...')\n",
        "\n",
        "            # Measure how long the training epoch takes.\n",
        "            t0 = time.time()\n",
        "\n",
        "            # Reset the total loss for this epoch.\n",
        "            total_train_loss = 0\n",
        "\n",
        "            # Put the model into training mode. Don't be mislead--the call to \n",
        "            # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "            # `dropout` and `batchnorm` layers behave differently during training\n",
        "            # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "            self.discriminator.train()\n",
        "\n",
        "            # For each batch of training data...\n",
        "            for step, batch in enumerate(self.train_dataloader):\n",
        "\n",
        "                # Progress update every 40 batches.\n",
        "                if step % 40 == 0 and not step == 0:\n",
        "                    # Calculate elapsed time in minutes.\n",
        "                    elapsed = format_time(time.time() - t0)\n",
        "                    \n",
        "                    # Report progress.\n",
        "                    print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(self.train_dataloader), elapsed))\n",
        "\n",
        "                # Unpack this training batch from our dataloader. \n",
        "                #\n",
        "                # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "                # `to` method.\n",
        "                #\n",
        "                # `batch` contains three pytorch tensors:\n",
        "                #   [0]: input ids \n",
        "                #   [1]: attention masks\n",
        "                #   [2]: labels \n",
        "                b_input_ids = batch[0].to(device)\n",
        "                b_input_mask = batch[1].to(device)\n",
        "                b_labels = batch[2].to(device)\n",
        "\n",
        "                # Always clear any previously calculated gradients before performing a\n",
        "                # backward pass. PyTorch doesn't do this automatically because \n",
        "                # accumulating the gradients is \"convenient while training RNNs\". \n",
        "                # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "                self.discriminator.zero_grad()        \n",
        "\n",
        "                # Perform a forward pass (evaluate the model on this training batch).\n",
        "                # The documentation for this `model` function is here: \n",
        "                # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "                # It returns different numbers of parameters depending on what arguments\n",
        "                # arge given and what flags are set. For our useage here, it returns\n",
        "                # the loss (because we provided labels) and the \"logits\"--the model\n",
        "                # outputs prior to activation.\n",
        "                outputs = self.discriminator(b_input_ids, \n",
        "                                    token_type_ids=None, \n",
        "                                    attention_mask=b_input_mask, \n",
        "                                    labels=b_labels)\n",
        "                loss, logits = outputs.loss, outputs.logits\n",
        "                # Accumulate the training loss over all of the batches so that we can\n",
        "                # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "                # single value; the `.item()` function just returns the Python value \n",
        "                # from the tensor.\n",
        "                total_train_loss += loss.item()\n",
        "\n",
        "                # Perform a backward pass to calculate the gradients.\n",
        "                loss.backward()\n",
        "\n",
        "                # Clip the norm of the gradients to 1.0.\n",
        "                # This is to help prevent the \"exploding gradients\" problem.\n",
        "                torch.nn.utils.clip_grad_norm_(self.discriminator.parameters(), 1.0)\n",
        "\n",
        "                # Update parameters and take a step using the computed gradient.\n",
        "                # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "                # modified based on their gradients, the learning rate, etc.\n",
        "                self.optimizer.step()\n",
        "\n",
        "                # Update the learning rate.\n",
        "                scheduler.step()\n",
        "\n",
        "            # Calculate the average loss over all of the batches.\n",
        "            avg_train_loss = total_train_loss / len(self.train_dataloader)            \n",
        "            \n",
        "            # Measure how long this epoch took.\n",
        "            training_time = format_time(time.time() - t0)\n",
        "\n",
        "            print(\"\")\n",
        "            print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "            print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "                \n",
        "            # ========================================\n",
        "            #               Validation\n",
        "            # ========================================\n",
        "            # After the completion of each training epoch, measure our performance on\n",
        "            # our validation set.\n",
        "\n",
        "            print(\"\")\n",
        "            print(\"Running Validation...\")\n",
        "\n",
        "            t0 = time.time()\n",
        "\n",
        "            # Put the model in evaluation mode--the dropout layers behave differently\n",
        "            # during evaluation.\n",
        "            self.discriminator.eval()\n",
        "\n",
        "            # Tracking variables \n",
        "            total_eval_accuracy = 0\n",
        "            total_eval_loss = 0\n",
        "            nb_eval_steps = 0\n",
        "\n",
        "            # Evaluate data for one epoch\n",
        "            for batch in self.validation_dataloader:\n",
        "                \n",
        "                # Unpack this training batch from our dataloader. \n",
        "                #\n",
        "                # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "                # the `to` method.\n",
        "                #\n",
        "                # `batch` contains three pytorch tensors:\n",
        "                #   [0]: input ids \n",
        "                #   [1]: attention masks\n",
        "                #   [2]: labels \n",
        "                b_input_ids = batch[0].to(device)\n",
        "                b_input_mask = batch[1].to(device)\n",
        "                b_labels = batch[2].to(device)\n",
        "                \n",
        "                # Tell pytorch not to bother with constructing the compute graph during\n",
        "                # the forward pass, since this is only needed for backprop (training).\n",
        "                with torch.no_grad():        \n",
        "\n",
        "                    # Forward pass, calculate logit predictions.\n",
        "                    # token_type_ids is the same as the \"segment ids\", which \n",
        "                    # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "                    # The documentation for this `model` function is here: \n",
        "                    # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "                    # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "                    # values prior to applying an activation function like the softmax.\n",
        "                    outputs = self.discriminator(b_input_ids, \n",
        "                                        token_type_ids=None, \n",
        "                                        attention_mask=b_input_mask,\n",
        "                                        labels=b_labels)\n",
        "                loss, logits = outputs.loss, outputs.logits\n",
        "                # Accumulate the validation loss.\n",
        "                total_eval_loss += loss.item()\n",
        "\n",
        "                # Move logits and labels to CPU\n",
        "                logits = logits.detach().cpu().numpy()\n",
        "                label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "                # Calculate the accuracy for this batch of test sentences, and\n",
        "                # accumulate it over all batches.\n",
        "                total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "                \n",
        "\n",
        "            # Report the final accuracy for this validation run.\n",
        "            avg_val_accuracy = total_eval_accuracy / len(self.validation_dataloader)\n",
        "            print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "            # Calculate the average loss over all of the batches.\n",
        "            avg_val_loss = total_eval_loss / len(self.validation_dataloader)\n",
        "            \n",
        "            # Measure how long the validation run took.\n",
        "            validation_time = format_time(time.time() - t0)\n",
        "            \n",
        "            print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "            print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "            # Record all statistics from this epoch.\n",
        "            training_stats.append(\n",
        "                {\n",
        "                    'epoch': epoch_i + 1,\n",
        "                    'Training Loss': avg_train_loss,\n",
        "                    'Valid. Loss': avg_val_loss,\n",
        "                    'Valid. Accur.': avg_val_accuracy,\n",
        "                    'Training Time': training_time,\n",
        "                    'Validation Time': validation_time\n",
        "                }\n",
        "            )\n",
        "\n",
        "        print(\"\")\n",
        "        print(\"Training complete!\")\n",
        "\n",
        "        print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n",
        "            \n",
        "\n",
        "        return training_stats\n",
        "\n",
        "    def save_model(self, output_dir = './model_save/'):\n",
        "        # Create output directory if needed\n",
        "        if not os.path.exists(output_dir):\n",
        "            os.makedirs(output_dir)\n",
        "\n",
        "        print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "        # Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "        # They can then be reloaded using `from_pretrained()`\n",
        "        model_to_save = self.discriminator.module if hasattr(self.discriminator, 'module') else self.discriminator  # Take care of distributed/parallel training\n",
        "        model_to_save.save_pretrained(output_dir)\n",
        "        self.tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "        # Good practice: save your training arguments together with the trained model\n",
        "        # torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n",
        "\n",
        "    def __load_model(self, input_dir = './drive/MyDrive/Colab Notebooks/summary/en_grammar_check_model'):\n",
        "        print('Loading BERT tokenizer...')\n",
        "        self.tokenizer = BertTokenizerFast.from_pretrained(input_dir)\n",
        "        self.discriminator = BertForSequenceClassification.from_pretrained(input_dir)\n",
        "\n",
        "    def transfer_learning(self, sentences, train_for = True):\n",
        "        \n",
        "        input_ids = []\n",
        "        attention_masks = []\n",
        "\n",
        "        # For every sentence...\n",
        "        for sent in sentences:\n",
        "            # `encode_plus` will:\n",
        "            #   (1) Tokenize the sentence.\n",
        "            #   (2) Prepend the `[CLS]` token to the start.\n",
        "            #   (3) Append the `[SEP]` token to the end.\n",
        "            #   (4) Map tokens to their IDs.\n",
        "            #   (5) Pad or truncate the sentence to `max_length`\n",
        "            #   (6) Create attention masks for [PAD] tokens.\n",
        "            encoded_dict = self.tokenizer.encode_plus(\n",
        "                                sent,                      # Sentence to encode.\n",
        "                                add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                                max_length = 64,           # Pad & truncate all sentences.\n",
        "                                pad_to_max_length = True,\n",
        "                                return_attention_mask = True,   # Construct attn. masks.\n",
        "                                return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                                truncation = True,\n",
        "                        )\n",
        "            # Add the encoded sentence to the list.    \n",
        "            input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "            # And its attention mask (simply differentiates padding from non-padding).\n",
        "            attention_masks.append(encoded_dict['attention_mask'])\n",
        "        \n",
        "        if train_for:\n",
        "            b_labels = torch.ones(len(sentences),dtype=torch.long).to(device)\n",
        "        else:\n",
        "            b_labels = torch.zeros(len(sentences),dtype=torch.long).to(device)\n",
        "        #print(b_labels)\n",
        "        # Convert the lists into tensors.\n",
        "        input_ids = torch.cat(input_ids, dim=0).to(device)\n",
        "        attention_masks = torch.cat(attention_masks, dim=0).to(device)    \n",
        "        #if str(discriminator1.device) == 'cpu':\n",
        "        #    pass\n",
        "        #else:\n",
        "        #    input_ids = input_ids.to(device)\n",
        "        #    attention_masks = attention_masks.to(device)        \n",
        "\n",
        "        outputs = self.discriminator(input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=attention_masks, \n",
        "                                labels=b_labels)\n",
        "\n",
        "        #print(outputs)\n",
        "        #return torch.sigmoid(outputs[0][:,1])\n",
        "        #return outputs[0][:,1]\n",
        "        return outputs['loss'], outputs['logits']\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4zeEb0NR2QH"
      },
      "source": [
        "# 문법 discriminator 활용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7Zf2oRMMXmH",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1d5368c-d0b3-4ab0-a9e1-e00cd813f4af"
      },
      "source": [
        "g_discriminator = Grammar_Discriminator(input_dir = '/content/drive/MyDrive/Colab Notebooks/summary/en_grammar_model')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEXRsgqlXkpf",
        "outputId": "2f5c1c6b-0e3a-428e-a813-e01a1a462131"
      },
      "source": [
        "txt = ['Her friends sadly never heard from her after they parted company.','Her friends sadly never from her after heard they parted company.']\n",
        "g_discriminator.discriminator.to(device)\n",
        "g_discriminator.transfer_learning(txt)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(2.1402, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor([[-5.8312,  5.9503],\n",
              "         [ 2.0386, -2.2279]], device='cuda:0', grad_fn=<AddmmBackward>))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d96kaCAHKuUc"
      },
      "source": [
        "##4.3 Static similarity discriminator class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZDpXe7XKxeg",
        "trusted": true
      },
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import BertTokenizer\n",
        "from scipy.signal import find_peaks\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.misc import electrocardiogram\n",
        "import scipy\n",
        "\n",
        "\n",
        "class Similarity_Discriminator:\n",
        "    '''\n",
        "    _instance = None\n",
        "    _embedder = None\n",
        "    def __new__(cls,pre_trained_model_name='stsb-roberta-large'):\n",
        "        if cls._instance is None:\n",
        "            print('Creating Similarity_Discriminator object')\n",
        "            cls._instance = super(Similarity_Discriminator, cls).__new__(cls)\n",
        "            # Put any initialization here.\n",
        "            cls._embedder = SentenceTransformer(pre_trained_model_name)\n",
        "        return cls._instance\n",
        "\n",
        "    '''\n",
        "\n",
        "    def __init__(self,pre_trained_model_name='stsb-roberta-large'): #'roberta-large-nli-stsb-mean-tokens'):\n",
        "        print('Creating Similarity_Discriminator object')\n",
        "        # Put any initialization here.\n",
        "        self._embedder = SentenceTransformer(pre_trained_model_name,device=device)  \n",
        "        #self.cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
        "\n",
        "    def encode(self,texts):\n",
        "        return self._embedder.encode(texts,show_progress_bar=False)\n",
        "\n",
        "    def similarity(self, query_text, org_text_emb):\n",
        "        queries = nltk.sent_tokenize(query_text)\n",
        "        query_embeddings = self._embedder.encode(queries,show_progress_bar=False)\n",
        "        #query_embeddings = self._embedder.encode(queries,show_progress_bar=False)\n",
        "        #print(queries)\n",
        "        #print(org_text_emb)\n",
        "        \n",
        "        if len(query_embeddings) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        cos_scores = scipy.spatial.distance.cdist(query_embeddings, org_text_emb, \"cosine\")\n",
        "        similarity_score = 1.0 - np.min(np.max(cos_scores,axis=1))\n",
        "        '''\n",
        "        for query, query_embedding in zip(queries, query_embeddings):\n",
        "            distances = scipy.spatial.distance.cdist([query_embedding], [org_text_emb], \"cosine\")[0]\n",
        "            results = zip(range(len(distances)), distances)\n",
        "            for idx, distance in results:\n",
        "                scores.append(1-distance)\n",
        "        '''\n",
        "        return similarity_score  \n",
        " "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sQZ36GuMumP"
      },
      "source": [
        "###4.3.1 영어 문장 유사도 pre-trained model 적용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9Miao14Muww",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "353a0a96-66d3-4f5a-8a95-c6b631a4c070"
      },
      "source": [
        "#del s_discriminator\n",
        "\n",
        "s_discriminator = Similarity_Discriminator()\n",
        "#s_discriminator = Similarity_Discriminator()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating Similarity_Discriminator object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xnk9GsQ0K1t1"
      },
      "source": [
        "# 4.4 Document source class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnBm6RCvNIWG"
      },
      "source": [
        "## 4.4.2 source class 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsJKbtc2K4xN",
        "trusted": true
      },
      "source": [
        "\n",
        "\n",
        "class Source:\n",
        "\n",
        "    def __init__(self,full_text,org_text,delete_ending = False):\n",
        "        self.full_text = full_text\n",
        "        self.org_text = org_text\n",
        "        self.delete_ending = delete_ending\n",
        "\n",
        "    def __crean_text(self, txt):\n",
        "        txt = txt.replace('\\n',' ')\n",
        "        txt = txt.replace('\\r',' ')    \n",
        "        txt = txt.replace('=','')\n",
        "        txt = txt.replace('\\\"','')   \n",
        "        txt = txt.replace('\\'','')\n",
        "        txt = txt.replace(',','')\n",
        "        txt = txt.replace('..','')\n",
        "        txt = txt.replace('...','')\n",
        "        txt = txt.replace(' .','.')\n",
        "        txt = txt.replace('.','. ')\n",
        "        txt = txt.replace('  ',' ')\n",
        "        txt = txt.replace('  ',' ')    \n",
        "        txt = txt.replace('  ',' ')   \n",
        "        txt = txt.replace('  ',' ')           \n",
        "        txt = txt.replace('  ',' ')\n",
        "        txt = txt.replace('  ',' ')    \n",
        "        txt = txt.replace('  ',' ')   \n",
        "        txt = txt.replace('  ',' ')           \n",
        "        return txt.strip()\n",
        "\n",
        "    def set_key_rate(self,s_discriminator):\n",
        "        # full_text에 대한 처리...\n",
        "        self.full_text = self.__crean_text(self.full_text.strip())\n",
        "        self.full_sentences = np.array(nltk.sent_tokenize(self.full_text))\n",
        "        self.s_discriminator = s_discriminator\n",
        "        self.full_text_emb = self.s_discriminator.encode(self.full_sentences)   \n",
        "\n",
        "        # original sentance, 즉 source sentence에 대한 처리\n",
        "        self.org_text = self.__crean_text(self.org_text.strip())\n",
        "        print('-'*50)\n",
        "        print(self.org_text)\n",
        "        print('-'*50)  \n",
        "\n",
        "        # 두개 이상의 문장이 있는 경우, 중간 문자의 마침표를 지우고,\n",
        "        # ' and'를 넣어서, 연결한다.\n",
        "        self.org_sentences = np.array(nltk.sent_tokenize(self.org_text))\n",
        "        self.org_text_emb = self.s_discriminator.encode(self.org_sentences)\n",
        "        s = []\n",
        "        for i,sents in enumerate(self.org_sentences):\n",
        "            if sents.endswith('.') and i < len(self.org_sentences)-1:\n",
        "                s.append(sents[:-1].strip() + \" and\")\n",
        "            else:\n",
        "                s.append(sents)\n",
        "                #self.org_sentences[i] = sents[:-1].strip() + \" and\"\n",
        "                #print(self.org_sentences[i])\n",
        "        self.org_sentences = s\n",
        "        #print(s)\n",
        "        #print(self.org_sentences)\n",
        "        # 하나의 문장을 token 단위로 잘라서 {index:token} dict을 만든다.\n",
        "        # 또한, 각 token의 attention을 설정한다.\n",
        "        self.org_term_set = (' '.join(self.org_sentences)).strip().split(' ')\n",
        "        self.org_source_length = len(self.org_term_set)\n",
        "        self.term_table = {}\n",
        "\n",
        "        self.seps = []\n",
        "        self.bias_table = {}\n",
        "        #morp_table = {}\n",
        "        aw = 1.0\n",
        "        for index, word in enumerate(self.org_term_set):\n",
        "            self.term_table[index] = word\n",
        "            attention = cosine_similarity(self.full_text,word)\n",
        "            if attention > 0.0 or index == len(self.org_term_set)-1:\n",
        "                self.bias_table[index] = aw\n",
        "            else:\n",
        "                self.bias_table[index] = -aw #attention #-cosine_similarity(self.full_text,word)\n",
        "            '''\n",
        "            if word.endswith(('.','?')):\n",
        "                self.seps.append(index)\n",
        "                if self.org_source_length - 1 == index:\n",
        "                    pass\n",
        "                else:\n",
        "                    self.term_table[index] = combine_sentence(word)\n",
        "            '''\n",
        "        # 또 다른 token 단위의 {index:token} dict을 만드는데, 이는 generator의 조합이\n",
        "        # 문법적으로 부실할 경우, corrector가 보정할때 '~~고'의 중간 연결문을 \n",
        "        # 부드럽게 만들기 위해 중간 문장의 '~다.'를 삭제한 dict에 해당한다.\n",
        "        self.combination_table = {}\n",
        "        for index, word in enumerate(self.org_term_set):\n",
        "            self.combination_table[index] = word\n",
        "            if index < len(self.org_term_set)-1: #중간 문장의 '~다.'를 삭제한다.\n",
        "                if self.org_term_set[index].endswith('다.'):\n",
        "                    self.combination_table[index] = word[0:len(word)-2]\n",
        "\n",
        "        print('Length ------------------------------------|',len(self.term_table))\n",
        "        print(self.bias_table)\n",
        "        #print(self.combination_table)\n",
        "        if len(self.term_table) > 128:\n",
        "            raise Exception(\"Too much sentence length.\")\n",
        "\n",
        "    def get_org_sample(self, num):\n",
        "        return self.org_sentences[np.random.choice(len(self.org_sentences), num)]\n",
        "\n",
        "    def get_source_embedded_code(self):\n",
        "        return self.org_text_emb\n",
        "\n",
        "    def get_random_text(self,rate=0.5):\n",
        "        cnt = int(len(self.term_table) * rate)\n",
        "        a = list(self.term_table.keys())\n",
        "        b = np.random.choice(a, cnt)\n",
        "        c = [fruit for fruit in a if fruit not in b]\n",
        "        txt = []\n",
        "        for i in c:\n",
        "            txt.append(self.term_table[i])\n",
        "        return ' '.join(txt).strip(), hash(tuple(b))"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af5b1VF7poE2"
      },
      "source": [
        "## N-Gram Similarity Comparison\n",
        "\n",
        "https://gist.github.com/gaulinmp/da5825de975ed0ea6a24186434c24fe4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAfA5fHxBoGW",
        "outputId": "2cd8fd58-de4f-489d-d988-da3661ee3a40"
      },
      "source": [
        "# Get Tuple algorithms \n",
        "import re\n",
        "import math\n",
        "import numpy as np\n",
        "from itertools import chain\n",
        "from collections import Counter\n",
        "import nltk\n",
        "from nltk.util import ngrams # This is the ngram magic.\n",
        "from textblob import TextBlob\n",
        "\n",
        "NGRAM = 4\n",
        "\n",
        "re_sent_ends_naive = re.compile(r'[.\\n]')\n",
        "re_stripper_alpha = re.compile('[^a-zA-Z]+')\n",
        "re_stripper_naive = re.compile('[^a-zA-Z\\.\\n]')\n",
        "\n",
        "splitter_naive = lambda x: re_sent_ends_naive.split(re_stripper_naive.sub(' ', x))\n",
        "\n",
        "sent_detector = nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "\n",
        "def get_tuples_nosentences(txt):\n",
        "    \"\"\"Get tuples that ignores all punctuation (including sentences).\"\"\"\n",
        "    if not txt: return None\n",
        "    #ng = ngrams(re_stripper_alpha.sub(' ', txt).split(), NGRAM)\n",
        "    ng = ngrams(txt, NGRAM)\n",
        "    return list(ng)\n",
        "\n",
        "def get_tuples_manual_sentences(txt):\n",
        "    \"\"\"Naive get tuples that uses periods or newlines to denote sentences.\"\"\"\n",
        "    if not txt: return None\n",
        "    sentences = (x.split() for x in splitter_naive(txt) if x)\n",
        "    ng = (ngrams(x, NGRAM) for x in sentences if len(x) >= NGRAM)\n",
        "    return list(chain(*ng))\n",
        "\n",
        "def get_tuples_nltk_punkt_sentences(txt):\n",
        "    \"\"\"Get tuples that doesn't use textblob.\"\"\"\n",
        "    if not txt: return None\n",
        "    sentences = (re_stripper_alpha.split(x) for x in sent_detector.tokenize(txt) if x)\n",
        "    # Need to filter X because of empty 'words' from punctuation split\n",
        "    ng = (ngrams(filter(None, x), NGRAM) for x in sentences if len(x) >= NGRAM)\n",
        "    return list(chain(*ng))\n",
        "\n",
        "def get_tuples_textblob_sentences(txt):\n",
        "    \"\"\"New get_tuples that does use textblob.\"\"\"\n",
        "    if not txt: return None\n",
        "    tb = TextBlob(txt)\n",
        "    ng = (ngrams(x.words, NGRAM) for x in tb.sentences if len(x.words) > NGRAM)\n",
        "    return [item for sublist in ng for item in sublist]\n",
        "\n",
        "def jaccard_distance(a, b):\n",
        "    \"\"\"Calculate the jaccard distance between sets A and B\"\"\"\n",
        "    a = set(a)\n",
        "    b = set(b)\n",
        "    return 1.0 * len(a&b)/len(a|b)\n",
        "\n",
        "def cosine_similarity_ngrams(a, b):\n",
        "    vec1 = Counter(a)\n",
        "    vec2 = Counter(b)\n",
        "    \n",
        "    intersection = set(vec1.keys()) & set(vec2.keys())\n",
        "    numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
        "\n",
        "    sum1 = sum([vec1[x]**2 for x in vec1.keys()])\n",
        "    sum2 = sum([vec2[x]**2 for x in vec2.keys()])\n",
        "    denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
        "\n",
        "    if not denominator:\n",
        "        return 0.0\n",
        "    return float(numerator) / denominator\n",
        "\n",
        "\n",
        "def test():\n",
        "    paragraph = \"\"\"It was the best of times, it was the worst of times.\n",
        "               It was the age of wisdom? It was the age of foolishness!\n",
        "               I first met Dr. Frankenstein in Munich; his monster was, presumably, at home.\"\"\"\n",
        "    print(paragraph)\n",
        "    _ = get_tuples_nosentences(paragraph);print(\"Number of N-grams (no sentences):\", len(_));_\n",
        "\n",
        "    _ = get_tuples_manual_sentences(paragraph);print(\"Number of N-grams (naive sentences):\", len(_));_\n",
        "\n",
        "    _ = get_tuples_nltk_punkt_sentences(paragraph);print(\"Number of N-grams (nltk sentences):\", len(_));_\n",
        "\n",
        "    _ = get_tuples_textblob_sentences(paragraph);print(\"Number of N-grams (TextBlob sentences):\", len(_));_\n",
        "\n",
        "    a = get_tuples_nosentences(\"It was the best of times.\")\n",
        "    b = get_tuples_nosentences(\"It was the worst of times.\")\n",
        "    print(\"Jaccard: {}   Cosine: {}\".format(jaccard_distance(a,b), cosine_similarity_ngrams(a,b)))\n",
        "\n",
        "    a = get_tuples_nosentences(\"Above is a bad example of four-gram similarity.\")\n",
        "    b = get_tuples_nosentences(\"This is a better example of four-gram similarity.\")\n",
        "    print(\"Jaccard: {}   Cosine: {}\".format(jaccard_distance(a,b), cosine_similarity_ngrams(a,b)))\n",
        "\n",
        "    a = get_tuples_nosentences(\"Jaccard Index ignores repetition repetition repetition repetition repetition.\")\n",
        "    b = get_tuples_nosentences(\"Cosine similarity weighs repetition repetition repetition repetition repetition.\")\n",
        "    print(\"Jaccard: {}   Cosine: {}\".format(jaccard_distance(a,b), cosine_similarity_ngrams(a,b)))\n",
        "test()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It was the best of times, it was the worst of times.\n",
            "               It was the age of wisdom? It was the age of foolishness!\n",
            "               I first met Dr. Frankenstein in Munich; his monster was, presumably, at home.\n",
            "Number of N-grams (no sentences): 214\n",
            "Number of N-grams (naive sentences): 25\n",
            "Number of N-grams (nltk sentences): 25\n",
            "Number of N-grams (TextBlob sentences): 25\n",
            "Jaccard: 0.6071428571428571   Cosine: 0.755742181606458\n",
            "Jaccard: 0.6071428571428571   Cosine: 0.755742181606458\n",
            "Jaccard: 0.23214285714285715   Cosine: 0.9208243668497166\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akhPuNZHBx4w"
      },
      "source": [
        "def cosine_similarity(src_txt,trg_txt):\n",
        "    try:\n",
        "        if src_txt == None or src_txt.strip() == '':\n",
        "            return 0.0\n",
        "        if trg_txt == None or trg_txt.strip() == '':\n",
        "            return 0.0\n",
        "\n",
        "        a = get_tuples_nosentences(src_txt)\n",
        "        b = get_tuples_nosentences(trg_txt)\n",
        "        return cosine_similarity_ngrams(a,b)\n",
        "    except Exception as ex:\n",
        "        #print(src_txt,trg_txt)\n",
        "        return 0.0"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UAeFBYMMxKY",
        "outputId": "48a027f5-f2cb-4db0-cc6a-7867408f5733"
      },
      "source": [
        "txt = \"\"\"\n",
        "The judge agreed with police that he would have been over the limit at the time his red Citroen hit Miss Titley’s blue Daihatsu Cuore on a road near Yarmouth, Isle of Wight, on October 11, 2013.\n",
        "His phone records showed he was also texting around the time of the crash.\n",
        "\"\"\"\n",
        "s = Source(txt,txt)\n",
        "s.set_key_rate(s_discriminator)\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            "The judge agreed with police that he would have been over the limit at the time his red Citroen hit Miss Titley’s blue Daihatsu Cuore on a road near Yarmouth Isle of Wight on October 11 2013. His phone records showed he was also texting around the time of the crash.\n",
            "--------------------------------------------------\n",
            "Length ------------------------------------| 52\n",
            "{0: -1.0, 1: 0.2, 2: 0.2, 3: 0.2, 4: 0.2, 5: 0.2, 6: -1.0, 7: 0.2, 8: 0.2, 9: 0.2, 10: 0.2, 11: -1.0, 12: 0.2, 13: -1.0, 14: -1.0, 15: 0.2, 16: -1.0, 17: -1.0, 18: 0.2, 19: -1.0, 20: 0.2, 21: 0.2, 22: 0.2, 23: 0.2, 24: 0.2, 25: -1.0, 26: -1.0, 27: 0.2, 28: 0.2, 29: 0.2, 30: 0.2, 31: -1.0, 32: 0.2, 33: -1.0, 34: 0.2, 35: -1.0, 36: 0.2, 37: -1.0, 38: -1.0, 39: 0.2, 40: 0.2, 41: 0.2, 42: -1.0, 43: -1.0, 44: 0.2, 45: 0.2, 46: 0.2, 47: -1.0, 48: 0.2, 49: -1.0, 50: -1.0, 51: 0.2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XY59mdNK8ub"
      },
      "source": [
        "# 4.5 Generator class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5CLF3WcK6lp",
        "trusted": true
      },
      "source": [
        "from functools import reduce\n",
        "\n",
        "\n",
        "# custom weights initialization called on netG and netD\n",
        "\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Linear') != -1:\n",
        "        m.weight.data.normal_(0.0, 0.05)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        m.weight.data.normal_(0.0, 0.05)\n",
        "        m.bias.data.fill_(0)\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    \"\"\"\n",
        "        Simple Generator w/ MLP\n",
        "    \"\"\"\n",
        "    '''\n",
        "    def __init__(self, input_size=1024):\n",
        "        super(Generator, self).__init__()\n",
        "        self.layer = nn.Sequential(\n",
        "            nn.Linear(input_size, input_size*2),\n",
        "            nn.BatchNorm1d(input_size*2),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(input_size*2, input_size*3),\n",
        "            nn.BatchNorm1d(input_size*3),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(input_size*3, input_size*3),\n",
        "            nn.BatchNorm1d(input_size*3),\n",
        "            nn.ReLU(True),            \n",
        "            nn.Linear(input_size*3, input_size*2),\n",
        "            nn.BatchNorm1d(input_size*2),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(input_size*2, input_size),\n",
        "            #nn.BatchNorm1d(term_length*4),\n",
        "            nn.Tanh() # -1 ~ 1\n",
        "        )\n",
        "\n",
        "    \n",
        "    def __init__(self, input_size=1024):\n",
        "        super(Generator, self).__init__()\n",
        "        l1 = nn.Linear(input_size, input_size*4)\n",
        "        l1.weight.data.normal_(0.0, 0.01)\n",
        "        bn = nn.BatchNorm1d(input_size*4)\n",
        "        bn.weight.data.normal_(0.0, 0.01)\n",
        "        bn.bias.data.fill_(0)        \n",
        "        l2 = nn.Linear(input_size*4, input_size)\n",
        "        l2.weight.data.normal_(0.05, 0.01)\n",
        "        self.layer = nn.Sequential(\n",
        "            l1,\n",
        "            bn,\n",
        "            nn.ReLU(True), #nn.LeakyReLU(0.2),\n",
        "            l2,\n",
        "            #nn.BatchNorm1d(term_length*4),\n",
        "            nn.Tanh() # -1 ~ 1\n",
        "        )\n",
        "    '''\n",
        "\n",
        "    def __init__(self, input_size=1024):\n",
        "        super(Generator, self).__init__()\n",
        "        self.layer = nn.Sequential(\n",
        "            nn.Linear(input_size, input_size*4),\n",
        "            nn.BatchNorm1d(input_size*4),\n",
        "            nn.ReLU(True), #nn.LeakyReLU(0.2),\n",
        "            nn.Linear(input_size*4, input_size*4),\n",
        "            nn.BatchNorm1d(input_size*4),\n",
        "            nn.ReLU(True), #nn.LeakyReLU(0.2),            \n",
        "            nn.Linear(input_size*4, input_size),\n",
        "            #nn.BatchNorm1d(input_size),\n",
        "            #nn.ReLU(True), #nn.LeakyReLU(0.2),\n",
        "            nn.Tanh() # -1 ~ 1\n",
        "        )\n",
        "\n",
        "    def forward(self, x, bias):\n",
        "        #biased_noise = torch.randn(N,_NOISE_DIM)\n",
        "        # stroy peak에 해당하는 term에게 평균값에 해당하는 bias를 추가 한다.\n",
        "                 \n",
        "        y_ = self.layer(x)\n",
        "        y = torch.add(y_,bias)\n",
        "        #y = nn.Sigmoid()(y)\n",
        "\n",
        "        return y, y_\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myU75t4_4dni"
      },
      "source": [
        "# multi-discriminator에 대한 Adaptive discriminant factor 를 구하기 위한 학습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0RQOPpQgUTE"
      },
      "source": [
        "# 학습기..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nd8GTS7HKz1H",
        "trusted": true
      },
      "source": [
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "from scipy.special import expit\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SAM_Summarizer:\n",
        "\n",
        "    def __init__(self,g_discriminator,s_discriminator):\n",
        "        self.g_discriminator = g_discriminator\n",
        "        #self.c_discriminator = c_discriminator\n",
        "        self.s_discriminator = s_discriminator\n",
        "        self.m = nn.Sigmoid()\n",
        "        self.with_bias = True\n",
        "\n",
        "    def ready(self,source):\n",
        "        self.source = source  \n",
        "        #self.source.analysis_frame_terms(self.s_discriminator)\n",
        "        self.generator = Generator(input_size=self.source.org_source_length)\n",
        "        self.generator.apply(weights_init)\n",
        "        return self\n",
        "\n",
        "    def summarize(self,epochs=10,batch_size=1,learning_rate=2e-4, display = False):\n",
        "        history = self.__train(epochs,batch_size,learning_rate,display)\n",
        "\n",
        "        if display and history is not None:\n",
        "            plt.figure(figsize=(12, 6))\n",
        "            plt.plot(history['gen_g_loss'],label='grammar loss')\n",
        "            plt.plot(history['gen_l_loss'],label='compression loss')\n",
        "            plt.plot(history['gen_s_loss'],label='n-gram similarity loss')\n",
        "            #plt.plot(history['gen_c_loss'],label='context similarity loss')\n",
        "            #plt.plot(history['total loss'],label='total loss')\n",
        "            plt.plot(history['losses std'],label='standard deviation of losses')\n",
        "            \n",
        "            #if 'dis_loss' in history:\n",
        "            #    plt.plot(history['dis_loss'],label='discriminator grammar loss')\n",
        "            plt.legend()\n",
        "            plt.show()\n",
        "\n",
        "        return history\n",
        "\n",
        "    # text의 생성 for torch\n",
        "    def __text_gen2(self, p_txt, gen_length):\n",
        "        gtext = []\n",
        "        sorted_noise, i = torch.sort(p_txt, descending=True)\n",
        "        order, i = torch.sort(i[:gen_length], descending=False)\n",
        "        #print(len(order))\n",
        "        #print(gen_length)\n",
        "        assert len(order) == gen_length\n",
        "        order = order.cpu().detach().numpy()\n",
        "        for k in order:\n",
        "            gtext.append((self.source.term_table[k],k))\n",
        "        return gtext\n",
        "\n",
        "    def __text_gen3(self, p_txt):\n",
        "        gtext = []\n",
        "\n",
        "        for order,p in enumerate(p_txt):\n",
        "            if p > 0.0:\n",
        "                gtext.append(self.source.term_table[order])\n",
        "        return gtext\n",
        "\n",
        "    def __text_gen5(self, p_txt):\n",
        "        gtext = []\n",
        "\n",
        "        for order,p in enumerate(p_txt):\n",
        "            if p > 0.0:\n",
        "                gtext.append(self.source.combination_table[order])\n",
        "        return gtext\n",
        "\n",
        "    def __text_hash(self, p_txt):\n",
        "        b = []\n",
        "        #hash(tuple(b))\n",
        "        for order,p in enumerate(p_txt):\n",
        "            if p > 0.0:\n",
        "                b.append(order)\n",
        "        return hash(tuple(b))\n",
        "\n",
        "    def __text_gen4(self, p_txt):\n",
        "        gtext = \"\"\n",
        "        indexs = []\n",
        "        for order,p in enumerate(p_txt):\n",
        "            if p > 0.0:\n",
        "                gtext += self.source.term_table[order] + ' '\n",
        "                indexs.append(order)\n",
        "        return gtext.strip(),indexs\n",
        "\n",
        "\n",
        "    def __discrete_gradient(self,weights,use_gpu=False, verbose=0):\n",
        "        fake_gen_out = torch.zeros(weights.shape).to(device)\n",
        "        fake_cos_out = torch.zeros(weights.shape).to(device)\n",
        "        fake_sim_out = torch.zeros(weights.shape).to(device)\n",
        "        fake_len_out = torch.zeros(weights.shape).to(device) \n",
        "\n",
        "        #real_text = self.source.get_org_sample(weights.shape[0])\n",
        "        fake_outs = []\n",
        "        #real_outs = []\n",
        "        apply_order = []\n",
        "        for i, noise in enumerate(weights):\n",
        "            #gtext = self.__text_gen2(noise,gen_length)\n",
        "            gtext,tk = self.__text_gen4(noise)\n",
        "            fake_outs.append(gtext)\n",
        "            apply_order.append((i,tk))\n",
        "  \n",
        "        #print(fake_outs)\n",
        "\n",
        "        D_z_loss, fake_gmr_out=self.g_discriminator.transfer_learning(fake_outs,train_for = False)\n",
        "\n",
        "        o_sim_out = []\n",
        "        o_cos_out = []\n",
        "        o_len_out = []\n",
        "        for fake_text in fake_outs:\n",
        "            s1 = cosine_similarity(self.source.full_text,fake_text)  \n",
        "            #s1 = self.s_discriminator.similarity(fake_text,self.source.full_text_emb)\n",
        "            #s2 = 0.5 #cosine_similarity(self.source.full_text,fake_text)  #self.s_discriminator.similarity(fake_text,self.source.full_text_emb)\n",
        "            #s = ((s1+s2)/2 - 0.5) * 2\n",
        "            #s = (s1 - 0.5) * 2\n",
        "            #print(s)\n",
        "            #print(s)\n",
        "            cs = 0.5 #(s2/2 - 0.5) * 2\n",
        "            l = 1 - len(fake_text)/len(self.source.org_text)\n",
        "            #l = ((1 - len(fake_text.split(' '))/len(self.source.org_text.split(' ')))-0.5) * 2\n",
        "            #print(l)\n",
        "            o_sim_out.append(s1)\n",
        "            o_cos_out.append(cs)\n",
        "            o_len_out.append(l)\n",
        "            #print(1 - len(fake_text.split(' '))/self.source.org_source_length)\n",
        "            #o_len_out.append(-len(fake_text.split(' '))/self.source.org_source_length)\n",
        "        \n",
        "        \n",
        "        for j, (i,tk) in enumerate(apply_order):\n",
        "\n",
        "            try:\n",
        "                '''\n",
        "                a = torch.tanh( fake_gmr_out[j,1])\n",
        "                if a > 0 :\n",
        "                    fake_gen_out[:] = -0.5\n",
        "                    fake_gen_out[i,tk] = a\n",
        "                else:\n",
        "                    fake_gen_out[:] = 0.5\n",
        "                    fake_gen_out[i,tk] = a\n",
        "                '''\n",
        "                fake_gen_out[i,tk] = torch.tanh( fake_gmr_out[j,1])\n",
        "                fake_sim_out[i,tk] = o_sim_out[j]\n",
        "                fake_cos_out[i,tk] = o_cos_out[j]\n",
        "                #fake_len_out[i,tk] = o_len_out[j]\n",
        "                fake_len_out[:] = -o_len_out[j]\n",
        "                #fake_len_out[i,tk] = 0 #torch.tensor(fake_text_len/self.source.org_source_length).to(device)\n",
        "                #fake_len_out[:] = o_len_out[j] #torch.tensor(fake_text_len/self.source.org_source_length).to(device)\n",
        "                #print(o_len_out[j])\n",
        "            except Exception as ex:\n",
        "                print(j,i,tk)\n",
        "                print(fake_gmr_out)\n",
        "                raise ex\n",
        "\n",
        "        return fake_gen_out, fake_sim_out, fake_cos_out, fake_len_out #fake_com_out, fake_sim_out #, D_z_loss, D_x_loss\n",
        "\n",
        "\n",
        "    def __train(self, epochs=10,batch_size=10,learning_rate=2e-4,display = False):\n",
        "        # In the Deepmind paper they use RMSProp however then Adam optimizer\n",
        "        # improves training time\n",
        "        #generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "        # This method returns a helper function to compute cross entropy loss\n",
        "        #cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "        # Set the seed value all over the place to make this reproducible.\n",
        "        seed_val = int(random.random()*100)\n",
        "\n",
        "        random.seed(seed_val)\n",
        "        np.random.seed(seed_val)\n",
        "        torch.manual_seed(seed_val)\n",
        "        torch.cuda.manual_seed_all(seed_val)\n",
        "        \n",
        "        criterion = nn.MSELoss()\n",
        "        #D_opt = torch.optim.Adam(D.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "        G_opt = AdamW(self.generator.parameters(),\n",
        "                        lr = 2e-3, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                        eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                        )\n",
        "        # Create the learning rate scheduler.\n",
        "        scheduler = get_linear_schedule_with_warmup(G_opt, \n",
        "                                                    num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                                    num_training_steps = epochs)\n",
        "        \n",
        "        #gen_length = len(self.source.story_peaks) + int(len(self.source.story_peaks)*self.frame_expansion_ratio)\n",
        "        pb = ProgressBar(epochs,prefix='Train...')\n",
        "        gen_gmr_loss_history = []\n",
        "        gen_len_loss_history = []\n",
        "        gen_sim_loss_history = []\n",
        "        gen_cos_loss_history = []\n",
        "        dis_loss_history = []    \n",
        "        total_loss_history = []\n",
        "        losses_std_history = []\n",
        "\n",
        "        #model 들은 cuda로 보낸다.\n",
        "        self.g_discriminator.discriminator.to(device)\n",
        "        self.g_discriminator.discriminator.eval() # 학습하지 않는다...\n",
        "        #self.c_discriminator.discriminator.to(device)\n",
        "        #self.c_discriminator.discriminator.eval() # 학습하지 않는다...\n",
        "\n",
        "        self.generator.to(device)       \n",
        "        self.generator.train()\n",
        "\n",
        "        #self.bias_w = init_bias\n",
        "        initial_bias = 0\n",
        "        G_s_loss = torch.tensor(0)\n",
        "        #G_c_loss = torch.tensor(0)\n",
        "        G_g_loss = torch.tensor(0)\n",
        "\n",
        "\n",
        "        epsilon = 1 # Epsilon-greedy algorithm in initialized at 1 meaning every step is random at the start\n",
        "        max_epsilon = 1 # You can't explore more than 100% of the time\n",
        "        min_epsilon = 0.001 # At a minimum, we'll always explore 1% of the time\n",
        "        decay = 10/epochs\n",
        "        \n",
        "\n",
        "        dfs = torch.tensor([ 1.0, 1.0, 3.0], device=device, dtype=torch.float, requires_grad=True)\n",
        "        target = torch.tensor([list(self.source.bias_table.values()) for u in range(batch_size)],dtype=torch.float).to(device)\n",
        "        #print(target)\n",
        "        #noise = torch.randn(batch_size,self.source.org_source_length).to(device) \n",
        "        a_w = 1.0\n",
        "        for i in range(epochs):\n",
        "   \n",
        "            if True:\n",
        "                noise = torch.randn(batch_size,self.source.org_source_length).to(device) \n",
        "                '''\n",
        "                random_number = np.random.rand()\n",
        "                # 2. Explore using the Epsilon Greedy Exploration Strategy\n",
        "                if random_number <= epsilon:\n",
        "                    # Explore\n",
        "                    bias = torch.randn(batch_size,self.source.org_source_length).to(device) * epsilon\n",
        "                    #b = torch.tensor([list(self.source.bias_table.values()) for u in range(batch_size)]).to(device)\n",
        "                    #bias = torch.add(a,b)\n",
        "                    #noise = torch.randn(batch_size,self.source.org_source_length).to(device) \n",
        "                else:\n",
        "                    #bias = torch.tensor([list(self.source.bias_table.values()) for u in range(batch_size)]).to(device)\n",
        "                    bias = torch.zeros_like(noise).to(device)\n",
        "                '''\n",
        "                bias = torch.zeros_like(noise).to(device)\n",
        "\n",
        "\n",
        "                #if self.with_bias:\n",
        "                #    bias[:,noise.shape[1]-1] = 0.1\n",
        "                #bias[:,noise.shape[1]-1] = 0.5\n",
        "                #if i < epochs/4:\n",
        "                #bias = torch.randn(batch_size,self.source.org_source_length).to(device) / 4                 \n",
        "                #bias = torch.randn(batch_size,self.source.org_source_length).to(device) \n",
        "\n",
        "                sw, sw0 = self.generator(noise,bias)\n",
        "                #print(sw)\n",
        "                with torch.no_grad():                \n",
        "                    fake_gmr_out, fake_sim_out, fake_cos_out, fake_len_out = self.__discrete_gradient(sw)\n",
        "\n",
        "                #print(fake_len_out)\n",
        "                #print(fake_gmr_out)\n",
        "                sw2 = sw * fake_gmr_out\n",
        "                #print(sw2)\n",
        "                G_g_loss = -torch.mean(sw2)\n",
        "                #print(G_g_loss)\n",
        "                sw1 = sw * fake_sim_out\n",
        "                G_s_loss = -torch.mean(sw1)\n",
        "\n",
        "                sw4 = sw * fake_cos_out\n",
        "                G_c_loss = -torch.mean(sw4) \n",
        "\n",
        "                #sw3 = sw * fake_len_out\n",
        "                #G_l_loss = -torch.mean(sw3)\n",
        "\n",
        "                G_l_loss = criterion(sw,target)\n",
        "\n",
        "                dsc_loss = torch.stack([G_g_loss,G_s_loss,G_l_loss])\n",
        "\n",
        "                G_loss = torch.dot(dfs,dsc_loss) #+ torch.std(dsc_loss)\n",
        "                #G_loss =  G_g_loss  + G_s_loss * 5 + G_l_loss\n",
        "                #G_loss = G_l_loss\n",
        "\n",
        "                #print(G_loss)\n",
        "                \n",
        "                self.generator.zero_grad()\n",
        "                G_loss.backward()\n",
        "                #print('backward:')\n",
        "                G_opt.step()\n",
        "                scheduler.step()\n",
        "                '''\n",
        "                learning_rate = 0.02\n",
        "                with torch.no_grad():\n",
        "                    dfs += learning_rate * dfs.grad\n",
        "                    dfs.grad = None                    \n",
        "                    dfs[dfs < 0] = 0.1                \n",
        "                '''\n",
        "                if G_g_loss == 0:# or (i > 100 and G_g_loss > 0):\n",
        "                    return None\n",
        "\n",
        "                #if G_g_loss > 0:\n",
        "                #    a_w += 0.4\n",
        "\n",
        "            gen_gmr_loss_history.append(G_g_loss.cpu().detach().numpy())\n",
        "            gen_cos_loss_history.append(G_c_loss.cpu().detach().numpy())\n",
        "            gen_sim_loss_history.append(G_s_loss.cpu().detach().numpy())\n",
        "            #dis_loss_history.append(D_loss.cpu().detach().numpy())\n",
        "            gen_len_loss_history.append(G_l_loss.cpu().detach().numpy())\n",
        "\n",
        "            #pb.printProgress(+1,f'{i+1}/{epochs} epochs, beta:{dfs} Generator / grammar loss:{G_g_loss}  similarity loss:{G_s_loss}') #,   Discriminator grammar_loss:{D_loss}        ')\n",
        "            #pb.printProgress(+1,'{}/{} epochs, beta:{}, grammar loss:{:.4f}  similarity loss:{:.4f} length loss:{:.4f}'.format(i+1,epochs,dfs,G_g_loss,G_s_loss,G_l_loss)) #,   Discriminator grammar_loss:{D_loss}        ')\n",
        "            pb.printProgress(+1,'{}/{} epochs, e {:.5f} gl:{:.8f}  sl:{:.4f} ll:{:.4f}'.format(i+1,epochs,epsilon, G_g_loss,G_s_loss,G_l_loss)) #,   Discriminator grammar_loss:{D_loss}        ')\n",
        "            \n",
        "            total_loss_history.append(torch.sum(dsc_loss).item())\n",
        "            losses_std_history.append(torch.std(dsc_loss).item())\n",
        "\n",
        "            epsilon = min_epsilon + (max_epsilon - min_epsilon) * np.exp(-decay * i)\n",
        "            \n",
        "        self.generator.eval()\n",
        "        #self.g_discriminator.discriminator.eval()\n",
        "        if display:\n",
        "            plt.figure(figsize=(12, 6))\n",
        "            xs = np.arange(self.source.org_source_length)\n",
        "            plt.bar(xs+0.0,sw0[0].cpu().detach().numpy(),label='before activation weights',width=0.2)\n",
        "            plt.bar(xs+0.2,sw[0].cpu().detach().numpy(),label='after activation weights',width=0.2)\n",
        "            plt.bar(xs+0.4,bias[0].cpu().detach().numpy(),label='bias weights',width=0.2)         \n",
        "            plt.legend()        \n",
        "            plt.show()\n",
        "\n",
        "        return  {'gen_g_loss':gen_gmr_loss_history,'gen_s_loss':gen_sim_loss_history,'gen_c_loss':gen_cos_loss_history,'gen_l_loss':gen_len_loss_history,'total loss':total_loss_history,'losses std':losses_std_history} #,'dis_loss':dis_loss_history }\n",
        "    '''\n",
        "    def get_summary(self, count):\n",
        "        #texts = []\n",
        "        self.generator.cpu()\n",
        "        self.generator.eval()\n",
        "        #gen_length = len(self.source.story_peaks) + int(len(self.source.story_peaks)*self.frame_expansion_ratio)\n",
        "        noise = torch.randn(count,self.source.org_source_length)\n",
        "        bias = torch.zeros_like(noise)\n",
        "        if self.with_bias:\n",
        "            bias[:,noise.shape[1]-1] = 1\n",
        "        with torch.no_grad():\n",
        "            sw,sw0 = self.generator(noise,bias)\n",
        "            #sw,sw0 = self.generator(noise)\n",
        "\n",
        "        max_score = 0\n",
        "        max_sim = 0\n",
        "        comp_rate = 0\n",
        "        best_text = \"\"\n",
        "\n",
        "        for p_txt in sw:\n",
        "            gtext = self.__text_gen3(p_txt)\n",
        "            text = ' '.join(gtext)\n",
        "            \n",
        "            #print('>>',text)\n",
        "            sim_score = self.s_discriminator.similarity(text,self.source.full_text_emb)\n",
        "            if sim_score > max_sim:\n",
        "                best_text = text.strip()\n",
        "                loss, out=self.g_discriminator.transfer_learning([text],train_for = False)\n",
        "                max_score = out[0,1].item()\n",
        "                comp_rate = 1 - len(best_text)/len(self.source.org_text)\n",
        "                max_sim = sim_score\n",
        "            #texts.append([text.strip(),out,sim_score])\n",
        "        return best_text, max_score, max_sim, comp_rate\n",
        "    '''\n",
        "    def get_samples(self,count):\n",
        "        self.generator.cpu()\n",
        "        self.generator.eval()\n",
        "        noise = torch.randn(count,self.source.org_source_length)\n",
        "        bias = torch.zeros_like(noise)\n",
        "        #if self.with_bias:\n",
        "        #    bias[:,noise.shape[1]-1] = 1\n",
        "        with torch.no_grad():\n",
        "            sw,sw0 = self.generator(noise,bias)\n",
        "        #samples = []\n",
        "        best_p_txt = None\n",
        "        best_text = \"\"\n",
        "        best_grammar_score = 0\n",
        "        max_score = 0\n",
        "        second_best_text = \"\"\n",
        "        second_max_score = 0        \n",
        "        hash_list = []\n",
        "        for p_txt in sw:\n",
        "            gtext = self.__text_gen3(p_txt)\n",
        "            h = self.__text_hash(p_txt)\n",
        "            if h in hash_list:\n",
        "                pass\n",
        "            else:\n",
        "                hash_list.append(h)\n",
        "                text = (' '.join(gtext).strip())\n",
        "                loss, out=self.g_discriminator.transfer_learning([text],train_for = False)\n",
        "                #sim_score = self.s_discriminator.similarity(text,self.source.org_text_emb)\n",
        "\n",
        "                sim_score = cosine_similarity(self.source.org_text,text)    \n",
        "                comp_rate = 1 - len(text)/len(self.source.org_text)\n",
        "\n",
        "                #samples.append((text,out[0,1].item(),sim_score,comp_rate))\n",
        "                #score = out[0,1].item() + sim_score + comp_rate*2\n",
        "                score = out[0,1].item()/6 + sim_score * 2 + comp_rate\n",
        "                print('{:.4f},{:.4f},score:{:.4f},[{}]'.format(sim_score,comp_rate,score,text))\n",
        "                if max_score < score and (comp_rate > 0.4 and comp_rate < 0.6 ):\n",
        "                    best_p_txt = p_txt\n",
        "                    max_score = score\n",
        "                    best_text = text\n",
        "                    best_grammar_score = out[0,1].item()\n",
        "                if max_score < score:\n",
        "                    second_max_score = score\n",
        "                    second_best_text = text\n",
        "                    best_p_txt = p_txt\n",
        "                    best_grammar_score = out[0,1].item()\n",
        "            if max_score == 0:\n",
        "                max_score = second_max_score\n",
        "                best_text = second_best_text                           \n",
        "        #return [best_text for i in range(count)], max_score\n",
        "        \n",
        "        correct_best_text = sentence_correct(' '.join(self.__text_gen5(best_p_txt)))\n",
        "        loss, out=self.g_discriminator.transfer_learning([best_text],train_for = False)\n",
        "        best_grammar_score = out[0,1].item()\n",
        "        loss, out=self.g_discriminator.transfer_learning([correct_best_text],train_for = False)\n",
        "        correct_best_grammar_score = out[0,1].item()\n",
        "        if best_grammar_score < 5.0 and correct_best_grammar_score > best_grammar_score:\n",
        "            print('correct_grammar_score:{:.4f} best_grammar_score:{:.4f}'.format(correct_best_grammar_score,best_grammar_score))\n",
        "            print(best_text)\n",
        "            print(correct_best_text)\n",
        "            best_text = correct_best_text\n",
        "        \n",
        "        return best_text, max_score, best_grammar_score\n"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCdfO9iuLH6D"
      },
      "source": [
        "#5. Experiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYs__02JjKjT"
      },
      "source": [
        "## CDD/Daily mail Sample data 수집"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCOWg1jX-OKH"
      },
      "source": [
        "import pickle\n",
        "with open(\"/content/drive/MyDrive/Colab Notebooks/summary/data/dnn_daily_mail_sample.bin\", \"rb\") as fp:\n",
        "    dt = pickle.load(fp)\n",
        "sentences_dataset = dt[0]\n",
        "gold_summary = dt[1]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_eAwIPLb4aj"
      },
      "source": [
        "## 비교 대상 요약 알고리즘 준비"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhcoXuPMGy09"
      },
      "source": [
        "def sam_wgan4(full_text,text, epochs=50, batch_size=100,display=False, retry = True, retry_count = 0):\n",
        "    if retry_count > 10:\n",
        "        raise Exception(\"Can't summarize the text\")\n",
        "\n",
        "    source = Source(full_text,text,delete_ending = False)\n",
        "    source.set_key_rate(s_discriminator)\n",
        "    summarizer = SAM_Summarizer(g_discriminator,s_discriminator)\n",
        "    summarizer.ready(source)\n",
        "    hist = summarizer.summarize(epochs,batch_size=2,learning_rate=5e-3,display=display)\n",
        "    if retry and hist == None and retry_count < 10:\n",
        "        print('\\n')\n",
        "        return sam_wgan4(full_text,text, epochs+10, batch_size,display=display,retry_count=retry_count+1)\n",
        "    samples, max_score, best_grammar_score = summarizer.get_samples(batch_size)\n",
        "    #print(samples)\n",
        "    \n",
        "    if retry and best_grammar_score < (1.0 - retry_count*0.1):\n",
        "        print('max score:{} grammar:{} text:{}'.format(max_score,best_grammar_score,samples))\n",
        "        return sam_wgan4(full_text,text, epochs+10, batch_size,display=display,retry_count=retry_count+1)\n",
        "    \n",
        "    return samples, max_score, best_grammar_score"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "-pJUPNgwmSKB",
        "outputId": "ead5346d-8705-4d7d-a96e-467aa212f4b1"
      },
      "source": [
        "sentences_dataset[2]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"A drunk driver who killed a young woman in a head-on crash while checking his mobile phone has been jailed for six years. Craig Eccleston-Todd, 27, was driving home from a night at a pub when he received a text message. As he was reading or replying to it, he veered across the road while driving round a bend and smashed into Rachel Titley’s car coming the other way. Craig Eccleston-Todd, 27 (left) was using his mobile phone when he crashed head-on into the car being driven by Rachel Titley, 28 (right). She died later from her injuries . The head-on crash took place in October 2013. Mr Eccleston-Todd's car was barely recognisable (pictured) Police said Eccleston-Todd had drunk at least three or four pints of beer before getting behind the wheel. He was found guilty of causing death by dangerous driving at Portsmouth Crown Court yesterday. Miss Titley, a 28-year-old solicitor’s clerk from Cowes, Isle of Wight, had also spent the evening with friends at a pub but had not drunk any alcohol, police said. She was driving responsibly and there was ‘nothing she could have done to avoid the collision’, they added. Lindsay Pennell, prosecuting, said: ‘Craig Eccleston-Todd’s driving resulted in the tragic death of a young woman, Rachel Titley, a death that could have been avoided. ‘Mr Eccleston-Todd took the decision to pick up his mobile phone whilst driving and, either reading or replying to this text message, was so distracted that he failed to negotiate a left-hand bend, crossing the central white line into the path of Miss Titley’s oncoming car. Miss Titley was pulled the wreckage of her\\xa0Daihatsu Cuore but died later from her injuries in hospital . ‘Miss Titley [had] a bright future ahead of her. She was also returning home having spent an enjoyable evening with friends and was driving responsibly. ‘She had arranged to contact her friends when she got home to confirm that she had arrived safely. Her friends sadly never heard from her after they parted company. ‘Miss Titley’s death in these circumstances reiterates the danger of using a hand-held mobile phone whilst driving.’ Police were unable to take breath or blood tests from Eccleston-Todd immediately, but in tests several hours after the accident he was only marginally under the drink-drive limit. The judge agreed with police that he would have been over the limit at the time his red Citroen hit Miss Titley’s blue Daihatsu Cuore on a road near Yarmouth, Isle of Wight, on October 11, 2013. His phone records showed he was also texting around the time of the crash. PC Mark Furse, from Hampshire constabulary’s serious collision investigation unit, said: 'Our thoughts are with Rachel's family at this time. She had been out with friends at a pub in Shalfleet that evening, but had not had any alcohol. 'Our investigation showed that there was nothing she could have done to avoid the collision and sadly it cost her her life. 'Mr Eccleston-Todd had left work in Yarmouth and met with friends at a pub where he drank at least three to four pints of lager. He hadn't long left the pub to return home when the collision occurred at around 9.30pm. 'We weren't able to take breath or blood tests from him immediately and although blood taken several hours after the collision showed he was marginally under the limit, we maintain he would have been over the limit at the time of the collision and in summing up today, the judge agreed. 'The analysis of his phone records showed that he was texting on his phone around the time of the collision so it's highly likely this would also have contributed to his dangerous driving and loss of control.' Eccleston-Todd was found guilty of causing death by dangerous driving following a trial at Portsmouth Crown Court (pictured) He added: 'Mr Eccleston-Todd will now spend six years behind bars, but Rachel's family have lost her forever. 'I hope this will make people think twice before drinking any alcohol and getting behind the wheel, or using a phone once they're on the road. 'The dangers of drink driving and driving whilst using a mobile phone are obvious. Those who continue to do so risk spending a substantial time in prison. This case highlights just how tragic the consequences of committing these offences can be.' ‘Mr Eccleston-Todd will now spend six years behind bars, but Rachel’s family have lost her for ever. I hope this will make people think twice before drinking any alcohol and getting behind the wheel, or using a phone once they’re on the road. This case highlights just how tragic the consequences of committing these offences can be.’ Eccleston-Todd, of Newport, Isle of Wight, was also disqualified from driving for eight years\\xa0after which he will have to complete an extended re-test.\""
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYHIkaar2zb-"
      },
      "source": [
        "# 간단한 전처리\n",
        "def __clean_text(txt):\n",
        "    txt = txt.replace('\\n',' ')\n",
        "    txt = txt.replace('\\r',' ')    \n",
        "    #txt = txt.replace('=','')\n",
        "    #txt = txt.replace('\\\"','')   \n",
        "    #txt = txt.replace('\\'','')\n",
        "    #txt = txt.replace(',','')\n",
        "    #txt = txt.replace('..','')\n",
        "    #txt = txt.replace('...','')\n",
        "    txt = txt.replace('.',' ')\n",
        "    #txt = txt.replace('.','. ')\n",
        "    txt = txt.replace('  ',' ')\n",
        "    txt = txt.replace('  ',' ')    \n",
        "    txt = txt.replace('  ',' ')   \n",
        "    txt = txt.replace('  ',' ')           \n",
        "    txt = txt.replace('  ',' ')\n",
        "    txt = txt.replace('  ',' ')    \n",
        "    txt = txt.replace('  ',' ')   \n",
        "    txt = txt.replace('  ',' ')             \n",
        "    return txt.strip()\n",
        "\n",
        "def get_prepared_doc(txt):\n",
        "    docs = []\n",
        "    sentences = np.array(nltk.sent_tokenize(txt))\n",
        "    for sen in sentences:\n",
        "        docs.append(__clean_text(sen) +'.')\n",
        "    return (' '.join(docs)).strip()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6v9sEryZOLa"
      },
      "source": [
        "# Sentence Corrector (EncoderDecoderModel)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUe3ZCSIz8N8"
      },
      "source": [
        "from transformers import EncoderDecoderModel, BertTokenizerFast\n",
        "import torch\n",
        "\n",
        "pre_trained_kobert_model_name='bert-base-uncased'\n",
        "\n",
        "tokenizer = BertTokenizerFast.from_pretrained(pre_trained_kobert_model_name)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euuB9E5uZ1j2"
      },
      "source": [
        "from transformers import EncoderDecoderModel, BertTokenizerFast\n",
        "try:\n",
        "    del model\n",
        "    print('delete model')\n",
        "except Exception as ex:\n",
        "    pass\n",
        "model = EncoderDecoderModel.from_pretrained(\"/content/drive/MyDrive/GAN_ENDE/en_sentence_complete_model\")"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hr_6N_CYaKAI"
      },
      "source": [
        "def sentence_correct(text):\n",
        "    text = text.strip()\n",
        "    w = text.split(' ')\n",
        "    last_token = w[len(w)-1][:-1]\n",
        "    inputs = tokenizer(text, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n",
        "    input_ids = inputs.input_ids.to(device)\n",
        "    attention_mask = inputs.attention_mask.to(device)\n",
        "    '''\n",
        "    v = torch.sum(attention_mask[0]).item()\n",
        "    c = random.sample([i for i in range(v)],int(v/2))\n",
        "    print(c)\n",
        "    #input_ids[0][c] = 0\n",
        "    attention_mask[0][c] = 0 #random.random()\n",
        "    attention_mask[0][0] = 1\n",
        "    attention_mask[0][v-1] = 1\n",
        "    \n",
        "    print(input_ids)    \n",
        "    print(attention_mask)\n",
        "    '''\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    outputs = model.generate(input_ids, attention_mask=attention_mask).cpu().detach().numpy()[0]\n",
        "    o=[]\n",
        "    for token in outputs:\n",
        "        if token == tokenizer.pad_token_id:\n",
        "            break\n",
        "        o.append(token)\n",
        "    output_str = tokenizer.batch_decode([o], skip_special_tokens=True)[0]\n",
        "    print('raw',output_str)\n",
        "    eos = output_str.find('.')\n",
        "    real_eos =  eos\n",
        "    if last_token.endswith('다'):\n",
        "        eos2 = output_str.find(last_token) \n",
        "        if eos2 > 0 and eos2 < eos:\n",
        "            real_eos = eos2 + len(last_token)\n",
        "    output_str = output_str[0:real_eos] + '.'\n",
        "    return output_str"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "GkdOT4m6Jlx9",
        "outputId": "156aeea0-64d5-499b-dfb3-b8a97ea03eea"
      },
      "source": [
        "txt = 'judge agreed with police that would have been over limit time Citroen Miss Titley’s blue Daihatsu Cuore road near Yarmouth Isle Wight October 2013 phone records showed also texting around time crash.'\n",
        "sentence_correct(txt)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "raw . as as as representative representative representative representatives representative representatives representatives representatives representative representative as as representatives representatives allies allies allies allied allied allied allies allied allies allies representatives representatives allied allied ally allies allies rivals allies allies ally allied allied rival allied allied dominion dominion dominion allied allied middle middle middle allies allies dominion dominion allies allies middle middle allied allies ally ally allies allied ally ally ally dominion dominion ally ally allied ally allied allies dominion ally allies ally dominion ally dominion allied ally dominion allies allied dominion allied allies rival dominion dominion middle middle ally ally middle middle dominion dominion supremacy dominion dominion dimension dominion dominion dependent dominion dominion representative dominion dominion rival middle middle body middle middle rival rival ally ally rival rival rival allies allies rival rival allied ally rival allied allies rivals rival rival dominion\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'.'"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_6X1JsSJLqi",
        "outputId": "6c5cefbe-397e-4fdc-8d40-e31b34b20391"
      },
      "source": [
        "!pip3 install bert-extractive-summarizer"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bert-extractive-summarizer in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (from bert-extractive-summarizer) (4.10.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from bert-extractive-summarizer) (0.22.2.post1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (from bert-extractive-summarizer) (2.2.4)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->bert-extractive-summarizer) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->bert-extractive-summarizer) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->bert-extractive-summarizer) (1.0.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (1.1.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (4.62.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (1.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (1.0.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (1.0.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (3.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (2.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (0.8.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (7.4.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (2.23.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->bert-extractive-summarizer) (4.6.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy->bert-extractive-summarizer) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy->bert-extractive-summarizer) (3.7.4.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy->bert-extractive-summarizer) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy->bert-extractive-summarizer) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy->bert-extractive-summarizer) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy->bert-extractive-summarizer) (1.24.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers->bert-extractive-summarizer) (0.0.17)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers->bert-extractive-summarizer) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers->bert-extractive-summarizer) (0.0.45)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers->bert-extractive-summarizer) (21.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers->bert-extractive-summarizer) (5.4.1)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers->bert-extractive-summarizer) (0.10.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers->bert-extractive-summarizer) (3.0.12)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers->bert-extractive-summarizer) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers->bert-extractive-summarizer) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers->bert-extractive-summarizer) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "porcPq1WJXF3"
      },
      "source": [
        "def besm(full_text,text,top_rank=2):\n",
        "\n",
        "    queries = nltk.sent_tokenize(text)\n",
        "    src_sentences = nltk.sent_tokenize(full_text)\n",
        "    query_embeddings = s_discriminator._embedder.encode(queries,show_progress_bar=False)\n",
        "    full_text_embeddings = s_discriminator._embedder.encode(src_sentences,show_progress_bar=False)\n",
        "    #print(queries)\n",
        "    #print(org_text_emb)\n",
        "    \n",
        "    if len(query_embeddings) == 0:\n",
        "        return 0.0\n",
        "\n",
        "    cos_scores = scipy.spatial.distance.cdist(query_embeddings, full_text_embeddings, \"cosine\")\n",
        "    scores = np.max(cos_scores,axis=1)\n",
        "    orderd = [(o,s) for o,s in enumerate(scores)]\n",
        "    orderd.sort(key=lambda e: e[1],reverse=True)\n",
        "    a = [orderd[i][0] for i in range(0,top_rank)]\n",
        "    a.sort()\n",
        "    summ_text = \" \".join([queries[i] for i in a])\n",
        "\n",
        "    return summ_text\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TN3dYRJ84j3Y"
      },
      "source": [
        "def besm2(full_text,text,top_rank=2):\n",
        "    scores = []\n",
        "    queries = nltk.sent_tokenize(text)\n",
        "    for sen in queries:\n",
        "        s = cosine_similarity(sen,full_text)\n",
        "        scores.append(s)\n",
        "        #print(s,sen)\n",
        "    orderd = [(o,s) for o,s in enumerate(scores)]\n",
        "    orderd.sort(key=lambda e: e[1],reverse=True)\n",
        "    a = [orderd[i][0] for i in range(0,top_rank)]\n",
        "    a.sort()\n",
        "    summ_text = \" \".join([queries[i] for i in a])\n",
        "\n",
        "    return summ_text\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250,
          "referenced_widgets": [
            "2725c384f0c5402f8e2e355a8d032c27",
            "841e791180cd4f06810c9fc2ee4b7ef7",
            "e4616ecb441f45f582820181bafcca7c",
            "af73e478e6714728952cae89bd429782",
            "aec90660de0d465d9cf92e176176b3ec",
            "d05d9f35970548faa2eb9ec1bf671aa6",
            "ee227a8ffea04f0084dc4838fb5fe616",
            "db0294e213aa4c86bae60f94aeb40513",
            "fcc1b445088b48a9950955a529a06dbb",
            "babecf53b500436dba413ad8ecfcd86c",
            "24f3badcdde646e7b9be6c0b260df980",
            "567c452d0dda422c918b9411143e0b85",
            "a588624c12b345df964352327718ff99",
            "124a61bb9d8b48bda4d9c187dfe991cc",
            "c1b6672cbf0d4d529d04110b02cec482",
            "91b4bb94c11e4e3e90d198c1f018b0c3",
            "5899d4b33b2f4ba0aca6a903bb844d45",
            "4deb448f6c304585839610a6061e80d1",
            "ddd6b1e63ff04c8ea1d1e4b3191d2b25",
            "094dba517d4549308c9eab2879fd7830",
            "d2ef8f4df6e64caa99980ba45d00aac1",
            "826da1d4aef4498b9448fed1d8be5466",
            "f850723df11b41c99b34012ef670e056",
            "f55d3a93f6b84ec2afee4a393fe3c8d9",
            "ad0464ca6170476b8f1081e784fa6aa4",
            "9bc3e18b752745e29cbef985a2dc2659",
            "5021647bd3664c338c028302ccf6a4b0",
            "689c4681ff4445f0a7ce12cd9c615d3b",
            "7c0975e55ca247aea5793ff3b3316bc5",
            "c87f658ecf7f4c3493cef3ba4fa4c746",
            "a91ceb8a986d4c808333b86b301b7b99",
            "f3e2da4627c54ca1bd6728fece19be42",
            "60f4bf0e200a4d9388c28520e72f728b",
            "631df6a9d8a2470da71920cc0f4bfb43",
            "8de5037a89e443098cc9f5689b76e338",
            "e41755b0bce94913baed72b97dc09dde",
            "553e9c929a2a4a2c9a322937a52b5858",
            "ede5fa1f45e24f1fa67308eda7065db6",
            "ac065fcace8042eeaba38867ac6015d5",
            "277fc75bc5cd49e08d183b04dfeeb263",
            "eaa7f05e2dfb47648cc22c800d2d5967",
            "c017c1a913aa405db460ac19bcdcd0a5",
            "edad20eb7f9b4a4587c273edee9e291f",
            "68d7eb154f534df6bdbd0ef724826851",
            "1d6ba2826e86487992e46568ff427917",
            "c5894f88f0a64bd7892a5feb8b408306",
            "d4ac5a7546d44f128a40e1003de8c78a",
            "5cc8f1cd1a164a6ba631c509b469ce99",
            "8228681ab7694daf8a3efd57e5b24127",
            "c2da357f3794465887383f4d10699c71",
            "84548e5edf894a079ccb063110bd9362",
            "dbf869a2638f47668812cab82815e17d",
            "d19407a17c954f4cb126915bb926a7ae",
            "76959845dd1441b7a7db9b2febb19fe2",
            "dcebf80dd97f4aad87ffe8c60a543096"
          ]
        },
        "id": "ClV7dqUAFmit",
        "outputId": "66ad6338-1281-470f-cd64-dc294f21bf67"
      },
      "source": [
        "from summarizer import Summarizer\n",
        "\n",
        "\n",
        "model1 = Summarizer()\n",
        "\n",
        "def besm(full_text,num_sentences=4):\n",
        "    result = model1(full_text, num_sentences=num_sentences)\n",
        "    return \"\".join(result)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2725c384f0c5402f8e2e355a8d032c27",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/571 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "567c452d0dda422c918b9411143e0b85",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f850723df11b41c99b34012ef670e056",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "631df6a9d8a2470da71920cc0f4bfb43",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1d6ba2826e86487992e46568ff427917",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "uMBrB8mWF2TG",
        "outputId": "942191e4-e9e0-4110-bdf2-81d75e54d6fc"
      },
      "source": [
        "full_text = get_prepared_doc(sentences_dataset[2])\n",
        "besm(full_text)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"A drunk driver who killed a young woman in a head-on crash while checking his mobile phone has been jailed for six years. Mr Eccleston-Todd's car was barely recognisable (pictured) Police said Eccleston-Todd had drunk at least three or four pints of beer before getting behind the wheel. He was found guilty of causing death by dangerous driving at Portsmouth Crown Court yesterday. Miss Titley [had] a bright future ahead of her. Miss Titley’s death in these circumstances reiterates the danger of using a hand-held mobile phone whilst driving ’ Police were unable to take breath or blood tests from Eccleston-Todd immediately, but in tests several hours after the accident he was only marginally under the drink-drive limit.\""
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFJ5v8fia6VD"
      },
      "source": [
        "def summary(ft,text,steps=4,top_rank=2):\n",
        "    org_sentences = np.array(nltk.sent_tokenize(text.strip()))\n",
        "    summary_text = []\n",
        "    for i in range(0,len(org_sentences),steps):\n",
        "        txt = ''\n",
        "        cnt = 0\n",
        "        for s in range(i,i+steps):\n",
        "            if s < len(org_sentences):\n",
        "                txt +=  ' ' + org_sentences[s]\n",
        "                cnt +=1\n",
        "        #print(cnt,top_rank)\n",
        "        txt = txt.strip()\n",
        "        if cnt > top_rank:\n",
        "            txt = besm2(ft,txt,top_rank=top_rank)\n",
        "\n",
        "        t,score, grammar = sam_wgan4(ft,txt.strip(),epochs=200,display=False)\n",
        "        print('-'*50)\n",
        "        print(t,score,grammar)\n",
        "        #t = sentence_correct(t)\n",
        "        #print(t)\n",
        "        summary_text.append(t)\n",
        "\n",
        "    return ' '.join(summary_text).strip()"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FstAHWGQ8KR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 948
        },
        "outputId": "7ef467ed-f090-4279-878a-598316e153f6"
      },
      "source": [
        "txt = \"\"\"\n",
        " The judge agreed with police that he would have been over the limit at the time his red Citroen hit Miss Titley’s blue Daihatsu Cuore on a road near Yarmouth, Isle of Wight, on October 11, 2013. His phone records showed he was also texting around the time of the crash.\n",
        " \"\"\"\n",
        "sam_wgan4(get_prepared_doc(sentences_dataset[2]),txt,epochs=300,display= True,retry = False)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            "The judge agreed with police that he would have been over the limit at the time his red Citroen hit Miss Titley’s blue Daihatsu Cuore on a road near Yarmouth Isle of Wight on October 11 2013. His phone records showed he was also texting around the time of the crash.\n",
            "--------------------------------------------------\n",
            "Length ------------------------------------| 52\n",
            "{0: -1.0, 1: 1.0, 2: 1.0, 3: 1.0, 4: 1.0, 5: 1.0, 6: -1.0, 7: 1.0, 8: 1.0, 9: 1.0, 10: 1.0, 11: -1.0, 12: 1.0, 13: -1.0, 14: -1.0, 15: 1.0, 16: -1.0, 17: -1.0, 18: 1.0, 19: -1.0, 20: 1.0, 21: 1.0, 22: 1.0, 23: 1.0, 24: 1.0, 25: -1.0, 26: -1.0, 27: 1.0, 28: 1.0, 29: 1.0, 30: 1.0, 31: -1.0, 32: 1.0, 33: -1.0, 34: 1.0, 35: -1.0, 36: 1.0, 37: -1.0, 38: -1.0, 39: 1.0, 40: 1.0, 41: 1.0, 42: -1.0, 43: -1.0, 44: 1.0, 45: 1.0, 46: 1.0, 47: -1.0, 48: 1.0, 49: -1.0, 50: -1.0, 51: 1.0}\n",
            "Train... |||||||||||||||||||||| 100.0%   300/300 epochs, e 0.00105 gl:0.53751653  sl:-0.1699 ll:0.0068\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7108,0.2519,score:1.3287,[judge agreed with police that would have been over limit time Citroen Miss Titley’s blue Daihatsu Cuore road near Yarmouth Isle Wight October 2013 phone records showed also texting around time crash.]\n",
            "correct_grammar_score:0.2135 best_grammar_score:-2.0681\n",
            "judge agreed with police that would have been over limit time Citroen Miss Titley’s blue Daihatsu Cuore road near Yarmouth Isle Wight October 2013 phone records showed also texting around time crash.\n",
            ".\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('.', 1.3287338963235569, -2.068101167678833)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "di_qtu_05Zcf"
      },
      "source": [
        "# 측정 도구..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFgYYBgh5b-P",
        "outputId": "048d7c51-7766-4ccc-883b-de1e02afe8a1"
      },
      "source": [
        "!pip install rouge-score"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rouge-score in /usr/local/lib/python3.7/dist-packages (0.0.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from rouge-score) (1.15.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from rouge-score) (3.2.5)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from rouge-score) (0.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rouge-score) (1.19.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqwC0uZrFAVo"
      },
      "source": [
        "from rouge_score import rouge_scorer\n",
        "\n",
        "scorer = rouge_scorer.RougeScorer(['rouge1','rouge2', 'rougeL'], use_stemmer=True)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SW3WKBjMbug5",
        "outputId": "5fe2a2f0-4a93-440e-e493-3c230ed761ed"
      },
      "source": [
        "import io\n",
        "R1 = []\n",
        "R2 = []\n",
        "RL = []\n",
        "for try_count in range(10):\n",
        "    \n",
        "    full_text = get_prepared_doc(sentences_dataset[try_count])\n",
        "\n",
        "    try:\n",
        "        del model\n",
        "        print('delete model')\n",
        "    except Exception as ex:\n",
        "        pass\n",
        "    model = EncoderDecoderModel.from_pretrained(\"/content/drive/MyDrive/GAN_ENDE/en_sentence_complete_model\")\n",
        "    try:\n",
        "        org_text = besm(full_text)\n",
        "        org_text = summary(full_text,org_text,steps=2,top_rank=2)\n",
        "        gsmry = gold_summary[try_count]\n",
        "        print()\n",
        "        print('='*50 + ' Summary ' + str(try_count) + '='*50)\n",
        "        for txt in np.array(nltk.sent_tokenize(org_text.strip())):\n",
        "            print(txt)\n",
        "        print('-'*50 + ' Ground truth' + '-'*50)\n",
        "        print(gsmry)\n",
        "        print('-'*120)\n",
        "        print()\n",
        "        with io.open('/content/drive/MyDrive/GAN_ENDE/CNN_Daily_summary_result.txt','a',encoding='utf8') as f:\n",
        "            f.write(org_text + '\\r\\n\\r\\n')\n",
        "        smry = org_text\n",
        "        scores = scorer.score(gsmry,smry)\n",
        "\n",
        "        if scores['rouge1'].fmeasure > 0.1:\n",
        "            print('rouge1', scores['rouge1'].fmeasure)\n",
        "            print('rouge2', scores['rouge2'].fmeasure)\n",
        "            print('rougeL', scores['rougeL'].fmeasure)\n",
        "            R1.append(scores['rouge1'].fmeasure)\n",
        "            R2.append(scores['rouge2'].fmeasure)\n",
        "            RL.append(scores['rougeL'].fmeasure)\n",
        "    except Exception as ex:\n",
        "        print(ex)\n",
        "\n",
        "\n",
        "print('R1',np.mean(R1))\n",
        "print('R2',np.mean(R2))\n",
        "print('RL',np.mean(RL))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "delete model\n",
            "--------------------------------------------------\n",
            "The bishop of the Fargo Catholic Diocese in North Dakota has exposed potentially hundreds of church members in Fargo Grand Forks and Jamestown to the hepatitis A virus in late September and early October. The state Health Department has issued an advisory of exposure for anyone who attended five churches and took communion.\n",
            "--------------------------------------------------\n",
            "Length ------------------------------------| 54\n",
            "{0: -1.0, 1: 0.2, 2: -1.0, 3: -1.0, 4: 0.2, 5: 0.2, 6: 0.2, 7: -1.0, 8: 0.2, 9: 0.2, 10: -1.0, 11: 0.2, 12: 0.2, 13: 0.2, 14: -1.0, 15: 0.2, 16: 0.2, 17: -1.0, 18: 0.2, 19: 0.2, 20: 0.2, 21: -1.0, 22: 0.2, 23: -1.0, 24: -1.0, 25: 0.2, 26: -1.0, 27: 0.2, 28: -1.0, 29: 0.2, 30: 0.2, 31: -1.0, 32: 0.2, 33: 0.2, 34: -1.0, 35: -1.0, 36: 0.2, 37: 0.2, 38: 0.2, 39: -1.0, 40: 0.2, 41: -1.0, 42: 0.2, 43: -1.0, 44: 0.2, 45: -1.0, 46: 0.2, 47: -1.0, 48: 0.2, 49: 0.2, 50: 0.2, 51: -1.0, 52: 0.2, 53: 0.2}\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, e 0.00105 gl:0.29784518  sl:-0.1852 ll:0.0671\n",
            "0.7479,0.2185,score:1.4402,[bishop Fargo Catholic Diocese North Dakota exposed potentially hundreds church members Fargo Grand Forks Jamestown hepatitis virus late September early October state Health Department issued advisory exposure anyone attended five churches took communion.]\n",
            "correct_grammar_score:0.2135 best_grammar_score:-1.6445\n",
            "bishop Fargo Catholic Diocese North Dakota exposed potentially hundreds church members Fargo Grand Forks Jamestown hepatitis virus late September early October state Health Department issued advisory exposure anyone attended five churches took communion.\n",
            ".\n",
            "max score:1.4401681599906955 grammar:-1.6444659233093262 text:.\n",
            "--------------------------------------------------\n",
            "The bishop of the Fargo Catholic Diocese in North Dakota has exposed potentially hundreds of church members in Fargo Grand Forks and Jamestown to the hepatitis A virus in late September and early October. The state Health Department has issued an advisory of exposure for anyone who attended five churches and took communion.\n",
            "--------------------------------------------------\n",
            "Length ------------------------------------| 54\n",
            "{0: -1.0, 1: 0.2, 2: -1.0, 3: -1.0, 4: 0.2, 5: 0.2, 6: 0.2, 7: -1.0, 8: 0.2, 9: 0.2, 10: -1.0, 11: 0.2, 12: 0.2, 13: 0.2, 14: -1.0, 15: 0.2, 16: 0.2, 17: -1.0, 18: 0.2, 19: 0.2, 20: 0.2, 21: -1.0, 22: 0.2, 23: -1.0, 24: -1.0, 25: 0.2, 26: -1.0, 27: 0.2, 28: -1.0, 29: 0.2, 30: 0.2, 31: -1.0, 32: 0.2, 33: 0.2, 34: -1.0, 35: -1.0, 36: 0.2, 37: 0.2, 38: 0.2, 39: -1.0, 40: 0.2, 41: -1.0, 42: 0.2, 43: -1.0, 44: 0.2, 45: -1.0, 46: 0.2, 47: -1.0, 48: 0.2, 49: 0.2, 50: 0.2, 51: -1.0, 52: 0.2, 53: 0.2}\n",
            "Train... |||||||||||||||||||||| 100.0%   210/210 epochs, e 0.00105 gl:0.30075270  sl:-0.1870 ll:0.0686\n",
            "0.7479,0.2185,score:1.4402,[bishop Fargo Catholic Diocese North Dakota exposed potentially hundreds church members Fargo Grand Forks Jamestown hepatitis virus late September early October state Health Department issued advisory exposure anyone attended five churches took communion.]\n",
            "correct_grammar_score:0.2135 best_grammar_score:-1.6445\n",
            "bishop Fargo Catholic Diocese North Dakota exposed potentially hundreds church members Fargo Grand Forks Jamestown hepatitis virus late September early October state Health Department issued advisory exposure anyone attended five churches took communion.\n",
            ".\n",
            "max score:1.4401681599906955 grammar:-1.6444659233093262 text:.\n",
            "--------------------------------------------------\n",
            "The bishop of the Fargo Catholic Diocese in North Dakota has exposed potentially hundreds of church members in Fargo Grand Forks and Jamestown to the hepatitis A virus in late September and early October. The state Health Department has issued an advisory of exposure for anyone who attended five churches and took communion.\n",
            "--------------------------------------------------\n",
            "Length ------------------------------------| 54\n",
            "{0: -1.0, 1: 0.2, 2: -1.0, 3: -1.0, 4: 0.2, 5: 0.2, 6: 0.2, 7: -1.0, 8: 0.2, 9: 0.2, 10: -1.0, 11: 0.2, 12: 0.2, 13: 0.2, 14: -1.0, 15: 0.2, 16: 0.2, 17: -1.0, 18: 0.2, 19: 0.2, 20: 0.2, 21: -1.0, 22: 0.2, 23: -1.0, 24: -1.0, 25: 0.2, 26: -1.0, 27: 0.2, 28: -1.0, 29: 0.2, 30: 0.2, 31: -1.0, 32: 0.2, 33: 0.2, 34: -1.0, 35: -1.0, 36: 0.2, 37: 0.2, 38: 0.2, 39: -1.0, 40: 0.2, 41: -1.0, 42: 0.2, 43: -1.0, 44: 0.2, 45: -1.0, 46: 0.2, 47: -1.0, 48: 0.2, 49: 0.2, 50: 0.2, 51: -1.0, 52: 0.2, 53: 0.2}\n",
            "Train... |||||||||||||||||||||| 100.0%   220/220 epochs, e 0.00105 gl:0.30005687  sl:-0.1866 ll:0.0703\n",
            "0.7479,0.2185,score:1.4402,[bishop Fargo Catholic Diocese North Dakota exposed potentially hundreds church members Fargo Grand Forks Jamestown hepatitis virus late September early October state Health Department issued advisory exposure anyone attended five churches took communion.]\n",
            "correct_grammar_score:0.2135 best_grammar_score:-1.6445\n",
            "bishop Fargo Catholic Diocese North Dakota exposed potentially hundreds church members Fargo Grand Forks Jamestown hepatitis virus late September early October state Health Department issued advisory exposure anyone attended five churches took communion.\n",
            ".\n",
            "max score:1.4401681599906955 grammar:-1.6444659233093262 text:.\n",
            "--------------------------------------------------\n",
            "The bishop of the Fargo Catholic Diocese in North Dakota has exposed potentially hundreds of church members in Fargo Grand Forks and Jamestown to the hepatitis A virus in late September and early October. The state Health Department has issued an advisory of exposure for anyone who attended five churches and took communion.\n",
            "--------------------------------------------------\n",
            "Length ------------------------------------| 54\n",
            "{0: -1.0, 1: 0.2, 2: -1.0, 3: -1.0, 4: 0.2, 5: 0.2, 6: 0.2, 7: -1.0, 8: 0.2, 9: 0.2, 10: -1.0, 11: 0.2, 12: 0.2, 13: 0.2, 14: -1.0, 15: 0.2, 16: 0.2, 17: -1.0, 18: 0.2, 19: 0.2, 20: 0.2, 21: -1.0, 22: 0.2, 23: -1.0, 24: -1.0, 25: 0.2, 26: -1.0, 27: 0.2, 28: -1.0, 29: 0.2, 30: 0.2, 31: -1.0, 32: 0.2, 33: 0.2, 34: -1.0, 35: -1.0, 36: 0.2, 37: 0.2, 38: 0.2, 39: -1.0, 40: 0.2, 41: -1.0, 42: 0.2, 43: -1.0, 44: 0.2, 45: -1.0, 46: 0.2, 47: -1.0, 48: 0.2, 49: 0.2, 50: 0.2, 51: -1.0, 52: 0.2, 53: 0.2}\n",
            "Train... |||||||||||||||||||||| 100.0%   230/230 epochs, e 0.00105 gl:0.29983279  sl:-0.1865 ll:0.0680\n",
            "0.7479,0.2185,score:1.4402,[bishop Fargo Catholic Diocese North Dakota exposed potentially hundreds church members Fargo Grand Forks Jamestown hepatitis virus late September early October state Health Department issued advisory exposure anyone attended five churches took communion.]\n",
            "correct_grammar_score:0.2135 best_grammar_score:-1.6445\n",
            "bishop Fargo Catholic Diocese North Dakota exposed potentially hundreds church members Fargo Grand Forks Jamestown hepatitis virus late September early October state Health Department issued advisory exposure anyone attended five churches took communion.\n",
            ".\n",
            "max score:1.4401681599906955 grammar:-1.6444659233093262 text:.\n",
            "--------------------------------------------------\n",
            "The bishop of the Fargo Catholic Diocese in North Dakota has exposed potentially hundreds of church members in Fargo Grand Forks and Jamestown to the hepatitis A virus in late September and early October. The state Health Department has issued an advisory of exposure for anyone who attended five churches and took communion.\n",
            "--------------------------------------------------\n",
            "Length ------------------------------------| 54\n",
            "{0: -1.0, 1: 0.2, 2: -1.0, 3: -1.0, 4: 0.2, 5: 0.2, 6: 0.2, 7: -1.0, 8: 0.2, 9: 0.2, 10: -1.0, 11: 0.2, 12: 0.2, 13: 0.2, 14: -1.0, 15: 0.2, 16: 0.2, 17: -1.0, 18: 0.2, 19: 0.2, 20: 0.2, 21: -1.0, 22: 0.2, 23: -1.0, 24: -1.0, 25: 0.2, 26: -1.0, 27: 0.2, 28: -1.0, 29: 0.2, 30: 0.2, 31: -1.0, 32: 0.2, 33: 0.2, 34: -1.0, 35: -1.0, 36: 0.2, 37: 0.2, 38: 0.2, 39: -1.0, 40: 0.2, 41: -1.0, 42: 0.2, 43: -1.0, 44: 0.2, 45: -1.0, 46: 0.2, 47: -1.0, 48: 0.2, 49: 0.2, 50: 0.2, 51: -1.0, 52: 0.2, 53: 0.2}\n",
            "Train... |||||||||||||||||||||| 100.0%   240/240 epochs, e 0.00105 gl:0.30087286  sl:-0.1871 ll:0.0685\n",
            "0.7479,0.2185,score:1.4402,[bishop Fargo Catholic Diocese North Dakota exposed potentially hundreds church members Fargo Grand Forks Jamestown hepatitis virus late September early October state Health Department issued advisory exposure anyone attended five churches took communion.]\n",
            "correct_grammar_score:0.2135 best_grammar_score:-1.6445\n",
            "bishop Fargo Catholic Diocese North Dakota exposed potentially hundreds church members Fargo Grand Forks Jamestown hepatitis virus late September early October state Health Department issued advisory exposure anyone attended five churches took communion.\n",
            ".\n",
            "max score:1.4401681599906955 grammar:-1.6444659233093262 text:.\n",
            "--------------------------------------------------\n",
            "The bishop of the Fargo Catholic Diocese in North Dakota has exposed potentially hundreds of church members in Fargo Grand Forks and Jamestown to the hepatitis A virus in late September and early October. The state Health Department has issued an advisory of exposure for anyone who attended five churches and took communion.\n",
            "--------------------------------------------------\n",
            "Length ------------------------------------| 54\n",
            "{0: -1.0, 1: 0.2, 2: -1.0, 3: -1.0, 4: 0.2, 5: 0.2, 6: 0.2, 7: -1.0, 8: 0.2, 9: 0.2, 10: -1.0, 11: 0.2, 12: 0.2, 13: 0.2, 14: -1.0, 15: 0.2, 16: 0.2, 17: -1.0, 18: 0.2, 19: 0.2, 20: 0.2, 21: -1.0, 22: 0.2, 23: -1.0, 24: -1.0, 25: 0.2, 26: -1.0, 27: 0.2, 28: -1.0, 29: 0.2, 30: 0.2, 31: -1.0, 32: 0.2, 33: 0.2, 34: -1.0, 35: -1.0, 36: 0.2, 37: 0.2, 38: 0.2, 39: -1.0, 40: 0.2, 41: -1.0, 42: 0.2, 43: -1.0, 44: 0.2, 45: -1.0, 46: 0.2, 47: -1.0, 48: 0.2, 49: 0.2, 50: 0.2, 51: -1.0, 52: 0.2, 53: 0.2}\n",
            "Train... |||||||||||||||||||||| 100.0%   250/250 epochs, e 0.00105 gl:0.29868647  sl:-0.1857 ll:0.0672\n",
            "0.7479,0.2185,score:1.4402,[bishop Fargo Catholic Diocese North Dakota exposed potentially hundreds church members Fargo Grand Forks Jamestown hepatitis virus late September early October state Health Department issued advisory exposure anyone attended five churches took communion.]\n",
            "correct_grammar_score:0.2135 best_grammar_score:-1.6445\n",
            "bishop Fargo Catholic Diocese North Dakota exposed potentially hundreds church members Fargo Grand Forks Jamestown hepatitis virus late September early October state Health Department issued advisory exposure anyone attended five churches took communion.\n",
            ".\n",
            "max score:1.4401681599906955 grammar:-1.6444659233093262 text:.\n",
            "--------------------------------------------------\n",
            "The bishop of the Fargo Catholic Diocese in North Dakota has exposed potentially hundreds of church members in Fargo Grand Forks and Jamestown to the hepatitis A virus in late September and early October. The state Health Department has issued an advisory of exposure for anyone who attended five churches and took communion.\n",
            "--------------------------------------------------\n",
            "Length ------------------------------------| 54\n",
            "{0: -1.0, 1: 0.2, 2: -1.0, 3: -1.0, 4: 0.2, 5: 0.2, 6: 0.2, 7: -1.0, 8: 0.2, 9: 0.2, 10: -1.0, 11: 0.2, 12: 0.2, 13: 0.2, 14: -1.0, 15: 0.2, 16: 0.2, 17: -1.0, 18: 0.2, 19: 0.2, 20: 0.2, 21: -1.0, 22: 0.2, 23: -1.0, 24: -1.0, 25: 0.2, 26: -1.0, 27: 0.2, 28: -1.0, 29: 0.2, 30: 0.2, 31: -1.0, 32: 0.2, 33: 0.2, 34: -1.0, 35: -1.0, 36: 0.2, 37: 0.2, 38: 0.2, 39: -1.0, 40: 0.2, 41: -1.0, 42: 0.2, 43: -1.0, 44: 0.2, 45: -1.0, 46: 0.2, 47: -1.0, 48: 0.2, 49: 0.2, 50: 0.2, 51: -1.0, 52: 0.2, 53: 0.2}\n",
            "Train... |||||||||||||||||||||| 100.0%   260/260 epochs, e 0.00105 gl:0.30051327  sl:-0.1869 ll:0.0677\n",
            "0.7479,0.2185,score:1.4402,[bishop Fargo Catholic Diocese North Dakota exposed potentially hundreds church members Fargo Grand Forks Jamestown hepatitis virus late September early October state Health Department issued advisory exposure anyone attended five churches took communion.]\n",
            "correct_grammar_score:0.2135 best_grammar_score:-1.6445\n",
            "bishop Fargo Catholic Diocese North Dakota exposed potentially hundreds church members Fargo Grand Forks Jamestown hepatitis virus late September early October state Health Department issued advisory exposure anyone attended five churches took communion.\n",
            ".\n",
            "max score:1.4401681599906955 grammar:-1.6444659233093262 text:.\n",
            "--------------------------------------------------\n",
            "The bishop of the Fargo Catholic Diocese in North Dakota has exposed potentially hundreds of church members in Fargo Grand Forks and Jamestown to the hepatitis A virus in late September and early October. The state Health Department has issued an advisory of exposure for anyone who attended five churches and took communion.\n",
            "--------------------------------------------------\n",
            "Length ------------------------------------| 54\n",
            "{0: -1.0, 1: 0.2, 2: -1.0, 3: -1.0, 4: 0.2, 5: 0.2, 6: 0.2, 7: -1.0, 8: 0.2, 9: 0.2, 10: -1.0, 11: 0.2, 12: 0.2, 13: 0.2, 14: -1.0, 15: 0.2, 16: 0.2, 17: -1.0, 18: 0.2, 19: 0.2, 20: 0.2, 21: -1.0, 22: 0.2, 23: -1.0, 24: -1.0, 25: 0.2, 26: -1.0, 27: 0.2, 28: -1.0, 29: 0.2, 30: 0.2, 31: -1.0, 32: 0.2, 33: 0.2, 34: -1.0, 35: -1.0, 36: 0.2, 37: 0.2, 38: 0.2, 39: -1.0, 40: 0.2, 41: -1.0, 42: 0.2, 43: -1.0, 44: 0.2, 45: -1.0, 46: 0.2, 47: -1.0, 48: 0.2, 49: 0.2, 50: 0.2, 51: -1.0, 52: 0.2, 53: 0.2}\n",
            "Train... |||||||||||||||||||||| 100.0%   270/270 epochs, e 0.00105 gl:0.30137557  sl:-0.1874 ll:0.0684\n",
            "0.7479,0.2185,score:1.4402,[bishop Fargo Catholic Diocese North Dakota exposed potentially hundreds church members Fargo Grand Forks Jamestown hepatitis virus late September early October state Health Department issued advisory exposure anyone attended five churches took communion.]\n",
            "correct_grammar_score:0.2135 best_grammar_score:-1.6445\n",
            "bishop Fargo Catholic Diocese North Dakota exposed potentially hundreds church members Fargo Grand Forks Jamestown hepatitis virus late September early October state Health Department issued advisory exposure anyone attended five churches took communion.\n",
            ".\n",
            "max score:1.4401681599906955 grammar:-1.6444659233093262 text:.\n",
            "--------------------------------------------------\n",
            "The bishop of the Fargo Catholic Diocese in North Dakota has exposed potentially hundreds of church members in Fargo Grand Forks and Jamestown to the hepatitis A virus in late September and early October. The state Health Department has issued an advisory of exposure for anyone who attended five churches and took communion.\n",
            "--------------------------------------------------\n",
            "Length ------------------------------------| 54\n",
            "{0: -1.0, 1: 0.2, 2: -1.0, 3: -1.0, 4: 0.2, 5: 0.2, 6: 0.2, 7: -1.0, 8: 0.2, 9: 0.2, 10: -1.0, 11: 0.2, 12: 0.2, 13: 0.2, 14: -1.0, 15: 0.2, 16: 0.2, 17: -1.0, 18: 0.2, 19: 0.2, 20: 0.2, 21: -1.0, 22: 0.2, 23: -1.0, 24: -1.0, 25: 0.2, 26: -1.0, 27: 0.2, 28: -1.0, 29: 0.2, 30: 0.2, 31: -1.0, 32: 0.2, 33: 0.2, 34: -1.0, 35: -1.0, 36: 0.2, 37: 0.2, 38: 0.2, 39: -1.0, 40: 0.2, 41: -1.0, 42: 0.2, 43: -1.0, 44: 0.2, 45: -1.0, 46: 0.2, 47: -1.0, 48: 0.2, 49: 0.2, 50: 0.2, 51: -1.0, 52: 0.2, 53: 0.2}\n",
            "Train... |||||||||||||||||||||| 100.0%   280/280 epochs, e 0.00105 gl:0.29990011  sl:-0.1865 ll:0.0682\n",
            "0.7479,0.2185,score:1.4402,[bishop Fargo Catholic Diocese North Dakota exposed potentially hundreds church members Fargo Grand Forks Jamestown hepatitis virus late September early October state Health Department issued advisory exposure anyone attended five churches took communion.]\n",
            "correct_grammar_score:0.2135 best_grammar_score:-1.6445\n",
            "bishop Fargo Catholic Diocese North Dakota exposed potentially hundreds church members Fargo Grand Forks Jamestown hepatitis virus late September early October state Health Department issued advisory exposure anyone attended five churches took communion.\n",
            ".\n",
            "max score:1.4401681599906955 grammar:-1.6444659233093262 text:.\n",
            "--------------------------------------------------\n",
            "The bishop of the Fargo Catholic Diocese in North Dakota has exposed potentially hundreds of church members in Fargo Grand Forks and Jamestown to the hepatitis A virus in late September and early October. The state Health Department has issued an advisory of exposure for anyone who attended five churches and took communion.\n",
            "--------------------------------------------------\n",
            "Length ------------------------------------| 54\n",
            "{0: -1.0, 1: 0.2, 2: -1.0, 3: -1.0, 4: 0.2, 5: 0.2, 6: 0.2, 7: -1.0, 8: 0.2, 9: 0.2, 10: -1.0, 11: 0.2, 12: 0.2, 13: 0.2, 14: -1.0, 15: 0.2, 16: 0.2, 17: -1.0, 18: 0.2, 19: 0.2, 20: 0.2, 21: -1.0, 22: 0.2, 23: -1.0, 24: -1.0, 25: 0.2, 26: -1.0, 27: 0.2, 28: -1.0, 29: 0.2, 30: 0.2, 31: -1.0, 32: 0.2, 33: 0.2, 34: -1.0, 35: -1.0, 36: 0.2, 37: 0.2, 38: 0.2, 39: -1.0, 40: 0.2, 41: -1.0, 42: 0.2, 43: -1.0, 44: 0.2, 45: -1.0, 46: 0.2, 47: -1.0, 48: 0.2, 49: 0.2, 50: 0.2, 51: -1.0, 52: 0.2, 53: 0.2}\n",
            "Train... |||||||||||||||||||||| 100.0%   290/290 epochs, e 0.00105 gl:0.29996148  sl:-0.1865 ll:0.0685\n",
            "0.7479,0.2185,score:1.4402,[bishop Fargo Catholic Diocese North Dakota exposed potentially hundreds church members Fargo Grand Forks Jamestown hepatitis virus late September early October state Health Department issued advisory exposure anyone attended five churches took communion.]\n",
            "correct_grammar_score:0.2135 best_grammar_score:-1.6445\n",
            "bishop Fargo Catholic Diocese North Dakota exposed potentially hundreds church members Fargo Grand Forks Jamestown hepatitis virus late September early October state Health Department issued advisory exposure anyone attended five churches took communion.\n",
            ".\n",
            "max score:1.4401681599906955 grammar:-1.6444659233093262 text:.\n",
            "--------------------------------------------------\n",
            "The bishop of the Fargo Catholic Diocese in North Dakota has exposed potentially hundreds of church members in Fargo Grand Forks and Jamestown to the hepatitis A virus in late September and early October. The state Health Department has issued an advisory of exposure for anyone who attended five churches and took communion.\n",
            "--------------------------------------------------\n",
            "Length ------------------------------------| 54\n",
            "{0: -1.0, 1: 0.2, 2: -1.0, 3: -1.0, 4: 0.2, 5: 0.2, 6: 0.2, 7: -1.0, 8: 0.2, 9: 0.2, 10: -1.0, 11: 0.2, 12: 0.2, 13: 0.2, 14: -1.0, 15: 0.2, 16: 0.2, 17: -1.0, 18: 0.2, 19: 0.2, 20: 0.2, 21: -1.0, 22: 0.2, 23: -1.0, 24: -1.0, 25: 0.2, 26: -1.0, 27: 0.2, 28: -1.0, 29: 0.2, 30: 0.2, 31: -1.0, 32: 0.2, 33: 0.2, 34: -1.0, 35: -1.0, 36: 0.2, 37: 0.2, 38: 0.2, 39: -1.0, 40: 0.2, 41: -1.0, 42: 0.2, 43: -1.0, 44: 0.2, 45: -1.0, 46: 0.2, 47: -1.0, 48: 0.2, 49: 0.2, 50: 0.2, 51: -1.0, 52: 0.2, 53: 0.2}\n",
            "Train... |||||||||||||||||||||| 100.0%   300/300 epochs, e 0.00105 gl:0.29954931  sl:-0.1863 ll:0.0671\n",
            "0.7479,0.2185,score:1.4402,[bishop Fargo Catholic Diocese North Dakota exposed potentially hundreds church members Fargo Grand Forks Jamestown hepatitis virus late September early October state Health Department issued advisory exposure anyone attended five churches took communion.]\n",
            "correct_grammar_score:0.2135 best_grammar_score:-1.6445\n",
            "bishop Fargo Catholic Diocese North Dakota exposed potentially hundreds church members Fargo Grand Forks Jamestown hepatitis virus late September early October state Health Department issued advisory exposure anyone attended five churches took communion.\n",
            ".\n",
            "max score:1.4401681599906955 grammar:-1.6444659233093262 text:.\n",
            "Can't summarize the text\n",
            "delete model\n",
            "--------------------------------------------------\n",
            "(CNN) -- Ralph Mata was an internal affairs lieutenant for the Miami-Dade Police Department working in the division that investigates allegations of wrongdoing by cops. Mata according to the complaint then used contacts at the airport to transport the weapons in his carry-on luggage on trips from Miami to the Dominican Republic.\n",
            "--------------------------------------------------\n",
            "Length ------------------------------------| 53\n",
            "{0: 0.2, 1: -1.0, 2: 0.2, 3: 0.2, 4: -1.0, 5: -1.0, 6: 0.2, 7: 0.2, 8: 0.2, 9: -1.0, 10: -1.0, 11: 0.2, 12: 0.2, 13: 0.2, 14: 0.2, 15: -1.0, 16: -1.0, 17: 0.2, 18: 0.2, 19: 0.2, 20: 0.2, 21: -1.0, 22: 0.2, 23: -1.0, 24: 0.2, 25: -1.0, 26: 0.2, 27: 0.2, 28: -1.0, 29: -1.0, 30: 0.2, 31: 0.2, 32: 0.2, 33: 0.2, 34: -1.0, 35: -1.0, 36: 0.2, 37: -1.0, 38: 0.2, 39: -1.0, 40: 0.2, 41: -1.0, 42: -1.0, 43: 0.2, 44: 0.2, 45: -1.0, 46: 0.2, 47: 0.2, 48: 0.2, 49: -1.0, 50: -1.0, 51: 0.2, 52: 0.2}\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, e 0.00105 gl:0.26229361  sl:-0.1259 ll:0.0353\n",
            "0.7419,0.2121,score:0.8970,[(CNN) Ralph Mata internal affairs lieutenant Miami-Dade Police Department working division that investigates allegations wrongdoing cops Mata according complaint then used contacts airport transport weapons carry-on luggage trips from Miami Dominican Republic.]\n",
            "correct_grammar_score:0.2135 best_grammar_score:-4.7940\n",
            "(CNN) Ralph Mata internal affairs lieutenant Miami-Dade Police Department working division that investigates allegations wrongdoing cops Mata according complaint then used contacts airport transport weapons carry-on luggage trips from Miami Dominican Republic.\n",
            ".\n",
            "max score:0.8970130632656321 grammar:-4.793972969055176 text:.\n",
            "--------------------------------------------------\n",
            "(CNN) -- Ralph Mata was an internal affairs lieutenant for the Miami-Dade Police Department working in the division that investigates allegations of wrongdoing by cops. Mata according to the complaint then used contacts at the airport to transport the weapons in his carry-on luggage on trips from Miami to the Dominican Republic.\n",
            "--------------------------------------------------\n",
            "Length ------------------------------------| 53\n",
            "{0: 0.2, 1: -1.0, 2: 0.2, 3: 0.2, 4: -1.0, 5: -1.0, 6: 0.2, 7: 0.2, 8: 0.2, 9: -1.0, 10: -1.0, 11: 0.2, 12: 0.2, 13: 0.2, 14: 0.2, 15: -1.0, 16: -1.0, 17: 0.2, 18: 0.2, 19: 0.2, 20: 0.2, 21: -1.0, 22: 0.2, 23: -1.0, 24: 0.2, 25: -1.0, 26: 0.2, 27: 0.2, 28: -1.0, 29: -1.0, 30: 0.2, 31: 0.2, 32: 0.2, 33: 0.2, 34: -1.0, 35: -1.0, 36: 0.2, 37: -1.0, 38: 0.2, 39: -1.0, 40: 0.2, 41: -1.0, 42: -1.0, 43: 0.2, 44: 0.2, 45: -1.0, 46: 0.2, 47: 0.2, 48: 0.2, 49: -1.0, 50: -1.0, 51: 0.2, 52: 0.2}\n",
            "Train... |||||||||||||||||||||| 100.0%   210/210 epochs, e 0.00105 gl:0.26570740  sl:-0.1276 ll:0.0370\n",
            "0.7419,0.2121,score:0.8970,[(CNN) Ralph Mata internal affairs lieutenant Miami-Dade Police Department working division that investigates allegations wrongdoing cops Mata according complaint then used contacts airport transport weapons carry-on luggage trips from Miami Dominican Republic.]\n",
            "correct_grammar_score:0.2135 best_grammar_score:-4.7940\n",
            "(CNN) Ralph Mata internal affairs lieutenant Miami-Dade Police Department working division that investigates allegations wrongdoing cops Mata according complaint then used contacts airport transport weapons carry-on luggage trips from Miami Dominican Republic.\n",
            ".\n",
            "max score:0.8970130632656321 grammar:-4.793972969055176 text:.\n",
            "--------------------------------------------------\n",
            "(CNN) -- Ralph Mata was an internal affairs lieutenant for the Miami-Dade Police Department working in the division that investigates allegations of wrongdoing by cops. Mata according to the complaint then used contacts at the airport to transport the weapons in his carry-on luggage on trips from Miami to the Dominican Republic.\n",
            "--------------------------------------------------\n",
            "Length ------------------------------------| 53\n",
            "{0: 0.2, 1: -1.0, 2: 0.2, 3: 0.2, 4: -1.0, 5: -1.0, 6: 0.2, 7: 0.2, 8: 0.2, 9: -1.0, 10: -1.0, 11: 0.2, 12: 0.2, 13: 0.2, 14: 0.2, 15: -1.0, 16: -1.0, 17: 0.2, 18: 0.2, 19: 0.2, 20: 0.2, 21: -1.0, 22: 0.2, 23: -1.0, 24: 0.2, 25: -1.0, 26: 0.2, 27: 0.2, 28: -1.0, 29: -1.0, 30: 0.2, 31: 0.2, 32: 0.2, 33: 0.2, 34: -1.0, 35: -1.0, 36: 0.2, 37: -1.0, 38: 0.2, 39: -1.0, 40: 0.2, 41: -1.0, 42: -1.0, 43: 0.2, 44: 0.2, 45: -1.0, 46: 0.2, 47: 0.2, 48: 0.2, 49: -1.0, 50: -1.0, 51: 0.2, 52: 0.2}\n",
            "Train... |||||||||||||||||||||| 100.0%   220/220 epochs, e 0.00105 gl:0.26234242  sl:-0.1260 ll:0.0351\n",
            "0.7419,0.2121,score:0.8970,[(CNN) Ralph Mata internal affairs lieutenant Miami-Dade Police Department working division that investigates allegations wrongdoing cops Mata according complaint then used contacts airport transport weapons carry-on luggage trips from Miami Dominican Republic.]\n",
            "correct_grammar_score:0.2135 best_grammar_score:-4.7940\n",
            "(CNN) Ralph Mata internal affairs lieutenant Miami-Dade Police Department working division that investigates allegations wrongdoing cops Mata according complaint then used contacts airport transport weapons carry-on luggage trips from Miami Dominican Republic.\n",
            ".\n",
            "max score:0.8970130632656321 grammar:-4.793972969055176 text:.\n",
            "--------------------------------------------------\n",
            "(CNN) -- Ralph Mata was an internal affairs lieutenant for the Miami-Dade Police Department working in the division that investigates allegations of wrongdoing by cops. Mata according to the complaint then used contacts at the airport to transport the weapons in his carry-on luggage on trips from Miami to the Dominican Republic.\n",
            "--------------------------------------------------\n",
            "Length ------------------------------------| 53\n",
            "{0: 0.2, 1: -1.0, 2: 0.2, 3: 0.2, 4: -1.0, 5: -1.0, 6: 0.2, 7: 0.2, 8: 0.2, 9: -1.0, 10: -1.0, 11: 0.2, 12: 0.2, 13: 0.2, 14: 0.2, 15: -1.0, 16: -1.0, 17: 0.2, 18: 0.2, 19: 0.2, 20: 0.2, 21: -1.0, 22: 0.2, 23: -1.0, 24: 0.2, 25: -1.0, 26: 0.2, 27: 0.2, 28: -1.0, 29: -1.0, 30: 0.2, 31: 0.2, 32: 0.2, 33: 0.2, 34: -1.0, 35: -1.0, 36: 0.2, 37: -1.0, 38: 0.2, 39: -1.0, 40: 0.2, 41: -1.0, 42: -1.0, 43: 0.2, 44: 0.2, 45: -1.0, 46: 0.2, 47: 0.2, 48: 0.2, 49: -1.0, 50: -1.0, 51: 0.2, 52: 0.2}\n",
            "Train... |||||||||||||||||||||| 100.0%   230/230 epochs, e 0.00105 gl:0.26264608  sl:-0.1261 ll:0.0351\n",
            "0.7419,0.2121,score:0.8970,[(CNN) Ralph Mata internal affairs lieutenant Miami-Dade Police Department working division that investigates allegations wrongdoing cops Mata according complaint then used contacts airport transport weapons carry-on luggage trips from Miami Dominican Republic.]\n",
            "correct_grammar_score:0.2135 best_grammar_score:-4.7940\n",
            "(CNN) Ralph Mata internal affairs lieutenant Miami-Dade Police Department working division that investigates allegations wrongdoing cops Mata according complaint then used contacts airport transport weapons carry-on luggage trips from Miami Dominican Republic.\n",
            ".\n",
            "max score:0.8970130632656321 grammar:-4.793972969055176 text:.\n",
            "--------------------------------------------------\n",
            "(CNN) -- Ralph Mata was an internal affairs lieutenant for the Miami-Dade Police Department working in the division that investigates allegations of wrongdoing by cops. Mata according to the complaint then used contacts at the airport to transport the weapons in his carry-on luggage on trips from Miami to the Dominican Republic.\n",
            "--------------------------------------------------\n",
            "Length ------------------------------------| 53\n",
            "{0: 0.2, 1: -1.0, 2: 0.2, 3: 0.2, 4: -1.0, 5: -1.0, 6: 0.2, 7: 0.2, 8: 0.2, 9: -1.0, 10: -1.0, 11: 0.2, 12: 0.2, 13: 0.2, 14: 0.2, 15: -1.0, 16: -1.0, 17: 0.2, 18: 0.2, 19: 0.2, 20: 0.2, 21: -1.0, 22: 0.2, 23: -1.0, 24: 0.2, 25: -1.0, 26: 0.2, 27: 0.2, 28: -1.0, 29: -1.0, 30: 0.2, 31: 0.2, 32: 0.2, 33: 0.2, 34: -1.0, 35: -1.0, 36: 0.2, 37: -1.0, 38: 0.2, 39: -1.0, 40: 0.2, 41: -1.0, 42: -1.0, 43: 0.2, 44: 0.2, 45: -1.0, 46: 0.2, 47: 0.2, 48: 0.2, 49: -1.0, 50: -1.0, 51: 0.2, 52: 0.2}\n",
            "Train... |||||||||||||||||||||| 100.0%   240/240 epochs, e 0.00105 gl:0.26269937  sl:-0.1261 ll:0.0350\n",
            "0.7419,0.2121,score:0.8970,[(CNN) Ralph Mata internal affairs lieutenant Miami-Dade Police Department working division that investigates allegations wrongdoing cops Mata according complaint then used contacts airport transport weapons carry-on luggage trips from Miami Dominican Republic.]\n",
            "correct_grammar_score:0.2135 best_grammar_score:-4.7940\n",
            "(CNN) Ralph Mata internal affairs lieutenant Miami-Dade Police Department working division that investigates allegations wrongdoing cops Mata according complaint then used contacts airport transport weapons carry-on luggage trips from Miami Dominican Republic.\n",
            ".\n",
            "max score:0.8970130632656321 grammar:-4.793972969055176 text:.\n",
            "--------------------------------------------------\n",
            "(CNN) -- Ralph Mata was an internal affairs lieutenant for the Miami-Dade Police Department working in the division that investigates allegations of wrongdoing by cops. Mata according to the complaint then used contacts at the airport to transport the weapons in his carry-on luggage on trips from Miami to the Dominican Republic.\n",
            "--------------------------------------------------\n",
            "Length ------------------------------------| 53\n",
            "{0: 0.2, 1: -1.0, 2: 0.2, 3: 0.2, 4: -1.0, 5: -1.0, 6: 0.2, 7: 0.2, 8: 0.2, 9: -1.0, 10: -1.0, 11: 0.2, 12: 0.2, 13: 0.2, 14: 0.2, 15: -1.0, 16: -1.0, 17: 0.2, 18: 0.2, 19: 0.2, 20: 0.2, 21: -1.0, 22: 0.2, 23: -1.0, 24: 0.2, 25: -1.0, 26: 0.2, 27: 0.2, 28: -1.0, 29: -1.0, 30: 0.2, 31: 0.2, 32: 0.2, 33: 0.2, 34: -1.0, 35: -1.0, 36: 0.2, 37: -1.0, 38: 0.2, 39: -1.0, 40: 0.2, 41: -1.0, 42: -1.0, 43: 0.2, 44: 0.2, 45: -1.0, 46: 0.2, 47: 0.2, 48: 0.2, 49: -1.0, 50: -1.0, 51: 0.2, 52: 0.2}\n",
            "Train... |||||||||||||||||||||| 100.0%   250/250 epochs, e 0.00105 gl:0.26453009  sl:-0.1270 ll:0.0360\n",
            "0.7419,0.2121,score:0.8970,[(CNN) Ralph Mata internal affairs lieutenant Miami-Dade Police Department working division that investigates allegations wrongdoing cops Mata according complaint then used contacts airport transport weapons carry-on luggage trips from Miami Dominican Republic.]\n",
            "correct_grammar_score:0.2135 best_grammar_score:-4.7940\n",
            "(CNN) Ralph Mata internal affairs lieutenant Miami-Dade Police Department working division that investigates allegations wrongdoing cops Mata according complaint then used contacts airport transport weapons carry-on luggage trips from Miami Dominican Republic.\n",
            ".\n",
            "max score:0.8970130632656321 grammar:-4.793972969055176 text:.\n",
            "--------------------------------------------------\n",
            "(CNN) -- Ralph Mata was an internal affairs lieutenant for the Miami-Dade Police Department working in the division that investigates allegations of wrongdoing by cops. Mata according to the complaint then used contacts at the airport to transport the weapons in his carry-on luggage on trips from Miami to the Dominican Republic.\n",
            "--------------------------------------------------\n",
            "Length ------------------------------------| 53\n",
            "{0: 0.2, 1: -1.0, 2: 0.2, 3: 0.2, 4: -1.0, 5: -1.0, 6: 0.2, 7: 0.2, 8: 0.2, 9: -1.0, 10: -1.0, 11: 0.2, 12: 0.2, 13: 0.2, 14: 0.2, 15: -1.0, 16: -1.0, 17: 0.2, 18: 0.2, 19: 0.2, 20: 0.2, 21: -1.0, 22: 0.2, 23: -1.0, 24: 0.2, 25: -1.0, 26: 0.2, 27: 0.2, 28: -1.0, 29: -1.0, 30: 0.2, 31: 0.2, 32: 0.2, 33: 0.2, 34: -1.0, 35: -1.0, 36: 0.2, 37: -1.0, 38: 0.2, 39: -1.0, 40: 0.2, 41: -1.0, 42: -1.0, 43: 0.2, 44: 0.2, 45: -1.0, 46: 0.2, 47: 0.2, 48: 0.2, 49: -1.0, 50: -1.0, 51: 0.2, 52: 0.2}\n",
            "Train... |||||||||||||||||||||| 100.0%   260/260 epochs, e 0.00105 gl:0.26247442  sl:-0.1260 ll:0.0345\n",
            "0.7419,0.2121,score:0.8970,[(CNN) Ralph Mata internal affairs lieutenant Miami-Dade Police Department working division that investigates allegations wrongdoing cops Mata according complaint then used contacts airport transport weapons carry-on luggage trips from Miami Dominican Republic.]\n",
            "correct_grammar_score:0.2135 best_grammar_score:-4.7940\n",
            "(CNN) Ralph Mata internal affairs lieutenant Miami-Dade Police Department working division that investigates allegations wrongdoing cops Mata according complaint then used contacts airport transport weapons carry-on luggage trips from Miami Dominican Republic.\n",
            ".\n",
            "max score:0.8970130632656321 grammar:-4.793972969055176 text:.\n",
            "--------------------------------------------------\n",
            "(CNN) -- Ralph Mata was an internal affairs lieutenant for the Miami-Dade Police Department working in the division that investigates allegations of wrongdoing by cops. Mata according to the complaint then used contacts at the airport to transport the weapons in his carry-on luggage on trips from Miami to the Dominican Republic.\n",
            "--------------------------------------------------\n",
            "Length ------------------------------------| 53\n",
            "{0: 0.2, 1: -1.0, 2: 0.2, 3: 0.2, 4: -1.0, 5: -1.0, 6: 0.2, 7: 0.2, 8: 0.2, 9: -1.0, 10: -1.0, 11: 0.2, 12: 0.2, 13: 0.2, 14: 0.2, 15: -1.0, 16: -1.0, 17: 0.2, 18: 0.2, 19: 0.2, 20: 0.2, 21: -1.0, 22: 0.2, 23: -1.0, 24: 0.2, 25: -1.0, 26: 0.2, 27: 0.2, 28: -1.0, 29: -1.0, 30: 0.2, 31: 0.2, 32: 0.2, 33: 0.2, 34: -1.0, 35: -1.0, 36: 0.2, 37: -1.0, 38: 0.2, 39: -1.0, 40: 0.2, 41: -1.0, 42: -1.0, 43: 0.2, 44: 0.2, 45: -1.0, 46: 0.2, 47: 0.2, 48: 0.2, 49: -1.0, 50: -1.0, 51: 0.2, 52: 0.2}\n",
            "Train... |||||||||||||||||||||| 100.0%   270/270 epochs, e 0.00105 gl:0.26249570  sl:-0.1260 ll:0.0348\n",
            "0.7419,0.2121,score:0.8970,[(CNN) Ralph Mata internal affairs lieutenant Miami-Dade Police Department working division that investigates allegations wrongdoing cops Mata according complaint then used contacts airport transport weapons carry-on luggage trips from Miami Dominican Republic.]\n",
            "correct_grammar_score:0.2135 best_grammar_score:-4.7940\n",
            "(CNN) Ralph Mata internal affairs lieutenant Miami-Dade Police Department working division that investigates allegations wrongdoing cops Mata according complaint then used contacts airport transport weapons carry-on luggage trips from Miami Dominican Republic.\n",
            ".\n",
            "max score:0.8970130632656321 grammar:-4.793972969055176 text:.\n",
            "--------------------------------------------------\n",
            "(CNN) -- Ralph Mata was an internal affairs lieutenant for the Miami-Dade Police Department working in the division that investigates allegations of wrongdoing by cops. Mata according to the complaint then used contacts at the airport to transport the weapons in his carry-on luggage on trips from Miami to the Dominican Republic.\n",
            "--------------------------------------------------\n",
            "Length ------------------------------------| 53\n",
            "{0: 0.2, 1: -1.0, 2: 0.2, 3: 0.2, 4: -1.0, 5: -1.0, 6: 0.2, 7: 0.2, 8: 0.2, 9: -1.0, 10: -1.0, 11: 0.2, 12: 0.2, 13: 0.2, 14: 0.2, 15: -1.0, 16: -1.0, 17: 0.2, 18: 0.2, 19: 0.2, 20: 0.2, 21: -1.0, 22: 0.2, 23: -1.0, 24: 0.2, 25: -1.0, 26: 0.2, 27: 0.2, 28: -1.0, 29: -1.0, 30: 0.2, 31: 0.2, 32: 0.2, 33: 0.2, 34: -1.0, 35: -1.0, 36: 0.2, 37: -1.0, 38: 0.2, 39: -1.0, 40: 0.2, 41: -1.0, 42: -1.0, 43: 0.2, 44: 0.2, 45: -1.0, 46: 0.2, 47: 0.2, 48: 0.2, 49: -1.0, 50: -1.0, 51: 0.2, 52: 0.2}\n",
            "Train... |||||||||||||||||||..| 90.0%   252/280 epochs, e 0.00113 gl:0.26238722  sl:-0.1260 ll:0.0347"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-e066a1e52894>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0morg_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbesm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0morg_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0morg_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtop_rank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mgsmry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgold_summary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtry_count\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-2580b3f34f7b>\u001b[0m in \u001b[0;36msummary\u001b[0;34m(ft, text, steps, top_rank)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mtxt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbesm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtxt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtop_rank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtop_rank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrammar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msam_wgan4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtxt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgrammar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-3cc5633ccda5>\u001b[0m in \u001b[0;36msam_wgan4\u001b[0;34m(full_text, text, epochs, batch_size, display, retry, retry_count)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mretry\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbest_grammar_score\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mretry_count\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'max score:{} grammar:{} text:{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_grammar_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msam_wgan4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mretry_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry_count\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_grammar_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-3cc5633ccda5>\u001b[0m in \u001b[0;36msam_wgan4\u001b[0;34m(full_text, text, epochs, batch_size, display, retry, retry_count)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mretry\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbest_grammar_score\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mretry_count\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'max score:{} grammar:{} text:{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_grammar_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msam_wgan4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mretry_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry_count\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_grammar_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-3cc5633ccda5>\u001b[0m in \u001b[0;36msam_wgan4\u001b[0;34m(full_text, text, epochs, batch_size, display, retry, retry_count)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mretry\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbest_grammar_score\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mretry_count\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'max score:{} grammar:{} text:{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_grammar_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msam_wgan4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mretry_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry_count\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_grammar_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-3cc5633ccda5>\u001b[0m in \u001b[0;36msam_wgan4\u001b[0;34m(full_text, text, epochs, batch_size, display, retry, retry_count)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mretry\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbest_grammar_score\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mretry_count\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'max score:{} grammar:{} text:{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_grammar_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msam_wgan4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mretry_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry_count\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_grammar_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-3cc5633ccda5>\u001b[0m in \u001b[0;36msam_wgan4\u001b[0;34m(full_text, text, epochs, batch_size, display, retry, retry_count)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mretry\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbest_grammar_score\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mretry_count\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'max score:{} grammar:{} text:{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_grammar_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msam_wgan4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mretry_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry_count\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_grammar_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-3cc5633ccda5>\u001b[0m in \u001b[0;36msam_wgan4\u001b[0;34m(full_text, text, epochs, batch_size, display, retry, retry_count)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mretry\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbest_grammar_score\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mretry_count\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'max score:{} grammar:{} text:{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_grammar_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msam_wgan4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mretry_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry_count\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_grammar_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-3cc5633ccda5>\u001b[0m in \u001b[0;36msam_wgan4\u001b[0;34m(full_text, text, epochs, batch_size, display, retry, retry_count)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mretry\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbest_grammar_score\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mretry_count\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'max score:{} grammar:{} text:{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_grammar_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msam_wgan4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mretry_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry_count\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_grammar_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-3cc5633ccda5>\u001b[0m in \u001b[0;36msam_wgan4\u001b[0;34m(full_text, text, epochs, batch_size, display, retry, retry_count)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mretry\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbest_grammar_score\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mretry_count\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'max score:{} grammar:{} text:{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_grammar_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msam_wgan4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mretry_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry_count\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_grammar_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-3cc5633ccda5>\u001b[0m in \u001b[0;36msam_wgan4\u001b[0;34m(full_text, text, epochs, batch_size, display, retry, retry_count)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0msummarizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSAM_Summarizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_discriminator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms_discriminator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0msummarizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummarizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummarize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5e-3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mretry\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhist\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mretry_count\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-35c3d5d3a0aa>\u001b[0m in \u001b[0;36msummarize\u001b[0;34m(self, epochs, batch_size, learning_rate, display)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2e-4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdisplay\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-35c3d5d3a0aa>\u001b[0m in \u001b[0;36m__train\u001b[0;34m(self, epochs, batch_size, learning_rate, display)\u001b[0m\n\u001b[1;32m    251\u001b[0m                 \u001b[0;31m#print(sw)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m                     \u001b[0mfake_gmr_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_sim_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_cos_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_len_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__discrete_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0;31m#print(fake_len_out)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-35c3d5d3a0aa>\u001b[0m in \u001b[0;36m__discrete_gradient\u001b[0;34m(self, weights, use_gpu, verbose)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;31m#print(fake_outs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0mD_z_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_gmr_out\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg_discriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransfer_learning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_outs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_for\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mo_sim_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-c1ad803358cd>\u001b[0m in \u001b[0;36mtransfer_learning\u001b[0;34m(self, sentences, train_for)\u001b[0m\n\u001b[1;32m    501\u001b[0m                             \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m                             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_masks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m                                 labels=b_labels)\n\u001b[0m\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m         \u001b[0;31m#print(outputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1531\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1532\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1533\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1534\u001b[0m         )\n\u001b[1;32m   1535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    998\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1000\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1001\u001b[0m         )\n\u001b[1;32m   1002\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    587\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m                 )\n\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    473\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself_attn_past_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         )\n\u001b[1;32m    477\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         )\n\u001b[0;32m--> 410\u001b[0;31m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# add attentions if we output them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_AzsvMX6KEq"
      },
      "source": [
        "model.save_pretrained(\"/content/drive/MyDrive/GAN_ENDE/sentence_complete_model_0\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}