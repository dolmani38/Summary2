{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "korean_frame_token_0_1.0_gamma_10.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "25ead44582c241acbd1a9502397b8736": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5ef9a258752a47b48146cb8443ffa1f3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6ebcfca00e49445ab51c4a5e5ec1da83",
              "IPY_MODEL_001d1f2dddae41439aeebc20405e8312"
            ]
          }
        },
        "5ef9a258752a47b48146cb8443ffa1f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6ebcfca00e49445ab51c4a5e5ec1da83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_eb02ac776515420b9e438a6125f003b2",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 434,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 434,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8afae9ce4bf54c5da09ce901d399ce3f"
          }
        },
        "001d1f2dddae41439aeebc20405e8312": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f4d145d34da9453c88612a5fbaba69e9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 434/434 [00:14&lt;00:00, 31.0B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1de6a59841e34bf1b09ef483a59058c3"
          }
        },
        "eb02ac776515420b9e438a6125f003b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8afae9ce4bf54c5da09ce901d399ce3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f4d145d34da9453c88612a5fbaba69e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1de6a59841e34bf1b09ef483a59058c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bc2f182353ec4978a6beb5893cd39fd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_41d7d8fe4f4042e99f50de423cae8131",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_583f2cfcf03249ec828aa694851aec04",
              "IPY_MODEL_7d4749c45f5f423faee514a9093b81bd"
            ]
          }
        },
        "41d7d8fe4f4042e99f50de423cae8131": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "583f2cfcf03249ec828aa694851aec04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_58d99cb692e445028a99d24632d6b29b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1344997306,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1344997306,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b8b038fc2a90492f9ce96316dd74ed3c"
          }
        },
        "7d4749c45f5f423faee514a9093b81bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b6c682697fc84faf8cd0684082c88555",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.34G/1.34G [00:41&lt;00:00, 32.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e47eafe8cde9408e83a9f3919f3937da"
          }
        },
        "58d99cb692e445028a99d24632d6b29b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b8b038fc2a90492f9ce96316dd74ed3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b6c682697fc84faf8cd0684082c88555": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e47eafe8cde9408e83a9f3919f3937da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "76c8939624a34cfb9146cf81b1b17795": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_feb424f8c61d431c98ce520f5addfbf8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f71d5222c3e74e2392936a96dcaaeee1",
              "IPY_MODEL_a595a754f7c347d99160017ecc9e2572"
            ]
          }
        },
        "feb424f8c61d431c98ce520f5addfbf8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f71d5222c3e74e2392936a96dcaaeee1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6654be75073c4ea9911de4ad6d70ccbc",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4958b56c9fd54b3aaa0fa199a1354075"
          }
        },
        "a595a754f7c347d99160017ecc9e2572": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_86dea1912dae4fef84d00052b95cfb4c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 606kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6018d03cff93466dbbe149c78fd0d36d"
          }
        },
        "6654be75073c4ea9911de4ad6d70ccbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4958b56c9fd54b3aaa0fa199a1354075": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "86dea1912dae4fef84d00052b95cfb4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6018d03cff93466dbbe149c78fd0d36d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0c096a94117440ec9d77c7fa07b70d6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6cf2916a1b284be89a2ab7616ee7a282",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_45b7dac6f4af4259a7bf7bb6727cde5a",
              "IPY_MODEL_115d1b24e89d4f39a8f6dad6129d5833"
            ]
          }
        },
        "6cf2916a1b284be89a2ab7616ee7a282": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "45b7dac6f4af4259a7bf7bb6727cde5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9e8d0affa78d4a3bbfacb1f789dac656",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 426,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 426,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_649e0a37febc4d4091b83882fdfa1125"
          }
        },
        "115d1b24e89d4f39a8f6dad6129d5833": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2fb2d927972a46f68eed0565749811dd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 426/426 [00:01&lt;00:00, 387B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_182a7ff8449b41bcb73d241ea0c6e536"
          }
        },
        "9e8d0affa78d4a3bbfacb1f789dac656": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "649e0a37febc4d4091b83882fdfa1125": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2fb2d927972a46f68eed0565749811dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "182a7ff8449b41bcb73d241ea0c6e536": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2fcf21886dd647c4b7f49647a05978bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3935bc2ac31d411c805e321b4d61bbf5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b83dbb10c4114ee9927004c55206c42f",
              "IPY_MODEL_5d79156e85144b1a926aa23fd0f42bf9"
            ]
          }
        },
        "3935bc2ac31d411c805e321b4d61bbf5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b83dbb10c4114ee9927004c55206c42f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6002d26eb695400188d466851387dc7c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 77779,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 77779,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1b0b736fa37242fab72ec38ead791bc0"
          }
        },
        "5d79156e85144b1a926aa23fd0f42bf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_20e4491775a84bc5ae5a0227a0f6a399",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 77.8k/77.8k [00:02&lt;00:00, 37.1kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0dfa95f66ed4441eb3f5eea0609f9a6a"
          }
        },
        "6002d26eb695400188d466851387dc7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1b0b736fa37242fab72ec38ead791bc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "20e4491775a84bc5ae5a0227a0f6a399": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0dfa95f66ed4441eb3f5eea0609f9a6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4851fbcdf28a4fb2bfdced5f7fc7514f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c213dc20112940ddbf5d17b98fdb32fd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_63660c7841ae4189b3eb452d2d699e61",
              "IPY_MODEL_3d0e342eea43436d92d650d78b206fdb"
            ]
          }
        },
        "c213dc20112940ddbf5d17b98fdb32fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "63660c7841ae4189b3eb452d2d699e61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_277adbf09e00412d9240264517028a15",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 51,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 51,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4d2861b3ebc5468bbe1c390e321dccc8"
          }
        },
        "3d0e342eea43436d92d650d78b206fdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ff9e58a7aa9d43149246d7b6c436d6f5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 51.0/51.0 [00:00&lt;00:00, 122B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_177a64b3065d4e928659af7a7ca15795"
          }
        },
        "277adbf09e00412d9240264517028a15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4d2861b3ebc5468bbe1c390e321dccc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ff9e58a7aa9d43149246d7b6c436d6f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "177a64b3065d4e928659af7a7ca15795": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6251a4d1e55249da8c05b38734df6108": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_34108b0ebb1b47209edcfc5a845817a4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e0a4ad157bdb406bacef3fe5310e151a",
              "IPY_MODEL_b7704096d73c4a5fa2cc9827525ae7bd"
            ]
          }
        },
        "34108b0ebb1b47209edcfc5a845817a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e0a4ad157bdb406bacef3fe5310e151a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a8efb5f6e790408ca83f4d24b0f228e2",
            "_dom_classes": [],
            "description": "Downloading:   6%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 368792146,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 22871040,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_af8e26d50f8a45b5a54d9964434ced43"
          }
        },
        "b7704096d73c4a5fa2cc9827525ae7bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1bcff3d64cb243c792fe23114928f6c6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 22.9M/369M [05:20&lt;1:09:58, 82.4kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_588f34d9e4f74266b767b8e93455b14e"
          }
        },
        "a8efb5f6e790408ca83f4d24b0f228e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "af8e26d50f8a45b5a54d9964434ced43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1bcff3d64cb243c792fe23114928f6c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "588f34d9e4f74266b767b8e93455b14e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dolmani38/Summary2/blob/main/multi-discriminator%20GAN%200508.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkQCxNatSIOk"
      },
      "source": [
        "# Multi-Discriminator GAN\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZjIW9VwyjDf"
      },
      "source": [
        "ABSTRACT\n",
        "\n",
        "----\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K87VNBbeRLFF"
      },
      "source": [
        "#4. Implementation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQZeBAf8NxAR"
      },
      "source": [
        "## 4.1 기본 설정..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAdXzWGuKSBT",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4eb7114-3470-4a48-ce4d-bf545d595f73"
      },
      "source": [
        "if True:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "newO0mBXKVnE",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4f43cd4-f658-4cd8-da16-178324133332"
      },
      "source": [
        "#!pip install keybert\n",
        "!pip install sentence-transformers==0.3.0\n",
        "!pip install transformers==3.0.2\n",
        "\n",
        "#!pip install sentence-transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentence-transformers==0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/23/833e0620753a36cb2f18e2e4a4f72fd8c49c123c3f07744b69f8a592e083/sentence-transformers-0.3.0.tar.gz (61kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 7.2MB/s \n",
            "\u001b[?25hCollecting transformers>=3.0.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b2/57495b5309f09fa501866e225c84532d1fd89536ea62406b2181933fb418/transformers-4.5.1-py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 21.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers==0.3.0) (4.41.1)\n",
            "Requirement already satisfied: torch>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers==0.3.0) (1.8.1+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers==0.3.0) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers==0.3.0) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers==0.3.0) (1.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers==0.3.0) (3.2.5)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 48.2MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 50.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.2->sentence-transformers==0.3.0) (20.9)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.2->sentence-transformers==0.3.0) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.2->sentence-transformers==0.3.0) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.2->sentence-transformers==0.3.0) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.2->sentence-transformers==0.3.0) (3.10.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.1->sentence-transformers==0.3.0) (3.7.4.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers==0.3.0) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers==0.3.0) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=3.0.2->sentence-transformers==0.3.0) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers>=3.0.2->sentence-transformers==0.3.0) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=3.0.2->sentence-transformers==0.3.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=3.0.2->sentence-transformers==0.3.0) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=3.0.2->sentence-transformers==0.3.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=3.0.2->sentence-transformers==0.3.0) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers>=3.0.2->sentence-transformers==0.3.0) (3.4.1)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-0.3.0-cp37-none-any.whl size=86754 sha256=b050f7ce66564eefb10801d46354eeffb73438ef1b8fa7051032e41d635751b5\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/23/85/85d6a9a6c68f0625a1ecdaad903bb0a78df058c10cf74f9de4\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: sacremoses, tokenizers, transformers, sentence-transformers\n",
            "Successfully installed sacremoses-0.0.45 sentence-transformers-0.3.0 tokenizers-0.10.2 transformers-4.5.1\n",
            "Collecting transformers==3.0.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\u001b[K     |████████████████████████████████| 778kB 19.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (0.0.45)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (4.41.1)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 54.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (20.9)\n",
            "Collecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/59/68c7e3833f535615fb97d33ffcb7b30bbf62bc7477a9c59cd19ad8535d72/tokenizers-0.8.1rc1-cp37-cp37m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 52.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (2.23.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.0.2) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (2020.12.5)\n",
            "Installing collected packages: sentencepiece, tokenizers, transformers\n",
            "  Found existing installation: tokenizers 0.10.2\n",
            "    Uninstalling tokenizers-0.10.2:\n",
            "      Successfully uninstalled tokenizers-0.10.2\n",
            "  Found existing installation: transformers 4.5.1\n",
            "    Uninstalling transformers-4.5.1:\n",
            "      Successfully uninstalled transformers-4.5.1\n",
            "Successfully installed sentencepiece-0.1.95 tokenizers-0.8.1rc1 transformers-3.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmIxp0FnKXif",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd1c9b02-6c31-4cb2-c844-3659ffc645e4"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# set seeds for reproducability\n",
        "from numpy.random import seed\n",
        "seed(1)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string, os \n",
        "\n",
        "import urllib.request\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1yL4NtUKaRn",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d99c4f2c-a2e8-4f07-a4cf-453d71bdfce8"
      },
      "source": [
        "import tensorflow as tf\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    print('GPU device not found')\n",
        "    print(device_name)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3J0n_lhKcgm",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1573565-6756-49b1-9e4b-b1cff0b2fc1c"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MJy2UYyLAoO",
        "trusted": true
      },
      "source": [
        "import random\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ue_4ZfdRKfdX",
        "trusted": true
      },
      "source": [
        "# Print iterations progress\n",
        "class ProgressBar:\n",
        "\n",
        "    def __init__(self,total=20, prefix = '', suffix = '', decimals = 1, length = 20, fill = '|', printEnd = \"\\r\"):\n",
        "        self.total = total\n",
        "        self.prefix = prefix\n",
        "        self.suffix = suffix\n",
        "        self.decimals = decimals\n",
        "        self.length = length\n",
        "        self.fill = fill\n",
        "        self.printEnd = printEnd\n",
        "        self.ite = 0\n",
        "        self.back_filledLength = 0\n",
        "\n",
        "    def printProgress(self,iteration, text):\n",
        "        self.ite += iteration\n",
        "        percent = (\"{0:.\" + str(self.decimals) + \"f}\").format(100 * (self.ite / float(self.total)))\n",
        "        filledLength = int(self.length * self.ite // self.total)\n",
        "        bar = self.fill * filledLength + '.' * (self.length - filledLength)\n",
        "        if filledLength > self.back_filledLength or percent == 100:\n",
        "            print(f'\\r{self.prefix} |{bar}| {percent}% {self.suffix}  {text}', end=\"\", flush=True)\n",
        "            # Print New Line on Complete\n",
        "            if self.ite == self.total: \n",
        "                print()\n",
        "        self.back_filledLength = filledLength    "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNHI0G6JKc5h",
        "trusted": true
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Zsv-LVkKmfL"
      },
      "source": [
        "##4.2 Grammar Discriminator Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "MGVvJrn3lEuO"
      },
      "source": [
        "# coding=utf-8\n",
        "# Copyright 2018 Google AI, Google Brain and Carnegie Mellon University Authors and the HuggingFace Inc. team and Jangwon Park\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\"\"\" Tokenization classes for KoBert model.\"\"\"\n",
        "\n",
        "\n",
        "import logging\n",
        "import os\n",
        "import unicodedata\n",
        "from shutil import copyfile\n",
        "\n",
        "from transformers import PreTrainedTokenizer\n",
        "\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "VOCAB_FILES_NAMES = {\"vocab_file\": \"tokenizer_78b3253a26.model\",\n",
        "                     \"vocab_txt\": \"vocab.txt\"}\n",
        "\n",
        "PRETRAINED_VOCAB_FILES_MAP = {\n",
        "    \"vocab_file\": {\n",
        "        \"monologg/kobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert/tokenizer_78b3253a26.model\",\n",
        "        \"monologg/kobert-lm\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert-lm/tokenizer_78b3253a26.model\",\n",
        "        \"monologg/distilkobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/distilkobert/tokenizer_78b3253a26.model\"\n",
        "    },\n",
        "    \"vocab_txt\": {\n",
        "        \"monologg/kobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert/vocab.txt\",\n",
        "        \"monologg/kobert-lm\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert-lm/vocab.txt\",\n",
        "        \"monologg/distilkobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/distilkobert/vocab.txt\"\n",
        "    }\n",
        "}\n",
        "\n",
        "PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES = {\n",
        "    \"monologg/kobert\": 512,\n",
        "    \"monologg/kobert-lm\": 512,\n",
        "    \"monologg/distilkobert\": 512\n",
        "}\n",
        "\n",
        "PRETRAINED_INIT_CONFIGURATION = {\n",
        "    \"monologg/kobert\": {\"do_lower_case\": False},\n",
        "    \"monologg/kobert-lm\": {\"do_lower_case\": False},\n",
        "    \"monologg/distilkobert\": {\"do_lower_case\": False}\n",
        "}\n",
        "\n",
        "SPIECE_UNDERLINE = u'▁'\n",
        "\n",
        "\n",
        "class KoBertTokenizer(PreTrainedTokenizer):\n",
        "    \"\"\"\n",
        "        SentencePiece based tokenizer. Peculiarities:\n",
        "            - requires `SentencePiece <https://github.com/google/sentencepiece>`_\n",
        "    \"\"\"\n",
        "    vocab_files_names = VOCAB_FILES_NAMES\n",
        "    pretrained_vocab_files_map = PRETRAINED_VOCAB_FILES_MAP\n",
        "    pretrained_init_configuration = PRETRAINED_INIT_CONFIGURATION\n",
        "    max_model_input_sizes = PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            vocab_file,\n",
        "            vocab_txt,\n",
        "            do_lower_case=False,\n",
        "            remove_space=True,\n",
        "            keep_accents=False,\n",
        "            unk_token=\"[UNK]\",\n",
        "            sep_token=\"[SEP]\",\n",
        "            pad_token=\"[PAD]\",\n",
        "            cls_token=\"[CLS]\",\n",
        "            mask_token=\"[MASK]\",\n",
        "            **kwargs):\n",
        "        super().__init__(\n",
        "            unk_token=unk_token,\n",
        "            sep_token=sep_token,\n",
        "            pad_token=pad_token,\n",
        "            cls_token=cls_token,\n",
        "            mask_token=mask_token,\n",
        "            **kwargs\n",
        "        )\n",
        "\n",
        "        # Build vocab\n",
        "        self.token2idx = dict()\n",
        "        self.idx2token = []\n",
        "        with open(vocab_txt, 'r', encoding='utf-8') as f:\n",
        "            for idx, token in enumerate(f):\n",
        "                token = token.strip()\n",
        "                self.token2idx[token] = idx\n",
        "                self.idx2token.append(token)\n",
        "\n",
        "        try:\n",
        "            import sentencepiece as spm\n",
        "        except ImportError:\n",
        "            logger.warning(\"You need to install SentencePiece to use KoBertTokenizer: https://github.com/google/sentencepiece\"\n",
        "                           \"pip install sentencepiece\")\n",
        "\n",
        "        self.do_lower_case = do_lower_case\n",
        "        self.remove_space = remove_space\n",
        "        self.keep_accents = keep_accents\n",
        "        self.vocab_file = vocab_file\n",
        "        self.vocab_txt = vocab_txt\n",
        "\n",
        "        self.sp_model = spm.SentencePieceProcessor()\n",
        "        self.sp_model.Load(vocab_file)\n",
        "\n",
        "    @property\n",
        "    def vocab_size(self):\n",
        "        return len(self.idx2token)\n",
        "\n",
        "    def get_vocab(self):\n",
        "        return dict(self.token2idx, **self.added_tokens_encoder)\n",
        "\n",
        "    def __getstate__(self):\n",
        "        state = self.__dict__.copy()\n",
        "        state[\"sp_model\"] = None\n",
        "        return state\n",
        "\n",
        "    def __setstate__(self, d):\n",
        "        self.__dict__ = d\n",
        "        try:\n",
        "            import sentencepiece as spm\n",
        "        except ImportError:\n",
        "            logger.warning(\"You need to install SentencePiece to use KoBertTokenizer: https://github.com/google/sentencepiece\"\n",
        "                           \"pip install sentencepiece\")\n",
        "        self.sp_model = spm.SentencePieceProcessor()\n",
        "        self.sp_model.Load(self.vocab_file)\n",
        "\n",
        "    def preprocess_text(self, inputs):\n",
        "        if self.remove_space:\n",
        "            outputs = \" \".join(inputs.strip().split())\n",
        "        else:\n",
        "            outputs = inputs\n",
        "        outputs = outputs.replace(\"``\", '\"').replace(\"''\", '\"')\n",
        "\n",
        "        if not self.keep_accents:\n",
        "            outputs = unicodedata.normalize('NFKD', outputs)\n",
        "            outputs = \"\".join([c for c in outputs if not unicodedata.combining(c)])\n",
        "        if self.do_lower_case:\n",
        "            outputs = outputs.lower()\n",
        "\n",
        "        return outputs\n",
        "\n",
        "    def _tokenize(self, text, return_unicode=True, sample=False):\n",
        "        \"\"\" Tokenize a string. \"\"\"\n",
        "        text = self.preprocess_text(text)\n",
        "\n",
        "        if not sample:\n",
        "            pieces = self.sp_model.EncodeAsPieces(text)\n",
        "        else:\n",
        "            pieces = self.sp_model.SampleEncodeAsPieces(text, 64, 0.1)\n",
        "        new_pieces = []\n",
        "        for piece in pieces:\n",
        "            if len(piece) > 1 and piece[-1] == str(\",\") and piece[-2].isdigit():\n",
        "                cur_pieces = self.sp_model.EncodeAsPieces(piece[:-1].replace(SPIECE_UNDERLINE, \"\"))\n",
        "                if piece[0] != SPIECE_UNDERLINE and cur_pieces[0][0] == SPIECE_UNDERLINE:\n",
        "                    if len(cur_pieces[0]) == 1:\n",
        "                        cur_pieces = cur_pieces[1:]\n",
        "                    else:\n",
        "                        cur_pieces[0] = cur_pieces[0][1:]\n",
        "                cur_pieces.append(piece[-1])\n",
        "                new_pieces.extend(cur_pieces)\n",
        "            else:\n",
        "                new_pieces.append(piece)\n",
        "\n",
        "        return new_pieces\n",
        "\n",
        "    def _convert_token_to_id(self, token):\n",
        "        \"\"\" Converts a token (str/unicode) in an id using the vocab. \"\"\"\n",
        "        return self.token2idx.get(token, self.token2idx[self.unk_token])\n",
        "\n",
        "    def _convert_id_to_token(self, index, return_unicode=True):\n",
        "        \"\"\"Converts an index (integer) in a token (string/unicode) using the vocab.\"\"\"\n",
        "        return self.idx2token[index]\n",
        "\n",
        "    def convert_tokens_to_string(self, tokens):\n",
        "        \"\"\"Converts a sequence of tokens (strings for sub-words) in a single string.\"\"\"\n",
        "        out_string = \"\".join(tokens).replace(SPIECE_UNDERLINE, \" \").strip()\n",
        "        return out_string\n",
        "\n",
        "    def build_inputs_with_special_tokens(self, token_ids_0, token_ids_1=None):\n",
        "        \"\"\"\n",
        "        Build model inputs from a sequence or a pair of sequence for sequence classification tasks\n",
        "        by concatenating and adding special tokens.\n",
        "        A KoBERT sequence has the following format:\n",
        "            single sequence: [CLS] X [SEP]\n",
        "            pair of sequences: [CLS] A [SEP] B [SEP]\n",
        "        \"\"\"\n",
        "        if token_ids_1 is None:\n",
        "            return [self.cls_token_id] + token_ids_0 + [self.sep_token_id]\n",
        "        cls = [self.cls_token_id]\n",
        "        sep = [self.sep_token_id]\n",
        "        return cls + token_ids_0 + sep + token_ids_1 + sep\n",
        "\n",
        "    def get_special_tokens_mask(self, token_ids_0, token_ids_1=None, already_has_special_tokens=False):\n",
        "        \"\"\"\n",
        "        Retrieves sequence ids from a token list that has no special tokens added. This method is called when adding\n",
        "        special tokens using the tokenizer ``prepare_for_model`` or ``encode_plus`` methods.\n",
        "        Args:\n",
        "            token_ids_0: list of ids (must not contain special tokens)\n",
        "            token_ids_1: Optional list of ids (must not contain special tokens), necessary when fetching sequence ids\n",
        "                for sequence pairs\n",
        "            already_has_special_tokens: (default False) Set to True if the token list is already formated with\n",
        "                special tokens for the model\n",
        "        Returns:\n",
        "            A list of integers in the range [0, 1]: 0 for a special token, 1 for a sequence token.\n",
        "        \"\"\"\n",
        "\n",
        "        if already_has_special_tokens:\n",
        "            if token_ids_1 is not None:\n",
        "                raise ValueError(\n",
        "                    \"You should not supply a second sequence if the provided sequence of \"\n",
        "                    \"ids is already formated with special tokens for the model.\"\n",
        "                )\n",
        "            return list(map(lambda x: 1 if x in [self.sep_token_id, self.cls_token_id] else 0, token_ids_0))\n",
        "\n",
        "        if token_ids_1 is not None:\n",
        "            return [1] + ([0] * len(token_ids_0)) + [1] + ([0] * len(token_ids_1)) + [1]\n",
        "        return [1] + ([0] * len(token_ids_0)) + [1]\n",
        "\n",
        "    def create_token_type_ids_from_sequences(self, token_ids_0, token_ids_1=None):\n",
        "        \"\"\"\n",
        "        Creates a mask from the two sequences passed to be used in a sequence-pair classification task.\n",
        "        A KoBERT sequence pair mask has the following format:\n",
        "        0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
        "        | first sequence    | second sequence\n",
        "        if token_ids_1 is None, only returns the first portion of the mask (0's).\n",
        "        \"\"\"\n",
        "        sep = [self.sep_token_id]\n",
        "        cls = [self.cls_token_id]\n",
        "        if token_ids_1 is None:\n",
        "            return len(cls + token_ids_0 + sep) * [0]\n",
        "        return len(cls + token_ids_0 + sep) * [0] + len(token_ids_1 + sep) * [1]\n",
        "\n",
        "    def save_vocabulary(self, save_directory):\n",
        "        \"\"\" Save the sentencepiece vocabulary (copy original file) and special tokens file\n",
        "            to a directory.\n",
        "        \"\"\"\n",
        "        if not os.path.isdir(save_directory):\n",
        "            logger.error(\"Vocabulary path ({}) should be a directory\".format(save_directory))\n",
        "            return\n",
        "\n",
        "        # 1. Save sentencepiece model\n",
        "        out_vocab_model = os.path.join(save_directory, VOCAB_FILES_NAMES[\"vocab_file\"])\n",
        "\n",
        "        if os.path.abspath(self.vocab_file) != os.path.abspath(out_vocab_model):\n",
        "            copyfile(self.vocab_file, out_vocab_model)\n",
        "\n",
        "        # 2. Save vocab.txt\n",
        "        index = 0\n",
        "        out_vocab_txt = os.path.join(save_directory, VOCAB_FILES_NAMES[\"vocab_txt\"])\n",
        "        with open(out_vocab_txt, \"w\", encoding=\"utf-8\") as writer:\n",
        "            for token, token_index in sorted(self.token2idx.items(), key=lambda kv: kv[1]):\n",
        "                if index != token_index:\n",
        "                    logger.warning(\n",
        "                        \"Saving vocabulary to {}: vocabulary indices are not consecutive.\"\n",
        "                        \" Please check that the vocabulary is not corrupted!\".format(out_vocab_txt)\n",
        "                    )\n",
        "                    index = token_index\n",
        "                writer.write(token + \"\\n\")\n",
        "                index += 1\n",
        "\n",
        "        return out_vocab_model, out_vocab_txt"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VQdGLciKc_y",
        "trusted": true
      },
      "source": [
        "from transformers import BertTokenizer, AutoTokenizer, BertForSequenceClassification, AdamW, BertConfig, get_linear_schedule_with_warmup\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset, random_split\n",
        "\n",
        "import time\n",
        "import random\n",
        "import datetime\n",
        "\n",
        "# 간단한 전처리\n",
        "def clean_text(txt):\n",
        "    txt = txt.replace('\\n',' ')\n",
        "    txt = txt.replace('\\r',' ')    \n",
        "    txt = txt.replace('=','')\n",
        "    txt = txt.replace('\\\"','')   \n",
        "    txt = txt.replace('\\'','')\n",
        "    #txt = txt.replace(',','')\n",
        "    txt = txt.replace('..','')\n",
        "    txt = txt.replace('...','')\n",
        "    txt = txt.replace(' .','.')\n",
        "    txt = txt.replace('.','. ')\n",
        "    txt = txt.replace('  ',' ')\n",
        "    txt = txt.replace('  ',' ')    \n",
        "    txt = txt.replace('  ',' ')   \n",
        "    txt = txt.replace('  ',' ')           \n",
        "    txt = txt.replace('  ',' ')\n",
        "    txt = txt.replace('  ',' ')    \n",
        "    txt = txt.replace('  ',' ')   \n",
        "    txt = txt.replace('  ',' ')             \n",
        "    return txt.strip()\n",
        "\n",
        "def shuffling(txt):\n",
        "    txt_list = txt.split(' ')\n",
        "    random.shuffle(txt_list)\n",
        "    return ' '.join(txt_list)\n",
        "\n",
        "def collect_training_dataset_for_grammar_discriminator(sentences_dataset):\n",
        "\n",
        "    sentences = []\n",
        "    labels = []\n",
        "\n",
        "    for txtss in sentences_dataset:\n",
        "        txtss = clean_text(txtss)\n",
        "        txts = txtss.strip().split('.')\n",
        "        for txt in txts:  \n",
        "            txt = txt.strip()\n",
        "            if len(txt) > 40:\n",
        "                #ko_grammar_dataset.append([txt,1])\n",
        "                txt = txt.replace('.','')\n",
        "                tf = random.choice([True,False])\n",
        "                # 정상 또는 비정상 둘중에 하나만 데이터셋에 추가\n",
        "                if (tf):\n",
        "                    sentences.append(txt) # '.'의 위치를 보고 True, False를 판단 하기 땜에...\n",
        "                    labels.append(1)\n",
        "                else:\n",
        "                    sentences.append(shuffling(txt))\n",
        "                    labels.append(0)\n",
        "\n",
        "    return sentences,labels\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
        "\n",
        "class Grammar_Discriminator:\n",
        "\n",
        "\n",
        "    def __init__(self, pretraoned_kobert_model_name='monologg/kobert', input_dir=None):\n",
        "\n",
        "        if input_dir is None:\n",
        "            self.tokenizer = KoBertTokenizer.from_pretrained(pretraoned_kobert_model_name)\n",
        "            self.discriminator = BertForSequenceClassification.from_pretrained(\n",
        "                                    pretraoned_kobert_model_name, # Use the 12-layer BERT model, with an uncased vocab.\n",
        "                                    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                                                    # You can increase this for multi-class tasks.   \n",
        "                                    output_attentions = False, # Whether the model returns attentions weights.\n",
        "                                    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        "                                )            \n",
        "        else:\n",
        "            self.__load_model(input_dir)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def set_dataset(self, sentences,labels):\n",
        "        # Print the original sentence.\n",
        "        print(' Original: ', sentences[0])\n",
        "\n",
        "        # Print the sentence split into tokens.\n",
        "        print('Tokenized: ', self.tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "        # Print the sentence mapped to token ids.\n",
        "        print('Token IDs: ', self.tokenizer.convert_tokens_to_ids(self.tokenizer.tokenize(sentences[0])))   \n",
        "\n",
        "        # Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "        input_ids = []\n",
        "        attention_masks = []\n",
        "\n",
        "        # For every sentence...\n",
        "        for sent in sentences:\n",
        "            # `encode_plus` will:\n",
        "            #   (1) Tokenize the sentence.\n",
        "            #   (2) Prepend the `[CLS]` token to the start.\n",
        "            #   (3) Append the `[SEP]` token to the end.\n",
        "            #   (4) Map tokens to their IDs.\n",
        "            #   (5) Pad or truncate the sentence to `max_length`\n",
        "            #   (6) Create attention masks for [PAD] tokens.\n",
        "            encoded_dict = self.tokenizer.encode_plus(\n",
        "                                sent,                      # Sentence to encode.\n",
        "                                add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                                max_length = 64,           # Pad & truncate all sentences.\n",
        "                                pad_to_max_length = True,\n",
        "                                return_attention_mask = True,   # Construct attn. masks.\n",
        "                                return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                                truncation = True,\n",
        "                        )\n",
        "            \n",
        "            # Add the encoded sentence to the list.    \n",
        "            input_ids.append(encoded_dict['input_ids'])\n",
        "            \n",
        "            # And its attention mask (simply differentiates padding from non-padding).\n",
        "            attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "        # Convert the lists into tensors.\n",
        "        input_ids = torch.cat(input_ids, dim=0)\n",
        "        attention_masks = torch.cat(attention_masks, dim=0)\n",
        "        labels = torch.tensor(labels)\n",
        "\n",
        "        # Print sentence 0, now as a list of IDs.\n",
        "        print('Original: ', sentences[0])\n",
        "        print('Token IDs:', input_ids[0])\n",
        "\n",
        "        # Training & Validation Split\n",
        "        # Divide up our training set to use 90% for training and 10% for validation.\n",
        "\n",
        "        # Combine the training inputs into a TensorDataset.\n",
        "        dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "        # Create a 90-10 train-validation split.\n",
        "\n",
        "        # Calculate the number of samples to include in each set.\n",
        "        train_size = int(0.9 * len(dataset))\n",
        "        val_size = len(dataset) - train_size\n",
        "\n",
        "        # Divide the dataset by randomly selecting samples.\n",
        "        train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "        print('{:>5,} training samples'.format(train_size))\n",
        "        print('{:>5,} validation samples'.format(val_size))\n",
        "\n",
        "        # The DataLoader needs to know our batch size for training, so we specify it \n",
        "        # here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "        # size of 16 or 32.\n",
        "        self.batch_size = 32\n",
        "\n",
        "        # Create the DataLoaders for our training and validation sets.\n",
        "        # We'll take training samples in random order. \n",
        "        self.train_dataloader = DataLoader(\n",
        "                    train_dataset,  # The training samples.\n",
        "                    sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "                    batch_size = self.batch_size # Trains with this batch size.\n",
        "                )\n",
        "\n",
        "        # For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "        self.validation_dataloader = DataLoader(\n",
        "                    val_dataset, # The validation samples.\n",
        "                    sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "                    batch_size = self.batch_size # Evaluate with this batch size.\n",
        "                )        \n",
        "\n",
        "\n",
        "\n",
        "    def train(self,epochs=4):\n",
        "        # Tell pytorch to run this model on the GPU.\n",
        "        self.discriminator.cuda()\n",
        "\n",
        "        # Get all of the model's parameters as a list of tuples.\n",
        "        params = list(self.discriminator.named_parameters())\n",
        "\n",
        "        print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "        print('==== Embedding Layer ====\\n')\n",
        "\n",
        "        for p in params[0:5]:\n",
        "            print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "        print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "        for p in params[5:21]:\n",
        "            print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "        print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "        for p in params[-4:]:\n",
        "            print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))  \n",
        "\n",
        "        # Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "        # I believe the 'W' stands for 'Weight Decay fix\"\n",
        "        self.optimizer = AdamW(self.discriminator.parameters(),\n",
        "                        lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                        eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                        )\n",
        "\n",
        "        # Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "        # We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "        # training data.\n",
        "        #epochs = 2\n",
        "\n",
        "        # Total number of training steps is [number of batches] x [number of epochs]. \n",
        "        # (Note that this is not the same as the number of training samples).\n",
        "        total_steps = len(self.train_dataloader) * epochs\n",
        "\n",
        "        # Create the learning rate scheduler.\n",
        "        scheduler = get_linear_schedule_with_warmup(self.optimizer, \n",
        "                                                    num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                                    num_training_steps = total_steps)\n",
        "            \n",
        "        # This training code is based on the `run_glue.py` script here:\n",
        "        # https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "        # Set the seed value all over the place to make this reproducible.\n",
        "        seed_val = 42\n",
        "\n",
        "        random.seed(seed_val)\n",
        "        np.random.seed(seed_val)\n",
        "        torch.manual_seed(seed_val)\n",
        "        torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "        # We'll store a number of quantities such as training and validation loss, \n",
        "        # validation accuracy, and timings.\n",
        "        training_stats = []\n",
        "\n",
        "        # Measure the total training time for the whole run.\n",
        "        total_t0 = time.time()\n",
        "\n",
        "        # For each epoch...\n",
        "        for epoch_i in range(0, epochs):\n",
        "            \n",
        "            # ========================================\n",
        "            #               Training\n",
        "            # ========================================\n",
        "            \n",
        "            # Perform one full pass over the training set.\n",
        "\n",
        "            print(\"\")\n",
        "            print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "            print('Training...')\n",
        "\n",
        "            # Measure how long the training epoch takes.\n",
        "            t0 = time.time()\n",
        "\n",
        "            # Reset the total loss for this epoch.\n",
        "            total_train_loss = 0\n",
        "\n",
        "            # Put the model into training mode. Don't be mislead--the call to \n",
        "            # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "            # `dropout` and `batchnorm` layers behave differently during training\n",
        "            # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "            self.discriminator.train()\n",
        "\n",
        "            # For each batch of training data...\n",
        "            for step, batch in enumerate(self.train_dataloader):\n",
        "\n",
        "                # Progress update every 40 batches.\n",
        "                if step % 40 == 0 and not step == 0:\n",
        "                    # Calculate elapsed time in minutes.\n",
        "                    elapsed = format_time(time.time() - t0)\n",
        "                    \n",
        "                    # Report progress.\n",
        "                    print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(self.train_dataloader), elapsed))\n",
        "\n",
        "                # Unpack this training batch from our dataloader. \n",
        "                #\n",
        "                # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "                # `to` method.\n",
        "                #\n",
        "                # `batch` contains three pytorch tensors:\n",
        "                #   [0]: input ids \n",
        "                #   [1]: attention masks\n",
        "                #   [2]: labels \n",
        "                b_input_ids = batch[0].to(device)\n",
        "                b_input_mask = batch[1].to(device)\n",
        "                b_labels = batch[2].to(device)\n",
        "\n",
        "                # Always clear any previously calculated gradients before performing a\n",
        "                # backward pass. PyTorch doesn't do this automatically because \n",
        "                # accumulating the gradients is \"convenient while training RNNs\". \n",
        "                # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "                self.discriminator.zero_grad()        \n",
        "\n",
        "                # Perform a forward pass (evaluate the model on this training batch).\n",
        "                # The documentation for this `model` function is here: \n",
        "                # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "                # It returns different numbers of parameters depending on what arguments\n",
        "                # arge given and what flags are set. For our useage here, it returns\n",
        "                # the loss (because we provided labels) and the \"logits\"--the model\n",
        "                # outputs prior to activation.\n",
        "                loss, logits = self.discriminator(b_input_ids, \n",
        "                                    token_type_ids=None, \n",
        "                                    attention_mask=b_input_mask, \n",
        "                                    labels=b_labels)\n",
        "\n",
        "                # Accumulate the training loss over all of the batches so that we can\n",
        "                # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "                # single value; the `.item()` function just returns the Python value \n",
        "                # from the tensor.\n",
        "                total_train_loss += loss.item()\n",
        "\n",
        "                # Perform a backward pass to calculate the gradients.\n",
        "                loss.backward()\n",
        "\n",
        "                # Clip the norm of the gradients to 1.0.\n",
        "                # This is to help prevent the \"exploding gradients\" problem.\n",
        "                torch.nn.utils.clip_grad_norm_(self.discriminator.parameters(), 1.0)\n",
        "\n",
        "                # Update parameters and take a step using the computed gradient.\n",
        "                # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "                # modified based on their gradients, the learning rate, etc.\n",
        "                self.optimizer.step()\n",
        "\n",
        "                # Update the learning rate.\n",
        "                scheduler.step()\n",
        "\n",
        "            # Calculate the average loss over all of the batches.\n",
        "            avg_train_loss = total_train_loss / len(self.train_dataloader)            \n",
        "            \n",
        "            # Measure how long this epoch took.\n",
        "            training_time = format_time(time.time() - t0)\n",
        "\n",
        "            print(\"\")\n",
        "            print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "            print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "                \n",
        "            # ========================================\n",
        "            #               Validation\n",
        "            # ========================================\n",
        "            # After the completion of each training epoch, measure our performance on\n",
        "            # our validation set.\n",
        "\n",
        "            print(\"\")\n",
        "            print(\"Running Validation...\")\n",
        "\n",
        "            t0 = time.time()\n",
        "\n",
        "            # Put the model in evaluation mode--the dropout layers behave differently\n",
        "            # during evaluation.\n",
        "            self.discriminator.eval()\n",
        "\n",
        "            # Tracking variables \n",
        "            total_eval_accuracy = 0\n",
        "            total_eval_loss = 0\n",
        "            nb_eval_steps = 0\n",
        "\n",
        "            # Evaluate data for one epoch\n",
        "            for batch in self.validation_dataloader:\n",
        "                \n",
        "                # Unpack this training batch from our dataloader. \n",
        "                #\n",
        "                # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "                # the `to` method.\n",
        "                #\n",
        "                # `batch` contains three pytorch tensors:\n",
        "                #   [0]: input ids \n",
        "                #   [1]: attention masks\n",
        "                #   [2]: labels \n",
        "                b_input_ids = batch[0].to(device)\n",
        "                b_input_mask = batch[1].to(device)\n",
        "                b_labels = batch[2].to(device)\n",
        "                \n",
        "                # Tell pytorch not to bother with constructing the compute graph during\n",
        "                # the forward pass, since this is only needed for backprop (training).\n",
        "                with torch.no_grad():        \n",
        "\n",
        "                    # Forward pass, calculate logit predictions.\n",
        "                    # token_type_ids is the same as the \"segment ids\", which \n",
        "                    # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "                    # The documentation for this `model` function is here: \n",
        "                    # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "                    # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "                    # values prior to applying an activation function like the softmax.\n",
        "                    (loss, logits) = self.discriminator(b_input_ids, \n",
        "                                        token_type_ids=None, \n",
        "                                        attention_mask=b_input_mask,\n",
        "                                        labels=b_labels)\n",
        "                    \n",
        "                # Accumulate the validation loss.\n",
        "                total_eval_loss += loss.item()\n",
        "\n",
        "                # Move logits and labels to CPU\n",
        "                logits = logits.detach().cpu().numpy()\n",
        "                label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "                # Calculate the accuracy for this batch of test sentences, and\n",
        "                # accumulate it over all batches.\n",
        "                total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "                \n",
        "\n",
        "            # Report the final accuracy for this validation run.\n",
        "            avg_val_accuracy = total_eval_accuracy / len(self.validation_dataloader)\n",
        "            print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "            # Calculate the average loss over all of the batches.\n",
        "            avg_val_loss = total_eval_loss / len(self.validation_dataloader)\n",
        "            \n",
        "            # Measure how long the validation run took.\n",
        "            validation_time = format_time(time.time() - t0)\n",
        "            \n",
        "            print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "            print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "            # Record all statistics from this epoch.\n",
        "            training_stats.append(\n",
        "                {\n",
        "                    'epoch': epoch_i + 1,\n",
        "                    'Training Loss': avg_train_loss,\n",
        "                    'Valid. Loss': avg_val_loss,\n",
        "                    'Valid. Accur.': avg_val_accuracy,\n",
        "                    'Training Time': training_time,\n",
        "                    'Validation Time': validation_time\n",
        "                }\n",
        "            )\n",
        "\n",
        "        print(\"\")\n",
        "        print(\"Training complete!\")\n",
        "\n",
        "        print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n",
        "            \n",
        "\n",
        "        return training_stats\n",
        "\n",
        "    def save_model(self, output_dir = './model_save/'):\n",
        "        # Create output directory if needed\n",
        "        if not os.path.exists(output_dir):\n",
        "            os.makedirs(output_dir)\n",
        "\n",
        "        print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "        # Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "        # They can then be reloaded using `from_pretrained()`\n",
        "        model_to_save = self.discriminator.module if hasattr(self.discriminator, 'module') else self.discriminator  # Take care of distributed/parallel training\n",
        "        model_to_save.save_pretrained(output_dir)\n",
        "        self.tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "        # Good practice: save your training arguments together with the trained model\n",
        "        # torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n",
        "\n",
        "    def __load_model(self, input_dir = './drive/MyDrive/Colab Notebooks/summary/en_grammar_check_model'):\n",
        "        print('Loading BERT tokenizer...')\n",
        "        self.tokenizer = KoBertTokenizer.from_pretrained(input_dir)\n",
        "        self.discriminator = BertForSequenceClassification.from_pretrained(input_dir)\n",
        "\n",
        "    def transfer_learning(self, sentences, train_for = True):\n",
        "        \n",
        "        input_ids = []\n",
        "        attention_masks = []\n",
        "\n",
        "        # For every sentence...\n",
        "        for sent in sentences:\n",
        "            # `encode_plus` will:\n",
        "            #   (1) Tokenize the sentence.\n",
        "            #   (2) Prepend the `[CLS]` token to the start.\n",
        "            #   (3) Append the `[SEP]` token to the end.\n",
        "            #   (4) Map tokens to their IDs.\n",
        "            #   (5) Pad or truncate the sentence to `max_length`\n",
        "            #   (6) Create attention masks for [PAD] tokens.\n",
        "            encoded_dict = self.tokenizer.encode_plus(\n",
        "                                sent,                      # Sentence to encode.\n",
        "                                add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                                max_length = 64,           # Pad & truncate all sentences.\n",
        "                                pad_to_max_length = True,\n",
        "                                return_attention_mask = True,   # Construct attn. masks.\n",
        "                                return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                                truncation = True,\n",
        "                        )\n",
        "            # Add the encoded sentence to the list.    \n",
        "            input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "            # And its attention mask (simply differentiates padding from non-padding).\n",
        "            attention_masks.append(encoded_dict['attention_mask'])\n",
        "        \n",
        "        if train_for:\n",
        "            b_labels = torch.ones(len(sentences),dtype=torch.long).to(device)\n",
        "        else:\n",
        "            b_labels = torch.zeros(len(sentences),dtype=torch.long).to(device)\n",
        "        #print(b_labels)\n",
        "        # Convert the lists into tensors.\n",
        "        input_ids = torch.cat(input_ids, dim=0).to(device)\n",
        "        attention_masks = torch.cat(attention_masks, dim=0).to(device)    \n",
        "        #if str(discriminator1.device) == 'cpu':\n",
        "        #    pass\n",
        "        #else:\n",
        "        #    input_ids = input_ids.to(device)\n",
        "        #    attention_masks = attention_masks.to(device)        \n",
        "\n",
        "        loss, logits = self.discriminator(input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=attention_masks, \n",
        "                                labels=b_labels)\n",
        "        #return torch.sigmoid(outputs[0][:,1])\n",
        "        #return outputs[0][:,1]\n",
        "        return loss, logits\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GN-Rb32zuatd"
      },
      "source": [
        "# 문법 학습을 위한 데이터셋 구성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "BVkxilUbwKTB",
        "outputId": "656d6903-d635-4af9-d4be-f8fbf7c4b946"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/summary/korean_news_corpus.csv')\n",
        "df"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>contents</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>문 대통령 변창흠 국토장관 사의표명 사실상 수용</td>\n",
              "      <td>정만호 국민소통수석이 12일 오후 청와대 춘추관 대브리핑룸에서 변창흠 국토부 장관 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>계급장 수여하는 문 대통령</td>\n",
              "      <td>(아산뉴스1) 이광호 기자 문재인 대통령이 12일 오후 충남 아산시 경찰대학에서 열...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>계급장 수여하는 문 대통령</td>\n",
              "      <td>(아산뉴스1) 이광호 기자 문재인 대통령이 12일 오후 충남 아산시 경찰대학에서 열...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>수상자 메달 걸어주는 문 대통령</td>\n",
              "      <td>(아산뉴스1) 이광호 기자 문재인 대통령이 12일 오후 충남 아산시 경찰대학에서 열...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>정몽구 서울아산병원에 50억 쾌척</td>\n",
              "      <td>인재 양성·소외 계층 지원 등 계획 “부친 질병·가난 악순환 끊기 원해 국내 최고 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140559</th>\n",
              "      <td>[건축과도시] 북한산을 캔버스 삼아. 미술관 또 하나의 작품이 되다</td>\n",
              "      <td>&lt;은평구 진관동 사비나 미술관&gt; 서울시 은평구 진관동에 자리잡은 사비나미술관. 삼각...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140560</th>\n",
              "      <td>조선후기 문인 김조순 별장 그린 옥호정도 첫 공개</td>\n",
              "      <td>국립중앙박물관 서화실 개편해 32점 새롭게 전시 옥호정도[국립중앙박물관 제공연합뉴스...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140561</th>\n",
              "      <td>안성 청룡사 대웅전에서 목재 곡자 발견</td>\n",
              "      <td>문화재청(청장 정재숙)의 국고보조와 기술지도로 안성시에서 시행하고 있는 안성 청룡사...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140562</th>\n",
              "      <td>156년전 ㄱ자 곡자 찾았다 안성 청룡사 기둥 밑에서</td>\n",
              "      <td>안성 청룡사 대웅전에서 발견된 곡자 【서울뉴시스】 이수지 기자 안성 청룡사 대웅전에...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140563</th>\n",
              "      <td>[김중기의 필름통] 새 영화 도굴 나인스 게이트 앙상블</td>\n",
              "      <td>영화 도굴 스틸컷 ◆도굴 감독: 박정배 출연: 이제훈 조우진 신혜선 도굴을 소재로 ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>140564 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        title                                           contents\n",
              "0                  문 대통령 변창흠 국토장관 사의표명 사실상 수용  정만호 국민소통수석이 12일 오후 청와대 춘추관 대브리핑룸에서 변창흠 국토부 장관 ...\n",
              "1                              계급장 수여하는 문 대통령  (아산뉴스1) 이광호 기자 문재인 대통령이 12일 오후 충남 아산시 경찰대학에서 열...\n",
              "2                              계급장 수여하는 문 대통령  (아산뉴스1) 이광호 기자 문재인 대통령이 12일 오후 충남 아산시 경찰대학에서 열...\n",
              "3                           수상자 메달 걸어주는 문 대통령  (아산뉴스1) 이광호 기자 문재인 대통령이 12일 오후 충남 아산시 경찰대학에서 열...\n",
              "4                          정몽구 서울아산병원에 50억 쾌척  인재 양성·소외 계층 지원 등 계획 “부친 질병·가난 악순환 끊기 원해 국내 최고 ...\n",
              "...                                       ...                                                ...\n",
              "140559  [건축과도시] 북한산을 캔버스 삼아. 미술관 또 하나의 작품이 되다  <은평구 진관동 사비나 미술관> 서울시 은평구 진관동에 자리잡은 사비나미술관. 삼각...\n",
              "140560            조선후기 문인 김조순 별장 그린 옥호정도 첫 공개  국립중앙박물관 서화실 개편해 32점 새롭게 전시 옥호정도[국립중앙박물관 제공연합뉴스...\n",
              "140561                  안성 청룡사 대웅전에서 목재 곡자 발견  문화재청(청장 정재숙)의 국고보조와 기술지도로 안성시에서 시행하고 있는 안성 청룡사...\n",
              "140562          156년전 ㄱ자 곡자 찾았다 안성 청룡사 기둥 밑에서  안성 청룡사 대웅전에서 발견된 곡자 【서울뉴시스】 이수지 기자 안성 청룡사 대웅전에...\n",
              "140563         [김중기의 필름통] 새 영화 도굴 나인스 게이트 앙상블  영화 도굴 스틸컷 ◆도굴 감독: 박정배 출연: 이제훈 조우진 신혜선 도굴을 소재로 ...\n",
              "\n",
              "[140564 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6o0_FoOVwUZn",
        "outputId": "6995d9d5-cead-41fd-c487-e9e5453ff26d"
      },
      "source": [
        "df = df.dropna(axis=0)\n",
        "df['contents'].count()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "140536"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wk8kX4Unwafw",
        "outputId": "813e473b-56bb-4da7-8ac0-6bb743c6b812"
      },
      "source": [
        "import re\n",
        "import sys\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "# 간단한 전처리\n",
        "def clean_text(txt):\n",
        "    txt = txt.replace('\\n',' ')\n",
        "    txt = txt.replace('\\r',' ')    \n",
        "    txt = txt.replace('=','')\n",
        "    txt = txt.replace('\\\"','')   \n",
        "    txt = txt.replace('\\'','')\n",
        "    #txt = txt.replace(',','')\n",
        "    txt = txt.replace('..','')\n",
        "    txt = txt.replace('...','')\n",
        "    #txt = txt.replace('.','. ')\n",
        "    txt = txt.replace('.','. ')\n",
        "    txt = txt.replace('  ',' ')\n",
        "    txt = txt.replace('  ',' ')    \n",
        "    txt = txt.replace('  ',' ')   \n",
        "    txt = txt.replace('  ',' ')           \n",
        "    txt = txt.replace('  ',' ')\n",
        "    txt = txt.replace('  ',' ')    \n",
        "    txt = txt.replace('  ',' ')   \n",
        "    txt = txt.replace('  ',' ')             \n",
        "    return txt.strip()\n",
        "    \n",
        "# 검사...\n",
        "pattens = [\"[34569][0-9]{3}[\\;.\\;-\\; ][0-9]{4}[\\;.\\;-\\; ][0-9]{4}[\\;.\\;-\\; ][0-9]{4}\",\n",
        "           \"[0-9]{2,3}[\\:\\s\\;.\\;,\\;-;)][0-9]{3,4}[\\:\\s\\;.\\;,\\;-][0-9]{4}\",\n",
        "           \"[0-9]{1}[0-9]{1}[\\W]?[0-1]{1}[0-9]{1}[\\W]?[0-3]{1}[\\W]?[0-9]{1}[\\W]?[1-4]{1}[\\W]?[0-9]{1}[\\W]?[0-9]{1}[\\W]?[0-9]{1}[\\W]?[0-9]{1}[\\W]?[0-9]{1}[\\W]?[0-9]{1}\",\n",
        "           \"[0-9]{2}[\\:\\s\\;.\\;,\\;-][0-9]{2}[\\:\\s\\;.\\;,\\;-][0-9]{6}|[0-9]{3}[\\:\\s\\;.\\;,\\;-]([0-9]{5,6}[\\:\\s\\;.\\;,\\;-][0-9]{3}|[0-9]{6}[\\:\\s\\;.\\;,\\;-][0-9]{5}|[0-9]{2,3}[\\:\\s\\;.\\;,\\;-][0-9]{6}|[0-9]{2}[\\:\\s\\;.\\;,\\;-][0-9]{7}|[0-9]{2}[\\:\\s\\;.\\;,\\;-][0-9]{4,6}[\\:\\s\\;.\\;,\\;-][0-9]|[0-9]{5}[\\:\\s\\;.\\;,\\;-][0-9]{3}[\\:\\s\\;.\\;,\\;-][0-9]{2}|[0-9]{2}[\\:\\s\\;.\\;,\\;-][0-9]{5}[\\:\\s\\;.\\;,\\;-][0-9]{3}|[0-9]{4}[\\:\\s\\;.\\;,\\;-][0-9]{4}[\\:\\s\\;.\\;,\\;-][0-9]{3}|[0-9]{6}[\\:\\s\\;.\\;,\\;-][0-9]{2}[\\:\\s\\;.\\;,\\;-][0-9]{3}|[0-9]{2}[\\:\\s\\;.\\;,\\;-][0-9]{2}[\\:\\s\\;.\\;,\\;-][0-9]{7})|[0-9]{4}[\\:\\s\\;.\\;,\\;-]([0-9]{3}[\\:\\s\\;.\\;,\\;-][0-9]{6}|[0-9]{2}[\\:\\s\\;.\\;,\\;-][0-9]{6}[\\:\\s\\;.\\;,\\;-][0-9])|[0-9]{5}[\\:\\s\\;.\\;,\\;-][0-9]{2}[\\:\\s\\;.\\;,\\;-][0-9]{6}|[0-9]{6}[\\:\\s\\;.\\;,\\;-][0-9]{2}[\\:\\s\\;.\\;,\\;-][0-9]{5,6}\"\n",
        "           ]\n",
        "\n",
        "filters = []\n",
        "for p in pattens:\n",
        "    filters.append(re.compile(p))\n",
        "\n",
        "sentences = []\n",
        "df = df.dropna(axis=0)\n",
        "cnt = df['contents'].count()\n",
        "#print('Total row count:',cnt)\n",
        "i=0\n",
        "for raw_text in df['contents']:\n",
        "    i=i+1\n",
        "    try:\n",
        "        if i%100 == 0:\n",
        "            percent = (\"{0:.2f}\").format(100 * (i / float(cnt)))\n",
        "            print(f'\\r {percent}% {i}/{str(cnt)}', end=\"\", flush=True)\n",
        "\n",
        "        docs = nltk.sent_tokenize(clean_text(raw_text))\n",
        "        for txt in docs:\n",
        "            if txt.find('▶') > -1 or txt.find('@') > -1 or txt.find('ⓒ') > -1: \n",
        "                pass\n",
        "            else:\n",
        "                txt = txt.strip()\n",
        "                if any(chr.isdigit() for chr in txt) :\n",
        "                    pass\n",
        "                else:\n",
        "                    sentences.append(txt)\n",
        "    except KeyboardInterrupt as ki:\n",
        "        raise ki        \n",
        "    except:\n",
        "        pass #print(\"Unexpected error:\", sys.exc_info()[0])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            " 99.97% 140500/140536"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaklRDcbwujZ"
      },
      "source": [
        "import re\n",
        "import sys\n",
        "import io\n",
        "\n",
        "#텍스트 정제(전처리)\n",
        "def cleanText(readData):\n",
        "    #텍스트에 포함되어 있는 특수 문자 제거\n",
        "    text = re.sub('[-=+,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》◆◇●🎧○▲\\t―△━▷]', '', readData)\n",
        "    return text"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzfNoeYTwvPA"
      },
      "source": [
        "\n",
        "c_sentences = []\n",
        "for sentence in sentences:\n",
        "    s = cleanText(sentence)\n",
        "    c = len(s.split())\n",
        "    if c >= 3 and c < 10 and s.find('재배포') < 0 and s.find('기자') < 0  and s.find('유투브') < 0 and s.find('www') < 0 and s.find('com') < 0 and s.find('접속하기') < 0 and s.find('http') < 0 and s.find('뉴스') < 0 and s.find('일보') < 0 :\n",
        "        if s.endswith(('다','요')):\n",
        "            c_sentences.append(s.strip())"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOe0V4W-wzCR",
        "outputId": "445cf126-84df-410f-bb82-66041a05e579"
      },
      "source": [
        "len(c_sentences)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "867766"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDz47Hf19_iU",
        "outputId": "5f58ec2a-2c40-4611-9187-0ad546fa987f"
      },
      "source": [
        "c_sentences[:100]"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['그동안 팔아치웠던 삼성전자와 SK하이닉스 등 반도체주를 다시 담기 시작했다',\n",
              " '조정장에서 순매수했던 삼성화재와 SK텔레콤은 더 많이 사들였다',\n",
              " '반면 빅히트 등에 대해서는 순매도를 이어갔다',\n",
              " '김성수 과학기술정보통신부 과학기술혁신본부장이 인사말을 하고 있다',\n",
              " '김성수 과학기술정보통신부 과학기술혁신본부장이 인사말을 하고 있다',\n",
              " '김성수 과학기술정보통신부 과학기술혁신본부장이 간담회 참석자들과 기념촬영 하고 있다',\n",
              " '충격적인 일”이라고 주장했다',\n",
              " '내가 엉터리 보도의 현장 증인이다',\n",
              " '지상최대의 이간 작전이 시작됐다”고 말했다',\n",
              " 'A씨는 취재진의 질문에 “딸이 낳은 아이가 맞다',\n",
              " '나는 아이를 낳은 적이 없다”고 말했다',\n",
              " '지속적인 손바뀜이 일어나고 있는 것 같아요',\n",
              " '지금 미국 정부가 하고 있는 부양책의 핵심은 고용이거든요',\n",
              " '이렇게 되면 기술주보다는 전통 산업 쪽으로 움직여야 할 것입니다',\n",
              " '연준도 물가 올라간다는 건 인정해요',\n",
              " '연준은 지금 평균 물가 목표제를 갖고 있거든요',\n",
              " '지속성이 있을 것 같다는 쪽에 비중을 많이 두는 편입니다',\n",
              " '비용이 최소가 되는 겁니다',\n",
              " '이걸 친환경으로 바꾸면서 아무래도 비용이 증가할 수밖에 없습니다',\n",
              " '최소한 올해 가을은 되어야 확인할 수 있어요',\n",
              " '그렇기 때문에 지금 시장이 어느 쪽 이야기를 믿어주느냐가 중요합니다',\n",
              " '하지만 최근에는 유가나 구리가 조금 안정되었어요',\n",
              " '지금은 일시적이라는 생각들이 많은 것 같아요',\n",
              " '채권의 매수 여력이 현저히 약화된 것으로 보입니다',\n",
              " '그런데 장기 채권에서는 연기금으로부터 꾸준하게 돈이 들어오고 있어요',\n",
              " '코로나 대응 채권 매입속도 높인다',\n",
              " '이전에 연준은 물가와 GDP성장률을 확실한 목표로 잡고 있었어요',\n",
              " '파월의장도 그 점을 작년에 다시 확인을 했습니다',\n",
              " '지금 미국의 GDP성장률이 올해 굉장히 높게 나올 것 같아요',\n",
              " '그러면 계속 부양하겠다는게 연준이 정해놓은 목표입니다',\n",
              " '고용을 계속 최상위 목표로 삼겠다고 반복을 할 것으로 봅니다',\n",
              " '이번에는 몇 명이 더 이탈할 수는 있을 것 같아요',\n",
              " '미국 달러화의 움직임을 보면 됩니다',\n",
              " '이번에 미국 경기 부양책도 자국 내 소비에만 집중됩니다',\n",
              " '최근에 달러화가 올랐어요',\n",
              " '다만 달러 강세는 상당히 조심스럽게 봐야 되는 움직임입니다',\n",
              " '우리나라에서 중소형주하고 대형주 사이에 역학관계가 약화되어 있는 상황이에요',\n",
              " '최근에 외국인들이나 기관들은 매수하고 개인들은 팔고 있습니다',\n",
              " '지금은 사실 이것도 버리기 어렵고 저것도 버리기 어려워요',\n",
              " '기존에 성장률 비중이 높았다면 가치주도 높이라는 말씀을 드리고 싶습니다',\n",
              " '장중에 중국 시장의 영향력을 너무 강하게 받고 있습니다',\n",
              " '음봉이 꽤 여러 번 나타나요',\n",
              " '중국이 긴축 이야기를 많이 해요',\n",
              " '제가 보기에 최근 중국은 긴축은 아니에요',\n",
              " '지난 한 해 사람들은 걷기여행을 위해 어디로 떠났을까요',\n",
              " '부산 갈맷길 한라산둘레길 남파랑길 해파랑길이 그 뒤를 이었습니다',\n",
              " '최근 날씨가 포근해지면서 산을 찾는 사람들도 늘고 있는데요',\n",
              " '그만큼 추락 조난 등 등산 사고 예방에 주의가 필요합니다',\n",
              " '정치실록 지지율 바람과 같다굳이 손잡겠어요',\n",
              " '앵커 첫번째 소식 가계대출과 관련된 소식 준비하셨네요',\n",
              " '어제 한국은행이 국회에 제출하는 통화신용정책보고서가 공개됐는데요',\n",
              " '때문에 정부가 이달안에 가계대출 관리 방안을 내놓겠다고 했는데요',\n",
              " '이때 이베이코리아 인수전에 참여할 기업들의 윤곽이 드러날 것으로 보입니다',\n",
              " '앵커 매각가가 가장 관심일텐데 얼마정도가 될까요',\n",
              " '하지만 가격에 대해서는 논란이 많습니다',\n",
              " '앵커 이베이코리아 매각을 위한 예비입찰이 다음주에 있습니다',\n",
              " '시기적으로 쿠팡 상장 등과 맞물려 관심을 받고 있습니다',\n",
              " '어떤 결과가 나올지 관심입니다',\n",
              " '앵커 이어서 다음주 주요 증시 일정도 살펴볼까요',\n",
              " 'FOMC 회의를 기점으로 금리를 둘러싼 시장의 불안심리가 진정될지가 관건입니다',\n",
              " '총량에는 변화없이 채권 매입 규모를 일시적으로 늘리겠다는 겁니다',\n",
              " '미 연준 입장에서는 고민이 되는 대목입니다',\n",
              " '당장의 관심은 연준의 향후 경기전망입니다',\n",
              " 'LG유플러스 측은 추가 피해자가 없는지 조사에 나서겠다고 밝혔습니다',\n",
              " '해당 대리점 점장음성변조  제가 썼어요',\n",
              " '피해자의 남편은 제대로 된 사과조차 받지 못했다며 울분을 토합니다',\n",
              " '대리점 측은 KBS 취재가 시작되자 뒤늦게 피해자에게 피해금을 지급했습니다',\n",
              " '아래 주소로 접속하시면 음성으로 기사를 들을 수 있습니다',\n",
              " '유럽의 일부 국가들이 아스트라제네카 백신 사용을 중단했습니다',\n",
              " 'LIG그룹 LS그룹이 대표적이다',\n",
              " '변화를 꾀하는 동시에 LG그룹의 명맥도 이어가겠다는 의미를 담았다',\n",
              " '논란의 여지가 없는 것은 아니다',\n",
              " '국토교통부 산하 공공기관인 한국국토정보공사에서도 LX를 영문 약칭으로 사용하고 있어서다',\n",
              " '현행법은 LX’와 같은 알파벳 약어를 인정하지 않는다',\n",
              " '그룹을 상징하는 로고 등의 이미지가 더해져야 상표가 된다',\n",
              " '본지에서 오늘 다룬 IT기사를 한눈에 읽을 수 있도록 구성했습니다',\n",
              " '퇴근길에 가볍게 읽을 수 있기를 기대합니다',\n",
              " '엔씨소프트는 이미 게임업계에서 ESG 지표가 가장 높은 축에 속한다',\n",
              " '여기에 ESG 경영실까지 신설하며 ESG 경영에 가속도를 붙이고 있다',\n",
              " '무제한 요금제 이용자들은 T맵 데이터도 무제한으로 사용할 수 있다',\n",
              " '음원 플랫폼 스포티파이가 국내 서비스를 론칭한다',\n",
              " '충격적인 일”이라고 주장했다',\n",
              " '내가 엉터리 보도의 현장 증인이다',\n",
              " '지상최대의 이간 작전이 시작됐다”고 말했다',\n",
              " '다만 변 장관 퇴진 시점은 다소 미루기로 했다',\n",
              " '변 장관의 임기가 시한부라는 얘기다',\n",
              " '이는 사실상 변 장관의 사의를 수락한 것으로 풀이된다',\n",
              " '사실상 사의를 수용한 것으로 보인다',\n",
              " 'A씨는 전북에서 본부장으로 근무할 때 바람직하지 않은 일을 했다',\n",
              " '국민께 죄송하다’는 내용의 유서를 남긴 것으로 전해졌다',\n",
              " '정만호 청와대 국민소통수석은 이날 브리핑을 통해 이같이 전했다',\n",
              " '문 대통령은 사실상 변 장관의 사의를 수용한 것으로 해석됩니다',\n",
              " '주택 공급도 중요하므로 그 일을 마치고 퇴임하라는 것이라고 했다',\n",
              " '정만호 청와대 국민소통수석은 이날 브리핑을 통해 이같이 전했다',\n",
              " '정만호 청와대 국민소통수석은 이날 브리핑을 통해 이같이 전했다',\n",
              " '변 장관의 사퇴는 예견된 것이라는게 정치권 안팍의 해석이다',\n",
              " '청와대의 결정에 따르겠다고 밝힌 바 있다',\n",
              " '뉴질랜드는 물에 대한 자랑스러운 역사를 가진 섬 나라이다',\n",
              " '바다와 해안선은 삶의 필수적인 부분으로 강하게 연결되어 있다',\n",
              " '특히 로드 스튜어트의 히트곡 세일링Sailing’ 공연을 선보일 계획이다']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nk93tR2Nuk8t"
      },
      "source": [
        "# 문법 discriminator의 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iK6_0do7xWn4"
      },
      "source": [
        "ko_sentences_dataset = c_sentences"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7Zf2oRMMXmH",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89c2aefc-1ed5-4924-b418-5a7f11aa5fb7"
      },
      "source": [
        "use_pretrained_model = True\n",
        "\n",
        "if use_pretrained_model:\n",
        "    #g_discriminator = Grammar_Discriminator(input_dir = '/content/drive/MyDrive/Colab Notebooks/summary/model_save')\n",
        "    g_discriminator = Grammar_Discriminator(input_dir = '/content/drive/MyDrive/Colab Notebooks/summary/ko_grammar_model2')\n",
        "else:\n",
        "    sentences,labels = collect_training_dataset_for_grammar_discriminator(ko_sentences_dataset)\n",
        "    print(len(sentences))\n",
        "    g_discriminator = Grammar_Discriminator()\n",
        "    g_discriminator.set_dataset(sentences,labels)\n",
        "    g_discriminator.train(epochs=1)\n",
        "    g_discriminator.save_model(output_dir='/content/drive/MyDrive/Colab Notebooks/summary/ko_grammar_model2')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbGhj6JGuFab",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a417f43-f2d9-4748-f9a0-039a359cff55"
      },
      "source": [
        "if True: ## 추가적인 fine-tuning\n",
        "    #sentences,labels = collect_training_dataset_for_grammar_discriminator(ko_sentences_dataset)\n",
        "    #print(len(sentences))\n",
        "    #g_discriminator = Grammar_Discriminator()\n",
        "    #g_discriminator.set_dataset(sentences,labels)\n",
        "    g_discriminator.train(epochs=2)\n",
        "    g_discriminator.save_model(output_dir='/content/drive/MyDrive/Colab Notebooks/summary/ko_grammar_model2')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                   (8002, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (2, 768)\n",
            "classifier.bias                                                 (2,)\n",
            "\n",
            "======== Epoch 1 / 2 ========\n",
            "Training...\n",
            "  Batch    40  of    859.    Elapsed: 0:00:14.\n",
            "  Batch    80  of    859.    Elapsed: 0:00:28.\n",
            "  Batch   120  of    859.    Elapsed: 0:00:42.\n",
            "  Batch   160  of    859.    Elapsed: 0:00:56.\n",
            "  Batch   200  of    859.    Elapsed: 0:01:10.\n",
            "  Batch   240  of    859.    Elapsed: 0:01:24.\n",
            "  Batch   280  of    859.    Elapsed: 0:01:38.\n",
            "  Batch   320  of    859.    Elapsed: 0:01:52.\n",
            "  Batch   360  of    859.    Elapsed: 0:02:06.\n",
            "  Batch   400  of    859.    Elapsed: 0:02:20.\n",
            "  Batch   440  of    859.    Elapsed: 0:02:34.\n",
            "  Batch   480  of    859.    Elapsed: 0:02:48.\n",
            "  Batch   520  of    859.    Elapsed: 0:03:02.\n",
            "  Batch   560  of    859.    Elapsed: 0:03:16.\n",
            "  Batch   600  of    859.    Elapsed: 0:03:30.\n",
            "  Batch   640  of    859.    Elapsed: 0:03:44.\n",
            "  Batch   680  of    859.    Elapsed: 0:03:58.\n",
            "  Batch   720  of    859.    Elapsed: 0:04:12.\n",
            "  Batch   760  of    859.    Elapsed: 0:04:26.\n",
            "  Batch   800  of    859.    Elapsed: 0:04:40.\n",
            "  Batch   840  of    859.    Elapsed: 0:04:54.\n",
            "\n",
            "  Average training loss: 0.03\n",
            "  Training epcoh took: 0:05:00\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "  Validation Loss: 0.04\n",
            "  Validation took: 0:00:11\n",
            "\n",
            "======== Epoch 2 / 2 ========\n",
            "Training...\n",
            "  Batch    40  of    859.    Elapsed: 0:00:14.\n",
            "  Batch    80  of    859.    Elapsed: 0:00:28.\n",
            "  Batch   120  of    859.    Elapsed: 0:00:42.\n",
            "  Batch   160  of    859.    Elapsed: 0:00:56.\n",
            "  Batch   200  of    859.    Elapsed: 0:01:10.\n",
            "  Batch   240  of    859.    Elapsed: 0:01:24.\n",
            "  Batch   280  of    859.    Elapsed: 0:01:38.\n",
            "  Batch   320  of    859.    Elapsed: 0:01:52.\n",
            "  Batch   360  of    859.    Elapsed: 0:02:06.\n",
            "  Batch   400  of    859.    Elapsed: 0:02:19.\n",
            "  Batch   440  of    859.    Elapsed: 0:02:33.\n",
            "  Batch   480  of    859.    Elapsed: 0:02:47.\n",
            "  Batch   520  of    859.    Elapsed: 0:03:01.\n",
            "  Batch   560  of    859.    Elapsed: 0:03:15.\n",
            "  Batch   600  of    859.    Elapsed: 0:03:29.\n",
            "  Batch   640  of    859.    Elapsed: 0:03:43.\n",
            "  Batch   680  of    859.    Elapsed: 0:03:57.\n",
            "  Batch   720  of    859.    Elapsed: 0:04:11.\n",
            "  Batch   760  of    859.    Elapsed: 0:04:25.\n",
            "  Batch   800  of    859.    Elapsed: 0:04:39.\n",
            "  Batch   840  of    859.    Elapsed: 0:04:53.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Training epcoh took: 0:04:59\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "  Validation Loss: 0.05\n",
            "  Validation took: 0:00:11\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:10:21 (h:mm:ss)\n",
            "Saving model to /content/drive/MyDrive/Colab Notebooks/summary/ko_grammar_model2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-kyzdkT-G2m",
        "outputId": "46d6c782-3b00-48cf-da90-0f9ac78d709f"
      },
      "source": [
        "txt = ['최근 날씨가 포근해지면서 산을 찾는 사람들도 늘고 있는데요','서비스를 음원 플랫폼 스포티파이가 국내  론칭한다']\n",
        "g_discriminator.discriminator.to(device)\n",
        "g_discriminator.transfer_learning(txt)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(3.9366, grad_fn=<NllLossBackward>), tensor([[-4.5302,  4.1747],\n",
              "         [ 4.0265, -3.8462]], grad_fn=<AddmmBackward>))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IO78vzTXQk33"
      },
      "source": [
        "## 문장완성 구분 discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyAd-syAQij_"
      },
      "source": [
        "\n",
        "def ellipsis(txt):\n",
        "    txt_list = txt.split(' ')\n",
        "    elp = random.sample(txt_list,k=random.randint(1,len(txt_list)-1))\n",
        "    #print(elp)\n",
        "    for e in elp:\n",
        "        txt_list.remove(e)\n",
        "    return ' '.join(txt_list)\n",
        "\n",
        "def collect_training_dataset_for_complete_discriminator(sentences_dataset):\n",
        "\n",
        "    sentences = []\n",
        "    labels = []\n",
        "\n",
        "    for txtss in sentences_dataset:\n",
        "        txtss = clean_text(txtss)\n",
        "        txts = txtss.strip().split('.')\n",
        "        try:\n",
        "            for txt in txts:  \n",
        "                txt = txt.strip()\n",
        "                if len(txt) > 40:\n",
        "                    #ko_grammar_dataset.append([txt,1])\n",
        "                    txt = txt.replace('.','')\n",
        "                    tf = random.choice([True,False])\n",
        "                    # 정상 또는 비정상 둘중에 하나만 데이터셋에 추가\n",
        "                    if (tf):\n",
        "                        sentences.append(txt) # '.'의 위치를 보고 True, False를 판단 하기 땜에...\n",
        "                        labels.append(1)\n",
        "                    else:\n",
        "                        sentences.append(ellipsis(txt))\n",
        "                        labels.append(0)\n",
        "        except Exception as ex:\n",
        "            pass\n",
        "            \n",
        "    return sentences,labels"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "bmM0F7hySbz5",
        "outputId": "38e3da6f-5aa0-489b-9c18-c3bbd23898e8"
      },
      "source": [
        "ellipsis('최근 날씨가 포근해지면서 산을 찾는 사람들도 늘고 있는데요')"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['산을', '사람들도', '찾는', '포근해지면서']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'최근 날씨가 늘고 있는데요'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41max2JlVQ0v",
        "outputId": "a4d7fadb-bbaa-4d99-c2f4-e51562fbd369"
      },
      "source": [
        "use_pretrained_model = True\n",
        "\n",
        "if use_pretrained_model:\n",
        "    c_discriminator = Grammar_Discriminator(input_dir = '/content/drive/MyDrive/Colab Notebooks/summary/ko_complete_model')\n",
        "else:\n",
        "    sentences,labels = collect_training_dataset_for_complete_discriminator(ko_sentences_dataset)\n",
        "    print(len(sentences))\n",
        "    c_discriminator = Grammar_Discriminator()\n",
        "    c_discriminator.set_dataset(sentences,labels)\n",
        "    c_discriminator.train(epochs=1)\n",
        "    c_discriminator.save_model(output_dir='/content/drive/MyDrive/Colab Notebooks/summary/ko_complete_model')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8N7mv1orHzb",
        "outputId": "b57d6f45-1ea3-465d-930b-b2d4897cc57c"
      },
      "source": [
        "txt = ['최근 날씨가 포근해지면서 산을 찾는 사람들도 늘고 있는데요','서비스를 음원 플랫폼 스포티파이가 국내 론칭한다']\n",
        "c_discriminator.discriminator.to(device)\n",
        "c_discriminator.transfer_learning(txt)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(7.2445, grad_fn=<NllLossBackward>), tensor([[ 3.3697, -3.4418],\n",
              "         [ 3.8260, -3.8498]], grad_fn=<AddmmBackward>))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArHCHioYWjDG",
        "outputId": "b7992c30-d798-4b61-bcf7-2040ba1a4404"
      },
      "source": [
        "if True: ## 추가적인 fine-tuning\n",
        "    c_discriminator.train(epochs=2)\n",
        "    c_discriminator.save_model(output_dir='/content/drive/MyDrive/Colab Notebooks/summary/ko_complete_model')"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                   (8002, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (2, 768)\n",
            "classifier.bias                                                 (2,)\n",
            "\n",
            "======== Epoch 1 / 2 ========\n",
            "Training...\n",
            "  Batch    40  of    859.    Elapsed: 0:00:14.\n",
            "  Batch    80  of    859.    Elapsed: 0:00:28.\n",
            "  Batch   120  of    859.    Elapsed: 0:00:42.\n",
            "  Batch   160  of    859.    Elapsed: 0:00:56.\n",
            "  Batch   200  of    859.    Elapsed: 0:01:10.\n",
            "  Batch   240  of    859.    Elapsed: 0:01:24.\n",
            "  Batch   280  of    859.    Elapsed: 0:01:38.\n",
            "  Batch   320  of    859.    Elapsed: 0:01:52.\n",
            "  Batch   360  of    859.    Elapsed: 0:02:06.\n",
            "  Batch   400  of    859.    Elapsed: 0:02:20.\n",
            "  Batch   440  of    859.    Elapsed: 0:02:34.\n",
            "  Batch   480  of    859.    Elapsed: 0:02:47.\n",
            "  Batch   520  of    859.    Elapsed: 0:03:01.\n",
            "  Batch   560  of    859.    Elapsed: 0:03:15.\n",
            "  Batch   600  of    859.    Elapsed: 0:03:29.\n",
            "  Batch   640  of    859.    Elapsed: 0:03:43.\n",
            "  Batch   680  of    859.    Elapsed: 0:03:57.\n",
            "  Batch   720  of    859.    Elapsed: 0:04:11.\n",
            "  Batch   760  of    859.    Elapsed: 0:04:25.\n",
            "  Batch   800  of    859.    Elapsed: 0:04:39.\n",
            "  Batch   840  of    859.    Elapsed: 0:04:53.\n",
            "\n",
            "  Average training loss: 0.12\n",
            "  Training epcoh took: 0:04:59\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.18\n",
            "  Validation took: 0:00:11\n",
            "\n",
            "======== Epoch 2 / 2 ========\n",
            "Training...\n",
            "  Batch    40  of    859.    Elapsed: 0:00:14.\n",
            "  Batch    80  of    859.    Elapsed: 0:00:28.\n",
            "  Batch   120  of    859.    Elapsed: 0:00:42.\n",
            "  Batch   160  of    859.    Elapsed: 0:00:56.\n",
            "  Batch   200  of    859.    Elapsed: 0:01:10.\n",
            "  Batch   240  of    859.    Elapsed: 0:01:24.\n",
            "  Batch   280  of    859.    Elapsed: 0:01:38.\n",
            "  Batch   320  of    859.    Elapsed: 0:01:51.\n",
            "  Batch   360  of    859.    Elapsed: 0:02:05.\n",
            "  Batch   400  of    859.    Elapsed: 0:02:19.\n",
            "  Batch   440  of    859.    Elapsed: 0:02:33.\n",
            "  Batch   480  of    859.    Elapsed: 0:02:47.\n",
            "  Batch   520  of    859.    Elapsed: 0:03:01.\n",
            "  Batch   560  of    859.    Elapsed: 0:03:15.\n",
            "  Batch   600  of    859.    Elapsed: 0:03:29.\n",
            "  Batch   640  of    859.    Elapsed: 0:03:43.\n",
            "  Batch   680  of    859.    Elapsed: 0:03:57.\n",
            "  Batch   720  of    859.    Elapsed: 0:04:11.\n",
            "  Batch   760  of    859.    Elapsed: 0:04:25.\n",
            "  Batch   800  of    859.    Elapsed: 0:04:38.\n",
            "  Batch   840  of    859.    Elapsed: 0:04:52.\n",
            "\n",
            "  Average training loss: 0.07\n",
            "  Training epcoh took: 0:04:59\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.96\n",
            "  Validation Loss: 0.16\n",
            "  Validation took: 0:00:11\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:10:20 (h:mm:ss)\n",
            "Saving model to /content/drive/MyDrive/Colab Notebooks/summary/ko_complete_model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d96kaCAHKuUc"
      },
      "source": [
        "##4.3 Static similarity discriminator class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZDpXe7XKxeg",
        "trusted": true
      },
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import BertTokenizer\n",
        "from scipy.signal import find_peaks\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.misc import electrocardiogram\n",
        "import scipy\n",
        "\n",
        "\n",
        "class Similarity_Discriminator:\n",
        "    '''\n",
        "    _instance = None\n",
        "    _embedder = None\n",
        "    def __new__(cls,pre_trained_model_name='stsb-roberta-large'):\n",
        "        if cls._instance is None:\n",
        "            print('Creating Similarity_Discriminator object')\n",
        "            cls._instance = super(Similarity_Discriminator, cls).__new__(cls)\n",
        "            # Put any initialization here.\n",
        "            cls._embedder = SentenceTransformer(pre_trained_model_name)\n",
        "        return cls._instance\n",
        "\n",
        "    '''\n",
        "\n",
        "    def __init__(self,pre_trained_model_name='xlm-r-large-en-ko-nli-ststb'):\n",
        "        print('Creating Similarity_Discriminator object')\n",
        "        # Put any initialization here.\n",
        "        self._embedder = SentenceTransformer(pre_trained_model_name)  \n",
        "        #self.cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
        "\n",
        "    def encode(self,texts):\n",
        "        return self._embedder.encode(texts,show_progress_bar=False)\n",
        "\n",
        "    def similarity(self, query_text, org_text_emb):\n",
        "        queries = nltk.sent_tokenize(query_text)\n",
        "        query_embeddings = self._embedder.encode(queries,show_progress_bar=False)\n",
        "        #query_embeddings = self._embedder.encode(queries,show_progress_bar=False)\n",
        "        #print(queries)\n",
        "        #print(org_text_emb)\n",
        "        \n",
        "        if len(query_embeddings) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        cos_scores = scipy.spatial.distance.cdist(query_embeddings, org_text_emb, \"cosine\")\n",
        "        similarity_score = 1.0 - np.mean(np.min(cos_scores,axis=0))\n",
        "        '''\n",
        "        for query, query_embedding in zip(queries, query_embeddings):\n",
        "            distances = scipy.spatial.distance.cdist([query_embedding], [org_text_emb], \"cosine\")[0]\n",
        "            results = zip(range(len(distances)), distances)\n",
        "            for idx, distance in results:\n",
        "                scores.append(1-distance)\n",
        "        '''\n",
        "        return similarity_score  \n",
        " "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sQZ36GuMumP"
      },
      "source": [
        "###4.3.1 한국어 문장 유사도 pre-trained model 적용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9Miao14Muww",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72ac677f-dbdb-4048-f8bf-aed393e1c955"
      },
      "source": [
        "s_discriminator = Similarity_Discriminator()\n",
        "#s_discriminator = Similarity_Discriminator()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating Similarity_Discriminator object\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1.80G/1.80G [00:56<00:00, 31.6MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xnk9GsQ0K1t1"
      },
      "source": [
        "##4.4 Document source class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_ztc0q3M_4F"
      },
      "source": [
        "###4.4.1 keyBERT를 위한 pre-trained model의 적재"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "dEc9R82hi1gO"
      },
      "source": [
        "#!pip install keybert"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJFTjWlwK3Uz",
        "trusted": true
      },
      "source": [
        "#from keybert import KeyBERT\n",
        "#key_model = KeyBERT('distilbert-base-nli-mean-tokens')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnBm6RCvNIWG"
      },
      "source": [
        "###4.4.2 frame term 추출을 위한 source class 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsJKbtc2K4xN",
        "trusted": true
      },
      "source": [
        "\n",
        "\n",
        "class Source:\n",
        "\n",
        "    def __init__(self,org_text):\n",
        "        self.org_text = org_text\n",
        "\n",
        "    def __crean_text(self, txt):\n",
        "        txt = txt.replace('\\n',' ')\n",
        "        txt = txt.replace('\\r',' ')    \n",
        "        txt = txt.replace('=','')\n",
        "        txt = txt.replace('\\\"','')   \n",
        "        txt = txt.replace('\\'','')\n",
        "        #txt = txt.replace(',','')\n",
        "        txt = txt.replace('..','')\n",
        "        txt = txt.replace('...','')\n",
        "        txt = txt.replace(' .','.')\n",
        "        txt = txt.replace('.','. ')\n",
        "        txt = txt.replace('  ',' ')\n",
        "        txt = txt.replace('  ',' ')    \n",
        "        txt = txt.replace('  ',' ')   \n",
        "        txt = txt.replace('  ',' ')           \n",
        "        txt = txt.replace('  ',' ')\n",
        "        txt = txt.replace('  ',' ')    \n",
        "        txt = txt.replace('  ',' ')   \n",
        "        txt = txt.replace('  ',' ')           \n",
        "        return txt.strip()\n",
        "\n",
        "\n",
        "    def extract_keywords(self,s_discriminator,key_model,comp_rate=0.2):\n",
        "        self.org_text = self.__crean_text(self.org_text.strip())\n",
        "        print('------------------------------------------------------------------')\n",
        "        print(self.org_text)\n",
        "        print('------------------------------------------------------------------')\n",
        "        self.org_sentences = np.array(nltk.sent_tokenize(self.org_text))\n",
        "        self.org_term_set = (' ' + self.org_text + ' ').split(' ')\n",
        "        self.org_source_length = len(self.org_term_set)\n",
        "        self.term_table = {}\n",
        "        #morp_table = {}\n",
        "        index_table = {}\n",
        "        for index, word in zip(range(len(self.org_term_set)),self.org_term_set):\n",
        "            self.term_table[index] = word\n",
        "        '''\n",
        "        print('Token table of origin text')\n",
        "        print('---------------------------------------------')\n",
        "        print(' Code     Token     ')\n",
        "        for k in self.term_table.keys():\n",
        "            print( f'  {str(k).ljust(5)}     {self.term_table[k]}')\n",
        "        print('---------------------------------------------')\n",
        "        '''\n",
        "        self.s_discriminator = s_discriminator\n",
        "        # 원문의 embedding...\n",
        "        self.org_text_emb = self.s_discriminator.encode(self.org_sentences)\n",
        "        '''\n",
        "        # weight 들의 초기화\n",
        "        terms = np.array(list(self.term_table.values()))\n",
        "\n",
        "        word_filters=np.array([[0]])\n",
        "\n",
        "        story_weights = np.zeros(self.org_source_length,)\n",
        "        word_weights = np.zeros(self.org_source_length,)\n",
        "\n",
        "        #terms = np.array(list(self.term_table.values()))\n",
        "\n",
        "        # story에 지배적인 word를 찾는다.\n",
        "        # 먼저 word의 강세 분석\n",
        "        for filter in word_filters:\n",
        "            #print(filter)\n",
        "            last_idx = len(terms)-(max(filter)+1)\n",
        "            pb = ProgressBar(last_idx,prefix='Frame token scan:')\n",
        "            for conv in range(last_idx,0,-1):\n",
        "                pb.printProgress(+1,f'filer:{filter} {conv}/{last_idx}       ')\n",
        "                t = np.array(filter) + conv\n",
        "                part_sen = ' '.join(terms[t]) \n",
        "                #print('\\n part_sen:',part_sen)\n",
        "                score = self.s_discriminator.similarity(part_sen.strip(),self.org_text_emb)\n",
        "                word_weights[t] += score \n",
        "\n",
        "        # story의 강세 분석\n",
        "        for filter in story_filters:\n",
        "            #print(filter)\n",
        "            last_idx = len(terms)-(max(filter)+1)\n",
        "            pb = ProgressBar(last_idx,prefix='Frame token scan:')\n",
        "            for conv in range(last_idx,0,-1):\n",
        "                pb.printProgress(+1,f'filer:{filter} {conv}/{last_idx}       ')\n",
        "                t = np.array(filter) + conv\n",
        "                part_sen = ' '.join(terms[t]) \n",
        "                score = self.s_discriminator.similarity(part_sen.strip(),self.org_text_emb)\n",
        "                story_weights[t] += score\n",
        "\n",
        "        #각각의 peak를 산출\n",
        "        word_peaks, _ = find_peaks(word_weights, height=0)\n",
        "        story_peaks, _ = find_peaks(story_weights, height=0)\n",
        "\n",
        "        #두개의 peak가 겹치는 word에 대해 한개 word가 유사도에 미치는 영향이 큰것으로 간주\n",
        "        #해당 word를 유사도 판단 필터에서 제외하고 다시 필터링...\n",
        "        #이를 통해 story에 대한 word를 최대한 추출 한다.\n",
        "\n",
        "        dup_order = []\n",
        "        for i in range(self.org_source_length):\n",
        "            #lst = \"\"\n",
        "            if (i in word_peaks) and (i in story_peaks):\n",
        "                if terms[i].endswith('.'):\n",
        "                    pass\n",
        "                else:\n",
        "                    dup_order.append(i)\n",
        "                    \n",
        "        # Story에 대한 weight을 추출하기 위해, word에 유독 강세가 있는 term을 제외 시킨다.\n",
        "        print('Negative tokens:',terms[dup_order])\n",
        "        '''\n",
        "\n",
        "        top_n = int(len(self.term_table) * comp_rate)\n",
        "\n",
        "        self.story_peaks = []\n",
        "        keywords = key_model.extract_keywords(self.org_text,top_n=top_n)\n",
        "        #print('keywords len',len(keywords))\n",
        "        #print('keywords',keywords)\n",
        "        for keyword,p in keywords:\n",
        "            for k in self.term_table.keys():\n",
        "                if self.term_table[k] == keyword: # and k not in dup_order:\n",
        "                    self.story_peaks.append(k)\n",
        "\n",
        "        self.story_peaks.append(len(self.term_table)-2)\n",
        "        self.story_peaks = np.sort(np.asarray(self.story_peaks))\n",
        "        print('story_peaks:',self.story_peaks)\n",
        "        print('Peak count:',len(self.story_peaks))          \n",
        "\n",
        "\n",
        "        # story skeleton 추출\n",
        "        self.frame_text = \"\"\n",
        "        for k in self.story_peaks:\n",
        "            #print(k,term_weight[k],word_table[k])\n",
        "            self.frame_text += self.term_table[k]+' '  \n",
        "\n",
        "        print('Frame tokens:',self.frame_text)\n",
        "        print('')\n",
        "        print(f'Similarity : {self.s_discriminator.similarity(self.frame_text.strip(),self.org_text_emb)}')    \n",
        "\n",
        "    def set_key_rate(self,s_discriminator,comp_rate=0.2):\n",
        "        self.org_text = self.__crean_text(self.org_text.strip())\n",
        "        print('------------------------------------------------------------------')\n",
        "        print(self.org_text)\n",
        "        print('------------------------------------------------------------------')\n",
        "        self.org_sentences = np.array(nltk.sent_tokenize(self.org_text))\n",
        "        self.org_term_set = (' ' + self.org_text + ' ').split(' ')\n",
        "        self.org_source_length = len(self.org_term_set)\n",
        "        self.term_table = {}\n",
        "        #morp_table = {}\n",
        "\n",
        "        for index, word in zip(range(len(self.org_term_set)),self.org_term_set):\n",
        "            self.term_table[index] = word\n",
        "\n",
        "        self.s_discriminator = s_discriminator\n",
        "        # 원문의 embedding...\n",
        "        self.org_text_emb = self.s_discriminator.encode(self.org_sentences)\n",
        "        top_n = int(len(self.term_table) * comp_rate)\n",
        "        #print('top_n',top_n)\n",
        "        self.story_peaks = [i+1 for i in range(top_n)]\n",
        "\n",
        "    def analysis_frame_terms(self,s_discriminator,story_filters=np.array([[0,1],[0,1,2],[0,1,2,3]]),peak_base_line = 0.0,comp_rate=0.2,except_key=True,display=False):\n",
        "\n",
        "        self.org_text = self.__crean_text(self.org_text.strip())\n",
        "        print('------------------------------------------------------------------')\n",
        "        print(self.org_text)\n",
        "        print('------------------------------------------------------------------')\n",
        "        self.org_sentences = np.array(nltk.sent_tokenize(self.org_text))\n",
        "        self.org_term_set = (' ' + self.org_text + ' ').split(' ')\n",
        "        self.org_source_length = len(self.org_term_set)\n",
        "        self.term_table = {}\n",
        "        #morp_table = {}\n",
        "\n",
        "        for index, word in zip(range(len(self.org_term_set)),self.org_term_set):\n",
        "            self.term_table[index] = word\n",
        "        '''\n",
        "        print('Token table of origin text')\n",
        "        print('---------------------------------------------')\n",
        "        print(' Code     Token     ')\n",
        "        for k in self.term_table.keys():\n",
        "            print( f'  {str(k).ljust(5)}     {self.term_table[k]}')\n",
        "        print('---------------------------------------------')\n",
        "        '''\n",
        "\n",
        "        self.s_discriminator = s_discriminator\n",
        "        # 원문의 embedding...\n",
        "        self.org_text_emb = self.s_discriminator.encode(self.org_sentences)\n",
        "\n",
        "        # weight 들의 초기화\n",
        "        terms = np.array(list(self.term_table.values()))\n",
        "\n",
        "        word_filters=np.array([[0]])\n",
        "\n",
        "        story_weights = np.zeros(self.org_source_length,)\n",
        "        word_weights = np.zeros(self.org_source_length,)\n",
        "\n",
        "        #terms = np.array(list(self.term_table.values()))\n",
        "\n",
        "        if except_key:\n",
        "            # story에 지배적인 word를 찾는다.\n",
        "            # 먼저 word의 강세 분석\n",
        "            for filter in word_filters:\n",
        "                #print(filter)\n",
        "                last_idx = len(terms)-(max(filter)+1)\n",
        "                pb = ProgressBar(last_idx,prefix='Frame token scan:')\n",
        "                for conv in range(last_idx,0,-1):\n",
        "                    pb.printProgress(+1,f'filer:{filter} {conv}/{last_idx}       ')\n",
        "                    t = np.array(filter) + conv\n",
        "                    part_sen = ' '.join(terms[t]) \n",
        "                    score = self.s_discriminator.similarity(part_sen.strip(),self.org_text_emb)\n",
        "                    word_weights[t] += score \n",
        "\n",
        "            # story의 강세 분석\n",
        "            for filter in story_filters:\n",
        "                #print(filter)\n",
        "                last_idx = len(terms)-(max(filter)+1)\n",
        "                pb = ProgressBar(last_idx,prefix='Frame token scan:')\n",
        "                for conv in range(last_idx,0,-1):\n",
        "                    pb.printProgress(+1,f'filer:{filter} {conv}/{last_idx}       ')\n",
        "                    t = np.array(filter) + conv\n",
        "                    part_sen = ' '.join(terms[t]) \n",
        "                    score = self.s_discriminator.similarity(part_sen.strip(),self.org_text_emb)\n",
        "                    story_weights[t] += score\n",
        "\n",
        "            #각각의 peak를 산출\n",
        "            word_peaks, _ = find_peaks(word_weights, height=0)\n",
        "            story_peaks, _ = find_peaks(story_weights, height=0)\n",
        "\n",
        "            #두개의 peak가 겹치는 word에 대해 한개 word가 유사도에 미치는 영향이 큰것으로 간주\n",
        "            #해당 word를 유사도 판단 필터에서 제외하고 다시 필터링...\n",
        "            #이를 통해 story에 대한 word를 최대한 추출 한다.\n",
        "\n",
        "            dup_order = []\n",
        "            for i in range(self.org_source_length):\n",
        "                #lst = \"\"\n",
        "                if (i in word_peaks) and (i in story_peaks):\n",
        "                    if terms[i].endswith('.'):\n",
        "                        pass\n",
        "                    else:\n",
        "                        dup_order.append(i)\n",
        "                        \n",
        "            # Story에 대한 weight을 추출하기 위해, word에 유독 강세가 있는 term을 제외 시킨다.\n",
        "            print('Negative tokens:',terms[dup_order])\n",
        "            if except_key:\n",
        "                terms[dup_order] = '---'\n",
        "        '''\n",
        "        print('Token table of origin text')\n",
        "        print('---------------------------------------------')\n",
        "        print(' Code         Token      ')\n",
        "        print('')\n",
        "        for index, word in zip(range(len(terms)),terms):\n",
        "            print( f'  {str(index).ljust(8)}    {word}')\n",
        "        print('---------------------------------------------')\n",
        "        '''\n",
        "        self.story_weights = np.zeros(self.org_source_length,)\n",
        "        # 그리고 다시 story 분석 스캔\n",
        "        for filter in story_filters:\n",
        "            #print(filter)\n",
        "            last_idx = len(terms)-(max(filter)+1)\n",
        "            pb = ProgressBar(last_idx,prefix='Frame token scan:')\n",
        "            for conv in range(last_idx):\n",
        "                pb.printProgress(+1,f'filer:{filter} {conv}/{last_idx}       ')\n",
        "                t = np.array(filter) + conv\n",
        "                part_sen = ' '.join(terms[t]) \n",
        "                #part_sen = part_sen.replace('소녀','---')\n",
        "                score = self.s_discriminator.similarity(part_sen.strip(),self.org_text_emb)\n",
        "                self.story_weights[t] += score        \n",
        "\n",
        "\n",
        "        # base line\n",
        "        base_line = peak_base_line\n",
        "        # 다시 peak 추출\n",
        "        story_peaks, _ = find_peaks(self.story_weights, height=base_line)\n",
        "\n",
        "        top_n = int(len(self.term_table) * comp_rate)\n",
        "\n",
        "        if len(story_peaks) > top_n:\n",
        "            peak_dict = {}\n",
        "            for i,peak in zip(range(len(story_peaks)),story_peaks):\n",
        "                peak_dict[peak] = self.story_weights[peak]\n",
        "            #print(peak_dict)\n",
        "            peaks = sorted(peak_dict, key=peak_dict.get, reverse=True)\n",
        "            #print(peaks)\n",
        "            peaks = peaks[:top_n]\n",
        "            #print(peaks)\n",
        "            peaks.sort()\n",
        "            story_peaks = peaks\n",
        "            #print(story_peaks)\n",
        "\n",
        "        #print('top_n:',top_n,'story_peaks:',len(story_peaks))\n",
        "        #print(story_peaks)\n",
        "        \n",
        "        self.story_peaks = np.append(story_peaks,len(story_weights)-2)\n",
        "        #print(self.story_peaks)\n",
        "        # story density 표출\n",
        "        if display:\n",
        "            plt.figure(figsize=(12, 6))\n",
        "            plt.plot(self.story_weights)\n",
        "            plt.plot(self.story_peaks, self.story_weights[self.story_peaks], \"x\")\n",
        "            plt.plot(np.zeros_like(self.story_weights)+base_line, \"--\", color=\"gray\")\n",
        "            plt.show() \n",
        "        print('Peak count:',len(self.story_peaks))          \n",
        "\n",
        "\n",
        "        # story skeleton 추출\n",
        "        self.frame_text = \"\"\n",
        "        for k in self.story_peaks:\n",
        "            #print(k,term_weight[k],word_table[k])\n",
        "            self.frame_text += self.term_table[k]+' '  \n",
        "\n",
        "        print('Frame tokens:',self.frame_text)\n",
        "        print('')\n",
        "        print(f'Similarity : {self.s_discriminator.similarity(self.frame_text.strip(),self.org_text_emb)}')      \n",
        "        ''' \n",
        "        for index, word in zip(range(len(self.org_term_set)),self.org_term_set):\n",
        "            self.term_table[index] = word\n",
        "   \n",
        "        print('Token table of origin text')\n",
        "        print('---------------------------------------------')\n",
        "        print(' Code     Score        Token              ')\n",
        "        print('')\n",
        "        for k in self.term_table.keys(): \n",
        "            print( f'  {str(k).ljust(5)}   {str(round(self.story_weights[k],4)).ljust(8)}  {self.term_table[k]}')\n",
        "\n",
        "        print('---------------------------------------------') \n",
        "        '''\n",
        "    def get_org_sample(self, num):\n",
        "        return self.org_sentences[np.random.choice(len(self.org_sentences), num)]\n",
        "\n",
        "    def get_source_embedded_code(self):\n",
        "        return self.org_text_emb"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XY59mdNK8ub"
      },
      "source": [
        "##4.5 Generator class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5CLF3WcK6lp",
        "trusted": true
      },
      "source": [
        "from functools import reduce\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    \"\"\"\n",
        "        Simple Generator w/ MLP\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size=1024):\n",
        "        super(Generator, self).__init__()\n",
        "        self.layer = nn.Sequential(\n",
        "            nn.Linear(input_size, input_size*2),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(input_size*2, input_size*3),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(input_size*3, input_size*3),\n",
        "            nn.LeakyReLU(0.2),            \n",
        "            nn.Linear(input_size*3, input_size*2),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(input_size*2, input_size),\n",
        "            #nn.BatchNorm1d(term_length*4),\n",
        "            nn.Tanh() # -1 ~ 1\n",
        "        )\n",
        "    '''\n",
        "    def forward(self, x, story_peaks, bias):\n",
        "        #biased_noise = torch.randn(N,_NOISE_DIM)\n",
        "        # stroy peak에 해당하는 term에게 평균값에 해당하는 bias를 추가 한다.\n",
        "                 \n",
        "        y_ = self.layer(x)\n",
        "        y_[:,story_peaks] += bias\n",
        "        y_ = nn.Sigmoid()(y_)\n",
        "        #reduce(torch.add, [y_,bias]) / 2\n",
        "        return y_\n",
        "    '''\n",
        "\n",
        "    \n",
        "    def forward(self, x, bias):\n",
        "        #biased_noise = torch.randn(N,_NOISE_DIM)\n",
        "        # stroy peak에 해당하는 term에게 평균값에 해당하는 bias를 추가 한다.\n",
        "                 \n",
        "        y_ = self.layer(x)\n",
        "        y = torch.add(y_,bias)\n",
        "        #y = nn.Sigmoid()(y)\n",
        "\n",
        "        return y, y_\n",
        "\n",
        "    '''    \n",
        "    def forward(self, x):\n",
        "        #biased_noise = torch.randn(N,_NOISE_DIM)\n",
        "        # stroy peak에 해당하는 term에게 평균값에 해당하는 bias를 추가 한다.\n",
        "                 \n",
        "        y_ = self.layer(x)\n",
        "        #y = torch.add(y_,bias)\n",
        "        y = nn.Sigmoid()(y_)\n",
        "\n",
        "        return y, y_    \n",
        "    '''    "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLVVmQdxLBHZ"
      },
      "source": [
        "##4.6 Summarizer class (GAN training)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Co1MnRG8a4Vq"
      },
      "source": [
        "## multi-discriminator에 대한 Adaptive discriminant factor 를 구하기 위한 학습\n",
        "\n",
        "ref : https://realpython.com/python-ai-neural-network/\n",
        "\n",
        "colab 수식입력 : \n",
        "\n",
        "https://wikidocs.net/1679\n",
        "\n",
        "https://en.wikipedia.org/wiki/Help:Displaying_a_formula#Formatting_using_TeX\n",
        "\n",
        "목적함수 : $$ J = \\sum_{i}^N (d_iG_i + (T - G_i)^2) $$\n",
        "\n",
        "여기서 T은 전체 loss $$ T= \\sum_{i}^N d_iG_i $$\n",
        "\n",
        "\n",
        "여기서 $$G_i$$는 i번째 discriminator에 대한 loss, $$d_i$$는 i번째 discriminator에 대한 discriminant factor 즉, weight에 해당\n",
        "\n",
        "GAN의 학습을 하면서, 목적함수 J를 최소화 하는 discriminant factor를 같이 학습한다.\n",
        "\n",
        "목적함수의 d에 대한 편미분은 아래와 같이 간략화 할 수 있다.\n",
        "\n",
        "$$ \\frac{\\partial J}{\\partial d_i} = 2T - G_i $$\n",
        "\n",
        "따라서 학습은 다음과 같이 이루어 진다.\n",
        "\n",
        "$$ d_i^{t+1} = d_i^t - \\alpha * (2T-G_i) $$ "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_2Acy-wa22J",
        "outputId": "bb0852f3-57dd-4477-e0d1-09353af85bed"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "dfs = [1.0,1.0,1.0] #torch.Tensor([1.0,1.0,1.0])\n",
        "print(dfs)\n",
        "#g0 = torch.tensor(0.023)\n",
        "dsc_loss = torch.Tensor([0.023,-0.0012,0.23])\n",
        "print(dsc_loss)\n",
        "total_loss = np.dot(dfs,dsc_loss)\n",
        "print('total_loss',total_loss)"
      ],
      "execution_count": 769,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.0, 1.0, 1.0]\n",
            "tensor([ 0.0230, -0.0012,  0.2300])\n",
            "total_loss 0.2518000041600317\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHgZw0u6swZ5",
        "outputId": "08900b60-941f-480e-fbfb-892c75ec99fd"
      },
      "source": [
        "#dfs[0] = 1.0\n",
        "total_loss = np.dot(dfs,dsc_loss)\n",
        "print('total_loss',total_loss)\n",
        "objective = total_loss / torch.std(dsc_loss)\n",
        "print('objective', objective)\n",
        "d_objective = dsc_loss / torch.std(dsc_loss)\n",
        "print('d_objective', d_objective)\n",
        "dfs = dfs - d_objective.numpy()\n",
        "dfs = [1.0 if i<0.0 else i for i in dfs]\n",
        "print('update dfs', dfs)"
      ],
      "execution_count": 793,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total_loss 0.23072486444978854\n",
            "objective tensor(1.8157)\n",
            "d_objective tensor([ 0.1810, -0.0094,  1.8100])\n",
            "update dfs [1.0, 1.2266381233930588, 1.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHOsXwQW4Hvb",
        "outputId": "7a37f011-b1e6-4bb0-a495-1ae48a70b1d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "a = [1,1,1]\n",
        "b = [0,0.5,0.3]\n",
        "c  = list(set(a) - set(b))\n",
        "c"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nd8GTS7HKz1H",
        "trusted": true
      },
      "source": [
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "from scipy.special import expit\n",
        "\n",
        "class SAM_Summarizer:\n",
        "\n",
        "    def __init__(self,g_discriminator,c_discriminator,s_discriminator):\n",
        "        self.g_discriminator = g_discriminator\n",
        "        self.c_discriminator = c_discriminator\n",
        "        self.s_discriminator = s_discriminator\n",
        "        self.m = nn.Sigmoid()\n",
        "\n",
        "    def ready(self,source):\n",
        "        self.source = source  \n",
        "        #self.source.analysis_frame_terms(self.s_discriminator)\n",
        "        self.generator = Generator(input_size=self.source.org_source_length)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def summarize(self,epochs=10,batch_size=2,frame_expansion_ratio = 0.8,init_bias = 1.0,learning_rate=2e-4, display = False):\n",
        "        self.frame_expansion_ratio = frame_expansion_ratio\n",
        "        history = self.__train(epochs,batch_size,init_bias,learning_rate,display)\n",
        "        if display:\n",
        "            plt.figure(figsize=(12, 6))\n",
        "            plt.plot(history['gen_g_loss'],label='generator grammar loss')\n",
        "            plt.plot(history['gen_c_loss'],label='generator completion loss')\n",
        "            plt.plot(history['gen_s_loss'],label='generator similarity loss')\n",
        "            #if 'dis_loss' in history:\n",
        "            #    plt.plot(history['dis_loss'],label='discriminator grammar loss')\n",
        "            plt.legend()\n",
        "            plt.show()\n",
        "\n",
        "        return self\n",
        "\n",
        "    # text의 생성 for torch\n",
        "    def __text_gen2(self, noise, gen_length):\n",
        "        gtext = []\n",
        "        sorted_noise, i = torch.sort(noise, descending=True)\n",
        "        order, i = torch.sort(i[:gen_length], descending=False)\n",
        "        #print(len(order))\n",
        "        assert len(order) == gen_length\n",
        "        order = order.cpu().detach().numpy()\n",
        "        for k in order:\n",
        "            gtext.append((self.source.term_table[k],k))\n",
        "        return gtext\n",
        "\n",
        "    def __discrete_gradient(self,weights,gen_length,beta,use_gpu=False, verbose=0):\n",
        "        fake_gen_out = torch.zeros(weights.shape).to(device)\n",
        "        fake_com_out = torch.zeros(weights.shape).to(device)\n",
        "        fake_sim_out = torch.zeros(weights.shape).to(device)\n",
        "\n",
        "        real_text = self.source.get_org_sample(weights.shape[0])\n",
        "        fake_outs = []\n",
        "        real_outs = []\n",
        "        apply_order = []\n",
        "        for i, noise in enumerate(weights):\n",
        "            gtext = self.__text_gen2(noise,gen_length)\n",
        "            tw = \"\"\n",
        "            tk = []\n",
        "            fake_scores = []\n",
        "            for (w,k) in gtext:\n",
        "                tw += w + ' '\n",
        "                tk.append(k)\n",
        "                if w.endswith('.'):\n",
        "                    fake_outs.append(tw.strip())\n",
        "                    real_outs.append(real_text[i])\n",
        "                    apply_order.append((i,tk))\n",
        "                    tw = \"\"\n",
        "                    tk = []\n",
        "                    \n",
        "            if len(tk) > 0:\n",
        "                fake_outs.append(tw.strip())\n",
        "                real_outs.append(real_text[i])\n",
        "                apply_order.append((i,tk))\n",
        "\n",
        "        D_z_loss, fake_gmr_out=self.g_discriminator.transfer_learning(fake_outs,train_for = False)\n",
        "        D_c_loss, fake_cpt_out=self.c_discriminator.transfer_learning(fake_outs,train_for = False)\n",
        "        #D_x_loss, real_gmr_out=self.g_discriminator.transfer_learning(real_outs,train_for = True)   # not use of 'real_gmr_out'\n",
        "\n",
        "        f_sim_out = []\n",
        "        for fake_text in fake_outs:\n",
        "            f_sim_out.append(self.s_discriminator.similarity(fake_text,self.source.org_text_emb))\n",
        "\n",
        "        #if use_gpu:\n",
        "        #    apply_order = torch.FloatTensor(apply_order).to(device)  \n",
        "        \n",
        "        #print(fake_dis_out)\n",
        "        \n",
        "        for j, (i,tk) in enumerate(apply_order):\n",
        "            #fake_gen_out[i,tk] += fake_dis_out[j].numpy() --> 이거는 tf 용...\n",
        "            #fake_gen_out[i,tk] += fake_dis_out[j] #.cpu().detach().numpy()\n",
        "            # \n",
        "            try:\n",
        "                #print('fake_gmr_out:',fake_gmr_out[j,1])\n",
        "                #print('real_gmr_out:',real_gmr_out[j,1])\n",
        "                #fake_gen_out[i,tk] += torch.sigmoid(fake_gmr_out[j,1])\n",
        "\n",
        "                fake_gen_out[i,tk] += torch.tanh( fake_gmr_out[j,1])\n",
        "                fake_com_out[i,tk] += torch.tanh( fake_cpt_out[j,1])\n",
        "                fake_sim_out[i,tk] += f_sim_out[j] * beta\n",
        "                \n",
        "            except Exception as ex:\n",
        "                print(j,i,tk)\n",
        "                print(fake_gmr_out)\n",
        "                raise ex\n",
        "\n",
        "        return fake_gen_out, fake_com_out, fake_sim_out #, D_z_loss, D_x_loss\n",
        "\n",
        "\n",
        "    def __train(self, epochs=10,batch_size=10,init_bias = 1.0,learning_rate=2e-4, display = False):\n",
        "        # In the Deepmind paper they use RMSProp however then Adam optimizer\n",
        "        # improves training time\n",
        "        #generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "        # This method returns a helper function to compute cross entropy loss\n",
        "        #cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "        # Set the seed value all over the place to make this reproducible.\n",
        "        seed_val = 10\n",
        "\n",
        "        random.seed(seed_val)\n",
        "        np.random.seed(seed_val)\n",
        "        torch.manual_seed(seed_val)\n",
        "        torch.cuda.manual_seed_all(seed_val)\n",
        "        \n",
        "        criterion = nn.BCELoss()\n",
        "        #D_opt = torch.optim.Adam(D.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "        G_opt = torch.optim.Adam(self.generator.parameters(), lr=learning_rate)\n",
        "        D1_opt = AdamW(self.g_discriminator.discriminator.parameters(),\n",
        "                        lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                        eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                        )\n",
        "\n",
        "        \n",
        "        gen_length = len(self.source.story_peaks) + int(len(self.source.story_peaks)*self.frame_expansion_ratio)\n",
        "        pb = ProgressBar(epochs,prefix='Train...')\n",
        "        gen_gmr_loss_history = []\n",
        "        gen_com_loss_history = []\n",
        "        gen_sim_loss_history = []\n",
        "        dis_loss_history = []    \n",
        "\n",
        "        #model 들은 cuda로 보낸다.\n",
        "        self.g_discriminator.discriminator.to(device)\n",
        "        self.g_discriminator.discriminator.eval() # 학습하지 않는다...\n",
        "        self.c_discriminator.discriminator.to(device)\n",
        "        self.c_discriminator.discriminator.eval() # 학습하지 않는다...\n",
        "\n",
        "        self.generator.to(device)       \n",
        "        self.generator.train()\n",
        "\n",
        "        self.bias_w = init_bias\n",
        "        initial_bias = 0\n",
        "        G_s_loss = torch.tensor(0)\n",
        "        G_c_loss = torch.tensor(0)\n",
        "        G_g_loss = torch.tensor(0)\n",
        "\n",
        "        beta = 1\n",
        "\n",
        "        #dfs = torch.Tensor([1.0,1.0,1.0]).to(device)\n",
        "        dfs = [1.0,1.0,1.0]\n",
        "\n",
        "        adf = nn.Linear(3,1)\n",
        "\n",
        "        for i in range(epochs):\n",
        "            '''\n",
        "            noise = torch.randn(batch_size,self.source.org_source_length).to(device)\n",
        "            bias = torch.zeros_like(noise).to(device)\n",
        "            bias[:,self.source.story_peaks] += self.bias_w \n",
        "            with torch.no_grad():        \n",
        "                sw, sw0 = self.generator(noise,bias)\n",
        "\n",
        "            self.g_discriminator.discriminator.train()          #discriminator는 evaluation 모드로 전환\n",
        "            fake_gmr_out, fake_sim_out, D_z_loss, D_x_loss = self.__discrete_gradient(sw,gen_length)\n",
        "            \n",
        "            D_loss = D_x_loss + D_z_loss      \n",
        "\n",
        "            self.g_discriminator.discriminator.zero_grad()\n",
        "            D_loss.backward()\n",
        "            D1_opt.step()\n",
        "            self.g_discriminator.discriminator.eval()\n",
        "            '''\n",
        "            if True:\n",
        "                noise = torch.randn(batch_size,self.source.org_source_length).to(device)\n",
        "                bias = torch.zeros_like(noise).to(device)\n",
        "                bias[:,self.source.story_peaks] += self.bias_w\n",
        "\n",
        "                sw, sw0 = self.generator(noise,bias)\n",
        "\n",
        "                with torch.no_grad():                \n",
        "                    #fake_gmr_out, fake_com_out, fake_sim_out, D_z_loss, D_x_loss = self.__discrete_gradient(sw,gen_length,beta)\n",
        "                    fake_gmr_out, fake_com_out, fake_sim_out = self.__discrete_gradient(sw,gen_length,beta)\n",
        "                    #print(D_z_loss)\n",
        "                '''\n",
        "                if int(i/10)%2 == 0:  # grammar와 similarity를 각각 한번씩 교대로 학습한다?\n",
        "                    sw1 = sw * fake_sim_out\n",
        "                    G_s_loss = -torch.mean(sw1)\n",
        "                    G_loss = G_s_loss    \n",
        "                else: #if i%2 == 1:\n",
        "                    sw1 = sw * fake_gmr_out\n",
        "                    G_g_loss = -torch.mean(sw1)\n",
        "                    G_loss = G_g_loss\n",
        "                '''\n",
        "                sw1 = sw * fake_sim_out\n",
        "                G_s_loss = -torch.mean(sw1)\n",
        "                sw2 = sw * fake_gmr_out\n",
        "                G_g_loss = -torch.mean(sw2)\n",
        "                sw3 = sw * fake_com_out\n",
        "                G_c_loss = -torch.mean(sw3)\n",
        "\n",
        "                dsc_loss = torch.stack([G_g_loss,G_c_loss,G_s_loss])\n",
        "                #dfs[1] = 1.0\n",
        "                tdfs = torch.Tensor(dfs).to(device)\n",
        "\n",
        "                #G_loss = adf(dsc_loss) / torch.std(dsc_loss) # torch.dot(tdfs,dsc_loss)\n",
        "                G_loss = torch.dot(tdfs,dsc_loss)\n",
        "                #print(dsc_loss)\n",
        "                #print(G_loss)\n",
        "                \n",
        "                #G_loss =  G_g_loss*1.9 + G_c_loss + G_s_loss*1.2\n",
        "\n",
        "                Gs = dsc_loss.cpu().detach().numpy()\n",
        "                total_loss = np.dot(dfs,Gs)\n",
        "\n",
        "                self.generator.zero_grad()\n",
        "                G_loss.backward()\n",
        "                #print('backward:')\n",
        "                G_opt.step()\n",
        "                #self.generator.eval()\n",
        "\n",
        "                ########################################\n",
        "                \n",
        "                #dsc_loss = dsc_loss.detach().numpy()\n",
        "                #objective = total_loss * np.var(Gs)\n",
        "                #print('objective', objective)\n",
        "                d_objective = np.mean(Gs) - Gs \n",
        "                #print(d_objective)\n",
        "                dfs = dfs - d_objective\n",
        "                dfs = [0.01 if i<0.0 else i for i in dfs]\n",
        "                print('update dfs', dfs, np.std(Gs))\n",
        "                \n",
        "                ########################################\n",
        "\n",
        "            #print('step:')\n",
        "            gen_gmr_loss_history.append(G_g_loss.cpu().detach().numpy())\n",
        "            gen_com_loss_history.append(G_c_loss.cpu().detach().numpy())\n",
        "            gen_sim_loss_history.append(G_s_loss.cpu().detach().numpy())\n",
        "            #dis_loss_history.append(D_loss.cpu().detach().numpy())\n",
        "\n",
        "            beta = self.m(-(G_g_loss-G_s_loss)*10) * 4\n",
        "\n",
        "            if math.isnan(beta) or beta > 5:\n",
        "                beta = 1\n",
        "\n",
        "            beta = 1\n",
        "            pb.printProgress(+1,f'{i+1}/{epochs} epochs, beta:{beta} Generator / grammar loss:{G_g_loss}  completion loss:{G_c_loss}   similarity loss:{G_s_loss}') #,   Discriminator grammar_loss:{D_loss}        ')\n",
        "            \n",
        "            \n",
        "        self.generator.eval()\n",
        "        #self.g_discriminator.discriminator.eval()\n",
        "        if display:\n",
        "            plt.figure(figsize=(12, 6))\n",
        "            plt.plot(sw0[0].cpu().detach().numpy(),label='before activation weights')\n",
        "            plt.plot(sw[0].cpu().detach().numpy(),label='after activation weights')\n",
        "            plt.plot(bias[0].cpu().detach().numpy(),label='bias weights')\n",
        "            plt.legend()        \n",
        "            plt.show()\n",
        "\n",
        "        return  {'gen_g_loss':gen_gmr_loss_history,'gen_c_loss':gen_com_loss_history,'gen_s_loss':gen_sim_loss_history} #,'dis_loss':dis_loss_history }\n",
        "\n",
        "    def get_summary(self, count):\n",
        "        texts = []\n",
        "        self.generator.cpu()\n",
        "        self.generator.eval()\n",
        "        gen_length = len(self.source.story_peaks) + int(len(self.source.story_peaks)*self.frame_expansion_ratio)\n",
        "        noise = torch.randn(count,self.source.org_source_length)\n",
        "        bias = torch.zeros_like(noise)\n",
        "        #bias = torch.randn(1,self.source.org_source_length)\n",
        "        bias[:,self.source.story_peaks] += self.bias_w #self.last_bias_max.cpu().detach().numpy()\n",
        "        #bias = 0\n",
        "        with torch.no_grad():\n",
        "            sw,sw0 = self.generator(noise,bias)\n",
        "            #sw,sw0 = self.generator(noise)\n",
        "\n",
        "        for noise in sw:\n",
        "            gtext = self.__text_gen2(noise,gen_length)\n",
        "            text = ' '.join([w for (w,k) in gtext])\n",
        "            #print(text)\n",
        "            texts.append(text)\n",
        "        return texts"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCdfO9iuLH6D"
      },
      "source": [
        "#5. Experiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_eAwIPLb4aj"
      },
      "source": [
        "## 비교 대상 요약 알고리즘 준비"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7Ty6_5gb_zR",
        "trusted": true
      },
      "source": [
        "\n",
        "def similarity(query_text, org_text):\n",
        "    sentences = nltk.sent_tokenize(org_text)\n",
        "    #print(\"Num sentences:\", len(sentences))\n",
        "    querys = nltk.sent_tokenize(query_text)\n",
        "    #print(\"Num querys:\", len(querys))\n",
        "\n",
        "    #Compute the sentence embeddings\n",
        "    org_embeddings = s_discriminator._embedder.encode(sentences,show_progress_bar=False)\n",
        "    query_embeddings = s_discriminator._embedder.encode(querys,show_progress_bar=False)\n",
        "\n",
        "    #Compute the pair-wise cosine similarities\n",
        "    cos_scores = scipy.spatial.distance.cdist(query_embeddings, org_embeddings, \"cosine\")\n",
        "    similarity_score = 1.0 - np.mean(np.min(cos_scores,axis=0))\n",
        "\n",
        "    return similarity_score\n",
        "\n",
        "def grammarity(text):\n",
        "    \n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    sentences = np.asarray(nltk.sent_tokenize(text))\n",
        "    # For every sentence...\n",
        "    for sent in sentences:\n",
        "        # `encode_plus` will:\n",
        "        #   (1) Tokenize the sentence.\n",
        "        #   (2) Prepend the `[CLS]` token to the start.\n",
        "        #   (3) Append the `[SEP]` token to the end.\n",
        "        #   (4) Map tokens to their IDs.\n",
        "        #   (5) Pad or truncate the sentence to `max_length`\n",
        "        #   (6) Create attention masks for [PAD] tokens.\n",
        "        encoded_dict = g_discriminator.tokenizer.encode_plus(\n",
        "                            sent,                      # Sentence to encode.\n",
        "                            add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                            max_length = 64,           # Pad & truncate all sentences.\n",
        "                            pad_to_max_length = True,\n",
        "                            return_attention_mask = True,   # Construct attn. masks.\n",
        "                            return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                            truncation = True,\n",
        "                       )\n",
        "        # Add the encoded sentence to the list.    \n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "        # And its attention mask (simply differentiates padding from non-padding).\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "    # Convert the lists into tensors.\n",
        "    input_ids = torch.cat(input_ids, dim=0).to(device)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0).to(device)\n",
        "    g_discriminator.discriminator.to(device)\n",
        "    #if str(discriminator1.device) == 'cpu':\n",
        "    #    pass\n",
        "    #else:\n",
        "    #    input_ids = input_ids.to(device)\n",
        "    #    attention_masks = attention_masks.to(device)        \n",
        "\n",
        "    with torch.no_grad():        \n",
        "        outputs = g_discriminator.discriminator(input_ids, \n",
        "                               token_type_ids=None, \n",
        "                               attention_mask=attention_masks)\n",
        "    #return torch.sigmoid(outputs[0][:,1])\n",
        "    return torch.mean(outputs[0][:,1]).detach().cpu().numpy()\n",
        "    #return outputs"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLbWuwKXcMyk",
        "trusted": true
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def evaluate(method_name, text, g_summ, org_text_1,org_text_2,org_text_3):\n",
        "    result = {}\n",
        "    result['method'] = [method_name]\n",
        "    org_text = org_text_1 + ' ' + org_text_2 + ' ' + org_text_3\n",
        "    result['comp ratio'] = [len(text)/len(org_text)]\n",
        "    result['intro'] = [similarity(text,org_text_1)]\n",
        "    result['body'] = [similarity(text,org_text_2)]\n",
        "    result['ending'] = [similarity(text,org_text_3)]\n",
        "    result['var'] = [np.var([result['intro'][0],result['body'][0],result['ending'][0]])]\n",
        "    result['total'] = [similarity(text,org_text)]\n",
        "    result['grammar'] = [np.tanh(float(grammarity(text)))]\n",
        "    #scores = scorer.score(g_summ,text)\n",
        "    #result['R1'] = [scores['rouge1'].fmeasure]\n",
        "    #result['R2'] = [scores['rouge2'].fmeasure]\n",
        "    #result['RL'] = [scores['rougeL'].fmeasure]\n",
        "    return pd.DataFrame(result),result"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utotZ2vLcSSO",
        "trusted": true
      },
      "source": [
        "\"\"\"\n",
        "LexRank implementation\n",
        "Source: https://github.com/crabcamp/lexrank/tree/dev\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "from scipy.sparse.csgraph import connected_components\n",
        "\n",
        "def degree_centrality_scores(\n",
        "    similarity_matrix,\n",
        "    threshold=None,\n",
        "    increase_power=True,\n",
        "):\n",
        "    if not (\n",
        "        threshold is None\n",
        "        or isinstance(threshold, float)\n",
        "        and 0 <= threshold < 1\n",
        "    ):\n",
        "        raise ValueError(\n",
        "            '\\'threshold\\' should be a floating-point number '\n",
        "            'from the interval [0, 1) or None',\n",
        "        )\n",
        "\n",
        "    if threshold is None:\n",
        "        markov_matrix = create_markov_matrix(similarity_matrix)\n",
        "\n",
        "    else:\n",
        "        markov_matrix = create_markov_matrix_discrete(\n",
        "            similarity_matrix,\n",
        "            threshold,\n",
        "        )\n",
        "\n",
        "    scores = stationary_distribution(\n",
        "        markov_matrix,\n",
        "        increase_power=increase_power,\n",
        "        normalized=False,\n",
        "    )\n",
        "\n",
        "    return scores\n",
        "\n",
        "\n",
        "def _power_method(transition_matrix, increase_power=True):\n",
        "    eigenvector = np.ones(len(transition_matrix))\n",
        "\n",
        "    if len(eigenvector) == 1:\n",
        "        return eigenvector\n",
        "\n",
        "    transition = transition_matrix.transpose()\n",
        "\n",
        "    while True:\n",
        "        eigenvector_next = np.dot(transition, eigenvector)\n",
        "\n",
        "        if np.allclose(eigenvector_next, eigenvector):\n",
        "            return eigenvector_next\n",
        "\n",
        "        eigenvector = eigenvector_next\n",
        "\n",
        "        if increase_power:\n",
        "            transition = np.dot(transition, transition)\n",
        "\n",
        "\n",
        "def connected_nodes(matrix):\n",
        "    _, labels = connected_components(matrix)\n",
        "\n",
        "    groups = []\n",
        "\n",
        "    for tag in np.unique(labels):\n",
        "        group = np.where(labels == tag)[0]\n",
        "        groups.append(group)\n",
        "\n",
        "    return groups\n",
        "\n",
        "\n",
        "def create_markov_matrix(weights_matrix):\n",
        "    n_1, n_2 = weights_matrix.shape\n",
        "    if n_1 != n_2:\n",
        "        raise ValueError('\\'weights_matrix\\' should be square')\n",
        "\n",
        "    row_sum = weights_matrix.sum(axis=1, keepdims=True)\n",
        "\n",
        "    return weights_matrix / row_sum\n",
        "\n",
        "\n",
        "def create_markov_matrix_discrete(weights_matrix, threshold):\n",
        "    discrete_weights_matrix = np.zeros(weights_matrix.shape)\n",
        "    ixs = np.where(weights_matrix >= threshold)\n",
        "    discrete_weights_matrix[ixs] = 1\n",
        "\n",
        "    return create_markov_matrix(discrete_weights_matrix)\n",
        "\n",
        "\n",
        "def graph_nodes_clusters(transition_matrix, increase_power=True):\n",
        "    clusters = connected_nodes(transition_matrix)\n",
        "    clusters.sort(key=len, reverse=True)\n",
        "\n",
        "    centroid_scores = []\n",
        "\n",
        "    for group in clusters:\n",
        "        t_matrix = transition_matrix[np.ix_(group, group)]\n",
        "        eigenvector = _power_method(t_matrix, increase_power=increase_power)\n",
        "        centroid_scores.append(eigenvector / len(group))\n",
        "\n",
        "    return clusters, centroid_scores\n",
        "\n",
        "\n",
        "def stationary_distribution(\n",
        "    transition_matrix,\n",
        "    increase_power=True,\n",
        "    normalized=True,\n",
        "):\n",
        "    n_1, n_2 = transition_matrix.shape\n",
        "    if n_1 != n_2:\n",
        "        raise ValueError('\\'transition_matrix\\' should be square')\n",
        "\n",
        "    distribution = np.zeros(n_1)\n",
        "\n",
        "    grouped_indices = connected_nodes(transition_matrix)\n",
        "\n",
        "    for group in grouped_indices:\n",
        "        t_matrix = transition_matrix[np.ix_(group, group)]\n",
        "        eigenvector = _power_method(t_matrix, increase_power=increase_power)\n",
        "        distribution[group] = eigenvector\n",
        "\n",
        "    if normalized:\n",
        "        distribution /= n_1\n",
        "\n",
        "    return distribution"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M25NP9gOeX15"
      },
      "source": [
        "\n",
        "* Hands-on Guide To Extractive Text Summarization With BERTSum<br>\n",
        "https://analyticsindiamag.com/hands-on-guide-to-extractive-text-summarization-with-bertsum/ <br>\n",
        "https://pypi.org/project/bert-extractive-summarizer/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9oEW5wyeI9C",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3f62f9e-02bb-4b76-8722-f8b3f984abcb"
      },
      "source": [
        "!pip install bert-extractive-summarizer"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert-extractive-summarizer\n",
            "  Downloading https://files.pythonhosted.org/packages/1a/07/fdb05f9e18b6f641499ef56737126fbd2fafe1cdc1a04ba069d5aa205901/bert_extractive_summarizer-0.7.1-py3-none-any.whl\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from bert-extractive-summarizer) (0.22.2.post1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (from bert-extractive-summarizer) (3.0.2)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (from bert-extractive-summarizer) (2.2.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->bert-extractive-summarizer) (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->bert-extractive-summarizer) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->bert-extractive-summarizer) (1.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers->bert-extractive-summarizer) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers->bert-extractive-summarizer) (20.9)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers->bert-extractive-summarizer) (4.41.1)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.7/dist-packages (from transformers->bert-extractive-summarizer) (0.1.95)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers->bert-extractive-summarizer) (0.0.45)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers->bert-extractive-summarizer) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers->bert-extractive-summarizer) (2.23.0)\n",
            "Requirement already satisfied: tokenizers==0.8.1.rc1 in /usr/local/lib/python3.7/dist-packages (from transformers->bert-extractive-summarizer) (0.8.1rc1)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (1.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (2.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (1.1.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (0.8.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (56.1.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (1.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (7.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (3.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (1.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers->bert-extractive-summarizer) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers->bert-extractive-summarizer) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers->bert-extractive-summarizer) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers->bert-extractive-summarizer) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers->bert-extractive-summarizer) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers->bert-extractive-summarizer) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers->bert-extractive-summarizer) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->bert-extractive-summarizer) (3.10.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->bert-extractive-summarizer) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->bert-extractive-summarizer) (3.4.1)\n",
            "Installing collected packages: bert-extractive-summarizer\n",
            "Successfully installed bert-extractive-summarizer-0.7.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJb2hLPRPp7Q",
        "trusted": true
      },
      "source": [
        "def bert_lexrank_sum(g_summ,org_text,n_top=4):\n",
        "    input_text = org_text[0] + org_text[1] + org_text[2]\n",
        "    #Split the document into sentences\n",
        "    sentences = nltk.sent_tokenize(input_text)\n",
        "    #print(\"Num sentences:\", len(sentences))\n",
        "\n",
        "    #Compute the sentence embeddings\n",
        "    embeddings = s_discriminator._embedder.encode(sentences,show_progress_bar=False)\n",
        "\n",
        "    #Compute the pair-wise cosine similarities\n",
        "    cos_scores = scipy.spatial.distance.cdist(embeddings, embeddings, \"cosine\")\n",
        "    #util.pytorch_cos_sim(embeddings, embeddings).numpy()\n",
        "    #print(cos_scores)\n",
        "    #Compute the centrality for each sentence\n",
        "    centrality_scores = degree_centrality_scores(cos_scores, threshold=None)\n",
        "\n",
        "    #We argsort so that the first element is the sentence with the highest score\n",
        "    most_central_sentence_indices = np.argsort(-centrality_scores)\n",
        "\n",
        "    #Print the 5 sentences with the highest scores\n",
        "    summary_text = \"\"\n",
        "    for idx in most_central_sentence_indices[0:n_top]:\n",
        "        summary_text += sentences[idx].strip()\n",
        "    print('bert_lexrank summary:')\n",
        "    print(summary_text)\n",
        "    print('-'*50)\n",
        "    df,arr = evaluate('BERT+LexRank',summary_text,g_summ,org_text[0],org_text[1],org_text[2])\n",
        "    return df,arr\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcDVXR4XQZAh",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166,
          "referenced_widgets": [
            "25ead44582c241acbd1a9502397b8736",
            "5ef9a258752a47b48146cb8443ffa1f3",
            "6ebcfca00e49445ab51c4a5e5ec1da83",
            "001d1f2dddae41439aeebc20405e8312",
            "eb02ac776515420b9e438a6125f003b2",
            "8afae9ce4bf54c5da09ce901d399ce3f",
            "f4d145d34da9453c88612a5fbaba69e9",
            "1de6a59841e34bf1b09ef483a59058c3",
            "bc2f182353ec4978a6beb5893cd39fd0",
            "41d7d8fe4f4042e99f50de423cae8131",
            "583f2cfcf03249ec828aa694851aec04",
            "7d4749c45f5f423faee514a9093b81bd",
            "58d99cb692e445028a99d24632d6b29b",
            "b8b038fc2a90492f9ce96316dd74ed3c",
            "b6c682697fc84faf8cd0684082c88555",
            "e47eafe8cde9408e83a9f3919f3937da",
            "76c8939624a34cfb9146cf81b1b17795",
            "feb424f8c61d431c98ce520f5addfbf8",
            "f71d5222c3e74e2392936a96dcaaeee1",
            "a595a754f7c347d99160017ecc9e2572",
            "6654be75073c4ea9911de4ad6d70ccbc",
            "4958b56c9fd54b3aaa0fa199a1354075",
            "86dea1912dae4fef84d00052b95cfb4c",
            "6018d03cff93466dbbe149c78fd0d36d"
          ]
        },
        "outputId": "16c93ce4-fea1-49cc-e9ca-04afd6a04c8c"
      },
      "source": [
        "\n",
        "from summarizer import Summarizer\n",
        "\n",
        "\n",
        "model1 = Summarizer()\n",
        "\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "25ead44582c241acbd1a9502397b8736",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=434.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bc2f182353ec4978a6beb5893cd39fd0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1344997306.0, style=ProgressStyle(descr…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "76c8939624a34cfb9146cf81b1b17795",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wqR1PeSIR4V"
      },
      "source": [
        "\n",
        "def besm(g_summ,org_text):\n",
        "    result = model1(org_text[0] + org_text[1] + org_text[2], num_sentences=2)\n",
        "    summary_text = \"\".join(result)\n",
        "    print('besm summary:')\n",
        "    print(summary_text)\n",
        "    print('-'*50)    \n",
        "    df,arr = evaluate('BESM',summary_text,g_summ,org_text[0],org_text[1],org_text[2])\n",
        "    return df,arr"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "T24x_-DPi1gV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571,
          "referenced_widgets": [
            "0c096a94117440ec9d77c7fa07b70d6d",
            "6cf2916a1b284be89a2ab7616ee7a282",
            "45b7dac6f4af4259a7bf7bb6727cde5a",
            "115d1b24e89d4f39a8f6dad6129d5833",
            "9e8d0affa78d4a3bbfacb1f789dac656",
            "649e0a37febc4d4091b83882fdfa1125",
            "2fb2d927972a46f68eed0565749811dd",
            "182a7ff8449b41bcb73d241ea0c6e536",
            "2fcf21886dd647c4b7f49647a05978bf",
            "3935bc2ac31d411c805e321b4d61bbf5",
            "b83dbb10c4114ee9927004c55206c42f",
            "5d79156e85144b1a926aa23fd0f42bf9",
            "6002d26eb695400188d466851387dc7c",
            "1b0b736fa37242fab72ec38ead791bc0",
            "20e4491775a84bc5ae5a0227a0f6a399",
            "0dfa95f66ed4441eb3f5eea0609f9a6a",
            "4851fbcdf28a4fb2bfdced5f7fc7514f",
            "c213dc20112940ddbf5d17b98fdb32fd",
            "63660c7841ae4189b3eb452d2d699e61",
            "3d0e342eea43436d92d650d78b206fdb",
            "277adbf09e00412d9240264517028a15",
            "4d2861b3ebc5468bbe1c390e321dccc8",
            "ff9e58a7aa9d43149246d7b6c436d6f5",
            "177a64b3065d4e928659af7a7ca15795",
            "6251a4d1e55249da8c05b38734df6108",
            "34108b0ebb1b47209edcfc5a845817a4",
            "e0a4ad157bdb406bacef3fe5310e151a",
            "b7704096d73c4a5fa2cc9827525ae7bd",
            "a8efb5f6e790408ca83f4d24b0f228e2",
            "af8e26d50f8a45b5a54d9964434ced43",
            "1bcff3d64cb243c792fe23114928f6c6",
            "588f34d9e4f74266b767b8e93455b14e"
          ]
        },
        "outputId": "c3437a76-31ec-4d57-9585-114e8422fed5"
      },
      "source": [
        "from transformers import AutoConfig,AutoTokenizer,AutoModel\n",
        "\n",
        "SQUAD_MODEL = \"monologg/kobert\"\n",
        "\n",
        "#SQUAD_MODEL = \"bert-large-uncased\"\n",
        "# Load model, model config and tokenizer via Transformers\n",
        "custom_config = AutoConfig.from_pretrained(SQUAD_MODEL)\n",
        "custom_config.output_hidden_states=True\n",
        "custom_tokenizer = AutoTokenizer.from_pretrained(SQUAD_MODEL)\n",
        "custom_model = AutoModel.from_pretrained(SQUAD_MODEL, config=custom_config)\n",
        "\n",
        "model2 = Summarizer(custom_model=custom_model, custom_tokenizer=custom_tokenizer)\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0c096a94117440ec9d77c7fa07b70d6d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=426.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2fcf21886dd647c4b7f49647a05978bf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=77779.0, style=ProgressStyle(descriptio…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4851fbcdf28a4fb2bfdced5f7fc7514f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=51.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6251a4d1e55249da8c05b38734df6108",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=368792146.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-8b08b00183ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mcustom_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mcustom_tokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSQUAD_MODEL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mcustom_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSQUAD_MODEL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmodel2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSummarizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_tokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_tokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mconfig_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_class\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mMODEL_MAPPING\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m         raise ValueError(\n\u001b[1;32m    504\u001b[0m             \u001b[0;34m\"Unrecognized configuration class {} for this kind of AutoModel: {}.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    650\u001b[0m                     \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m                     \u001b[0mresume_download\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_download\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m                     \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_files_only\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    653\u001b[0m                 )\n\u001b[1;32m    654\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mresolved_archive_file\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, local_files_only)\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0mresume_download\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_download\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m             \u001b[0muser_agent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muser_agent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m             \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_files_only\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         )\n\u001b[1;32m    573\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_or_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36mget_from_cache\u001b[0;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, local_files_only)\u001b[0m\n\u001b[1;32m    748\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s not found in cache or force_download set to True, downloading to %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m             \u001b[0mhttp_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_agent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muser_agent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storing %s in cache at %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36mhttp_get\u001b[0;34m(url, temp_file, proxies, resume_size, user_agent)\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetEffectiveLevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNOTSET\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m     )\n\u001b[0;32m--> 643\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# filter out keep-alive new chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m             \u001b[0mprogress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'stream'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_fp_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m                 \u001b[0mcache_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Platform-specific: Buggy versions of Python.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m                     \u001b[0;31m# Close the connection when no data is returned\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    459\u001b[0m             \u001b[0;31m# Amount is given, implement using readinto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;31m# connection, and the user is reading more bytes than will be provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m             \u001b[0;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1069\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1071\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    927\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6xQHXrUZ9K_"
      },
      "source": [
        "def besm_bert(g_summ,org_text):\n",
        "    result = model2(org_text[0].lower() + org_text[1].lower() + org_text[2].lower(), num_sentences=2)\n",
        "    summary_text = \"\".join(result)\n",
        "    print('besm_bert summary:')\n",
        "    print(summary_text)\n",
        "    print('-'*50)      \n",
        "    df,arr = evaluate('BESM+kobert',summary_text,g_summ,org_text[0],org_text[1],org_text[2])\n",
        "    return df,arr"
      ],
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "0S301yeelEvG"
      },
      "source": [
        "org_text_1 = \"\"\"\n",
        "옛날 어느 집에 귀여운 여자 아기가 태어났어요.\n",
        "아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요.\n",
        "그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요.\n",
        "소녀의 아버지는 홀로 남은 소녀가 걱정되었어요.\n",
        "그래서 얼마 후 새어머니를 맞이했어요.\n",
        "새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요.\n",
        "그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요.\n",
        "새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요.\n",
        "그런데 이번에는 아버지마저 돌아가셨어요.\n",
        "소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요.\n",
        "해도 해도 끝이 없는 집안일이 힘들어 지칠때면\n",
        "난롯가에 앉아서 잠시 쉬곤 했지요.\n",
        "\"\"\"\n",
        "\n",
        "org_text_2 = \"\"\"\n",
        "어느 날, 왕궁에서 무도회가 열렸어요.\n",
        "신데렐라의 집에도 초대장이 왔어요.\n",
        "새어머니는 언니들을 데리고 무도회장으로 떠났어요.\n",
        "신데렐라도 무도회에 가고 싶었어요.\n",
        "혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요.\n",
        "신데렐라, 너도 무도회에 가고 싶니?\n",
        "신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요.\n",
        "내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴.\n",
        "마법사 할머니가 주문을 외웠어요.\n",
        "그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요.\n",
        "이번에는 생쥐와 도마뱀을 건드렸어요.\n",
        "그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다.\n",
        "신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요.\n",
        "신데렐라, 발을 내밀어 보거라.\n",
        "할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요.\n",
        "신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지?\n",
        "왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요.\n",
        "왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요.\n",
        "신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요.\n",
        "땡, 땡, 땡...... 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요.\n",
        "신데렐라가 허둥지둥 왕궁을 빠져나가는데,\n",
        "유리 구두 한 짝이 벗겨졌어요.\n",
        "하지만 구두를 주울 틈이 없었어요.\n",
        "신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요.\n",
        "왕자님은 유리 구두를 가지고 임금님께 가서 말했어요.\n",
        "이 유리 구두의 주인과 결혼하겠어요.\n",
        "\"\"\"\n",
        "\n",
        "org_text_3 = \"\"\"\n",
        "그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요.\n",
        "언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요.\n",
        "그때, 신데렐라가 조용히 다가와 말했어요.\n",
        "저도 한번 신어 볼 수 있나요?\n",
        "신데렐라는 신하게 건넨 유리 구두를 신었어요,\n",
        "유리 구두는 신데렐라의 발에 꼭 맞았어요.\n",
        "신하들은 신데렐라를 왕궁으로 데리고 갔어요.\n",
        "그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
        "\"\"\""
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "tRZIwu73lEvH"
      },
      "source": [
        "# 기,승,전,결  모두 비슷한 내용이 반복되니... 지협성의 문제가 나타나지 않는다.\n",
        "ko_sentences_dataset2 = []\n",
        "\n",
        "if True:\n",
        "    urls = ['https://raw.githubusercontent.com/dolmani38/Summary/master/data/%EC%95%A0%EA%B1%B0%EC%84%9C%ED%81%AC%EB%A6%AC%EC%8A%A4%ED%8B%B0-ABC%20%EC%82%B4%EC%9D%B8%EC%82%AC%EA%B1%B4.txt',\n",
        "            'https://raw.githubusercontent.com/dolmani38/Summary/master/data/%EC%95%A0%EA%B1%B0%EC%84%9C%ED%81%AC%EB%A6%AC%EC%8A%A4%ED%8B%B0-%EA%B7%B8%EB%A6%AC%EA%B3%A0%20%EC%95%84%EB%AC%B4%EB%8F%84%20%EC%97%86%EC%97%88%EB%8B%A4.txt',\n",
        "            'https://raw.githubusercontent.com/dolmani38/Summary/master/data/%EC%95%A0%EA%B1%B0%EC%84%9C%ED%81%AC%EB%A6%AC%EC%8A%A4%ED%8B%B0-%EB%82%98%EC%9D%BC%EA%B0%95%EC%9D%98%20%EC%A3%BD%EC%9D%8C.txt',\n",
        "            'https://raw.githubusercontent.com/dolmani38/Summary/master/data/%EC%95%A0%EA%B1%B0%EC%84%9C%ED%81%AC%EB%A6%AC%EC%8A%A4%ED%8B%B0-%EB%A7%8C%EC%B0%AC%ED%9A%8C%EC%9D%98%2013%EC%9D%B8.txt',\n",
        "            'https://raw.githubusercontent.com/dolmani38/Summary/master/data/%EC%95%A0%EA%B1%B0%EC%84%9C%ED%81%AC%EB%A6%AC%EC%8A%A4%ED%8B%B0-%EB%A9%94%EC%86%8C%ED%8F%AC%ED%83%80%EB%AF%B8%EC%95%84%EC%9D%98%20%EC%A3%BD%EC%9D%8C.txt',\n",
        "            'https://raw.githubusercontent.com/dolmani38/Summary/master/data/%EC%95%A0%EA%B1%B0%EC%84%9C%ED%81%AC%EB%A6%AC%EC%8A%A4%ED%8B%B0-%EB%AA%A9%EC%82%AC%EA%B4%80%EC%82%B4%EC%9D%B8.txt',\n",
        "            'https://raw.githubusercontent.com/dolmani38/Summary/master/data/%EC%95%A0%EA%B1%B0%EC%84%9C%ED%81%AC%EB%A6%AC%EC%8A%A4%ED%8B%B0-%EB%B2%99%EC%96%B4%EB%A6%AC%20%EB%AA%A9%EA%B2%A9%EC%9E%90.txt',\n",
        "            'https://raw.githubusercontent.com/dolmani38/Summary/master/data/%EC%95%A0%EA%B1%B0%EC%84%9C%ED%81%AC%EB%A6%AC%EC%8A%A4%ED%8B%B0-%EB%B9%84%EB%B0%80%20%EC%84%9C%EB%A5%98%EB%A5%BC%20%EB%85%B8%EB%A0%A4%EB%9D%BC.txt',\n",
        "            'https://raw.githubusercontent.com/dolmani38/Summary/master/data/%EC%95%A0%EA%B1%B0%EC%84%9C%ED%81%AC%EB%A6%AC%EC%8A%A4%ED%8B%B0-%EC%8A%A4%ED%8E%98%EC%9D%B8%EA%B6%A4%EC%A7%9D%EC%9D%98%20%EB%B9%84%EB%B0%80.txt',\n",
        "            'https://raw.githubusercontent.com/dolmani38/Summary/master/data/%EC%95%A0%EA%B1%B0%EC%84%9C%ED%81%AC%EB%A6%AC%EC%8A%A4%ED%8B%B0-%EC%95%84%ED%8C%8C%ED%8A%B8%EC%97%90%20%EB%82%98%ED%83%80%EB%82%9C%20%EC%9A%94%EC%A0%95.txt',\n",
        "            'https://raw.githubusercontent.com/dolmani38/Summary/master/data/%EC%95%A0%EA%B1%B0%EC%84%9C%ED%81%AC%EB%A6%AC%EC%8A%A4%ED%8B%B0-%EC%95%A0%ED%81%AC%EB%A1%9C%EC%9D%B4%EB%93%9C%20%EC%82%B4%EC%9D%B8%20%EC%82%AC%EA%B1%B4.txt',\n",
        "            'https://raw.githubusercontent.com/dolmani38/Summary/master/data/%EC%95%A0%EA%B1%B0%EC%84%9C%ED%81%AC%EB%A6%AC%EC%8A%A4%ED%8B%B0-%EC%98%88%EA%B3%A0%20%EC%82%B4%EC%9D%B8.txt',\n",
        "            'https://raw.githubusercontent.com/dolmani38/Summary/master/data/%EC%95%A0%EA%B1%B0%EC%84%9C%ED%81%AC%EB%A6%AC%EC%8A%A4%ED%8B%B0-%EC%A5%90%EB%8D%AB.txt',\n",
        "            'https://raw.githubusercontent.com/dolmani38/Summary/master/data/%EC%95%A0%EA%B1%B0%EC%84%9C%ED%81%AC%EB%A6%AC%EC%8A%A4%ED%8B%B0-%EC%BB%A4%ED%8A%BC.txt',\n",
        "            'https://raw.githubusercontent.com/dolmani38/Summary/master/data/%EC%95%A0%EA%B1%B0%EC%84%9C%ED%81%AC%EB%A6%AC%EC%8A%A4%ED%8B%B0-%ED%81%AC%EB%A6%AC%EC%8A%A4%EB%A7%88%EC%8A%A4%20%ED%91%B8%EB%94%A9%EC%9D%98%20%EB%AA%A8%ED%97%98.txt',\n",
        "            'https://raw.githubusercontent.com/dolmani38/Summary/master/data/%EC%95%A0%EA%B1%B0%EC%84%9C%ED%81%AC%EB%A6%AC%EC%8A%A4%ED%8B%B0-%ED%91%B8%EB%A5%B8%EC%97%B4%EC%B0%A8%EC%9D%98%EC%A3%BD%EC%9D%8C.txt',\n",
        "            'https://raw.githubusercontent.com/dolmani38/Summary/master/data/%EC%95%A0%EA%B1%B0%EC%84%9C%ED%81%AC%EB%A6%AC%EC%8A%A4%ED%8B%B0-%ED%99%94%EC%9A%94%EC%9D%BC%20%ED%81%B4%EB%9F%BD%EC%9D%98%20%EC%82%B4%EC%9D%B8.txt']\n",
        "\n",
        "    \n",
        "    for url in urls:\n",
        "        raw_text = urllib.request.urlopen(url).read().decode('utf-8')\n",
        "        ko_sentences_dataset2 += nltk.sent_tokenize(clean_text(raw_text))\n",
        "    #random.shuffle(ko_sentences_dataset2)\n",
        "else:\n",
        "    # 각 문장이 유사하지 않도록 구성한다. --> 그래야 지협성의 문제 대두??\n",
        "    df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/summary/korean_sentences.csv')\n",
        "    ko_sentences_dataset2 += list(df['sentence'])\n",
        "    random.shuffle(ko_sentences_dataset2)\n",
        "    \n",
        "len(ko_sentences_dataset2)    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3run5EVvMSiB",
        "trusted": true
      },
      "source": [
        "document = []\n",
        "offset = 0\n",
        "#document += [[org_text_1,org_text_2,org_text_3]]\n",
        "while (offset < len(ko_sentences_dataset2)):\n",
        "    intro_cnt = 2*2 #random.choice([5,8,10,13])\n",
        "    body_cnt = 5*2 #random.choice([10,15,18,20,25])\n",
        "    conclu_cnt = 3*2 #random.choice([5,8,10,13])\n",
        "    intro = ' '.join(ko_sentences_dataset2[offset:offset+intro_cnt])\n",
        "    body = ' '.join(ko_sentences_dataset2[offset+intro_cnt:offset+intro_cnt+body_cnt])\n",
        "    conclu = ' '.join(ko_sentences_dataset2[offset+intro_cnt+body_cnt:offset+intro_cnt+body_cnt+conclu_cnt])\n",
        "    offset = offset+intro_cnt+body_cnt+conclu_cnt\n",
        "    document.append([intro,body,conclu])\n",
        "\n",
        "print(len(document))\n",
        "\n",
        "document[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "rcvSSH_Ri1gZ"
      },
      "source": [
        "def sam_wgan(g_summ,org_text,init_bias=0.0, display = False):\n",
        "    source = Source(org_text[0] + org_text[1] + org_text[2])\n",
        "    comp_rate=0.05\n",
        "    if init_bias > 0:\n",
        "        source.analysis_frame_terms(s_discriminator,comp_rate=comp_rate,except_key=True,display=display)\n",
        "    else:\n",
        "        #source.extract_keywords(s_discriminator,key_model, comp_rate=0.1)\n",
        "        source.set_key_rate(s_discriminator,comp_rate=comp_rate)\n",
        "    summarizer = SAM_Summarizer(g_discriminator,c_discriminator,s_discriminator)\n",
        "    summarizer.ready(source)\n",
        "    summarizer.summarize(epochs=200,batch_size=1,frame_expansion_ratio = 2.0, init_bias=init_bias,learning_rate=5e-5,display=display)\n",
        "    summary_text = summarizer.get_summary(3)[0]\n",
        "    print('-'*50)\n",
        "    print('gold summary:')\n",
        "    print(g_summ)    \n",
        "    print('-'*50)\n",
        "    print('sam_wgan summary:')\n",
        "    print(summary_text)\n",
        "    print('-'*50)\n",
        "    df,arr = evaluate('SAM+WGAN',summary_text,g_summ,org_text[0],org_text[1],org_text[2])\n",
        "    return df,arr"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCxKl8YVgF6F"
      },
      "source": [
        "Test용 Data 준비"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "r9HG9E8blEvJ"
      },
      "source": [
        "def seeding(seed):\n",
        "\n",
        "    SEED = seed\n",
        "\n",
        "    random.seed(SEED)\n",
        "    np.random.seed(SEED)\n",
        "    torch.manual_seed(SEED)\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "    torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDK19hrh-TeV"
      },
      "source": [
        "## 신데렐라 Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5UtTRX0j3qUO",
        "outputId": "fe6d08ab-257c-4a5a-9468-a0ef7d6c0b89"
      },
      "source": [
        "df1,_ = sam_wgan('',[org_text_1,org_text_2,org_text_3],init_bias=0.0,display= True)\n",
        "print(df1)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "update dfs [1.0004015692975372, 1.0015298567013815, 0.998068573884666] 0.0014413104\n",
            "update dfs [1.0028072390705347, 1.0016034642467275, 0.9955892965663224] 0.0019949505\n",
            "update dfs [1.0040000457083806, 1.0032109576277435, 0.9927889967802912] 0.001987335\n",
            "update dfs [1.005956408684142, 1.0022980837966315, 0.9917455075774342] 0.0013843849\n",
            "update dfs [1.0062294279923663, 1.002952388371341, 0.9908181835198775] 0.00067393965\n",
            "update dfs [1.0058238292112947, 1.0030729785794392, 0.9911031925585121] 0.00029455192\n",
            "update dfs [1.00809689424932, 1.002578231098596, 0.9893248750595376] 0.0016905633\n",
            "update dfs [1.0103044961579144, 1.0011118237744085, 0.9885836804751307] 0.0015888388\n",
            "update dfs [1.01026695757173, 1.001472650503274, 0.9882603922160342] 0.0002805473\n",
            "update dfs [1.0110357293160632, 1.0021140709868632, 0.9868501998716965] 0.000998511\n",
            "Train... ||...................| 5.0%   10/200 epochs, beta:1 Generator / grammar loss:4.370871465653181e-05  completion loss:-8.36425315355882e-05   similarity loss:-0.0021352553740143776update dfs [1.0141073303529993, 1.0005300840712152, 0.9853625855175778] 0.0021723062\n",
            "update dfs [1.0155728940153494, 1.0007361379975919, 0.9836909678997472] 0.00128901\n",
            "update dfs [1.0172051917761564, 0.9993828265287448, 0.983411981840618] 0.0012347309\n",
            "update dfs [1.016819714102894, 1.000494154781336, 0.9826861311448738] 0.00079801894\n",
            "update dfs [1.0207163756713271, 0.9971911922621075, 0.9820924322120845] 0.0029690634\n",
            "update dfs [1.0229680726770312, 0.9955577978689689, 0.9814741295995191] 0.001645237\n",
            "update dfs [1.0251208695117384, 0.9953927727183327, 0.9794863580027595] 0.0016944029\n",
            "update dfs [1.0261926313396543, 0.9931272574467584, 0.9806801114464179] 0.0016027353\n",
            "update dfs [1.0274580963887274, 0.9904848168371245, 0.9820570860756561] 0.0018690418\n",
            "update dfs [1.027949869632721, 0.9884109915001318, 0.9836391370045021] 0.0015324793\n",
            "Train... |||..................| 10.0%   20/200 epochs, beta:1 Generator / grammar loss:-0.004044722765684128  completion loss:-0.006610321346670389   similarity loss:-0.002954445080831647update dfs [1.0293180611915886, 0.9859131806297228, 0.9847687558503821] 0.0017689023\n",
            "update dfs [1.028013029601425, 0.9892628298839554, 0.9827241379534826] 0.002387727\n",
            "update dfs [1.0294257905334234, 0.9877751796739176, 0.9827990269986913] 0.0011852714\n",
            "update dfs [1.0283309270162135, 0.9891517303185537, 0.9825173394056037] 0.0010284237\n",
            "update dfs [1.0294102018233389, 0.9863337805727497, 0.9842560143442824] 0.0020106935\n",
            "update dfs [1.0306809900794178, 0.9833439301000908, 0.9859750760952011] 0.0021220495\n",
            "update dfs [1.0330367512069643, 0.979543264140375, 0.9874199811602011] 0.0027130807\n",
            "update dfs [1.0341320736333728, 0.9762699600541964, 0.9895979628199711] 0.0023563993\n",
            "update dfs [1.0364114153198898, 0.9722246156306937, 0.991363964159973] 0.0028681566\n",
            "update dfs [1.0379213602282107, 0.9682495320448652, 0.9938291037688032] 0.00283773\n",
            "Train... ||||.................| 15.0%   30/200 epochs, beta:1 Generator / grammar loss:-0.006176911760121584  completion loss:-0.01166194025427103   similarity loss:-0.005221717059612274update dfs [1.0394957563839853, 0.9641158228041604, 0.9963884177850559] 0.0029505007\n",
            "update dfs [1.0408365740440786, 0.960204831440933, 0.9989585891598836] 0.0028106598\n",
            "update dfs [1.0419390914030373, 0.9565026542404667, 1.0015582476044074] 0.0026882389\n",
            "update dfs [1.0435665012337267, 0.9514422897482291, 1.0049912004033104] 0.003653351\n",
            "update dfs [1.0456188595853746, 0.9456493525067344, 1.0087317797588184] 0.0041538025\n",
            "update dfs [1.0469225873239338, 0.9402801260584965, 1.012797278468497] 0.003960496\n",
            "update dfs [1.048270472791046, 0.9348239140817896, 1.0169056045124307] 0.004019344\n",
            "update dfs [1.049428805243224, 0.9286566373193637, 1.021914547891356] 0.004635607\n",
            "update dfs [1.05103960307315, 0.9220173094654456, 1.0269430788466707] 0.0048976685\n",
            "update dfs [1.0529327034018934, 0.9149289379129186, 1.032138352864422] 0.0051903664\n",
            "Train... |||||................| 20.0%   40/200 epochs, beta:1 Generator / grammar loss:-0.011824525892734528  completion loss:-0.020805997774004936   similarity loss:-0.008522352203726768update dfs [1.0554115059785545, 0.9072076618904248, 1.0373808281728998] 0.0055751265\n",
            "update dfs [1.0578813613392413, 0.8991338411578909, 1.0429847926134244] 0.005850675\n",
            "update dfs [1.0603184145875275, 0.8901159135857597, 1.0495656641433015] 0.0065972246\n",
            "update dfs [1.0628194347955287, 0.8809526195982471, 1.0562279416481033] 0.006698433\n",
            "update dfs [1.0652807331643999, 0.8721387075493112, 1.0625805543968454] 0.006431659\n",
            "update dfs [1.067256265785545, 0.8622281128773466, 1.0705156155163422] 0.0074181715\n",
            "update dfs [1.069732395466417, 0.8507966274628416, 1.0794709712499753] 0.008505067\n",
            "update dfs [1.073205394204706, 0.8398730425396934, 1.0869215592974797] 0.007892986\n",
            "update dfs [1.076482459437102, 0.8276893185684457, 1.0958282189676538] 0.0089164805\n",
            "update dfs [1.0799717637710273, 0.81409500783775, 1.1059332272270694] 0.00998485\n",
            "Train... ||||||...............| 25.0%   50/200 epochs, beta:1 Generator / grammar loss:-0.023275163024663925  completion loss:-0.0403587780892849   similarity loss:-0.016659459099173546update dfs [1.0838728598318994, 0.7992769634583965, 1.1168501699576154] 0.010862361\n",
            "update dfs [1.0877988296560943, 0.7842116268584505, 1.1279895404586568] 0.011052349\n",
            "update dfs [1.0906931064091623, 0.7701305920490995, 1.1391762947896495] 0.010516588\n",
            "update dfs [1.095144861843437, 0.7529575960943475, 1.151897537172772] 0.012603702\n",
            "update dfs [1.0993036474101245, 0.7362542921910062, 1.164442059234716] 0.0122971665\n",
            "update dfs [1.1040954473428428, 0.7169329436728731, 1.178971609682776] 0.014228887\n",
            "update dfs [1.1082691918127239, 0.6962302239844576, 1.1955005830386654] 0.015483644\n",
            "update dfs [1.1118009085766971, 0.67723246908281, 1.2109666193136945] 0.014289693\n",
            "update dfs [1.1158362547867, 0.6562184157082811, 1.227945320890285] 0.015770761\n",
            "update dfs [1.1196136395446956, 0.6351518469164148, 1.2452345049241558] 0.015884845\n",
            "Train... |||||||..............| 30.0%   60/200 epochs, beta:1 Generator / grammar loss:-0.04226258397102356  completion loss:-0.06710653752088547   similarity loss:-0.028750784695148468update dfs [1.123298096936196, 0.613444029004313, 1.2632578617194667] 0.016428085\n",
            "update dfs [1.1264737318269908, 0.5920129703590646, 1.28151328174863] 0.016356805\n",
            "update dfs [1.1300019691698253, 0.5686027618357912, 1.3013952492037788] 0.017849173\n",
            "update dfs [1.1337233777157962, 0.5439920524368063, 1.3222845575073734] 0.018760767\n",
            "update dfs [1.1374704050831497, 0.5180368038127199, 1.3444927824893966] 0.019840367\n",
            "update dfs [1.1392870279960334, 0.4950548211345449, 1.3656581422546878] 0.018068796\n",
            "update dfs [1.1421735468320549, 0.4690153362462297, 1.3888111232081428] 0.020186193\n",
            "update dfs [1.1426254729740322, 0.4465701902518049, 1.4108043467858806] 0.018144703\n",
            "update dfs [1.1450788895599544, 0.41985118633601815, 1.4350699378410354] 0.020886546\n",
            "update dfs [1.1453730235807598, 0.3956988701829687, 1.4589280976215377] 0.019601298\n",
            "Train... ||||||||.............| 35.0%   70/200 epochs, beta:1 Generator / grammar loss:-0.06235601752996445  completion loss:-0.08680246770381927   similarity loss:-0.03879199177026749update dfs [1.1459215725772083, 0.3702871525892988, 1.4837912699440494] 0.020528303\n",
            "update dfs [1.1442041392438114, 0.34792994207236916, 1.5078659212449566] 0.018994588\n",
            "update dfs [1.2007796200923622, 0.29542158043477684, 1.503798802033998] 0.044626057\n",
            "update dfs [1.2552151451818645, 0.2435640754410997, 1.5012207744875923] 0.04343222\n",
            "update dfs [1.306760701816529, 0.19411224743817002, 1.4991270458558574] 0.04125858\n",
            "update dfs [1.3031942057423294, 0.1726559834787622, 1.5241498096147552] 0.019141836\n",
            "update dfs [1.351488574873656, 0.12730266398284584, 1.5212087637046352] 0.038288027\n",
            "update dfs [1.3560129622928798, 0.1054863432655111, 1.5385006932774559] 0.016283251\n",
            "update dfs [1.3404606017284095, 0.10323188325855881, 1.5563075026730075] 0.013711807\n",
            "update dfs [1.3359565469436347, 0.09054149559233338, 1.5735019562998787] 0.012609278\n",
            "Train... |||||||||............| 40.0%   80/200 epochs, beta:1 Generator / grammar loss:-0.06637492775917053  completion loss:-0.07456126064062119   similarity loss:-0.04467641934752464update dfs [1.31171541986987, 0.09217797836754471, 1.5961065968731418] 0.01915968\n",
            "update dfs [1.2788562583737075, 0.0987889455864206, 1.6223547836998478] 0.024579102\n",
            "update dfs [1.2460720422677696, 0.10578440001700073, 1.648143537924625] 0.02441858\n",
            "update dfs [1.241012569051236, 0.11143213754985482, 1.6475552736083046] 0.0043909475\n",
            "update dfs [1.2062760177068412, 0.11975948011968285, 1.6739644823828712] 0.025647735\n",
            "update dfs [1.1704305368475616, 0.12919812893960625, 1.7003713181475177] 0.026276145\n",
            "update dfs [1.1347448858432472, 0.13855784630868584, 1.7266972555080429] 0.026166933\n",
            "update dfs [1.0953012364916503, 0.15151521808002144, 1.7531835293630138] 0.02843248\n",
            "update dfs [1.0575322317890823, 0.16288778430316597, 1.7795799715677276] 0.027401978\n",
            "update dfs [1.0186487170867622, 0.17539805418346077, 1.8059532387414947] 0.028071241\n",
            "Train... ||||||||||...........| 45.0%   90/200 epochs, beta:1 Generator / grammar loss:-0.11544457077980042  completion loss:-0.06405078619718552   similarity loss:-0.050187788903713226update dfs [0.9796227323822677, 0.1881143698701635, 1.832262915209867] 0.028148009\n",
            "update dfs [0.9386003646068275, 0.2027707943925634, 1.8586288808146492] 0.029398467\n",
            "update dfs [0.8971983450464904, 0.21785517281387, 1.8849465294042602] 0.029632663\n",
            "update dfs [0.8542492124252021, 0.2345017927000299, 1.9112490384140983] 0.030624392\n",
            "update dfs [0.8112322497181594, 0.25122704973910004, 1.9375407366314903] 0.030667283\n",
            "update dfs [0.7682275655679405, 0.267961191595532, 1.9638112677494064] 0.030657109\n",
            "update dfs [0.7246251436881721, 0.28531998640391976, 1.990054894820787] 0.0310442\n",
            "update dfs [0.6814292254857719, 0.30229411518666893, 2.016276669339277] 0.03077656\n",
            "update dfs [0.6366640138439834, 0.32088439783547074, 2.0424515983322635] 0.031804875\n",
            "update dfs [0.592990096192807, 0.33834691962692887, 2.068662994191982] 0.031087982\n",
            "Train... |||||||||||..........| 50.0%   100/200 epochs, beta:1 Generator / grammar loss:-0.12278728187084198  completion loss:-0.0616508424282074   similarity loss:-0.052901968359947205update dfs [0.5483957934193313, 0.3567608246812597, 2.0948433993617073] 0.031691942\n",
            "update dfs [0.5044100913219154, 0.37456894910428673, 2.1210209584096447] 0.0312897\n",
            "update dfs [0.45988744078204036, 0.39292276895139366, 2.147189777926542] 0.031643514\n",
            "update dfs [0.4151398721151054, 0.41151188185904175, 2.173348222509958] 0.031791847\n",
            "update dfs [0.37031714199110866, 0.4301783876726404, 2.1995044430950657] 0.031841606\n",
            "update dfs [0.32574262050911784, 0.4485957684228197, 2.225661583826877] 0.031676933\n",
            "update dfs [0.281524624209851, 0.46667090675327927, 2.251804434345104] 0.03143984\n",
            "update dfs [0.23656798480078578, 0.4854839878389612, 2.277947988943197] 0.031929698\n",
            "update dfs [0.19177479622885585, 0.5041311295935884, 2.304094017134048] 0.03182117\n",
            "update dfs [0.14677016763016582, 0.5229950012871996, 2.3302347591379657] 0.03196144\n",
            "Train... ||||||||||||.........| 55.0%   110/200 epochs, beta:1 Generator / grammar loss:-0.12477707117795944  completion loss:-0.060908570885658264   similarity loss:-0.053631700575351715update dfs [0.10167919425293803, 0.5419499824056402, 2.356370751396753] 0.032018628\n",
            "update dfs [0.0568634900264442, 0.5606279248604551, 2.3825085206190124] 0.031835493\n",
            "update dfs [0.012079480569809675, 0.5792763145873323, 2.408644132898189] 0.031814255\n",
            "update dfs [0.01, 0.5980964215705171, 2.4347806615987793] 0.031929158\n",
            "update dfs [0.01, 0.6169333705911413, 2.460916970507242] 0.031940207\n",
            "update dfs [0.01, 0.6354948045918718, 2.4870470805326477] 0.031752385\n",
            "update dfs [0.01, 0.6544111842522398, 2.513178069726564] 0.03198919\n",
            "update dfs [0.01, 0.6735337177524343, 2.539303288445808] 0.032122456\n",
            "update dfs [0.01, 0.6924625026294962, 2.5654355181613937] 0.03199838\n",
            "update dfs [0.01, 0.7112636031815782, 2.5915672859409824] 0.03191298\n",
            "Train... |||||||||||||........| 60.0%   120/200 epochs, beta:1 Generator / grammar loss:-0.12465481460094452  completion loss:-0.0609208345413208   similarity loss:-0.05359016731381416update dfs [0.01, 0.7301687138387933, 2.617698692367412] 0.031981982\n",
            "update dfs [0.01, 0.7491581613430753, 2.643827431485988] 0.032036237\n",
            "update dfs [0.01, 0.7683233494171873, 2.6699493235209957] 0.03214849\n",
            "update dfs [0.01, 0.7871382670709863, 2.696076706633903] 0.031918917\n",
            "update dfs [0.01, 0.8061400899896398, 2.722204909310676] 0.032044094\n",
            "update dfs [0.01, 0.8246111558983102, 2.7483197344699875] 0.031681046\n",
            "update dfs [0.01, 0.8434427144238725, 2.7744481755653396] 0.031930786\n",
            "update dfs [0.01, 0.8622265817830339, 2.8005746310809627] 0.031897556\n",
            "update dfs [0.01, 0.8811659315833822, 2.826704022125341] 0.032003313\n",
            "update dfs [0.01, 0.9001905719051138, 2.8528324036160484] 0.032059442\n",
            "Train... ||||||||||||||.......| 65.0%   130/200 epochs, beta:1 Generator / grammar loss:-0.12499210983514786  completion loss:-0.06081445515155792   similarity loss:-0.05371071398258209update dfs [0.01, 0.9192686440655962, 2.8789595185080543] 0.032094173\n",
            "update dfs [0.01, 0.9383487278828397, 2.9050857728580013] 0.03209488\n",
            "update dfs [0.01, 0.9574337141821161, 2.931212038383819] 0.032098163\n",
            "update dfs [0.01, 0.9764537612209097, 2.957340513006784] 0.032056447\n",
            "update dfs [0.01, 0.9954551594564691, 2.9834687678376213] 0.03204385\n",
            "update dfs [0.01, 1.0141490834066644, 3.0095940424362198] 0.03183684\n",
            "update dfs [0.01, 1.033194592804648, 3.035721000866033] 0.032072313\n",
            "update dfs [0.01, 1.0519922139355913, 3.0618508389452472] 0.031909216\n",
            "update dfs [0.01, 1.071026841760613, 3.0879790416220203] 0.032065976\n",
            "update dfs [0.01, 1.0899626115569845, 3.11410907341633] 0.032001402\n",
            "Train... |||||||||||||||......| 70.0%   140/200 epochs, beta:1 Generator / grammar loss:-0.12486837804317474  completion loss:-0.06086679548025131   similarity loss:-0.053672533482313156update dfs [0.01, 1.1089505465934053, 3.1402396565536037] 0.032036584\n",
            "update dfs [0.01, 1.127628660411574, 3.166369457379915] 0.03182969\n",
            "update dfs [0.01, 1.1466345438966528, 3.192499545053579] 0.032048196\n",
            "update dfs [0.01, 1.1656389298150316, 3.218629606650211] 0.032047182\n",
            "update dfs [0.01, 1.1846846180269495, 3.244757798151113] 0.03207336\n",
            "update dfs [0.01, 1.203390690148808, 3.2708895882824436] 0.03184976\n",
            "update dfs [0.01, 1.2224253515014425, 3.2970184652367607] 0.032066498\n",
            "update dfs [0.01, 1.2413309240946546, 3.3231503075221553] 0.031982612\n",
            "update dfs [0.01, 1.2602549070725217, 3.349282835260965] 0.031995393\n",
            "update dfs [0.01, 1.2792211646446958, 3.3754155008355156] 0.032023683\n",
            "Train... ||||||||||||||||.....| 75.0%   150/200 epochs, beta:1 Generator / grammar loss:-0.12493293732404709  completion loss:-0.06086774915456772   similarity loss:-0.05370134115219116update dfs [0.01, 1.2982857736060396, 3.4015438786009327] 0.03208612\n",
            "update dfs [0.01, 1.3173346804687753, 3.4276723755756393] 0.032075725\n",
            "update dfs [0.01, 1.3361784430453554, 3.4538072465220466] 0.031943683\n",
            "update dfs [0.01, 1.3552483121166006, 3.4799353746930137] 0.032089446\n",
            "update dfs [0.01, 1.3743141802260652, 3.5060639089206234] 0.03208708\n",
            "update dfs [0.01, 1.3932357715675607, 3.5321975020924583] 0.031994577\n",
            "update dfs [0.01, 1.412350489408709, 3.5583230672637] 0.032117493\n",
            "update dfs [0.01, 1.4313165495404974, 3.5844561575213447] 0.03202386\n",
            "update dfs [0.01, 1.4500610629329458, 3.6105919560650364] 0.031878304\n",
            "update dfs [0.01, 1.4688561918446794, 3.6367291180649772] 0.031913005\n",
            "Train... |||||||||||||||||....| 80.0%   160/200 epochs, beta:1 Generator / grammar loss:-0.12471191585063934  completion loss:-0.06098448857665062   similarity loss:-0.053642455488443375update dfs [0.01, 1.4879035713383928, 3.662858129129745] 0.0320751\n",
            "update dfs [0.01, 1.5066963011631742, 3.6889962336281314] 0.0319121\n",
            "update dfs [0.01, 1.525621278793551, 3.7151319651165977] 0.031998433\n",
            "update dfs [0.01, 1.5446464145788923, 3.7412623135605827] 0.032061238\n",
            "update dfs [0.01, 1.5636303561041132, 3.767395713017322] 0.032036014\n",
            "update dfs [0.01, 1.5824851641664281, 3.7935350170591846] 0.031954322\n",
            "update dfs [0.01, 1.6014214704046026, 3.819670923636295] 0.03200612\n",
            "update dfs [0.01, 1.6205235483357683, 3.8457968762377277] 0.032109343\n",
            "update dfs [0.01, 1.639295301050879, 3.87193892209325] 0.03190107\n",
            "update dfs [0.01, 1.657882540137507, 3.898087271139957] 0.031783078\n",
            "Train... ||||||||||||||||||...| 85.0%   170/200 epochs, beta:1 Generator / grammar loss:-0.12448284775018692  completion loss:-0.06116004288196564   similarity loss:-0.053598932921886444update dfs [0.01, 1.676649315864779, 3.924230211065151] 0.031898424\n",
            "update dfs [0.01, 1.695646638632752, 3.9503627052763477] 0.03204426\n",
            "update dfs [0.01, 1.7142779814312235, 3.976511542336084] 0.031812742\n",
            "update dfs [0.01, 1.7328113900730386, 4.002662703976966] 0.03174944\n",
            "update dfs [0.01, 1.7514922494301572, 4.028810054645874] 0.031844564\n",
            "update dfs [0.01, 1.7704333314904943, 4.054944731877185] 0.03200838\n",
            "update dfs [0.01, 1.7891977044055238, 4.081089623854496] 0.031898268\n",
            "update dfs [0.01, 1.8079577895114198, 4.107234508381225] 0.031895407\n",
            "update dfs [0.01, 1.8267002055654302, 4.133380167768337] 0.03188423\n",
            "update dfs [0.01, 1.8453995460877195, 4.159527943120338] 0.03185716\n",
            "Train... |||||||||||||||||||..| 90.0%   180/200 epochs, beta:1 Generator / grammar loss:-0.12471143901348114  completion loss:-0.0611649751663208   similarity loss:-0.05371654033660889update dfs [0.01, 1.8640081124613062, 4.185680196271278] 0.03180016\n",
            "update dfs [0.01, 1.8825965808937326, 4.21183272136841] 0.03178702\n",
            "update dfs [0.01, 1.8873271184274927, 4.2290837249020115] 0.016362183\n",
            "update dfs [0.01, 1.8920131461927667, 4.246339385048486] 0.0163417\n",
            "update dfs [0.01, 1.896714991540648, 4.263622757629491] 0.01637245\n",
            "update dfs [0.01, 1.9013390900800005, 4.280912560061552] 0.016335428\n",
            "update dfs [0.01, 1.9059271650621668, 4.298219249234535] 0.016329447\n",
            "update dfs [0.01, 1.910339898080565, 4.3155326849082485] 0.016240424\n",
            "update dfs [0.01, 1.9148685025284067, 4.332857650355436] 0.01631197\n",
            "update dfs [0.01, 1.9191919477889314, 4.350192960933782] 0.016210146\n",
            "Train... ||||||||||||||||||||.| 95.0%   190/200 epochs, beta:1 Generator / grammar loss:-0.092875637114048  completion loss:-0.06689344346523285   similarity loss:-0.053881578147411346update dfs [0.01, 1.9236860336968675, 4.367529404000379] 0.016302567\n",
            "update dfs [0.01, 1.928022942156531, 4.384875830844976] 0.01622625\n",
            "update dfs [0.01, 1.93259120604489, 4.4022121435264125] 0.01634245\n",
            "update dfs [0.01, 1.9369129600236192, 4.419565030024387] 0.016223336\n",
            "update dfs [0.01, 1.9411218153545633, 4.436926074908115] 0.016169725\n",
            "update dfs [0.01, 1.9455203177640215, 4.454276957199909] 0.016262796\n",
            "update dfs [0.01, 1.9499283792683855, 4.471627742634155] 0.016267847\n",
            "update dfs [0.01, 1.9542066963622347, 4.488988198922016] 0.016206231\n",
            "update dfs [0.01, 1.958456969470717, 4.506351601914503] 0.016193658\n",
            "update dfs [0.01, 1.962686842889525, 4.52371625660453] 0.016183805\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:1 Generator / grammar loss:-0.0929669514298439  completion loss:-0.067142553627491   similarity loss:-0.054007772356271744\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "아기가 되었어요. 딸들보다 이번에는 돌아가셨어요. 소녀는 쓸고, 닦고, 도맡아 해도 없는 집안일이 지칠때면 잠시 무도회가 신데렐라의 새어머니는 데리고 무도회에 가고 싶었어요. 혼자 시작했어요. 싶니? 신데렐라가 호박이 멋진 마부로 변했답니다. 신데렐라의 예쁜 발을 할머니는 호박으로, 그러니까 밤 전에 신데렐라에게 마음을 모인 춤을 추느라 알리는 소리에 화들짝 왕궁을 빠져나가는데, 벗겨졌어요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro  ...       var     total   grammar\n",
            "0  SAM+WGAN    0.151934  0.458443  ...  0.002244  0.523088  0.983886\n",
            "\n",
            "[1 rows x 8 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvigjmChLVPb",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42f6b6e1-28b4-4106-87f3-c1a3cfb0b720"
      },
      "source": [
        "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
        "\n",
        "\n",
        "\n",
        "num = 0\n",
        "for i in range(30):\n",
        "    seeding(i)\n",
        "    df1,_ = sam_wgan('',[org_text_1,org_text_2,org_text_3],init_bias=0.0,display= False)\n",
        "    print(df1)\n",
        "\n",
        "for i in range(10):\n",
        "    for j in range(5):\n",
        "        seeding(i+j)\n",
        "        df1,_ = sam_wgan('',[org_text_1,org_text_2,org_text_3],init_bias=0.1*i,display= False)\n",
        "        #df2,_ = bert_lexrank_sum('',[org_text_1,org_text_2,org_text_3])\n",
        "        #df3,_ = besm('',[org_text_1,org_text_2,org_text_3])\n",
        "        #df4,_ = besm_bert('',[org_text_1,org_text_2,org_text_3])\n",
        "        #df5,_ = abstract_method_1(g_summ,[org_text_1,org_text_2,org_text_3])\n",
        "        #df6,_ = abstract_method_2(g_summ,[org_text_1,org_text_2,org_text_3])\n",
        "        #result = pd.concat([df1, df2, df3, df4], ignore_index=True)\n",
        "        #result\n",
        "        print(df1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.235438346862793 Generator / grammar loss:-0.1325722187757492   similarity loss:-0.10891871154308319\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            " 여자 그러던 소녀의 어머니가 병이들어 세상을 말았어요. 홀로 새어머니를 소녀보다 데리고 돌아가셨어요. 했어요. 집안일이 잠시 쉬곤 했지요. 날, 신데렐라도 신데렐라, 보내주마 할머니가 이번에는 건드렸어요. 흰말로, 처음대로 생쥐로, 돌아와야 알겠지? 아름다운 무도회장에 아가씨들은 땡, 허둥지둥 빠져나가는데, 짝이 틈이 왕자님은 유리 짝을 왕자님은 구두를 말했어요. 이 유리 구두의 결혼하겠어요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.153315  0.543796  0.572032  0.546569  0.000161  0.561405   \n",
            "\n",
            "    grammar  \n",
            "0  0.973289  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.3417510986328125 Generator / grammar loss:-0.1420641988515854   similarity loss:-0.10755050927400589\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "옛날 집에 귀여운 여자 고운 소녀가 되었어요. 그러던 어느날, 어머니가 말았어요. 아버지는 데리고 새어머니는 돌아가셨어요. 닦고, 해도 지칠때면 새어머니는 신데렐라, 웃고 호박 생쥐 두마리, 구해 호박이 황금 이번에는 생쥐는 마부로 변했답니다. 흰말은 하지만 신데렐라를 말했어요. 결혼하겠어요. 주인을 찾아 온 언니들은 발을 보고, 유리 작았어요. 구두는 데리고 왕자님과 살았대요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.147099  0.575101  0.534964  0.581717  0.000427  0.551677   \n",
            "\n",
            "    grammar  \n",
            "0  0.987413  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.3704774379730225 Generator / grammar loss:-0.13397637009620667   similarity loss:-0.09649591892957687\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "집에 귀여운 여자 아기는 무럭무럭 자라서, 마음씨 고운 소녀보다 딸을 심술쟁이들이었어요. 착한 하녀처럼 어느 집에도 왔어요. 무도회에 내가 변했어요. 이번에는 그랬더니 반짝이는 드레스로 주었어요. 왕자님은 모인 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 추느라 땡, 벽시계가 열두 유리 구두 층계에서 구두 가서 말했어요. 구두의 언니들은 발을 오므려도 구두를 작았어요. 저도 \n",
            "--------------------------------------------------\n",
            "     method  comp ratio    intro      body   ending       var    total  \\\n",
            "0  SAM+WGAN    0.146409  0.53452  0.518029  0.57098  0.000489  0.53003   \n",
            "\n",
            "    grammar  \n",
            "0  0.985035  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.345921277999878 Generator / grammar loss:-0.1428072303533554   similarity loss:-0.10786382853984833\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "집에 태어났어요. 예쁘고 그러던 어머니가 병이들어 말았어요. 후 나이가 새어머니와 언니들은 고약한 심술쟁이들이었어요. 못마땅했어요. 아버지마저 돌아가셨어요. 하녀처럼 쓸고, 닦고, 집에도 새어머니는 신데렐라는 신데렐라, 너도 웃고 내가 무도회에 한개와 구해 주문을 건드리자, 화려한 마차로 변했어요. 건드렸어요. 흰말로, 도마뱀은 멋진 신데렐라의 구슬 장식이 내밀어 반짝반짝 신겨 열두시가 도마뱀으로 변하게 돼.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN     0.15884  0.631332  0.528319  0.539165  0.002136  0.554603   \n",
            "\n",
            "    grammar  \n",
            "0  0.987601  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.3472719192504883 Generator / grammar loss:-0.12633922696113586   similarity loss:-0.09125658124685287\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "집에 무럭무럭 되었어요. 어느날, 말았어요. 새어머니는 왔어요. 그러나 언니들은 게 종일 닦고, 해도 지칠때면 난롯가에 잠시 무도회가 왔어요. 새어머니는 언니들을 떠났어요. 혼자 가고 고개를 보내주마 호박 생쥐 오렴. 할머니가 그리고 그랬더니 멋진 마부로 드레스로 발을 내밀어 유리 전에 다른 아가씨들은 땡, 땡 열두 놀랐어요. 짝이 벗겨졌어요. 틈이 없었어요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.139503  0.590466  0.505587  0.544776  0.001203  0.531848   \n",
            "\n",
            "   grammar  \n",
            "0  0.98539  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.3839917182922363 Generator / grammar loss:-0.13573215901851654   similarity loss:-0.0968504250049591\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "아기가 마음씨 고운 소녀가 그만 떠나고 말았어요. 맞이했어요. 새어머니와 소녀가 게 없는 어느 무도회가 가고 싶었어요. 고개를 호박을 건드리자, 생쥐는 도마뱀은 멋진 옷도 반짝이는 드레스로 빛나는 신데렐라, 호박으로, 도마뱀으로 왕자님도 다른 아가씨들은 추었어요. 왕자님과 시간 가는 벽시계가 열두 벗겨졌어요. 하지만 구두를 한 가서 유리 주인과 결혼하겠어요. 너무 신하게\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.143646  0.466301  0.541258  0.492026  0.000967  0.515842   \n",
            "\n",
            "    grammar  \n",
            "0  0.973568  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.445119857788086 Generator / grammar loss:-0.1363501250743866   similarity loss:-0.09108055382966995\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "옛날 그러던 병이들어 아버지는 걱정되었어요. 얼마 두 새어머니와 도맡아 앉아서 잠시 왔어요. 언니들을 떠났어요. 신데렐라는 훌쩍훌쩍 울기 들어보니, 도마뱀을 외웠어요. 건드리자, 생쥐와 흰말로, 예쁜 내밀어 빛나는 신데렐라, 열두시가 처음대로 돌아간단다. 도마뱀으로 돼. 그러니까 되기 몰랐어요. 열두 놀랐어요. 주울 없었어요. 층계에서 유리 유리 찾아 보고, 유리 구두는 한번 살았대요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro     body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.149862  0.502796  0.54561  0.573116  0.000837  0.539558   \n",
            "\n",
            "    grammar  \n",
            "0  0.977948  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:1.8541998863220215 Generator / grammar loss:-0.07117191702127457   similarity loss:-0.08577782660722733\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            " 여자 자라서, 예쁘고 마음씨 고운 그러던 병이들어 말았어요. 아버지는 소녀가 데리고 왔어요. 새어머니와 언니들은 고약한 새어머니는 예쁘고 못마땅했어요. 그런데 돌아가셨어요. 날, 신데렐라의 초대장이 왔어요. 언니들을 데리고 혼자 시작했어요. 고개를 할머니가 도마뱀을 구해 지팡이로 건드리자, 호박이 이번에는 멋진 신데렐라의 열두시가 밤 알겠지? 왕자님도 쳐다보지도 춤을 추었어요. 신데렐라는 놀랐어요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body   ending       var     total  \\\n",
            "0  SAM+WGAN    0.155387  0.599481  0.565622  0.54636  0.000482  0.570787   \n",
            "\n",
            "    grammar  \n",
            "0  0.981267  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.1255342960357666 Generator / grammar loss:-0.10029229521751404   similarity loss:-0.08772233873605728\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "마음씨 소녀가 얼마 새어머니와 게 닦고, 해도 없는 집안일이 지칠때면 잠시 무도회가 초대장이 왔어요. 빙그레 너를 무도회에 지팡이로 황금 마차로 변했답니다. 신데렐라의 구슬 밤 모든게 그러니까 반드시 시가 왕자님도 모인 신데렐라는 추느라 줄도 몰랐어요. 땡, 땡 소리에 화들짝 놀랐어요. 신데렐라가 허둥지둥 빠져나가는데, 짝이 벗겨졌어요. 틈이 없었어요. 이 돌아다녔어요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro     body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.143646  0.473305  0.57508  0.509829  0.001772  0.540813   \n",
            "\n",
            "    grammar  \n",
            "0  0.967419  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.546694040298462 Generator / grammar loss:-0.14414696395397186   similarity loss:-0.0880514457821846\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            " 집에 귀여운 아기가 예쁘고 세상을 떠나고 말았어요. 소녀의 소녀가 걱정되었어요. 새어머니는 그런데 종일 쓸고, 집안일이 지칠때면 앉아서 잠시 왕궁에서 왔어요. 신데렐라도 무도회에 신데렐라, 할머니가 있었어요. 호박 생쥐 두마리, 구해 지팡이로 변했어요. 이번에는 건드렸어요. 그랬더니 구슬 바뀌웠어요. 발을 주었어요. 처음대로 돌아간단다. 호박으로, 그러니까 돌아와야 몰랐어요. 신데렐라는 빠져나가는데, 주웠어요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var    total  \\\n",
            "0  SAM+WGAN    0.160221  0.550314  0.565554  0.516929  0.000412  0.55451   \n",
            "\n",
            "    grammar  \n",
            "0  0.992254  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.186699628829956 Generator / grammar loss:-0.13292549550533295   similarity loss:-0.11420103162527084\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "어느 집에 소녀가 병이들어 세상을 왔어요. 왕궁에서 마법사 내가 너를 호박 한개와 그리고 호박이 마차로 생쥐와 도마뱀을 흰말로, 마부로 신데렐라, 발을 내밀어 보거라. 마차는 쳐다보지도 줄도 알리는 화들짝 신데렐라가 한 구두를 주울 신데렐라를 주웠어요. 가서 신하들은 언니들은 보았지만 구두는 신데렐라는 구두를 발에 맞았어요. 신하들은 갔어요. 신데렐라는 오래오래 행복하게\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.143646  0.500388  0.587041  0.621793  0.002606  0.571608   \n",
            "\n",
            "   grammar  \n",
            "0  0.96129  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.282188653945923 Generator / grammar loss:-0.1201433390378952   similarity loss:-0.09173493832349777\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "옛날 고운 그래서 소녀가 자기 그런데 쓸고, 닦고, 집안일을 도맡아 앉아서 잠시 쉬곤 날, 왕궁에서 열렸어요. 집에도 언니들을 데리고 무도회장으로 떠났어요. 가고 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 들어보니, 내가 무도회에 보내주마 두마리, 구해 외웠어요. 변했어요. 건드렸어요. 흰말로, 신데렐라의 신데렐라, 발을 보거라. 열두시가 호박으로, 돌아와야 땡, 왕자님은 가서 말했어요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body   ending       var     total  \\\n",
            "0  SAM+WGAN    0.150552  0.486061  0.545191  0.54023  0.000717  0.530297   \n",
            "\n",
            "   grammar  \n",
            "0   0.9779  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.1492981910705566 Generator / grammar loss:-0.10790187120437622   similarity loss:-0.09294421225786209\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "아기가 어느날, 소녀의 소녀보다 새어머니와 심술쟁이들이었어요. 착한 게 못마땅했어요. 이번에는 돌아가셨어요. 하루 집안일이 앉아서 새어머니는 언니들을 훌쩍훌쩍 싶니? 신데렐라가 빙그레 있었어요. 무도회에 도마뱀을 오렴. 그리고 마차로 그랬더니 흰말로, 도마뱀은 멋진 장식이 바뀌웠어요. 신데렐라에게 빛나는 구두를 주었어요. 시가 왕자님도 마음을 추었어요. 땡, 놀랐어요. 이 신데렐라는 신데렐라의 신하들은 오래오래 행복하게\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.162983  0.560835  0.619731  0.613985  0.000703  0.604773   \n",
            "\n",
            "    grammar  \n",
            "0  0.988195  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.3685879707336426 Generator / grammar loss:-0.13422226905822754   similarity loss:-0.09693747758865356\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            " 옛날 태어났어요. 자라서, 고운 소녀의 아버지는 새어머니를 새어머니는 새어머니는 예쁘고 그런데 하녀처럼 열렸어요. 신데렐라도 혼자 너도 가고 빙그레 웃고 내가 너를 호박 생쥐 도마뱀을 외웠어요. 호박을 건드리자, 화려한 도마뱀을 보거라. 유리 신데렐라, 돌아간단다. 흰말은 생쥐로, 변하게 돼. 전에 신데렐라는 추느라 몰랐어요. 허둥지둥 구두 하지만 틈이 주인과 결혼하겠어요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.145718  0.461222  0.554786  0.509361  0.001459  0.525499   \n",
            "\n",
            "    grammar  \n",
            "0  0.978783  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.273050546646118 Generator / grammar loss:-0.12515820562839508   similarity loss:-0.09768157452344894\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "어느 집에 아기가 무럭무럭 어머니가 남은 고약한 심술쟁이들이었어요. 게 못마땅했어요. 아버지마저 하녀처럼 종일 했어요. 집안일이 힘들어 고개를 지팡이로 도마뱀을 변했답니다. 신데렐라, 내밀어 할머니는 빛나는 유리 신겨 흰말은 생쥐로, 마부는 열두 왕자님도 아가씨들은 춤을 줄도 구두 벗겨졌어요. 구두를 틈이 없었어요. 구두를 돌아다녔어요. 오므려도 보았지만 유리 유리 신데렐라를 왕궁으로 갔어요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.152624  0.518128  0.571578  0.571504  0.000634  0.558785   \n",
            "\n",
            "    grammar  \n",
            "0  0.979256  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.337252616882324 Generator / grammar loss:-0.14145870506763458   similarity loss:-0.10740819573402405\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "귀여운 소녀보다 나이가 데리고 고약한 딸들보다 집안일이 쉬곤 했지요. 집에도 울기 시작했어요. 무도회에 건드리자, 장식이 신데렐라, 모든게 처음대로 도마뱀으로 변하게 반드시 다른 아가씨들은 쳐다보지도 신데렐라는 몰랐어요. 땡, 땡, 열두 신데렐라는 왕궁을 하지만 주울 뛰쫓아오던 층계에서 유리 구두 주웠어요. 유리 가지고 온 발을 보고, 한눈에 저도 발에 데리고 갔어요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.142956  0.453575  0.515976  0.549784  0.001588  0.506199   \n",
            "\n",
            "    grammar  \n",
            "0  0.989489  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.206098794937134 Generator / grammar loss:-0.12035493552684784   similarity loss:-0.09967163950204849\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "그만 소녀가 데리고 성질이 못마땅했어요. 가고 싶었어요. 혼자 훌쩍훌쩍 울기 너도 가고 신데렐라가 고개를 들어보니, 마법사 할머니가 너를 두마리, 도마뱀을 오렴. 마법사 외웠어요. 보거라. 그러니까 시가 전에 빼았겼어요. 춤을 왕자님과 시간 땡, 소리에 신데렐라는 화들짝 허둥지둥 하지만 주울 신데렐라를 뛰쫓아오던 층계에서 유리 구두의 주인과 결혼하겠어요. 신하들은 나라를 돌아다녔어요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.149171  0.408545  0.573196  0.549897  0.005293  0.530278   \n",
            "\n",
            "    grammar  \n",
            "0  0.980767  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.1875619888305664 Generator / grammar loss:-0.1346302479505539   similarity loss:-0.11581878364086151\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "여자 어느날, 소녀의 얼마 위인 성질이 예쁘고 하루 종일 해도 없는 집안일이 앉아서 무도회장으로 가고 시작했어요. 너도 싶니? 신데렐라가 고개를 들어보니, 웃고 너를 보내주마 생쥐 구해 오렴. 마법사 할머니가 주문을 외웠어요. 생쥐와 반짝이는 모든게 마차는 생쥐로, 그러니까 열두 전에 돌아와야 쳐다보지도 신데렐라는 추느라 땡, 구두 한 짝을 주웠어요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN     0.13605  0.450914  0.522257  0.548934  0.001712  0.509256   \n",
            "\n",
            "    grammar  \n",
            "0  0.990481  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:1.7070997953414917 Generator / grammar loss:-0.05959697812795639   similarity loss:-0.08909914642572403\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "귀여운 여자 태어났어요. 마음씨 소녀가 되었어요. 소녀가 두 예쁘고 착한 이번에는 종일 닦고, 집안일을 끝이 지칠때면 어느 날, 무도회가 신데렐라의 데리고 무도회에 혼자 훌쩍훌쩍 울기 시작했어요. 싶니? 고개를 빙그레 웃고 한개와 두마리, 마법사 지팡이로 그랬더니 멋진 신데렐라의 옷도 구슬 내밀어 보거라. 신겨 주었어요. 시가 왕자님과 구두 신데렐라는 살았대요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var    total  \\\n",
            "0  SAM+WGAN    0.140193  0.524048  0.531931  0.569287  0.000389  0.53573   \n",
            "\n",
            "    grammar  \n",
            "0  0.968789  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.4882969856262207 Generator / grammar loss:-0.13661527633666992   similarity loss:-0.08677909523248672\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            " 집에 태어났어요. 무럭무럭 자라서, 되었어요. 어머니가 그만 세상을 떠나고 말았어요. 소녀가 왔어요. 심술쟁이들이었어요. 새어머니는 예쁘고 못마땅했어요. 아버지마저 집안일을 해도 힘들어 지칠때면 어느 날, 무도회가 신데렐라의 집에도 떠났어요. 싶었어요. 너도 무도회에 가고 할머니가 구해 외웠어요. 그리고 호박이 마차로 건드렸어요. 황금 흰말은 도마뱀으로 밤 되기 왕자님은 추느라 몰랐어요. 유리\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro    body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.153315  0.604783  0.4755  0.453901  0.004438  0.503129   \n",
            "\n",
            "   grammar  \n",
            "0  0.99175  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.3348686695098877 Generator / grammar loss:-0.1409808248281479   similarity loss:-0.10717566311359406\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "태어났어요. 아기는 예쁘고 그러던 소녀가 얼마 새어머니를 맞이했어요. 데리고 새어머니는 소녀는 종일 도맡아 앉아서 쉬곤 어느 집에도 초대장이 왔어요. 울기 가고 들어보니, 빙그레 너를 그리고 지팡이로 건드리자, 호박이 신데렐라의 발을 유리 신겨 주었어요. 호박으로, 마부는 열두 해. 알겠지? 마음을 추느라 유리 왕자님은 구두를 보았지만 보기에도 신데렐라는 왕자님과 살았대요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var    total  \\\n",
            "0  SAM+WGAN    0.145028  0.560531  0.554514  0.551867  0.000013  0.55555   \n",
            "\n",
            "    grammar  \n",
            "0  0.985261  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.3550832271575928 Generator / grammar loss:-0.1333031803369522   similarity loss:-0.09741455316543579\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "마음씨 소녀의 어머니가 떠나고 걱정되었어요. 얼마 맞이했어요. 두 새어머니와 고약한 심술쟁이들이었어요. 새어머니는 딸들보다 돌아가셨어요. 했어요. 집안일이 앉아서 했지요. 열렸어요. 집에도 데리고 혼자 훌쩍훌쩍 생쥐와 장식이 변하게 빼았겼어요. 아가씨들은 땡, 소리에 허둥지둥 신데렐라를 왕자님은 유리 짝을 가서 신하들은 언니들은 오므려도 구두를 보았지만 한눈에 유리 구두는 말했어요. 갔어요. 왕자님과 살았대요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN     0.15953  0.627212  0.522638  0.587711  0.001859  0.557547   \n",
            "\n",
            "    grammar  \n",
            "0  0.968449  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.4468977451324463 Generator / grammar loss:-0.14081428945064545   similarity loss:-0.09535763412714005\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "어느 여자 아기는 고운 되었어요. 병이들어 말았어요. 소녀의 고약한 새어머니는 아버지마저 하루 난롯가에 앉아서 왔어요. 언니들을 떠났어요. 싶었어요. 생쥐 구해 마법사 할머니가 외웠어요. 변했답니다. 신데렐라에게 처음대로 반드시 무도회장에 쳐다보지도 왕자님과 벽시계가 허둥지둥 짝이 벗겨졌어요. 말했어요. 결혼하겠어요. 신하들은 찾아 돌아다녔어요. 구두를 한눈에 보기에도 신하게 구두는 데리고 왕자님과 오래오래 살았대요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending      var     total  \\\n",
            "0  SAM+WGAN    0.162293  0.563039  0.549744  0.568117  0.00006  0.555719   \n",
            "\n",
            "    grammar  \n",
            "0  0.979315  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.541001319885254 Generator / grammar loss:-0.13350644707679749   similarity loss:-0.07802563160657883\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "예쁘고 되었어요. 그만 떠나고 후 소녀보다 언니들은 못마땅했어요. 아버지마저 돌아가셨어요. 초대장이 훌쩍훌쩍 울기 시작했어요. 신데렐라가 고개를 들어보니, 마법사 있었어요. 무도회에 보내주마 생쥐 도마뱀을 구해 외웠어요. 호박이 화려한 마차로 변했어요. 흰말로, 변했답니다. 반짝이는 발을 보거라. 반짝반짝 유리 구두를 신겨 주었어요. 돌아간단다. 추느라 땡 시를 허둥지둥 틈이 없었어요. 조용히 신어\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro     body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.154696  0.562016  0.56163  0.549979  0.000031  0.559949   \n",
            "\n",
            "    grammar  \n",
            "0  0.989096  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.3853676319122314 Generator / grammar loss:-0.1423969268798828   similarity loss:-0.10337232798337936\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "아기가 예쁘고 그러던 어머니가 병이들어 그만 세상을 맞이했어요. 새어머니는 나이가 성질이 고약한 게 못마땅했어요. 그랬더니 변했답니다. 옷도 구슬 반짝이는 예쁜 드레스로 신데렐라, 발을 보거라. 신데렐라에게 반짝반짝 유리 구두를 신겨 모든게 황금 호박으로, 도마뱀으로 변하게 돼. 반드시 되기 전에 신데렐라에게 빼았겼어요. 가는 줄도 놀랐어요. 한 한 나라를 돌아다녔어요. 신데렐라가\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var    total  \\\n",
            "0  SAM+WGAN     0.14779  0.568118  0.598853  0.606853  0.000279  0.59272   \n",
            "\n",
            "    grammar  \n",
            "0  0.993237  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.2732324600219727 Generator / grammar loss:-0.1387566179037094   similarity loss:-0.11126145720481873\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "아기는 예쁘고 소녀의 병이들어 소녀의 소녀가 얼마 위인 쓸고, 지칠때면 쉬곤 했지요. 데리고 혼자 시작했어요. 너도 도마뱀을 구해 할머니가 화려한 내밀어 빛나는 신데렐라, 처음대로 황금 마차는 생쥐로, 밤 왕자님도 무도회장에 모인 아가씨들은 춤을 놀랐어요. 신데렐라가 주울 신데렐라를 유리 한 이 구두를 한눈에 보기에도 너무 작았어요. 신데렐라가 조용히 신어\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.138122  0.467625  0.548868  0.621528  0.003952  0.540498   \n",
            "\n",
            "    grammar  \n",
            "0  0.981294  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.406708240509033 Generator / grammar loss:-0.13459062576293945   similarity loss:-0.09334485232830048\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "어느 집에 귀여운 여자 되었어요. 어머니가 성질이 닦고, 끝이 앉아서 했지요. 어느 새어머니는 언니들을 데리고 싶었어요. 혼자 남은 훌쩍훌쩍 시작했어요. 가고 할머니가 있었어요. 두마리, 구해 주문을 그리고 도마뱀은 신데렐라의 구슬 예쁜 발을 내밀어 보거라. 할머니는 모든게 처음대로 돌아간단다. 마차는 마부는 도마뱀으로 그러니까 춤을 시간 열두 소리에 놀랐어요. 돌아다녔어요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.145718  0.576355  0.496464  0.447383  0.002825  0.508099   \n",
            "\n",
            "    grammar  \n",
            "0  0.983447  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.3416621685028076 Generator / grammar loss:-0.1343889832496643   similarity loss:-0.09988445043563843\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "그러던 어느날, 소녀의 어머니가 그만 떠나고 그래서 얼마 소녀보다 나이가 두 딸을 데리고 고약한 착한 못마땅했어요. 아버지마저 하녀처럼 하루 했어요. 힘들어 잠시 쉬곤 왕궁에서 무도회가 열렸어요. 초대장이 언니들을 데리고 무도회장으로 떠났어요. 싶었어요. 신데렐라는 훌쩍훌쩍 시작했어요. 신데렐라, 너도 무도회에 가고 신데렐라가 고개를 보내주마 생쥐와 도마뱀을 해. 짝이 짝을 주웠어요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.149171  0.548775  0.576394  0.532884  0.000323  0.563169   \n",
            "\n",
            "    grammar  \n",
            "0  0.989946  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.2851483821868896 Generator / grammar loss:-0.13412897288799286   similarity loss:-0.10541852563619614\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            " 어느 귀여운 여자 아기가 태어났어요. 예쁘고 떠나고 소녀의 소녀가 소녀보다 위인 하녀처럼 하루 종일 해도 끝이 지칠때면 잠시 초대장이 데리고 무도회장으로 떠났어요. 혼자 한개와 이번에는 발을 돌아간단다. 반드시 추느라 가는 줄도 몰랐어요. 땡, 열두 신데렐라가 한 벗겨졌어요. 틈이 없었어요. 신데렐라를 짝을 가지고 말했어요. 저도 신데렐라는 왕자님과 행복하게\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.139503  0.512125  0.526909  0.566406  0.000525  0.529384   \n",
            "\n",
            "    grammar  \n",
            "0  0.987494  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.216546058654785 Generator / grammar loss:-0.12076540291309357   similarity loss:-0.09902559220790863\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "소녀가 되었어요. 말았어요. 소녀의 소녀가 소녀보다 나이가 위인 딸들보다 못마땅했어요. 집안일이 쉬곤 어느 언니들을 무도회장으로 무도회에 싶니? 내가 생쥐 할머니가 외웠어요. 호박을 건드렸어요. 흰말로, 마부로 변했답니다. 할머니는 신데렐라, 밤 되면 황금 흰말은 생쥐로, 마부는 열두 전에 해. 왕자님도 무도회장에 다른 춤을 추었어요. 추느라 시간 몰랐어요. 땡, 신데렐라는 놀랐어요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.149171  0.549774  0.569982  0.512988  0.000557  0.556477   \n",
            "\n",
            "   grammar  \n",
            "0  0.98779  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.235438346862793 Generator / grammar loss:-0.1325722187757492   similarity loss:-0.10891871154308319\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            " 여자 그러던 소녀의 어머니가 병이들어 세상을 말았어요. 홀로 새어머니를 소녀보다 데리고 돌아가셨어요. 했어요. 집안일이 잠시 쉬곤 했지요. 날, 신데렐라도 신데렐라, 보내주마 할머니가 이번에는 건드렸어요. 흰말로, 처음대로 생쥐로, 돌아와야 알겠지? 아름다운 무도회장에 아가씨들은 땡, 허둥지둥 빠져나가는데, 짝이 틈이 왕자님은 유리 짝을 왕자님은 구두를 말했어요. 이 유리 구두의 결혼하겠어요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.153315  0.543796  0.572032  0.546569  0.000161  0.561405   \n",
            "\n",
            "    grammar  \n",
            "0  0.973289  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.3417510986328125 Generator / grammar loss:-0.1420641988515854   similarity loss:-0.10755050927400589\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "옛날 집에 귀여운 여자 고운 소녀가 되었어요. 그러던 어느날, 어머니가 말았어요. 아버지는 데리고 새어머니는 돌아가셨어요. 닦고, 해도 지칠때면 새어머니는 신데렐라, 웃고 호박 생쥐 두마리, 구해 호박이 황금 이번에는 생쥐는 마부로 변했답니다. 흰말은 하지만 신데렐라를 말했어요. 결혼하겠어요. 주인을 찾아 온 언니들은 발을 보고, 유리 작았어요. 구두는 데리고 왕자님과 살았대요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.147099  0.575101  0.534964  0.581717  0.000427  0.551677   \n",
            "\n",
            "    grammar  \n",
            "0  0.987413  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.3704774379730225 Generator / grammar loss:-0.13397637009620667   similarity loss:-0.09649591892957687\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "집에 귀여운 여자 아기는 무럭무럭 자라서, 마음씨 고운 소녀보다 딸을 심술쟁이들이었어요. 착한 하녀처럼 어느 집에도 왔어요. 무도회에 내가 변했어요. 이번에는 그랬더니 반짝이는 드레스로 주었어요. 왕자님은 모인 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 추느라 땡, 벽시계가 열두 유리 구두 층계에서 구두 가서 말했어요. 구두의 언니들은 발을 오므려도 구두를 작았어요. 저도 \n",
            "--------------------------------------------------\n",
            "     method  comp ratio    intro      body   ending       var    total  \\\n",
            "0  SAM+WGAN    0.146409  0.53452  0.518029  0.57098  0.000489  0.53003   \n",
            "\n",
            "    grammar  \n",
            "0  0.985035  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.345921277999878 Generator / grammar loss:-0.1428072303533554   similarity loss:-0.10786382853984833\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "집에 태어났어요. 예쁘고 그러던 어머니가 병이들어 말았어요. 후 나이가 새어머니와 언니들은 고약한 심술쟁이들이었어요. 못마땅했어요. 아버지마저 돌아가셨어요. 하녀처럼 쓸고, 닦고, 집에도 새어머니는 신데렐라는 신데렐라, 너도 웃고 내가 무도회에 한개와 구해 주문을 건드리자, 화려한 마차로 변했어요. 건드렸어요. 흰말로, 도마뱀은 멋진 신데렐라의 구슬 장식이 내밀어 반짝반짝 신겨 열두시가 도마뱀으로 변하게 돼.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN     0.15884  0.631332  0.528319  0.539165  0.002136  0.554603   \n",
            "\n",
            "    grammar  \n",
            "0  0.987601  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.3472719192504883 Generator / grammar loss:-0.12633922696113586   similarity loss:-0.09125658124685287\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "집에 무럭무럭 되었어요. 어느날, 말았어요. 새어머니는 왔어요. 그러나 언니들은 게 종일 닦고, 해도 지칠때면 난롯가에 잠시 무도회가 왔어요. 새어머니는 언니들을 떠났어요. 혼자 가고 고개를 보내주마 호박 생쥐 오렴. 할머니가 그리고 그랬더니 멋진 마부로 드레스로 발을 내밀어 유리 전에 다른 아가씨들은 땡, 땡 열두 놀랐어요. 짝이 벗겨졌어요. 틈이 없었어요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.139503  0.590466  0.505587  0.544776  0.001203  0.531848   \n",
            "\n",
            "   grammar  \n",
            "0  0.98539  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/327       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/324       \n",
            "Negative tokens: ['여자' '소녀가' '소녀의' '소녀가' '딸을' '새어머니와' '새어머니는' '집안일이' '신데렐라의' '신데렐라도'\n",
            " '신데렐라는' '신데렐라,' '신데렐라가' '할머니가' '무도회에' '할머니가' '마차로' '신데렐라의' '신데렐라,'\n",
            " '신데렐라에게' '신데렐라,' '흰말은' '신데렐라에게' '신데렐라는' '신데렐라는' '신데렐라가' '구두' '구두를'\n",
            " '신데렐라를' '구두' '왕자님은' '구두를' '구두의' '언니들은' '구두를' '신데렐라가' '신데렐라는' '신데렐라의'\n",
            " '신데렐라를' '신데렐라는']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 325/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 324/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 323/324       \n",
            "Peak count: 17\n",
            "Frame tokens: 소녀의 맞이했어요. 소녀는 왕궁에서 언니들을 무도회에 무도회에 드레스로 할머니는 왕자님도 무도회장에 않고,신데렐라하고만 왕궁을 결혼하겠어요. 왕궁으로 결혼하여 살았대요. \n",
            "\n",
            "Similarity : 0.4716061490671215\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.320927619934082 Generator / grammar loss:-0.15463551878929138   similarity loss:-0.12226297706365585\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "옛날 집에 귀여운 아기가 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 말았어요. 아버지는 맞이했어요. 위인 데리고 소녀는 종일 닦고, 집안일을 지칠때면 왕궁에서 새어머니는 언니들을 데리고 무도회에 가고 신데렐라, 무도회에 생쥐 두마리, 구해 이번에는 생쥐와 마부로 변했답니다. 층계에서 결혼하겠어요. 그래서 찾아 온 언니들은 보고, 늘려도 작았어요. 구두를 구두는 왕궁으로 데리고 결혼하여 살았대요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.158149  0.596396  0.504073  0.549628  0.001421  0.533083   \n",
            "\n",
            "    grammar  \n",
            "0  0.991487  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/327       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/324       \n",
            "Negative tokens: ['여자' '소녀가' '소녀의' '소녀가' '딸을' '새어머니와' '새어머니는' '집안일이' '신데렐라의' '신데렐라도'\n",
            " '신데렐라는' '신데렐라,' '신데렐라가' '할머니가' '무도회에' '할머니가' '마차로' '신데렐라의' '신데렐라,'\n",
            " '신데렐라에게' '신데렐라,' '흰말은' '신데렐라에게' '신데렐라는' '신데렐라는' '신데렐라가' '구두' '구두를'\n",
            " '신데렐라를' '구두' '왕자님은' '구두를' '구두의' '언니들은' '구두를' '신데렐라가' '신데렐라는' '신데렐라의'\n",
            " '신데렐라를' '신데렐라는']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 325/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 324/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 323/324       \n",
            "Peak count: 17\n",
            "Frame tokens: 소녀의 맞이했어요. 소녀는 왕궁에서 언니들을 무도회에 무도회에 드레스로 할머니는 왕자님도 무도회장에 않고,신데렐라하고만 왕궁을 결혼하겠어요. 왕궁으로 결혼하여 살았대요. \n",
            "\n",
            "Similarity : 0.4716061490671215\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.2413923740386963 Generator / grammar loss:-0.1483447551727295   similarity loss:-0.12408727407455444\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "소녀보다 왔어요. 착한 소녀는 하녀처럼 종일 잠시 어느 왕궁에서 무도회가 열렸어요. 집에도 왔어요. 무도회에 내가 변했어요. 이번에는 그랬더니 흰말로, 반짝이는 드레스로 신데렐라, 할머니는 주었어요. 왕자님도 빼았겼어요. 왕자님은 무도회장에 다른 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 추느라 땡, 왕궁을 하지만 뛰쫓아오던 층계에서 구두 가서 결혼하겠어요. 언니들은 구두를 발에 신하들은 신데렐라를 왕궁으로 데리고 살았대요. \n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.167127  0.456832  0.581877  0.635594  0.005609  0.560149   \n",
            "\n",
            "    grammar  \n",
            "0  0.980903  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/327       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/324       \n",
            "Negative tokens: ['여자' '소녀가' '소녀의' '소녀가' '딸을' '새어머니와' '새어머니는' '집안일이' '신데렐라의' '신데렐라도'\n",
            " '신데렐라는' '신데렐라,' '신데렐라가' '할머니가' '무도회에' '할머니가' '마차로' '신데렐라의' '신데렐라,'\n",
            " '신데렐라에게' '신데렐라,' '흰말은' '신데렐라에게' '신데렐라는' '신데렐라는' '신데렐라가' '구두' '구두를'\n",
            " '신데렐라를' '구두' '왕자님은' '구두를' '구두의' '언니들은' '구두를' '신데렐라가' '신데렐라는' '신데렐라의'\n",
            " '신데렐라를' '신데렐라는']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 325/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 324/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 323/324       \n",
            "Peak count: 17\n",
            "Frame tokens: 소녀의 맞이했어요. 소녀는 왕궁에서 언니들을 무도회에 무도회에 드레스로 할머니는 왕자님도 무도회장에 않고,신데렐라하고만 왕궁을 결혼하겠어요. 왕궁으로 결혼하여 살았대요. \n",
            "\n",
            "Similarity : 0.4716061490671215\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:1.857708215713501 Generator / grammar loss:-0.07923335582017899   similarity loss:-0.09348660707473755\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "집에 태어났어요. 그러던 소녀의 병이들어 맞이했어요. 새어머니는 새어머니와 언니들은 고약한 심술쟁이들이었어요. 게 못마땅했어요. 아버지마저 돌아가셨어요. 소녀는 하루 날, 왕궁에서 새어머니는 언니들을 떠났어요. 가고 남은 신데렐라, 무도회에 웃고 내가 한개와 구해 화려한 마차로 변했어요. 건드렸어요. 소리에 결혼하겠어요. 유리 구두의 온 오므려도 늘려도 한눈에 수 신데렐라는 건넨 유리 유리 왕궁으로 결혼하여 살았대요. \n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending      var     total  \\\n",
            "0  SAM+WGAN    0.162983  0.623063  0.561262  0.606217  0.00068  0.582881   \n",
            "\n",
            "    grammar  \n",
            "0  0.963253  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/327       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/324       \n",
            "Negative tokens: ['여자' '소녀가' '소녀의' '소녀가' '딸을' '새어머니와' '새어머니는' '집안일이' '신데렐라의' '신데렐라도'\n",
            " '신데렐라는' '신데렐라,' '신데렐라가' '할머니가' '무도회에' '할머니가' '마차로' '신데렐라의' '신데렐라,'\n",
            " '신데렐라에게' '신데렐라,' '흰말은' '신데렐라에게' '신데렐라는' '신데렐라는' '신데렐라가' '구두' '구두를'\n",
            " '신데렐라를' '구두' '왕자님은' '구두를' '구두의' '언니들은' '구두를' '신데렐라가' '신데렐라는' '신데렐라의'\n",
            " '신데렐라를' '신데렐라는']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 325/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 324/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 323/324       \n",
            "Peak count: 17\n",
            "Frame tokens: 소녀의 맞이했어요. 소녀는 왕궁에서 언니들을 무도회에 무도회에 드레스로 할머니는 왕자님도 무도회장에 않고,신데렐라하고만 왕궁을 결혼하겠어요. 왕궁으로 결혼하여 살았대요. \n",
            "\n",
            "Similarity : 0.4716061490671215\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.493842840194702 Generator / grammar loss:-0.15018989145755768   similarity loss:-0.09976356476545334\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "옛날 여자 무럭무럭 되었어요. 소녀의 세상을 말았어요. 소녀의 아버지는 소녀가 얼마 새어머니를 맞이했어요. 새어머니는 왔어요. 자기 이번에는 소녀는 해도 없는 집안일이 지칠때면 잠시 왕궁에서 무도회가 왔어요. 언니들을 떠났어요. 너도 가고 고개를 호박 할머니가 외웠어요. 도마뱀은 밤 황금 흰말은 도마뱀으로 아름다운 주울 틈이 없었어요. 뛰쫓아오던 왕자님은 짝을 주웠어요. 임금님께 유리 결혼하겠어요. 신데렐라가\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN     0.15884  0.571244  0.552183  0.541502  0.000151  0.555115   \n",
            "\n",
            "    grammar  \n",
            "0  0.971976  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/327       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/324       \n",
            "Negative tokens: ['여자' '소녀가' '소녀의' '소녀가' '딸을' '새어머니와' '새어머니는' '집안일이' '신데렐라의' '신데렐라도'\n",
            " '신데렐라는' '신데렐라,' '신데렐라가' '할머니가' '무도회에' '할머니가' '마차로' '신데렐라의' '신데렐라,'\n",
            " '신데렐라에게' '신데렐라,' '흰말은' '신데렐라에게' '신데렐라는' '신데렐라는' '신데렐라가' '구두' '구두를'\n",
            " '신데렐라를' '구두' '왕자님은' '구두를' '구두의' '언니들은' '구두를' '신데렐라가' '신데렐라는' '신데렐라의'\n",
            " '신데렐라를' '신데렐라는']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 325/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 324/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 323/324       \n",
            "Peak count: 17\n",
            "Frame tokens: 소녀의 맞이했어요. 소녀는 왕궁에서 언니들을 무도회에 무도회에 드레스로 할머니는 왕자님도 무도회장에 않고,신데렐라하고만 왕궁을 결혼하겠어요. 왕궁으로 결혼하여 살았대요. \n",
            "\n",
            "Similarity : 0.4716061490671215\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:1.9687683582305908 Generator / grammar loss:-0.1051708534359932   similarity loss:-0.10829427093267441\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "아기가 무럭무럭 고운 그러던 소녀의 새어머니를 맞이했어요. 그러나 새어머니와 소녀가 예쁘고 이번에는 소녀는 하녀처럼 난롯가에 쉬곤 했지요. 왕궁에서 무도회가 왔어요. 언니들을 무도회에 가고 싶었어요. 훌쩍훌쩍 이번에는 내밀어 주었어요. 그러니까 가는 주인과 결혼하겠어요. 유리 주인을 오므려도 보고, 늘려도 보았지만 한눈에 너무 그때, 저도 한번 신데렐라는 유리 구두는 왕궁으로 데리고 왕자님과 결혼하여 살았대요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN     0.15953  0.569019  0.545122  0.622047  0.001033  0.562542   \n",
            "\n",
            "    grammar  \n",
            "0  0.989234  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/327       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/324       \n",
            "Negative tokens: ['여자' '소녀가' '소녀의' '소녀가' '딸을' '새어머니와' '새어머니는' '집안일이' '신데렐라의' '신데렐라도'\n",
            " '신데렐라는' '신데렐라,' '신데렐라가' '할머니가' '무도회에' '할머니가' '마차로' '신데렐라의' '신데렐라,'\n",
            " '신데렐라에게' '신데렐라,' '흰말은' '신데렐라에게' '신데렐라는' '신데렐라는' '신데렐라가' '구두' '구두를'\n",
            " '신데렐라를' '구두' '왕자님은' '구두를' '구두의' '언니들은' '구두를' '신데렐라가' '신데렐라는' '신데렐라의'\n",
            " '신데렐라를' '신데렐라는']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 325/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 324/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 323/324       \n",
            "Peak count: 17\n",
            "Frame tokens: 소녀의 맞이했어요. 소녀는 왕궁에서 언니들을 무도회에 무도회에 드레스로 할머니는 왕자님도 무도회장에 않고,신데렐라하고만 왕궁을 결혼하겠어요. 왕궁으로 결혼하여 살았대요. \n",
            "\n",
            "Similarity : 0.4716061490671215\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.2414064407348633 Generator / grammar loss:-0.1510217934846878   similarity loss:-0.12676286697387695\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "어느 얼마 소녀보다 왔어요. 착한 소녀는 하녀처럼 종일 잠시 어느 왕궁에서 무도회가 열렸어요. 집에도 왔어요. 이번에는 그랬더니 반짝이는 드레스로 신데렐라, 할머니는 주었어요. 왕자님도 빼았겼어요. 왕자님은 무도회장에 다른 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 추느라 땡, 소리에 왕궁을 하지만 뛰쫓아오던 층계에서 구두 가서 결혼하겠어요. 유리 언니들은 구두를 발에 신하들은 신데렐라를 왕궁으로 데리고 살았대요. \n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body   ending       var     total  \\\n",
            "0  SAM+WGAN    0.162983  0.456691  0.585461  0.62915  0.005359  0.561316   \n",
            "\n",
            "    grammar  \n",
            "0  0.974781  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/327       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/324       \n",
            "Negative tokens: ['여자' '소녀가' '소녀의' '소녀가' '딸을' '새어머니와' '새어머니는' '집안일이' '신데렐라의' '신데렐라도'\n",
            " '신데렐라는' '신데렐라,' '신데렐라가' '할머니가' '무도회에' '할머니가' '마차로' '신데렐라의' '신데렐라,'\n",
            " '신데렐라에게' '신데렐라,' '흰말은' '신데렐라에게' '신데렐라는' '신데렐라는' '신데렐라가' '구두' '구두를'\n",
            " '신데렐라를' '구두' '왕자님은' '구두를' '구두의' '언니들은' '구두를' '신데렐라가' '신데렐라는' '신데렐라의'\n",
            " '신데렐라를' '신데렐라는']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 325/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 324/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 323/324       \n",
            "Peak count: 17\n",
            "Frame tokens: 소녀의 맞이했어요. 소녀는 왕궁에서 언니들을 무도회에 무도회에 드레스로 할머니는 왕자님도 무도회장에 않고,신데렐라하고만 왕궁을 결혼하겠어요. 왕궁으로 결혼하여 살았대요. \n",
            "\n",
            "Similarity : 0.4716061490671215\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:1.8327347040176392 Generator / grammar loss:-0.0799584835767746   similarity loss:-0.09672418981790543\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            " 집에 그러던 소녀의 병이들어 맞이했어요. 새어머니는 새어머니와 언니들은 고약한 심술쟁이들이었어요. 게 못마땅했어요. 아버지마저 돌아가셨어요. 소녀는 하루 날, 왕궁에서 새어머니는 언니들을 떠났어요. 무도회에 가고 남은 신데렐라, 무도회에 웃고 내가 한개와 화려한 마차로 변했어요. 건드렸어요. 소리에 결혼하겠어요. 유리 구두의 온 오므려도 늘려도 한눈에 수 신데렐라는 건넨 유리 유리 왕궁으로 결혼하여 살았대요. \n",
            "--------------------------------------------------\n",
            "     method  comp ratio    intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.160221  0.63552  0.561807  0.615116  0.000966  0.587546   \n",
            "\n",
            "    grammar  \n",
            "0  0.948956  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/327       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/324       \n",
            "Negative tokens: ['여자' '소녀가' '소녀의' '소녀가' '딸을' '새어머니와' '새어머니는' '집안일이' '신데렐라의' '신데렐라도'\n",
            " '신데렐라는' '신데렐라,' '신데렐라가' '할머니가' '무도회에' '할머니가' '마차로' '신데렐라의' '신데렐라,'\n",
            " '신데렐라에게' '신데렐라,' '흰말은' '신데렐라에게' '신데렐라는' '신데렐라는' '신데렐라가' '구두' '구두를'\n",
            " '신데렐라를' '구두' '왕자님은' '구두를' '구두의' '언니들은' '구두를' '신데렐라가' '신데렐라는' '신데렐라의'\n",
            " '신데렐라를' '신데렐라는']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 325/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 324/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 323/324       \n",
            "Peak count: 17\n",
            "Frame tokens: 소녀의 맞이했어요. 소녀는 왕궁에서 언니들을 무도회에 무도회에 드레스로 할머니는 왕자님도 무도회장에 않고,신데렐라하고만 왕궁을 결혼하겠어요. 왕궁으로 결혼하여 살았대요. \n",
            "\n",
            "Similarity : 0.4716061490671215\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.3507466316223145 Generator / grammar loss:-0.15909110009670258   similarity loss:-0.12365008145570755\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "옛날 여자 무럭무럭 되었어요. 소녀의 세상을 말았어요. 아버지는 소녀가 새어머니를 맞이했어요. 새어머니는 왔어요. 자기 소녀는 해도 없는 집안일이 지칠때면 잠시 왕궁에서 무도회가 왔어요. 언니들을 떠났어요. 무도회에 너도 무도회에 가고 고개를 호박 할머니가 외웠어요. 뛰쫓아오던 왕자님은 짝을 주웠어요. 임금님께 결혼하겠어요. 언니들은 볼 수 있나요? 건넨 유리 구두는 신데렐라의 왕궁으로 신데렐라는 결혼하여 살았대요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.161602  0.575793  0.526493  0.578339  0.000569  0.546172   \n",
            "\n",
            "    grammar  \n",
            "0  0.992331  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/327       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/324       \n",
            "Negative tokens: ['여자' '소녀가' '소녀의' '소녀가' '딸을' '새어머니와' '새어머니는' '집안일이' '신데렐라의' '신데렐라도'\n",
            " '신데렐라는' '신데렐라,' '신데렐라가' '할머니가' '무도회에' '할머니가' '마차로' '신데렐라의' '신데렐라,'\n",
            " '신데렐라에게' '신데렐라,' '흰말은' '신데렐라에게' '신데렐라는' '신데렐라는' '신데렐라가' '구두' '구두를'\n",
            " '신데렐라를' '구두' '왕자님은' '구두를' '구두의' '언니들은' '구두를' '신데렐라가' '신데렐라는' '신데렐라의'\n",
            " '신데렐라를' '신데렐라는']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 325/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 324/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 323/324       \n",
            "Peak count: 17\n",
            "Frame tokens: 소녀의 맞이했어요. 소녀는 왕궁에서 언니들을 무도회에 무도회에 드레스로 할머니는 왕자님도 무도회장에 않고,신데렐라하고만 왕궁을 결혼하겠어요. 왕궁으로 결혼하여 살았대요. \n",
            "\n",
            "Similarity : 0.4716061490671215\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:1.6874799728393555 Generator / grammar loss:-0.06429622322320938   similarity loss:-0.09580638259649277\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "아기가 무럭무럭 그러던 소녀의 어머니가 남은 새어머니를 맞이했어요. 왔어요. 그러나 새어머니와 소녀가 예쁘고 이번에는 소녀는 하녀처럼 하루 했어요. 왕궁에서 무도회가 왔어요. 언니들을 무도회에 가고 싶었어요. 훌쩍훌쩍 무도회에 보내주마 이번에는 변했답니다. 내밀어 주었어요. 가는 땡, 유리 주인을 오므려도 보고, 보았지만 한눈에 너무 그때, 저도 한번 신데렐라는 유리 구두는 왕궁으로 데리고 결혼하여 살았대요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN     0.15884  0.536737  0.562781  0.618586  0.001166  0.565045   \n",
            "\n",
            "    grammar  \n",
            "0  0.965325  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/327       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/324       \n",
            "Negative tokens: ['여자' '소녀가' '소녀의' '소녀가' '딸을' '새어머니와' '새어머니는' '집안일이' '신데렐라의' '신데렐라도'\n",
            " '신데렐라는' '신데렐라,' '신데렐라가' '할머니가' '무도회에' '할머니가' '마차로' '신데렐라의' '신데렐라,'\n",
            " '신데렐라에게' '신데렐라,' '흰말은' '신데렐라에게' '신데렐라는' '신데렐라는' '신데렐라가' '구두' '구두를'\n",
            " '신데렐라를' '구두' '왕자님은' '구두를' '구두의' '언니들은' '구두를' '신데렐라가' '신데렐라는' '신데렐라의'\n",
            " '신데렐라를' '신데렐라는']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 325/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 324/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 323/324       \n",
            "Peak count: 17\n",
            "Frame tokens: 소녀의 맞이했어요. 소녀는 왕궁에서 언니들을 무도회에 무도회에 드레스로 할머니는 왕자님도 무도회장에 않고,신데렐라하고만 왕궁을 결혼하겠어요. 왕궁으로 결혼하여 살았대요. \n",
            "\n",
            "Similarity : 0.4716061490671215\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.3183181285858154 Generator / grammar loss:-0.1601250022649765   similarity loss:-0.1280202567577362\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "그러던 소녀의 걱정되었어요. 맞이했어요. 두 새어머니와 소녀는 도맡아 앉아서 잠시 왕궁에서 초대장이 왔어요. 언니들을 떠났어요. 무도회에 신데렐라는 훌쩍훌쩍 무도회에 빙그레 건드리자, 생쥐와 흰말로, 예쁜 드레스로 바뀌웠어요. 내밀어 보거라. 할머니는 빛나는 신데렐라, 열두시가 처음대로 돌아간단다. 돼. 그러니까 왕자님도 무도회장에 쳐다보지도 않고,신데렐라하고만 춤을 열두 놀랐어요. 결혼하겠어요. 유리 구두는 한번 신데렐라의 왕궁으로 결혼하여 살았대요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.176105  0.481326  0.622961  0.622324  0.004438  0.588995   \n",
            "\n",
            "    grammar  \n",
            "0  0.983208  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/327       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/324       \n",
            "Negative tokens: ['여자' '소녀가' '소녀의' '소녀가' '딸을' '새어머니와' '새어머니는' '집안일이' '신데렐라의' '신데렐라도'\n",
            " '신데렐라는' '신데렐라,' '신데렐라가' '할머니가' '무도회에' '할머니가' '마차로' '신데렐라의' '신데렐라,'\n",
            " '신데렐라에게' '신데렐라,' '흰말은' '신데렐라에게' '신데렐라는' '신데렐라는' '신데렐라가' '구두' '구두를'\n",
            " '신데렐라를' '구두' '왕자님은' '구두를' '구두의' '언니들은' '구두를' '신데렐라가' '신데렐라는' '신데렐라의'\n",
            " '신데렐라를' '신데렐라는']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 325/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 324/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 323/324       \n",
            "Peak count: 17\n",
            "Frame tokens: 소녀의 맞이했어요. 소녀는 왕궁에서 언니들을 무도회에 무도회에 드레스로 할머니는 왕자님도 무도회장에 않고,신데렐라하고만 왕궁을 결혼하겠어요. 왕궁으로 결혼하여 살았대요. \n",
            "\n",
            "Similarity : 0.4716061490671215\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:1.843947172164917 Generator / grammar loss:-0.08543117344379425   similarity loss:-0.10106825828552246\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            " 집에 태어났어요. 그러던 소녀의 병이들어 맞이했어요. 새어머니는 새어머니와 언니들은 고약한 심술쟁이들이었어요. 게 못마땅했어요. 아버지마저 돌아가셨어요. 소녀는 하루 날, 왕궁에서 새어머니는 언니들을 무도회에 가고 남은 신데렐라, 무도회에 웃고 내가 한개와 구해 화려한 마차로 변했어요. 건드렸어요. 결혼하겠어요. 유리 구두의 온 오므려도 늘려도 한눈에 수 신데렐라는 건넨 유리 유리 왕궁으로 결혼하여 살았대요. \n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro     body    ending       var    total  \\\n",
            "0  SAM+WGAN    0.160221  0.612693  0.53888  0.617664  0.001298  0.56852   \n",
            "\n",
            "    grammar  \n",
            "0  0.976946  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/327       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/324       \n",
            "Negative tokens: ['여자' '소녀가' '소녀의' '소녀가' '딸을' '새어머니와' '새어머니는' '집안일이' '신데렐라의' '신데렐라도'\n",
            " '신데렐라는' '신데렐라,' '신데렐라가' '할머니가' '무도회에' '할머니가' '마차로' '신데렐라의' '신데렐라,'\n",
            " '신데렐라에게' '신데렐라,' '흰말은' '신데렐라에게' '신데렐라는' '신데렐라는' '신데렐라가' '구두' '구두를'\n",
            " '신데렐라를' '구두' '왕자님은' '구두를' '구두의' '언니들은' '구두를' '신데렐라가' '신데렐라는' '신데렐라의'\n",
            " '신데렐라를' '신데렐라는']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 325/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 324/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 323/324       \n",
            "Peak count: 17\n",
            "Frame tokens: 소녀의 맞이했어요. 소녀는 왕궁에서 언니들을 무도회에 무도회에 드레스로 할머니는 왕자님도 무도회장에 않고,신데렐라하고만 왕궁을 결혼하겠어요. 왕궁으로 결혼하여 살았대요. \n",
            "\n",
            "Similarity : 0.4716061490671215\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.3201866149902344 Generator / grammar loss:-0.15955817699432373   similarity loss:-0.1272616982460022\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "옛날 여자 무럭무럭 소녀의 세상을 말았어요. 소녀의 아버지는 새어머니를 맞이했어요. 새어머니는 왔어요. 자기 소녀는 해도 지칠때면 잠시 왕궁에서 무도회가 왔어요. 새어머니는 언니들을 떠났어요. 무도회에 너도 무도회에 가고 고개를 호박 할머니가 외웠어요. 도마뱀은 도마뱀으로 춤을 뛰쫓아오던 왕자님은 짝을 주웠어요. 임금님께 결혼하겠어요. 언니들은 신어 있나요? 건넨 유리 구두는 신데렐라의 왕궁으로 신데렐라는 결혼하여 살았대요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.165055  0.569154  0.570789  0.597522  0.000169  0.574466   \n",
            "\n",
            "    grammar  \n",
            "0  0.992447  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/327       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/324       \n",
            "Negative tokens: ['여자' '소녀가' '소녀의' '소녀가' '딸을' '새어머니와' '새어머니는' '집안일이' '신데렐라의' '신데렐라도'\n",
            " '신데렐라는' '신데렐라,' '신데렐라가' '할머니가' '무도회에' '할머니가' '마차로' '신데렐라의' '신데렐라,'\n",
            " '신데렐라에게' '신데렐라,' '흰말은' '신데렐라에게' '신데렐라는' '신데렐라는' '신데렐라가' '구두' '구두를'\n",
            " '신데렐라를' '구두' '왕자님은' '구두를' '구두의' '언니들은' '구두를' '신데렐라가' '신데렐라는' '신데렐라의'\n",
            " '신데렐라를' '신데렐라는']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 325/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 324/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 323/324       \n",
            "Peak count: 17\n",
            "Frame tokens: 소녀의 맞이했어요. 소녀는 왕궁에서 언니들을 무도회에 무도회에 드레스로 할머니는 왕자님도 무도회장에 않고,신데렐라하고만 왕궁을 결혼하겠어요. 왕궁으로 결혼하여 살았대요. \n",
            "\n",
            "Similarity : 0.4716061490671215\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.218899965286255 Generator / grammar loss:-0.14615286886692047   similarity loss:-0.12417483329772949\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "아기가 무럭무럭 고운 그러던 소녀의 어머니가 새어머니를 맞이했어요. 그러나 새어머니와 소녀가 예쁘고 이번에는 소녀는 하녀처럼 하루 난롯가에 쉬곤 했지요. 왕궁에서 무도회가 왔어요. 언니들을 무도회에 가고 싶었어요. 훌쩍훌쩍 무도회에 보내주마 외웠어요. 이번에는 내밀어 주었어요. 결혼하겠어요. 유리 주인을 오므려도 보고, 보았지만 한눈에 너무 그때, 저도 한번 신데렐라는 유리 구두는 왕궁으로 데리고 결혼하여 살았대요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var    total  \\\n",
            "0  SAM+WGAN    0.161602  0.569394  0.557412  0.638851  0.001289  0.57267   \n",
            "\n",
            "    grammar  \n",
            "0  0.989357  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/327       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/324       \n",
            "Negative tokens: ['여자' '소녀가' '소녀의' '소녀가' '딸을' '새어머니와' '새어머니는' '집안일이' '신데렐라의' '신데렐라도'\n",
            " '신데렐라는' '신데렐라,' '신데렐라가' '할머니가' '무도회에' '할머니가' '마차로' '신데렐라의' '신데렐라,'\n",
            " '신데렐라에게' '신데렐라,' '흰말은' '신데렐라에게' '신데렐라는' '신데렐라는' '신데렐라가' '구두' '구두를'\n",
            " '신데렐라를' '구두' '왕자님은' '구두를' '구두의' '언니들은' '구두를' '신데렐라가' '신데렐라는' '신데렐라의'\n",
            " '신데렐라를' '신데렐라는']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 325/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 324/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 323/324       \n",
            "Peak count: 17\n",
            "Frame tokens: 소녀의 맞이했어요. 소녀는 왕궁에서 언니들을 무도회에 무도회에 드레스로 할머니는 왕자님도 무도회장에 않고,신데렐라하고만 왕궁을 결혼하겠어요. 왕궁으로 결혼하여 살았대요. \n",
            "\n",
            "Similarity : 0.4716061490671215\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.3246662616729736 Generator / grammar loss:-0.16558831930160522   similarity loss:-0.1328319013118744\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "그러던 소녀의 걱정되었어요. 맞이했어요. 두 새어머니와 소녀는 도맡아 앉아서 잠시 왕궁에서 초대장이 왔어요. 언니들을 떠났어요. 무도회에 신데렐라는 훌쩍훌쩍 무도회에 건드리자, 생쥐와 흰말로, 예쁜 드레스로 바뀌웠어요. 내밀어 보거라. 할머니는 빛나는 신데렐라, 열두시가 처음대로 돌아간단다. 돼. 그러니까 왕자님도 무도회장에 쳐다보지도 않고,신데렐라하고만 춤을 열두 놀랐어요. 왕궁을 결혼하겠어요. 유리 구두는 한번 신데렐라의 왕궁으로 결혼하여 살았대요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body   ending       var     total  \\\n",
            "0  SAM+WGAN    0.176105  0.481326  0.624498  0.62301  0.004508  0.590034   \n",
            "\n",
            "    grammar  \n",
            "0  0.980627  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/327       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/324       \n",
            "Negative tokens: ['여자' '소녀가' '소녀의' '소녀가' '딸을' '새어머니와' '새어머니는' '집안일이' '신데렐라의' '신데렐라도'\n",
            " '신데렐라는' '신데렐라,' '신데렐라가' '할머니가' '무도회에' '할머니가' '마차로' '신데렐라의' '신데렐라,'\n",
            " '신데렐라에게' '신데렐라,' '흰말은' '신데렐라에게' '신데렐라는' '신데렐라는' '신데렐라가' '구두' '구두를'\n",
            " '신데렐라를' '구두' '왕자님은' '구두를' '구두의' '언니들은' '구두를' '신데렐라가' '신데렐라는' '신데렐라의'\n",
            " '신데렐라를' '신데렐라는']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 325/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 324/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 323/324       \n",
            "Peak count: 17\n",
            "Frame tokens: 소녀의 맞이했어요. 소녀는 왕궁에서 언니들을 무도회에 무도회에 드레스로 할머니는 왕자님도 무도회장에 않고,신데렐라하고만 왕궁을 결혼하겠어요. 왕궁으로 결혼하여 살았대요. \n",
            "\n",
            "Similarity : 0.4716061490671215\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:1.9519212245941162 Generator / grammar loss:-0.10843615978956223   similarity loss:-0.11324495822191238\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            " 여자 예쁘고 고운 그러던 소녀의 병이들어 소녀가 새어머니를 맞이했어요. 데리고 왔어요. 고약한 새어머니는 못마땅했어요. 소녀는 왕궁에서 신데렐라의 초대장이 왔어요. 언니들을 데리고 무도회에 혼자 무도회에 할머니가 지팡이로 건드리자, 호박이 도마뱀은 멋진 드레스로 발을 보거라. 할머니는 해. 왕자님도 무도회장에 놀랐어요. 왕궁을 결혼하겠어요. 구두를 늘려도 구두는 구두를 신데렐라의 왕궁으로 뒤 결혼하여 오래오래 살았대요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.163674  0.582207  0.580077  0.647102  0.000968  0.590786   \n",
            "\n",
            "    grammar  \n",
            "0  0.956387  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/327       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/324       \n",
            "Negative tokens: ['여자' '소녀가' '소녀의' '소녀가' '딸을' '새어머니와' '새어머니는' '집안일이' '신데렐라의' '신데렐라도'\n",
            " '신데렐라는' '신데렐라,' '신데렐라가' '할머니가' '무도회에' '할머니가' '마차로' '신데렐라의' '신데렐라,'\n",
            " '신데렐라에게' '신데렐라,' '흰말은' '신데렐라에게' '신데렐라는' '신데렐라는' '신데렐라가' '구두' '구두를'\n",
            " '신데렐라를' '구두' '왕자님은' '구두를' '구두의' '언니들은' '구두를' '신데렐라가' '신데렐라는' '신데렐라의'\n",
            " '신데렐라를' '신데렐라는']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 325/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 324/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 323/324       \n",
            "Peak count: 17\n",
            "Frame tokens: 소녀의 맞이했어요. 소녀는 왕궁에서 언니들을 무도회에 무도회에 드레스로 할머니는 왕자님도 무도회장에 않고,신데렐라하고만 왕궁을 결혼하겠어요. 왕궁으로 결혼하여 살았대요. \n",
            "\n",
            "Similarity : 0.4716061490671215\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:1.9356273412704468 Generator / grammar loss:-0.09899678826332092   similarity loss:-0.10543627291917801\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "옛날 여자 무럭무럭 되었어요. 소녀의 소녀의 아버지는 소녀가 새어머니를 맞이했어요. 새어머니는 왔어요. 자기 소녀는 해도 없는 집안일이 지칠때면 잠시 왕궁에서 무도회가 왔어요. 새어머니는 언니들을 떠났어요. 무도회에 너도 무도회에 가고 고개를 호박 할머니가 외웠어요. 도마뱀으로 뛰쫓아오던 왕자님은 짝을 주웠어요. 임금님께 결혼하겠어요. 언니들은 신데렐라가 볼 유리 구두는 신데렐라의 왕궁으로 뒤 신데렐라는 결혼하여 살았대요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.164365  0.586528  0.562263  0.583875  0.000118  0.571354   \n",
            "\n",
            "    grammar  \n",
            "0  0.983444  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/327       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/324       \n",
            "Negative tokens: ['여자' '소녀가' '소녀의' '소녀가' '딸을' '새어머니와' '새어머니는' '집안일이' '신데렐라의' '신데렐라도'\n",
            " '신데렐라는' '신데렐라,' '신데렐라가' '할머니가' '무도회에' '할머니가' '마차로' '신데렐라의' '신데렐라,'\n",
            " '신데렐라에게' '신데렐라,' '흰말은' '신데렐라에게' '신데렐라는' '신데렐라는' '신데렐라가' '구두' '구두를'\n",
            " '신데렐라를' '구두' '왕자님은' '구두를' '구두의' '언니들은' '구두를' '신데렐라가' '신데렐라는' '신데렐라의'\n",
            " '신데렐라를' '신데렐라는']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 325/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 324/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 323/324       \n",
            "Peak count: 17\n",
            "Frame tokens: 소녀의 맞이했어요. 소녀는 왕궁에서 언니들을 무도회에 무도회에 드레스로 할머니는 왕자님도 무도회장에 않고,신데렐라하고만 왕궁을 결혼하겠어요. 왕궁으로 결혼하여 살았대요. \n",
            "\n",
            "Similarity : 0.4716061490671215\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:1.5721518993377686 Generator / grammar loss:-0.048676107078790665   similarity loss:-0.0921320989727974\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "아기가 무럭무럭 고운 그러던 소녀의 어머니가 새어머니를 맞이했어요. 왔어요. 그러나 새어머니와 소녀가 예쁘고 게 이번에는 소녀는 하녀처럼 하루 난롯가에 쉬곤 했지요. 왕궁에서 무도회가 왔어요. 언니들을 무도회에 가고 싶었어요. 훌쩍훌쩍 무도회에 보내주마 이번에는 변했답니다. 결혼하겠어요. 유리 주인을 오므려도 늘려도 보았지만 한눈에 너무 그때, 저도 한번 신데렐라는 유리 구두는 왕궁으로 데리고 결혼하여 살았대요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro     body    ending      var     total  \\\n",
            "0  SAM+WGAN    0.160221  0.565405  0.56326  0.614923  0.00057  0.571635   \n",
            "\n",
            "    grammar  \n",
            "0  0.958366  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/327       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/324       \n",
            "Negative tokens: ['여자' '소녀가' '소녀의' '소녀가' '딸을' '새어머니와' '새어머니는' '집안일이' '신데렐라의' '신데렐라도'\n",
            " '신데렐라는' '신데렐라,' '신데렐라가' '할머니가' '무도회에' '할머니가' '마차로' '신데렐라의' '신데렐라,'\n",
            " '신데렐라에게' '신데렐라,' '흰말은' '신데렐라에게' '신데렐라는' '신데렐라는' '신데렐라가' '구두' '구두를'\n",
            " '신데렐라를' '구두' '왕자님은' '구두를' '구두의' '언니들은' '구두를' '신데렐라가' '신데렐라는' '신데렐라의'\n",
            " '신데렐라를' '신데렐라는']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 325/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 324/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 323/324       \n",
            "Peak count: 17\n",
            "Frame tokens: 소녀의 맞이했어요. 소녀는 왕궁에서 언니들을 무도회에 무도회에 드레스로 할머니는 왕자님도 무도회장에 않고,신데렐라하고만 왕궁을 결혼하겠어요. 왕궁으로 결혼하여 살았대요. \n",
            "\n",
            "Similarity : 0.4716061490671215\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.3310317993164062 Generator / grammar loss:-0.17058806121349335   similarity loss:-0.13717754185199738\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "그러던 소녀의 걱정되었어요. 맞이했어요. 두 새어머니와 소녀는 도맡아 앉아서 잠시 왕궁에서 초대장이 왔어요. 언니들을 떠났어요. 무도회에 신데렐라는 훌쩍훌쩍 무도회에 건드리자, 생쥐와 흰말로, 예쁜 드레스로 바뀌웠어요. 내밀어 보거라. 할머니는 빛나는 신데렐라, 열두시가 처음대로 돌아간단다. 돼. 그러니까 왕자님도 무도회장에 쳐다보지도 않고,신데렐라하고만 춤을 열두 놀랐어요. 왕궁을 결혼하겠어요. 유리 구두는 한번 신데렐라의 왕궁으로 결혼하여 살았대요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body   ending       var     total  \\\n",
            "0  SAM+WGAN    0.176105  0.481326  0.624498  0.62301  0.004508  0.590034   \n",
            "\n",
            "    grammar  \n",
            "0  0.980627  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/327       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/324       \n",
            "Negative tokens: ['여자' '소녀가' '소녀의' '소녀가' '딸을' '새어머니와' '새어머니는' '집안일이' '신데렐라의' '신데렐라도'\n",
            " '신데렐라는' '신데렐라,' '신데렐라가' '할머니가' '무도회에' '할머니가' '마차로' '신데렐라의' '신데렐라,'\n",
            " '신데렐라에게' '신데렐라,' '흰말은' '신데렐라에게' '신데렐라는' '신데렐라는' '신데렐라가' '구두' '구두를'\n",
            " '신데렐라를' '구두' '왕자님은' '구두를' '구두의' '언니들은' '구두를' '신데렐라가' '신데렐라는' '신데렐라의'\n",
            " '신데렐라를' '신데렐라는']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 325/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 324/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 323/324       \n",
            "Peak count: 17\n",
            "Frame tokens: 소녀의 맞이했어요. 소녀는 왕궁에서 언니들을 무도회에 무도회에 드레스로 할머니는 왕자님도 무도회장에 않고,신데렐라하고만 왕궁을 결혼하겠어요. 왕궁으로 결혼하여 살았대요. \n",
            "\n",
            "Similarity : 0.4716061490671215\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:1.9516862630844116 Generator / grammar loss:-0.11171410232782364   similarity loss:-0.11654641479253769\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            " 여자 예쁘고 고운 그러던 소녀의 병이들어 소녀가 새어머니를 맞이했어요. 데리고 왔어요. 고약한 새어머니는 못마땅했어요. 소녀는 왕궁에서 신데렐라의 초대장이 왔어요. 언니들을 데리고 무도회에 혼자 무도회에 할머니가 지팡이로 건드리자, 호박이 도마뱀은 멋진 드레스로 발을 보거라. 할머니는 해. 왕자님도 무도회장에 놀랐어요. 왕궁을 결혼하겠어요. 구두를 늘려도 구두는 구두를 신데렐라의 왕궁으로 뒤 결혼하여 오래오래 살았대요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.163674  0.582207  0.580077  0.647102  0.000968  0.590786   \n",
            "\n",
            "    grammar  \n",
            "0  0.956387  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/327       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/324       \n",
            "Negative tokens: ['여자' '소녀가' '소녀의' '소녀가' '딸을' '새어머니와' '새어머니는' '집안일이' '신데렐라의' '신데렐라도'\n",
            " '신데렐라는' '신데렐라,' '신데렐라가' '할머니가' '무도회에' '할머니가' '마차로' '신데렐라의' '신데렐라,'\n",
            " '신데렐라에게' '신데렐라,' '흰말은' '신데렐라에게' '신데렐라는' '신데렐라는' '신데렐라가' '구두' '구두를'\n",
            " '신데렐라를' '구두' '왕자님은' '구두를' '구두의' '언니들은' '구두를' '신데렐라가' '신데렐라는' '신데렐라의'\n",
            " '신데렐라를' '신데렐라는']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 325/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 324/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 323/324       \n",
            "Peak count: 17\n",
            "Frame tokens: 소녀의 맞이했어요. 소녀는 왕궁에서 언니들을 무도회에 무도회에 드레스로 할머니는 왕자님도 무도회장에 않고,신데렐라하고만 왕궁을 결혼하겠어요. 왕궁으로 결혼하여 살았대요. \n",
            "\n",
            "Similarity : 0.4716061490671215\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.2600440979003906 Generator / grammar loss:-0.14698845148086548   similarity loss:-0.12083599716424942\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "태어났어요. 아기는 예쁘고 그러던 소녀의 어머니가 맞이했어요. 성질이 예쁘고 소녀는 하루 닦고, 잠시 왕궁에서 왔어요. 신데렐라, 빙그레 이번에는 모든게 열두 왕자님도 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 벗겨졌어요. 유리 이 결혼하겠어요. 돌아다녔어요. 보고, 구두를 보았지만 보기에도 구두는 너무 작았어요. 다가와 신어 건넨 신었어요, 꼭 왕궁으로 그 뒤 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio   intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN     0.15953  0.5208  0.537928  0.609363  0.001471  0.544703   \n",
            "\n",
            "    grammar  \n",
            "0  0.965139  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/327       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/324       \n",
            "Negative tokens: ['여자' '소녀가' '소녀의' '소녀가' '딸을' '새어머니와' '새어머니는' '집안일이' '신데렐라의' '신데렐라도'\n",
            " '신데렐라는' '신데렐라,' '신데렐라가' '할머니가' '무도회에' '할머니가' '마차로' '신데렐라의' '신데렐라,'\n",
            " '신데렐라에게' '신데렐라,' '흰말은' '신데렐라에게' '신데렐라는' '신데렐라는' '신데렐라가' '구두' '구두를'\n",
            " '신데렐라를' '구두' '왕자님은' '구두를' '구두의' '언니들은' '구두를' '신데렐라가' '신데렐라는' '신데렐라의'\n",
            " '신데렐라를' '신데렐라는']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 325/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 324/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 323/324       \n",
            "Peak count: 17\n",
            "Frame tokens: 소녀의 맞이했어요. 소녀는 왕궁에서 언니들을 무도회에 무도회에 드레스로 할머니는 왕자님도 무도회장에 않고,신데렐라하고만 왕궁을 결혼하겠어요. 왕궁으로 결혼하여 살았대요. \n",
            "\n",
            "Similarity : 0.4716061490671215\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.1549038887023926 Generator / grammar loss:-0.1462133228778839   similarity loss:-0.13069185614585876\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "아기가 무럭무럭 그러던 소녀의 어머니가 새어머니를 맞이했어요. 그러나 새어머니와 소녀가 예쁘고 이번에는 소녀는 하녀처럼 하루 했어요. 난롯가에 쉬곤 했지요. 왕궁에서 무도회가 왔어요. 언니들을 무도회에 가고 싶었어요. 훌쩍훌쩍 무도회에 보내주마 이번에는 변했답니다. 왕자님도 결혼하겠어요. 유리 주인을 언니들은 오므려도 보고, 늘려도 보았지만 너무 그때, 저도 한번 신데렐라는 유리 구두는 왕궁으로 데리고 결혼하여 살았대요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio    intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.163674  0.59085  0.536649  0.609955  0.000964  0.560766   \n",
            "\n",
            "    grammar  \n",
            "0  0.990198  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/327       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/324       \n",
            "Negative tokens: ['여자' '소녀가' '소녀의' '소녀가' '딸을' '새어머니와' '새어머니는' '집안일이' '신데렐라의' '신데렐라도'\n",
            " '신데렐라는' '신데렐라,' '신데렐라가' '할머니가' '무도회에' '할머니가' '마차로' '신데렐라의' '신데렐라,'\n",
            " '신데렐라에게' '신데렐라,' '흰말은' '신데렐라에게' '신데렐라는' '신데렐라는' '신데렐라가' '구두' '구두를'\n",
            " '신데렐라를' '구두' '왕자님은' '구두를' '구두의' '언니들은' '구두를' '신데렐라가' '신데렐라는' '신데렐라의'\n",
            " '신데렐라를' '신데렐라는']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 325/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 324/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 323/324       \n",
            "Peak count: 17\n",
            "Frame tokens: 소녀의 맞이했어요. 소녀는 왕궁에서 언니들을 무도회에 무도회에 드레스로 할머니는 왕자님도 무도회장에 않고,신데렐라하고만 왕궁을 결혼하겠어요. 왕궁으로 결혼하여 살았대요. \n",
            "\n",
            "Similarity : 0.4716061490671215\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.337256669998169 Generator / grammar loss:-0.17558735609054565   similarity loss:-0.14153644442558289\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "그러던 소녀의 걱정되었어요. 맞이했어요. 두 새어머니와 소녀는 도맡아 앉아서 잠시 왕궁에서 초대장이 왔어요. 언니들을 떠났어요. 무도회에 신데렐라는 훌쩍훌쩍 무도회에 건드리자, 생쥐와 흰말로, 예쁜 드레스로 바뀌웠어요. 내밀어 보거라. 할머니는 빛나는 신데렐라, 열두시가 처음대로 돌아간단다. 돼. 그러니까 왕자님도 무도회장에 쳐다보지도 않고,신데렐라하고만 춤을 열두 놀랐어요. 왕궁을 결혼하겠어요. 유리 구두는 한번 신데렐라의 왕궁으로 결혼하여 살았대요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body   ending       var     total  \\\n",
            "0  SAM+WGAN    0.176105  0.481326  0.624498  0.62301  0.004508  0.590034   \n",
            "\n",
            "    grammar  \n",
            "0  0.980627  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/327       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/324       \n",
            "Negative tokens: ['여자' '소녀가' '소녀의' '소녀가' '딸을' '새어머니와' '새어머니는' '집안일이' '신데렐라의' '신데렐라도'\n",
            " '신데렐라는' '신데렐라,' '신데렐라가' '할머니가' '무도회에' '할머니가' '마차로' '신데렐라의' '신데렐라,'\n",
            " '신데렐라에게' '신데렐라,' '흰말은' '신데렐라에게' '신데렐라는' '신데렐라는' '신데렐라가' '구두' '구두를'\n",
            " '신데렐라를' '구두' '왕자님은' '구두를' '구두의' '언니들은' '구두를' '신데렐라가' '신데렐라는' '신데렐라의'\n",
            " '신데렐라를' '신데렐라는']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 325/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 324/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 323/324       \n",
            "Peak count: 17\n",
            "Frame tokens: 소녀의 맞이했어요. 소녀는 왕궁에서 언니들을 무도회에 무도회에 드레스로 할머니는 왕자님도 무도회장에 않고,신데렐라하고만 왕궁을 결혼하겠어요. 왕궁으로 결혼하여 살았대요. \n",
            "\n",
            "Similarity : 0.4716061490671215\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:1.9515066146850586 Generator / grammar loss:-0.11499553173780441   similarity loss:-0.11984582990407944\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            " 여자 예쁘고 고운 그러던 소녀의 병이들어 소녀가 새어머니를 맞이했어요. 데리고 왔어요. 고약한 새어머니는 못마땅했어요. 소녀는 왕궁에서 신데렐라의 초대장이 왔어요. 언니들을 데리고 무도회에 혼자 무도회에 할머니가 지팡이로 건드리자, 호박이 도마뱀은 멋진 드레스로 발을 보거라. 할머니는 해. 왕자님도 무도회장에 놀랐어요. 왕궁을 결혼하겠어요. 구두를 늘려도 구두는 구두를 신데렐라의 왕궁으로 뒤 결혼하여 오래오래 살았대요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.163674  0.582207  0.580077  0.647102  0.000968  0.590786   \n",
            "\n",
            "    grammar  \n",
            "0  0.956387  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/327       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/324       \n",
            "Negative tokens: ['여자' '소녀가' '소녀의' '소녀가' '딸을' '새어머니와' '새어머니는' '집안일이' '신데렐라의' '신데렐라도'\n",
            " '신데렐라는' '신데렐라,' '신데렐라가' '할머니가' '무도회에' '할머니가' '마차로' '신데렐라의' '신데렐라,'\n",
            " '신데렐라에게' '신데렐라,' '흰말은' '신데렐라에게' '신데렐라는' '신데렐라는' '신데렐라가' '구두' '구두를'\n",
            " '신데렐라를' '구두' '왕자님은' '구두를' '구두의' '언니들은' '구두를' '신데렐라가' '신데렐라는' '신데렐라의'\n",
            " '신데렐라를' '신데렐라는']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 325/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 324/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 323/324       \n",
            "Peak count: 17\n",
            "Frame tokens: 소녀의 맞이했어요. 소녀는 왕궁에서 언니들을 무도회에 무도회에 드레스로 할머니는 왕자님도 무도회장에 않고,신데렐라하고만 왕궁을 결혼하겠어요. 왕궁으로 결혼하여 살았대요. \n",
            "\n",
            "Similarity : 0.4716061490671215\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.1349780559539795 Generator / grammar loss:-0.13177771866321564   similarity loss:-0.11825937777757645\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "태어났어요. 아기는 예쁘고 그러던 소녀의 어머니가 새어머니를 맞이했어요. 성질이 예쁘고 소녀는 하루 닦고, 잠시 왕궁에서 왔어요. 신데렐라는 신데렐라, 열두 왕자님도 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 벗겨졌어요. 유리 가서 이 결혼하겠어요. 돌아다녔어요. 보고, 구두를 보았지만 보기에도 구두는 너무 작았어요. 다가와 신어 건넨 신었어요, 꼭 왕궁으로 그 뒤 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.160912  0.540456  0.552397  0.612073  0.000981  0.558623   \n",
            "\n",
            "   grammar  \n",
            "0  0.95102  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/327       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/324       \n",
            "Negative tokens: ['여자' '소녀가' '소녀의' '소녀가' '딸을' '새어머니와' '새어머니는' '집안일이' '신데렐라의' '신데렐라도'\n",
            " '신데렐라는' '신데렐라,' '신데렐라가' '할머니가' '무도회에' '할머니가' '마차로' '신데렐라의' '신데렐라,'\n",
            " '신데렐라에게' '신데렐라,' '흰말은' '신데렐라에게' '신데렐라는' '신데렐라는' '신데렐라가' '구두' '구두를'\n",
            " '신데렐라를' '구두' '왕자님은' '구두를' '구두의' '언니들은' '구두를' '신데렐라가' '신데렐라는' '신데렐라의'\n",
            " '신데렐라를' '신데렐라는']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 325/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 324/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 323/324       \n",
            "Peak count: 17\n",
            "Frame tokens: 소녀의 맞이했어요. 소녀는 왕궁에서 언니들을 무도회에 무도회에 드레스로 할머니는 왕자님도 무도회장에 않고,신데렐라하고만 왕궁을 결혼하겠어요. 왕궁으로 결혼하여 살았대요. \n",
            "\n",
            "Similarity : 0.4716061490671215\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.368504524230957 Generator / grammar loss:-0.1575765609741211   similarity loss:-0.12030038982629776\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "귀여운 소녀의 그만 소녀의 소녀가 걱정되었어요. 맞이했어요. 새어머니는 그런데 소녀는 종일 쓸고, 집안일이 지칠때면 잠시 왕궁에서 왔어요. 신데렐라도 무도회에 신데렐라, 무도회에 있었어요. 호박 생쥐 두마리, 구해 그리고 지팡이로 변했어요. 이번에는 구슬 드레스로 바뀌웠어요. 할머니는 주었어요. 처음대로 돌아간단다. 왕자님도 무도회장에 않고,신데렐라하고만 왕궁을 빠져나가는데, 짝이 결혼하겠어요. 말했어요. 볼 있나요? 왕궁으로 데리고 결혼하여 살았대요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.176105  0.569656  0.618882  0.590465  0.000407  0.602786   \n",
            "\n",
            "    grammar  \n",
            "0  0.962472  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/327       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/324       \n",
            "Negative tokens: ['여자' '소녀가' '소녀의' '소녀가' '딸을' '새어머니와' '새어머니는' '집안일이' '신데렐라의' '신데렐라도'\n",
            " '신데렐라는' '신데렐라,' '신데렐라가' '할머니가' '무도회에' '할머니가' '마차로' '신데렐라의' '신데렐라,'\n",
            " '신데렐라에게' '신데렐라,' '흰말은' '신데렐라에게' '신데렐라는' '신데렐라는' '신데렐라가' '구두' '구두를'\n",
            " '신데렐라를' '구두' '왕자님은' '구두를' '구두의' '언니들은' '구두를' '신데렐라가' '신데렐라는' '신데렐라의'\n",
            " '신데렐라를' '신데렐라는']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 325/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 324/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 323/324       \n",
            "Peak count: 17\n",
            "Frame tokens: 소녀의 맞이했어요. 소녀는 왕궁에서 언니들을 무도회에 무도회에 드레스로 할머니는 왕자님도 무도회장에 않고,신데렐라하고만 왕궁을 결혼하겠어요. 왕궁으로 결혼하여 살았대요. \n",
            "\n",
            "Similarity : 0.4716061490671215\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.3433492183685303 Generator / grammar loss:-0.18058644235134125   similarity loss:-0.14590811729431152\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "그러던 소녀의 걱정되었어요. 맞이했어요. 두 새어머니와 소녀는 도맡아 앉아서 잠시 왕궁에서 초대장이 왔어요. 언니들을 떠났어요. 무도회에 신데렐라는 훌쩍훌쩍 무도회에 건드리자, 생쥐와 흰말로, 예쁜 드레스로 바뀌웠어요. 내밀어 보거라. 할머니는 빛나는 신데렐라, 열두시가 처음대로 돌아간단다. 돼. 그러니까 왕자님도 무도회장에 쳐다보지도 않고,신데렐라하고만 춤을 열두 놀랐어요. 왕궁을 결혼하겠어요. 유리 구두는 한번 신데렐라의 왕궁으로 결혼하여 살았대요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body   ending       var     total  \\\n",
            "0  SAM+WGAN    0.176105  0.481326  0.624498  0.62301  0.004508  0.590034   \n",
            "\n",
            "    grammar  \n",
            "0  0.980627  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/327       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/324       \n",
            "Negative tokens: ['여자' '소녀가' '소녀의' '소녀가' '딸을' '새어머니와' '새어머니는' '집안일이' '신데렐라의' '신데렐라도'\n",
            " '신데렐라는' '신데렐라,' '신데렐라가' '할머니가' '무도회에' '할머니가' '마차로' '신데렐라의' '신데렐라,'\n",
            " '신데렐라에게' '신데렐라,' '흰말은' '신데렐라에게' '신데렐라는' '신데렐라는' '신데렐라가' '구두' '구두를'\n",
            " '신데렐라를' '구두' '왕자님은' '구두를' '구두의' '언니들은' '구두를' '신데렐라가' '신데렐라는' '신데렐라의'\n",
            " '신데렐라를' '신데렐라는']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 325/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 324/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 323/324       \n",
            "Peak count: 17\n",
            "Frame tokens: 소녀의 맞이했어요. 소녀는 왕궁에서 언니들을 무도회에 무도회에 드레스로 할머니는 왕자님도 무도회장에 않고,신데렐라하고만 왕궁을 결혼하겠어요. 왕궁으로 결혼하여 살았대요. \n",
            "\n",
            "Similarity : 0.4716061490671215\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:1.9512490034103394 Generator / grammar loss:-0.11827398836612701   similarity loss:-0.1231500506401062\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            " 여자 예쁘고 고운 그러던 소녀의 병이들어 소녀가 새어머니를 맞이했어요. 데리고 왔어요. 고약한 새어머니는 못마땅했어요. 소녀는 왕궁에서 신데렐라의 초대장이 왔어요. 언니들을 데리고 무도회에 혼자 무도회에 할머니가 지팡이로 건드리자, 호박이 도마뱀은 멋진 드레스로 발을 보거라. 할머니는 해. 왕자님도 무도회장에 놀랐어요. 왕궁을 결혼하겠어요. 구두를 늘려도 구두는 구두를 신데렐라의 왕궁으로 뒤 결혼하여 오래오래 살았대요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.163674  0.582207  0.580077  0.647102  0.000968  0.590786   \n",
            "\n",
            "    grammar  \n",
            "0  0.956387  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/327       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/324       \n",
            "Negative tokens: ['여자' '소녀가' '소녀의' '소녀가' '딸을' '새어머니와' '새어머니는' '집안일이' '신데렐라의' '신데렐라도'\n",
            " '신데렐라는' '신데렐라,' '신데렐라가' '할머니가' '무도회에' '할머니가' '마차로' '신데렐라의' '신데렐라,'\n",
            " '신데렐라에게' '신데렐라,' '흰말은' '신데렐라에게' '신데렐라는' '신데렐라는' '신데렐라가' '구두' '구두를'\n",
            " '신데렐라를' '구두' '왕자님은' '구두를' '구두의' '언니들은' '구두를' '신데렐라가' '신데렐라는' '신데렐라의'\n",
            " '신데렐라를' '신데렐라는']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 325/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 324/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 323/324       \n",
            "Peak count: 17\n",
            "Frame tokens: 소녀의 맞이했어요. 소녀는 왕궁에서 언니들을 무도회에 무도회에 드레스로 할머니는 왕자님도 무도회장에 않고,신데렐라하고만 왕궁을 결혼하겠어요. 왕궁으로 결혼하여 살았대요. \n",
            "\n",
            "Similarity : 0.4716061490671215\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.323513984680176 Generator / grammar loss:-0.15638293325901031   similarity loss:-0.12374485284090042\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            " 태어났어요. 아기는 무럭무럭 소녀의 어머니가 병이들어 세상을 떠나고 소녀가 맞이했어요. 예쁘고 소녀는 하루 잠시 왕궁에서 왔어요. 신데렐라, 밤 왕자님도 추었어요. 가는 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 벗겨졌어요. 틈이 없었어요. 유리 이 결혼하겠어요. 돌아다녔어요. 보았지만 보기에도 구두는 너무 작았어요. 다가와 신어 건넨 유리 신었어요, 꼭 왕궁으로 뒤 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro     body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.160221  0.521859  0.59757  0.616513  0.001672  0.582348   \n",
            "\n",
            "    grammar  \n",
            "0  0.972751  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/327       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/324       \n",
            "Negative tokens: ['여자' '소녀가' '소녀의' '소녀가' '딸을' '새어머니와' '새어머니는' '집안일이' '신데렐라의' '신데렐라도'\n",
            " '신데렐라는' '신데렐라,' '신데렐라가' '할머니가' '무도회에' '할머니가' '마차로' '신데렐라의' '신데렐라,'\n",
            " '신데렐라에게' '신데렐라,' '흰말은' '신데렐라에게' '신데렐라는' '신데렐라는' '신데렐라가' '구두' '구두를'\n",
            " '신데렐라를' '구두' '왕자님은' '구두를' '구두의' '언니들은' '구두를' '신데렐라가' '신데렐라는' '신데렐라의'\n",
            " '신데렐라를' '신데렐라는']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 325/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 324/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 323/324       \n",
            "Peak count: 17\n",
            "Frame tokens: 소녀의 맞이했어요. 소녀는 왕궁에서 언니들을 무도회에 무도회에 드레스로 할머니는 왕자님도 무도회장에 않고,신데렐라하고만 왕궁을 결혼하겠어요. 왕궁으로 결혼하여 살았대요. \n",
            "\n",
            "Similarity : 0.4716061490671215\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.334571123123169 Generator / grammar loss:-0.16208986937999725   similarity loss:-0.12831531465053558\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "그만 소녀가 맞이했어요. 새어머니는 그런데 소녀는 종일 쓸고, 없는 집안일이 지칠때면 잠시 왕궁에서 왔어요. 신데렐라도 무도회에 신데렐라, 무도회에 있었어요. 호박 생쥐 두마리, 구해 그리고 지팡이로 변했어요. 이번에는 멋진 구슬 드레스로 바뀌웠어요. 할머니는 신데렐라에게 주었어요. 처음대로 돌아간단다. 왕자님도 무도회장에 않고,신데렐라하고만 왕궁을 빠져나가는데, 짝이 결혼하겠어요. 언니들은 말했어요. 볼 있나요? 왕궁으로 데리고 결혼하여 살았대요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var    total  \\\n",
            "0  SAM+WGAN    0.174724  0.527101  0.621957  0.587758  0.001539  0.59407   \n",
            "\n",
            "   grammar  \n",
            "0  0.97614  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/327       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/324       \n",
            "Negative tokens: ['여자' '소녀가' '소녀의' '소녀가' '딸을' '새어머니와' '새어머니는' '집안일이' '신데렐라의' '신데렐라도'\n",
            " '신데렐라는' '신데렐라,' '신데렐라가' '할머니가' '무도회에' '할머니가' '마차로' '신데렐라의' '신데렐라,'\n",
            " '신데렐라에게' '신데렐라,' '흰말은' '신데렐라에게' '신데렐라는' '신데렐라는' '신데렐라가' '구두' '구두를'\n",
            " '신데렐라를' '구두' '왕자님은' '구두를' '구두의' '언니들은' '구두를' '신데렐라가' '신데렐라는' '신데렐라의'\n",
            " '신데렐라를' '신데렐라는']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 325/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 324/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 323/324       \n",
            "Peak count: 17\n",
            "Frame tokens: 소녀의 맞이했어요. 소녀는 왕궁에서 언니들을 무도회에 무도회에 드레스로 할머니는 왕자님도 무도회장에 않고,신데렐라하고만 왕궁을 결혼하겠어요. 왕궁으로 결혼하여 살았대요. \n",
            "\n",
            "Similarity : 0.4716061490671215\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.226469039916992 Generator / grammar loss:-0.17643769085407257   similarity loss:-0.15369325876235962\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "어느 귀여운 소녀의 어머니가 병이들어 세상을 후 새어머니를 맞이했어요. 착한 소녀는 왕궁에서 언니들을 무도회에 무도회에 내가 너를 주문을 그리고 마차로 생쥐와 흰말로, 도마뱀은 드레스로 발을 내밀어 보거라. 할머니는 신겨 모든게 돼. 왕자님도 무도회장에 아가씨들은 쳐다보지도 않고,신데렐라하고만 화들짝 왕궁을 한 신데렐라를 결혼하겠어요. 수 신데렐라는 건넨 왕궁으로 갔어요. 신데렐라는 결혼하여 오래오래 행복하게 살았대요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio    intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.162983  0.54155  0.569808  0.586715  0.000347  0.565624   \n",
            "\n",
            "    grammar  \n",
            "0  0.979307  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/327       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/324       \n",
            "Negative tokens: ['여자' '소녀가' '소녀의' '소녀가' '딸을' '새어머니와' '새어머니는' '집안일이' '신데렐라의' '신데렐라도'\n",
            " '신데렐라는' '신데렐라,' '신데렐라가' '할머니가' '무도회에' '할머니가' '마차로' '신데렐라의' '신데렐라,'\n",
            " '신데렐라에게' '신데렐라,' '흰말은' '신데렐라에게' '신데렐라는' '신데렐라는' '신데렐라가' '구두' '구두를'\n",
            " '신데렐라를' '구두' '왕자님은' '구두를' '구두의' '언니들은' '구두를' '신데렐라가' '신데렐라는' '신데렐라의'\n",
            " '신데렐라를' '신데렐라는']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 325/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 324/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 323/324       \n",
            "Peak count: 17\n",
            "Frame tokens: 소녀의 맞이했어요. 소녀는 왕궁에서 언니들을 무도회에 무도회에 드레스로 할머니는 왕자님도 무도회장에 않고,신데렐라하고만 왕궁을 결혼하겠어요. 왕궁으로 결혼하여 살았대요. \n",
            "\n",
            "Similarity : 0.4716061490671215\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:1.9337332248687744 Generator / grammar loss:-0.12057529389858246   similarity loss:-0.12720441818237305\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            " 여자 예쁘고 고운 그러던 소녀의 병이들어 소녀가 새어머니를 맞이했어요. 데리고 왔어요. 언니들은 고약한 새어머니는 못마땅했어요. 소녀는 왕궁에서 신데렐라의 초대장이 왔어요. 언니들을 데리고 무도회에 혼자 무도회에 할머니가 지팡이로 건드리자, 호박이 도마뱀은 멋진 드레스로 발을 보거라. 할머니는 해. 왕자님도 무도회장에 왕궁을 결혼하겠어요. 구두를 늘려도 구두는 구두를 신데렐라의 왕궁으로 뒤 결혼하여 오래오래 살았대요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.162983  0.597581  0.583926  0.650082  0.000813  0.597259   \n",
            "\n",
            "    grammar  \n",
            "0  0.931063  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/327       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/324       \n",
            "Negative tokens: ['여자' '소녀가' '소녀의' '소녀가' '딸을' '새어머니와' '새어머니는' '집안일이' '신데렐라의' '신데렐라도'\n",
            " '신데렐라는' '신데렐라,' '신데렐라가' '할머니가' '무도회에' '할머니가' '마차로' '신데렐라의' '신데렐라,'\n",
            " '신데렐라에게' '신데렐라,' '흰말은' '신데렐라에게' '신데렐라는' '신데렐라는' '신데렐라가' '구두' '구두를'\n",
            " '신데렐라를' '구두' '왕자님은' '구두를' '구두의' '언니들은' '구두를' '신데렐라가' '신데렐라는' '신데렐라의'\n",
            " '신데렐라를' '신데렐라는']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 325/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 324/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 323/324       \n",
            "Peak count: 17\n",
            "Frame tokens: 소녀의 맞이했어요. 소녀는 왕궁에서 언니들을 무도회에 무도회에 드레스로 할머니는 왕자님도 무도회장에 않고,신데렐라하고만 왕궁을 결혼하겠어요. 왕궁으로 결혼하여 살았대요. \n",
            "\n",
            "Similarity : 0.4716061490671215\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.0723979473114014 Generator / grammar loss:-0.12019409239292145   similarity loss:-0.11295114457607269\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            " 태어났어요. 아기는 무럭무럭 소녀의 어머니가 병이들어 세상을 떠나고 소녀가 맞이했어요. 자기 예쁘고 소녀는 잠시 왕궁에서 왔어요. 신데렐라, 밤 왕자님도 추었어요. 가는 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 벗겨졌어요. 틈이 없었어요. 유리 이 결혼하겠어요. 돌아다녔어요. 보고, 보았지만 보기에도 구두는 너무 작았어요. 다가와 신어 유리 신었어요, 꼭 왕궁으로 뒤 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.160912  0.523426  0.595691  0.610813  0.001454  0.580712   \n",
            "\n",
            "   grammar  \n",
            "0  0.95343  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/327       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/324       \n",
            "Negative tokens: ['여자' '소녀가' '소녀의' '소녀가' '딸을' '새어머니와' '새어머니는' '집안일이' '신데렐라의' '신데렐라도'\n",
            " '신데렐라는' '신데렐라,' '신데렐라가' '할머니가' '무도회에' '할머니가' '마차로' '신데렐라의' '신데렐라,'\n",
            " '신데렐라에게' '신데렐라,' '흰말은' '신데렐라에게' '신데렐라는' '신데렐라는' '신데렐라가' '구두' '구두를'\n",
            " '신데렐라를' '구두' '왕자님은' '구두를' '구두의' '언니들은' '구두를' '신데렐라가' '신데렐라는' '신데렐라의'\n",
            " '신데렐라를' '신데렐라는']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 325/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 324/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 323/324       \n",
            "Peak count: 17\n",
            "Frame tokens: 소녀의 맞이했어요. 소녀는 왕궁에서 언니들을 무도회에 무도회에 드레스로 할머니는 왕자님도 무도회장에 않고,신데렐라하고만 왕궁을 결혼하겠어요. 왕궁으로 결혼하여 살았대요. \n",
            "\n",
            "Similarity : 0.4716061490671215\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.3505618572235107 Generator / grammar loss:-0.16549943387508392   similarity loss:-0.13007745146751404\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "그만 맞이했어요. 새어머니는 그런데 소녀는 종일 쓸고, 없는 집안일이 지칠때면 잠시 왕궁에서 왔어요. 무도회에 신데렐라, 무도회에 있었어요. 호박 생쥐 두마리, 구해 마법사 그리고 지팡이로 변했어요. 이번에는 멋진 구슬 드레스로 바뀌웠어요. 할머니는 신데렐라에게 주었어요. 처음대로 돌아간단다. 왕자님도 무도회장에 않고,신데렐라하고만 왕궁을 빠져나가는데, 짝이 결혼하겠어요. 언니들은 말했어요. 볼 있나요? 왕궁으로 데리고 왕자님과 결혼하여 살았대요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.174033  0.519239  0.617352  0.591971  0.001729  0.590028   \n",
            "\n",
            "    grammar  \n",
            "0  0.972355  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/327       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/324       \n",
            "Negative tokens: ['여자' '소녀가' '소녀의' '소녀가' '딸을' '새어머니와' '새어머니는' '집안일이' '신데렐라의' '신데렐라도'\n",
            " '신데렐라는' '신데렐라,' '신데렐라가' '할머니가' '무도회에' '할머니가' '마차로' '신데렐라의' '신데렐라,'\n",
            " '신데렐라에게' '신데렐라,' '흰말은' '신데렐라에게' '신데렐라는' '신데렐라는' '신데렐라가' '구두' '구두를'\n",
            " '신데렐라를' '구두' '왕자님은' '구두를' '구두의' '언니들은' '구두를' '신데렐라가' '신데렐라는' '신데렐라의'\n",
            " '신데렐라를' '신데렐라는']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 325/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 324/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 323/324       \n",
            "Peak count: 17\n",
            "Frame tokens: 소녀의 맞이했어요. 소녀는 왕궁에서 언니들을 무도회에 무도회에 드레스로 할머니는 왕자님도 무도회장에 않고,신데렐라하고만 왕궁을 결혼하겠어요. 왕궁으로 결혼하여 살았대요. \n",
            "\n",
            "Similarity : 0.4716061490671215\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.263364791870117 Generator / grammar loss:-0.17886558175086975   similarity loss:-0.15237528085708618\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "어느 귀여운 소녀의 어머니가 병이들어 세상을 후 새어머니를 맞이했어요. 아버지마저 소녀는 왕궁에서 언니들을 데리고 무도회에 무도회에 내가 너를 주문을 그리고 마차로 생쥐와 흰말로, 도마뱀은 드레스로 발을 내밀어 보거라. 할머니는 신겨 모든게 돼. 왕자님도 무도회장에 아가씨들은 쳐다보지도 않고,신데렐라하고만 화들짝 왕궁을 구두 결혼하겠어요. 수 신데렐라는 건넨 왕궁으로 갔어요. 신데렐라는 결혼하여 오래오래 행복하게 살았대요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio    intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.164365  0.54155  0.566483  0.580615  0.000261  0.562672   \n",
            "\n",
            "    grammar  \n",
            "0  0.967169  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/327       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/324       \n",
            "Negative tokens: ['여자' '소녀가' '소녀의' '소녀가' '딸을' '새어머니와' '새어머니는' '집안일이' '신데렐라의' '신데렐라도'\n",
            " '신데렐라는' '신데렐라,' '신데렐라가' '할머니가' '무도회에' '할머니가' '마차로' '신데렐라의' '신데렐라,'\n",
            " '신데렐라에게' '신데렐라,' '흰말은' '신데렐라에게' '신데렐라는' '신데렐라는' '신데렐라가' '구두' '구두를'\n",
            " '신데렐라를' '구두' '왕자님은' '구두를' '구두의' '언니들은' '구두를' '신데렐라가' '신데렐라는' '신데렐라의'\n",
            " '신데렐라를' '신데렐라는']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 325/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 324/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 323/324       \n",
            "Peak count: 17\n",
            "Frame tokens: 소녀의 맞이했어요. 소녀는 왕궁에서 언니들을 무도회에 무도회에 드레스로 할머니는 왕자님도 무도회장에 않고,신데렐라하고만 왕궁을 결혼하겠어요. 왕궁으로 결혼하여 살았대요. \n",
            "\n",
            "Similarity : 0.4716061490671215\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.328450918197632 Generator / grammar loss:-0.17059852182865143   similarity loss:-0.13745328783988953\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "옛날 맞이했어요. 소녀보다 소녀가 자기 소녀는 종일 쓸고, 닦고, 도맡아 앉아서 잠시 왕궁에서 열렸어요. 언니들을 데리고 무도회장으로 무도회에 가고 남은 훌쩍훌쩍 울기 시작했어요. 무도회에 들어보니, 내가 무도회에 보내주마 구해 외웠어요. 건드렸어요. 할머니는 열두시가 호박으로, 무도회장에 않고,신데렐라하고만 왕자님과 왕궁을 가서 신하들은 나라를 보았지만 너무 신어 수 건넨 신하들은 왕궁으로 데리고 결혼하여 살았대요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.162293  0.465784  0.467278  0.530631  0.000913  0.476561   \n",
            "\n",
            "    grammar  \n",
            "0  0.981341  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/327       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/324       \n",
            "Negative tokens: ['여자' '소녀가' '소녀의' '소녀가' '딸을' '새어머니와' '새어머니는' '집안일이' '신데렐라의' '신데렐라도'\n",
            " '신데렐라는' '신데렐라,' '신데렐라가' '할머니가' '무도회에' '할머니가' '마차로' '신데렐라의' '신데렐라,'\n",
            " '신데렐라에게' '신데렐라,' '흰말은' '신데렐라에게' '신데렐라는' '신데렐라는' '신데렐라가' '구두' '구두를'\n",
            " '신데렐라를' '구두' '왕자님은' '구두를' '구두의' '언니들은' '구두를' '신데렐라가' '신데렐라는' '신데렐라의'\n",
            " '신데렐라를' '신데렐라는']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 325/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 324/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 323/324       \n",
            "Peak count: 17\n",
            "Frame tokens: 소녀의 맞이했어요. 소녀는 왕궁에서 언니들을 무도회에 무도회에 드레스로 할머니는 왕자님도 무도회장에 않고,신데렐라하고만 왕궁을 결혼하겠어요. 왕궁으로 결혼하여 살았대요. \n",
            "\n",
            "Similarity : 0.4716061490671215\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.1015026569366455 Generator / grammar loss:-0.1243116483092308   similarity loss:-0.11415264755487442\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            " 태어났어요. 아기는 무럭무럭 소녀의 어머니가 병이들어 세상을 떠나고 소녀가 맞이했어요. 자기 예쁘고 소녀는 하루 잠시 왕궁에서 열렸어요. 왔어요. 밤 왕자님도 가는 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 벗겨졌어요. 틈이 없었어요. 유리 이 결혼하겠어요. 돌아다녔어요. 늘려도 보았지만 보기에도 구두는 너무 작았어요. 다가와 신어 유리 신었어요, 꼭 왕궁으로 뒤 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro    body  ending       var     total  grammar\n",
            "0  SAM+WGAN     0.15884  0.514844  0.5565  0.6327  0.002381  0.558135   0.9515\n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/327       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/324       \n",
            "Negative tokens: ['여자' '소녀가' '소녀의' '소녀가' '딸을' '새어머니와' '새어머니는' '집안일이' '신데렐라의' '신데렐라도'\n",
            " '신데렐라는' '신데렐라,' '신데렐라가' '할머니가' '무도회에' '할머니가' '마차로' '신데렐라의' '신데렐라,'\n",
            " '신데렐라에게' '신데렐라,' '흰말은' '신데렐라에게' '신데렐라는' '신데렐라는' '신데렐라가' '구두' '구두를'\n",
            " '신데렐라를' '구두' '왕자님은' '구두를' '구두의' '언니들은' '구두를' '신데렐라가' '신데렐라는' '신데렐라의'\n",
            " '신데렐라를' '신데렐라는']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 325/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 324/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 323/324       \n",
            "Peak count: 17\n",
            "Frame tokens: 소녀의 맞이했어요. 소녀는 왕궁에서 언니들을 무도회에 무도회에 드레스로 할머니는 왕자님도 무도회장에 않고,신데렐라하고만 왕궁을 결혼하겠어요. 왕궁으로 결혼하여 살았대요. \n",
            "\n",
            "Similarity : 0.4716061490671215\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.3627660274505615 Generator / grammar loss:-0.16897565126419067   similarity loss:-0.13229317963123322\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "그만 맞이했어요. 새어머니는 그런데 소녀는 종일 쓸고, 없는 집안일이 지칠때면 잠시 왕궁에서 왔어요. 무도회에 신데렐라, 무도회에 있었어요. 호박 생쥐 두마리, 구해 그리고 지팡이로 변했어요. 이번에는 멋진 구슬 드레스로 바뀌웠어요. 할머니는 신데렐라에게 주었어요. 처음대로 돌아간단다. 해. 왕자님도 무도회장에 않고,신데렐라하고만 왕궁을 빠져나가는데, 짝이 결혼하겠어요. 그래서 언니들은 말했어요. 볼 있나요? 왕궁으로 데리고 결혼하여 살았대요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body   ending       var     total  \\\n",
            "0  SAM+WGAN    0.172652  0.527971  0.624732  0.58682  0.001585  0.595824   \n",
            "\n",
            "    grammar  \n",
            "0  0.973141  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/327       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/324       \n",
            "Negative tokens: ['여자' '소녀가' '소녀의' '소녀가' '딸을' '새어머니와' '새어머니는' '집안일이' '신데렐라의' '신데렐라도'\n",
            " '신데렐라는' '신데렐라,' '신데렐라가' '할머니가' '무도회에' '할머니가' '마차로' '신데렐라의' '신데렐라,'\n",
            " '신데렐라에게' '신데렐라,' '흰말은' '신데렐라에게' '신데렐라는' '신데렐라는' '신데렐라가' '구두' '구두를'\n",
            " '신데렐라를' '구두' '왕자님은' '구두를' '구두의' '언니들은' '구두를' '신데렐라가' '신데렐라는' '신데렐라의'\n",
            " '신데렐라를' '신데렐라는']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 325/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 324/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 323/324       \n",
            "Peak count: 17\n",
            "Frame tokens: 소녀의 맞이했어요. 소녀는 왕궁에서 언니들을 무도회에 무도회에 드레스로 할머니는 왕자님도 무도회장에 않고,신데렐라하고만 왕궁을 결혼하겠어요. 왕궁으로 결혼하여 살았대요. \n",
            "\n",
            "Similarity : 0.4716061490671215\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.26601505279541 Generator / grammar loss:-0.18737007677555084   similarity loss:-0.16061000525951385\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "어느 집에 귀여운 소녀의 어머니가 병이들어 세상을 후 새어머니를 맞이했어요. 돌아가셨어요. 소녀는 왕궁에서 언니들을 데리고 무도회에 무도회에 내가 너를 주문을 그리고 마차로 생쥐와 흰말로, 도마뱀은 드레스로 발을 내밀어 보거라. 할머니는 신겨 모든게 돼. 왕자님도 무도회장에 아가씨들은 쳐다보지도 않고,신데렐라하고만 화들짝 왕궁을 결혼하겠어요. 수 신데렐라는 건넨 왕궁으로 갔어요. 신데렐라는 결혼하여 오래오래 행복하게 살았대요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro     body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.165746  0.576563  0.57094  0.578841  0.000011  0.573487   \n",
            "\n",
            "    grammar  \n",
            "0  0.974367  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/327       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/324       \n",
            "Negative tokens: ['여자' '소녀가' '소녀의' '소녀가' '딸을' '새어머니와' '새어머니는' '집안일이' '신데렐라의' '신데렐라도'\n",
            " '신데렐라는' '신데렐라,' '신데렐라가' '할머니가' '무도회에' '할머니가' '마차로' '신데렐라의' '신데렐라,'\n",
            " '신데렐라에게' '신데렐라,' '흰말은' '신데렐라에게' '신데렐라는' '신데렐라는' '신데렐라가' '구두' '구두를'\n",
            " '신데렐라를' '구두' '왕자님은' '구두를' '구두의' '언니들은' '구두를' '신데렐라가' '신데렐라는' '신데렐라의'\n",
            " '신데렐라를' '신데렐라는']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 325/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 324/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 323/324       \n",
            "Peak count: 17\n",
            "Frame tokens: 소녀의 맞이했어요. 소녀는 왕궁에서 언니들을 무도회에 무도회에 드레스로 할머니는 왕자님도 무도회장에 않고,신데렐라하고만 왕궁을 결혼하겠어요. 왕궁으로 결혼하여 살았대요. \n",
            "\n",
            "Similarity : 0.4716061490671215\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.3789093494415283 Generator / grammar loss:-0.17644867300987244   similarity loss:-0.13809438049793243\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "옛날 맞이했어요. 소녀보다 소녀가 자기 소녀는 종일 쓸고, 닦고, 도맡아 앉아서 잠시 왕궁에서 열렸어요. 언니들을 데리고 무도회장으로 무도회에 가고 남은 훌쩍훌쩍 울기 시작했어요. 무도회에 들어보니, 빙그레 내가 무도회에 보내주마 구해 외웠어요. 건드렸어요. 열두시가 호박으로, 무도회장에 않고,신데렐라하고만 왕궁을 가서 신하들은 나라를 보았지만 너무 다가와 신어 수 건넨 신하들은 왕궁으로 데리고 결혼하여 살았대요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro     body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.160912  0.463515  0.48122  0.533218  0.000875  0.484899   \n",
            "\n",
            "    grammar  \n",
            "0  0.984024  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/327       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/324       \n",
            "Negative tokens: ['여자' '소녀가' '소녀의' '소녀가' '딸을' '새어머니와' '새어머니는' '집안일이' '신데렐라의' '신데렐라도'\n",
            " '신데렐라는' '신데렐라,' '신데렐라가' '할머니가' '무도회에' '할머니가' '마차로' '신데렐라의' '신데렐라,'\n",
            " '신데렐라에게' '신데렐라,' '흰말은' '신데렐라에게' '신데렐라는' '신데렐라는' '신데렐라가' '구두' '구두를'\n",
            " '신데렐라를' '구두' '왕자님은' '구두를' '구두의' '언니들은' '구두를' '신데렐라가' '신데렐라는' '신데렐라의'\n",
            " '신데렐라를' '신데렐라는']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 325/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 324/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 323/324       \n",
            "Peak count: 17\n",
            "Frame tokens: 소녀의 맞이했어요. 소녀는 왕궁에서 언니들을 무도회에 무도회에 드레스로 할머니는 왕자님도 무도회장에 않고,신데렐라하고만 왕궁을 결혼하겠어요. 왕궁으로 결혼하여 살았대요. \n",
            "\n",
            "Similarity : 0.4716061490671215\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.287177801132202 Generator / grammar loss:-0.18156081438064575   similarity loss:-0.15264320373535156\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "그러던 어느날, 소녀의 아버지는 남은 맞이했어요. 소녀보다 새어머니와 언니들은 심술쟁이들이었어요. 착한 게 돌아가셨어요. 소녀는 하루 왕궁에서 언니들을 무도회에 가고 무도회에 신데렐라가 있었어요. 도마뱀을 마차로 그랬더니 흰말로, 멋진 드레스로 바뀌웠어요. 할머니는 신데렐라에게 유리 구두를 주었어요. 그래서 유리 주인을 언니들은 보았지만 한눈에 유리 구두는 신데렐라가 저도 유리 신데렐라의 신하들은 왕궁으로 데리고 결혼하여 살았대요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.167818  0.496448  0.588522  0.643218  0.003668  0.574827   \n",
            "\n",
            "    grammar  \n",
            "0  0.990118  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/327       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/324       \n",
            "Negative tokens: ['여자' '소녀가' '소녀의' '소녀가' '딸을' '새어머니와' '새어머니는' '집안일이' '신데렐라의' '신데렐라도'\n",
            " '신데렐라는' '신데렐라,' '신데렐라가' '할머니가' '무도회에' '할머니가' '마차로' '신데렐라의' '신데렐라,'\n",
            " '신데렐라에게' '신데렐라,' '흰말은' '신데렐라에게' '신데렐라는' '신데렐라는' '신데렐라가' '구두' '구두를'\n",
            " '신데렐라를' '구두' '왕자님은' '구두를' '구두의' '언니들은' '구두를' '신데렐라가' '신데렐라는' '신데렐라의'\n",
            " '신데렐라를' '신데렐라는']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 325/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 324/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 323/324       \n",
            "Peak count: 17\n",
            "Frame tokens: 소녀의 맞이했어요. 소녀는 왕궁에서 언니들을 무도회에 무도회에 드레스로 할머니는 왕자님도 무도회장에 않고,신데렐라하고만 왕궁을 결혼하겠어요. 왕궁으로 결혼하여 살았대요. \n",
            "\n",
            "Similarity : 0.4716061490671215\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.033937931060791 Generator / grammar loss:-0.11158382147550583   similarity loss:-0.10818969458341599\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "소녀의 소녀의 소녀가 걱정되었어요. 맞이했어요. 성질이 새어머니는 그런데 소녀는 종일 쓸고, 없는 집안일이 지칠때면 잠시 왕궁에서 왔어요. 무도회에 무도회에 있었어요. 호박 생쥐 두마리, 구해 그리고 지팡이로 변했어요. 이번에는 멋진 구슬 드레스로 바뀌웠어요. 할머니는 주었어요. 처음대로 돌아간단다. 해. 왕자님도 무도회장에 않고,신데렐라하고만 왕궁을 빠져나가는데, 짝이 결혼하겠어요. 말했어요. 볼 있나요? 왕궁으로 데리고 결혼하여 살았대요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.171961  0.555707  0.570786  0.550448  0.000074  0.564085   \n",
            "\n",
            "   grammar  \n",
            "0  0.93223  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/327       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/324       \n",
            "Negative tokens: ['여자' '소녀가' '소녀의' '소녀가' '딸을' '새어머니와' '새어머니는' '집안일이' '신데렐라의' '신데렐라도'\n",
            " '신데렐라는' '신데렐라,' '신데렐라가' '할머니가' '무도회에' '할머니가' '마차로' '신데렐라의' '신데렐라,'\n",
            " '신데렐라에게' '신데렐라,' '흰말은' '신데렐라에게' '신데렐라는' '신데렐라는' '신데렐라가' '구두' '구두를'\n",
            " '신데렐라를' '구두' '왕자님은' '구두를' '구두의' '언니들은' '구두를' '신데렐라가' '신데렐라는' '신데렐라의'\n",
            " '신데렐라를' '신데렐라는']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 325/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 324/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 323/324       \n",
            "Peak count: 17\n",
            "Frame tokens: 소녀의 맞이했어요. 소녀는 왕궁에서 언니들을 무도회에 무도회에 드레스로 할머니는 왕자님도 무도회장에 않고,신데렐라하고만 왕궁을 결혼하겠어요. 왕궁으로 결혼하여 살았대요. \n",
            "\n",
            "Similarity : 0.4716061490671215\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.2797656059265137 Generator / grammar loss:-0.17686641216278076   similarity loss:-0.14870521426200867\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "옛날 어느 집에 귀여운 소녀의 어머니가 병이들어 세상을 걱정되었어요. 그래서 후 새어머니를 맞이했어요. 심술쟁이들이었어요. 아버지마저 돌아가셨어요. 소녀는 하루 왕궁에서 언니들을 무도회에 무도회에 내가 너를 주문을 그리고 호박이 마차로 생쥐와 흰말로, 도마뱀은 드레스로 발을 내밀어 보거라. 할머니는 신겨 열두시가 되면 모든게 돼. 수 신데렐라는 건넨 왕궁으로 갔어요. 신데렐라는 결혼하여 오래오래 행복하게 살았대요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio    intro      body    ending      var     total  \\\n",
            "0  SAM+WGAN    0.160912  0.68087  0.586685  0.591264  0.00188  0.609904   \n",
            "\n",
            "    grammar  \n",
            "0  0.986331  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/327       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/324       \n",
            "Negative tokens: ['여자' '소녀가' '소녀의' '소녀가' '딸을' '새어머니와' '새어머니는' '집안일이' '신데렐라의' '신데렐라도'\n",
            " '신데렐라는' '신데렐라,' '신데렐라가' '할머니가' '무도회에' '할머니가' '마차로' '신데렐라의' '신데렐라,'\n",
            " '신데렐라에게' '신데렐라,' '흰말은' '신데렐라에게' '신데렐라는' '신데렐라는' '신데렐라가' '구두' '구두를'\n",
            " '신데렐라를' '구두' '왕자님은' '구두를' '구두의' '언니들은' '구두를' '신데렐라가' '신데렐라는' '신데렐라의'\n",
            " '신데렐라를' '신데렐라는']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 325/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 324/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 323/324       \n",
            "Peak count: 17\n",
            "Frame tokens: 소녀의 맞이했어요. 소녀는 왕궁에서 언니들을 무도회에 무도회에 드레스로 할머니는 왕자님도 무도회장에 않고,신데렐라하고만 왕궁을 결혼하겠어요. 왕궁으로 결혼하여 살았대요. \n",
            "\n",
            "Similarity : 0.4716061490671215\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.3825647830963135 Generator / grammar loss:-0.1799049824476242   similarity loss:-0.1411714106798172\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "옛날 맞이했어요. 소녀보다 소녀가 자기 소녀는 종일 쓸고, 닦고, 도맡아 앉아서 잠시 왕궁에서 열렸어요. 언니들을 데리고 무도회장으로 무도회에 가고 남은 훌쩍훌쩍 울기 시작했어요. 무도회에 들어보니, 빙그레 내가 무도회에 보내주마 구해 외웠어요. 건드렸어요. 열두시가 호박으로, 무도회장에 않고,신데렐라하고만 왕궁을 가서 신하들은 나라를 보았지만 너무 다가와 신어 수 건넨 신하들은 왕궁으로 데리고 결혼하여 살았대요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro     body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.160912  0.463515  0.48122  0.533218  0.000875  0.484899   \n",
            "\n",
            "    grammar  \n",
            "0  0.984024  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/327       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/324       \n",
            "Negative tokens: ['여자' '소녀가' '소녀의' '소녀가' '딸을' '새어머니와' '새어머니는' '집안일이' '신데렐라의' '신데렐라도'\n",
            " '신데렐라는' '신데렐라,' '신데렐라가' '할머니가' '무도회에' '할머니가' '마차로' '신데렐라의' '신데렐라,'\n",
            " '신데렐라에게' '신데렐라,' '흰말은' '신데렐라에게' '신데렐라는' '신데렐라는' '신데렐라가' '구두' '구두를'\n",
            " '신데렐라를' '구두' '왕자님은' '구두를' '구두의' '언니들은' '구두를' '신데렐라가' '신데렐라는' '신데렐라의'\n",
            " '신데렐라를' '신데렐라는']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 325/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 324/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 323/324       \n",
            "Peak count: 17\n",
            "Frame tokens: 소녀의 맞이했어요. 소녀는 왕궁에서 언니들을 무도회에 무도회에 드레스로 할머니는 왕자님도 무도회장에 않고,신데렐라하고만 왕궁을 결혼하겠어요. 왕궁으로 결혼하여 살았대요. \n",
            "\n",
            "Similarity : 0.4716061490671215\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.270249366760254 Generator / grammar loss:-0.180463507771492   similarity loss:-0.15327225625514984\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "그러던 어느날, 소녀의 아버지는 남은 맞이했어요. 소녀보다 새어머니와 언니들은 심술쟁이들이었어요. 착한 게 돌아가셨어요. 소녀는 하루 앉아서 왕궁에서 언니들을 무도회에 가고 무도회에 신데렐라가 있었어요. 도마뱀을 마차로 그랬더니 흰말로, 멋진 드레스로 바뀌웠어요. 할머니는 신데렐라에게 유리 구두를 주었어요. 유리 주인을 언니들은 보았지만 한눈에 유리 구두는 신데렐라가 저도 유리 신데렐라의 신하들은 왕궁으로 데리고 결혼하여 살았대요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.167818  0.499524  0.581906  0.639229  0.003288  0.570929   \n",
            "\n",
            "    grammar  \n",
            "0  0.985488  \n",
            "------------------------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했지요. 어느 날, 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라, 너도 무도회에 가고 싶니? 신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라, 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지? 왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡, 땡, 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때, 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요? 신데렐라는 신하게 건넨 유리 구두를 신었어요, 유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/327       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/324       \n",
            "Negative tokens: ['여자' '소녀가' '소녀의' '소녀가' '딸을' '새어머니와' '새어머니는' '집안일이' '신데렐라의' '신데렐라도'\n",
            " '신데렐라는' '신데렐라,' '신데렐라가' '할머니가' '무도회에' '할머니가' '마차로' '신데렐라의' '신데렐라,'\n",
            " '신데렐라에게' '신데렐라,' '흰말은' '신데렐라에게' '신데렐라는' '신데렐라는' '신데렐라가' '구두' '구두를'\n",
            " '신데렐라를' '구두' '왕자님은' '구두를' '구두의' '언니들은' '구두를' '신데렐라가' '신데렐라는' '신데렐라의'\n",
            " '신데렐라를' '신데렐라는']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 325/326       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 324/325       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 323/324       \n",
            "Peak count: 17\n",
            "Frame tokens: 소녀의 맞이했어요. 소녀는 왕궁에서 언니들을 무도회에 무도회에 드레스로 할머니는 왕자님도 무도회장에 않고,신데렐라하고만 왕궁을 결혼하겠어요. 왕궁으로 결혼하여 살았대요. \n",
            "\n",
            "Similarity : 0.4716061490671215\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.047881841659546 Generator / grammar loss:-0.1336839497089386   similarity loss:-0.1288948506116867\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            " 태어났어요. 되었어요. 소녀의 아버지는 새어머니를 맞이했어요. 위인 새어머니는 소녀가 예쁘고 그런데 소녀는 하녀처럼 왕궁에서 열렸어요. 왔어요. 언니들을 무도회에 무도회에 호박 도마뱀을 외웠어요. 호박을 건드리자, 도마뱀을 장식이 예쁜 드레스로 보거라. 할머니는 유리 구두를 신데렐라, 생쥐로, 돼. 왕궁을 결혼하겠어요. 언니들은 유리 구두는 너무 신데렐라가 신데렐라는 유리 왕궁으로 뒤 신데렐라는 왕자님과 결혼하여 살았대요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.165055  0.471117  0.579211  0.574324  0.002484  0.552618   \n",
            "\n",
            "    grammar  \n",
            "0  0.945724  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8z4bfSR-atB"
      },
      "source": [
        "## 한국어 Sample Test (No frame token)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "OhUFVVRki1ga"
      },
      "source": [
        "import sys\n",
        "\n",
        "def get_features(dct1):\n",
        "    return [dct1['comp ratio'][0],dct1['intro'][0],dct1['body'][0],dct1['ending'][0],dct1['var'][0],dct1['total'][0],dct1['grammar'][0]]\n",
        "\n",
        "test_result = {}\n",
        "test_result['SAM+WGAN']=[]\n",
        "test_result['BERT+LexRank']=[]\n",
        "test_result['BESM']=[]\n",
        "test_result['BESM+kobert']=[]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "R0yLlIo3i1ga"
      },
      "source": [
        "def get_test_statistics(test_result):\n",
        "    df_data = {}\n",
        "    df_data['method'] = []\n",
        "    df_data['comp rate'] = []\n",
        "    df_data['intro'] = []\n",
        "    df_data['body'] = []\n",
        "    df_data['conclusion'] = []\n",
        "    df_data['isthmus'] = []\n",
        "    df_data['simlirality'] = []\n",
        "    df_data['grammarity'] = []\n",
        "\n",
        "    for key in test_result:\n",
        "        df_data['method'].append(key)\n",
        "        data = np.asarray(test_result[key])\n",
        "        df_data['comp rate'].append(np.mean(data[:,0]))\n",
        "        df_data['intro'].append(np.mean(data[:,1]))\n",
        "        df_data['body'].append(np.mean(data[:,2]))\n",
        "        df_data['conclusion'].append(np.mean(data[:,3]))\n",
        "        df_data['isthmus'].append(np.mean(data[:,4]))\n",
        "        df_data['simlirality'].append(np.mean(data[:,5]))\n",
        "        df_data['grammarity'].append(np.mean(data[:,6]))\n",
        "\n",
        "\n",
        "    df = pd.DataFrame(df_data)\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "8E5m2SVti1gb"
      },
      "source": [
        "def prepare_data(offset,length):\n",
        "    return document[offset:offset+length]\n",
        "\n",
        "\n",
        "ko_docs = prepare_data(0,70)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "wOfI-ih2i1gb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "378f4863-e0a3-4433-f007-801de5b84f16"
      },
      "source": [
        "ko_docs[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['이 이야기에서는 내가 직접 입회한 사건이나 장면만을 이야기하는 전의 내 방법을 바꿔 보았다. 그래서 몇몇 장은 3인칭으로 씌어 있다. 이제부터의 각 장에서 이야기되는 사건들은 모두 내가 확증 할 수 있었던 것임을 밝혀둔다. 여러 인물들의 생각이나 감정을 서술하는 데 있어 얼마쯤 내가 시인의 특권을 행사했다 해도 그것은 아주 정확을 기해서 한 일이다.',\n",
              " '또한 그것들은 모두 내 친구 에르큘 포아로의 검토를 받았음을 덧붙여 둔다. 끝으로, 나는 이 이상한 연쇄 범죄의 결과로서 일어나는 부차적인 인간관계에 대해 너무 많은 이야기를 했는지도 모른다. 하지만 인간적, 개인적 요소란 빠뜨려선 안 되는 것이다. 에르큘 포아로가 언젠가 과장된 몸짓으로 나에게 가르쳐 준 일이 있다. 로맨스란 범죄의 부산물일 경우가 있다고. ABC 수수께끼의 해결에 대해 말한다면, 에르큘 포아로는 이제까지 그가 다뤄 온 어느 사건과도 다른 방법으로 문제에 뛰어들어 그 진정한 천재성을 발휘했다고 말해도 좋으리라. < 편지 > 1935년 6월, 나는 남아메리카의 내 농장에서 떠나 여섯 달쯤 머무를 예정으로 귀국했다. 그때는 어려웠던 시대로, 다른 사람들과 마찬가지로 우리 역시 세계적인 불황에 어려움을 겪고 있었다. 영국에서 나 자신이 손대지 않으면 도저히 잘되어 나가지 않을 것 같은 볼일이 여러 가지 있었다. 농장 관리를 위해 아내가 뒤에 남았다.',\n",
              " '영국에 와 닿아 내가 맨 먼저 한 일의 하나는 말할 나위도 없이 오랜 친구인 에르큘 포아로를 찾아간 것이었다. 그는 런던의 어떤 최신형 아파트에 살고 있었다. 내가 그것을 지적하며, 그가 이 특별한 건물을 고른 것은 완전히 그 기하학적이 겉모습과 넓이 때문일 거라고 말하자 그는 고개를 끄덕였다. “그러나 아주 기분 좋게 균형이 잡혀 있지. 그렇게 생각되지 않나?” 나는 좀 너무 모난 것같이 생각된다고 말했다. 그리고 오래된 농담이 생각나 이 아파트에서는 암탉에게 네모난 달걀을 낳게 할 수 있을 듯하다고 말했다.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBEVNQsqBy7w",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e1205b0d-0620-4d8e-edcf-311f83782af4"
      },
      "source": [
        "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
        " \n",
        "step = 0\n",
        "for intro,body,end in ko_docs:\n",
        "    step += 1\n",
        "    print(\"=\" * 50)\n",
        "    print(str(step),\"/\",len(ko_docs))\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    org_text_1 = intro\n",
        "    org_text_2 = body\n",
        "    org_text_3 = end\n",
        " \n",
        "    try:\n",
        "        df1,dct1 = sam_wgan('',[org_text_1,org_text_2,org_text_3],init_bias=0.0,display= False)\n",
        "        if dct1['grammar'][0] > 0.0:\n",
        "            df2,dct2 = bert_lexrank_sum('',[org_text_1,org_text_2,org_text_3])\n",
        "            df3,dct3 = besm('',[org_text_1,org_text_2,org_text_3])\n",
        "            df4,dct4 = besm_bert('',[org_text_1,org_text_2,org_text_3])\n",
        "            #df5,dct5 = abstract_method_1(g_summ,[org_text_1,org_text_2,org_text_3])\n",
        "            #df6,dct6 = abstract_method_2(g_summ,[org_text_1,org_text_2,org_text_3])\n",
        " \n",
        "            test_result['SAM+WGAN'].append(get_features(dct1))\n",
        "            test_result['BERT+LexRank'].append(get_features(dct2))\n",
        "            test_result['BESM'].append(get_features(dct3))\n",
        "            test_result['BESM+kobert'].append(get_features(dct4))\n",
        "            #test_result['Transformer'].append(get_features(dct5))\n",
        "            #test_result['T5'].append(get_features(dct6))\n",
        "            #result = pd.concat([df1, df2, df3, df4, df5, df6 ], ignore_index=True)\n",
        "            result = pd.concat([df1, df2, df3, df4 ], ignore_index=True)\n",
        "            \n",
        "            print(result)\n",
        "            \n",
        "            print(\"Current result\",\"=\" * 50)\n",
        "            print(\"Sample count:\",len(test_result['SAM+WGAN']))\n",
        "            print(get_test_statistics(test_result))\n",
        "        \n",
        "    except KeyboardInterrupt as ki:\n",
        "        raise ki\n",
        "    except :\n",
        "        print(\"Unexpected error:\", sys.exc_info()[0])\n",
        "        #raise e\n",
        "        pass\n",
        " \n",
        "get_test_statistics(test_result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "1 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "이 이야기에서는 내가 직접 입회한 사건이나 장면만을 이야기하는 전의 내 방법을 바꿔 보았다. 그래서 몇몇 장은 3인칭으로 씌어 있다. 이제부터의 각 장에서 이야기되는 사건들은 모두 내가 확증 할 수 있었던 것임을 밝혀둔다. 여러 인물들의 생각이나 감정을 서술하는 데 있어 얼마쯤 내가 시인의 특권을 행사했다 해도 그것은 아주 정확을 기해서 한 일이다. 또한 그것들은 모두 내 친구 에르큘 포아로의 검토를 받았음을 덧붙여 둔다. 끝으로, 나는 이 이상한 연쇄 범죄의 결과로서 일어나는 부차적인 인간관계에 대해 너무 많은 이야기를 했는지도 모른다. 하지만 인간적, 개인적 요소란 빠뜨려선 안 되는 것이다. 에르큘 포아로가 언젠가 과장된 몸짓으로 나에게 가르쳐 준 일이 있다. 로맨스란 범죄의 부산물일 경우가 있다고. ABC 수수께끼의 해결에 대해 말한다면, 에르큘 포아로는 이제까지 그가 다뤄 온 어느 사건과도 다른 방법으로 문제에 뛰어들어 그 진정한 천재성을 발휘했다고 말해도 좋으리라. < 편지 > 1935년 6월, 나는 남아메리카의 내 농장에서 떠나 여섯 달쯤 머무를 예정으로 귀국했다. 그때는 어려웠던 시대로, 다른 사람들과 마찬가지로 우리 역시 세계적인 불황에 어려움을 겪고 있었다. 영국에서 나 자신이 손대지 않으면 도저히 잘되어 나가지 않을 것 같은 볼일이 여러 가지 있었다. 농장 관리를 위해 아내가 뒤에 남았다. 영국에 와 닿아 내가 맨 먼저 한 일의 하나는 말할 나위도 없이 오랜 친구인 에르큘 포아로를 찾아간 것이었다. 그는 런던의 어떤 최신형 아파트에 살고 있었다. 내가 그것을 지적하며, 그가 이 특별한 건물을 고른 것은 완전히 그 기하학적이 겉모습과 넓이 때문일 거라고 말하자 그는 고개를 끄덕였다. “그러나 아주 기분 좋게 균형이 잡혀 있지. 그렇게 생각되지 않나?” 나는 좀 너무 모난 것같이 생각된다고 말했다. 그리고 오래된 농담이 생각나 이 아파트에서는 암탉에게 네모난 달걀을 낳게 할 수 있을 듯하다고 말했다.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.3519999980926514 Generator / grammar loss:-0.12269207835197449   similarity loss:-0.08712171018123627\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "직접 내 보았다. 몇몇 그것들은 내 둔다. 귀국했다. 같은 뒤에 내가 맨 한 오랜 친구인 그는 어떤 최신형 아파트에 겉모습과 넓이 그는 끄덕였다. “그러나 아주 기분 균형이 있지. 나는 모난 것같이 생각된다고 농담이 암탉에게 말했다. \n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "< 편지 > 1935년 6월, 나는 남아메리카의 내 농장에서 떠나 여섯 달쯤 머무를 예정으로 귀국했다.그때는 어려웠던 시대로, 다른 사람들과 마찬가지로 우리 역시 세계적인 불황에 어려움을 겪고 있었다.그는 런던의 어떤 최신형 아파트에 살고 있었다.그렇게 생각되지 않나?” 나는 좀 너무 모난 것같이 생각된다고 말했다.\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "이 이야기에서는 내가 직접 입회한 사건이나 장면만을 이야기하는 전의 내 방법을 바꿔 보았다. 그때는 어려웠던 시대로, 다른 사람들과 마찬가지로 우리 역시 세계적인 불황에 어려움을 겪고 있었다. 영국에서 나 자신이 손대지 않으면 도저히 잘되어 나가지 않을 것 같은 볼일이 여러 가지 있었다.\n",
            "--------------------------------------------------\n",
            "besm_bert summary:\n",
            "이 이야기에서는 내가 직접 입회한 사건이나 장면만을 이야기하는 전의 내 방법을 바꿔 보았다. abc 수수께끼의 해결에 대해 말한다면, 에르큘 포아로는 이제까지 그가 다뤄 온 어느 사건과도 다른 방법으로 문제에 뛰어들어 그 진정한 천재성을 발휘했다고 말해도 좋으리라. < 편지 > 1935년 6월, 나는 남아메리카의 내 농장에서 떠나 여섯 달쯤 머무를 예정으로 귀국했다.\n",
            "--------------------------------------------------\n",
            "         method  comp ratio     intro      body    ending       var     total  \\\n",
            "0      SAM+WGAN    0.134497  0.483653  0.361809  0.617523  0.010906  0.462892   \n",
            "1  BERT+LexRank    0.181725  0.174120  0.265249  0.262216  0.001786  0.246113   \n",
            "2          BESM    0.165298  0.610233  0.504501  0.296348  0.017003  0.463201   \n",
            "3   BESM+kobert    0.211499  0.610233  0.486227  0.298381  0.016435  0.454675   \n",
            "\n",
            "    grammar  \n",
            "0  0.990238  \n",
            "1  0.999038  \n",
            "2  0.999022  \n",
            "3  0.999026  \n",
            "Current result ==================================================\n",
            "Sample count: 1\n",
            "         method  comp rate     intro      body  conclusion   isthmus  \\\n",
            "0      SAM+WGAN   0.134497  0.483653  0.361809    0.617523  0.010906   \n",
            "1  BERT+LexRank   0.181725  0.174120  0.265249    0.262216  0.001786   \n",
            "2          BESM   0.165298  0.610233  0.504501    0.296348  0.017003   \n",
            "3   BESM+kobert   0.211499  0.610233  0.486227    0.298381  0.016435   \n",
            "\n",
            "   simlirality  grammarity  \n",
            "0     0.462892    0.990238  \n",
            "1     0.246113    0.999038  \n",
            "2     0.463201    0.999022  \n",
            "3     0.454675    0.999026  \n",
            "==================================================\n",
            "2 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "포아로는 크게 웃었다. “아니, 자네는 아직도 그걸 기억하고 있나? 하지만 유감스럽게도 과학은 아직 암탉을 현대 취미에 알맞도록 하는 일에 성공하지 못하고 있네. 닭들이 지금도 여전히 크기와 빛깔이 서로 다른 달걀을 낳고 있지. ” 나는 애정어린 눈길로 오랜 친구를 관찰했다. 그는 굉장히 활기가 넘쳐 전에 만났을 때보다 조금도 더 나이먹은 것같이 보이지 않았다. “자네는 정말 건강해 보이는군, 포아로. 거의 나이를 안 먹었잖나. 전에 만났을 때보다 흰머리가 더 적어졌다고 해도 좋을 정도일세, 그런 일이 있을 수 있다면. ” 포아로는 나에게 빙그레 웃어 보였다. “어째서 그런 일이 있을 수 있겠나? 진짜 그 말대로인데. ” “자네 머리는 검은빛에서 잿빛이 되는 대신 잿빛에서 검은빛으로 된단 말인가?” “그렇다네. ” “그렇지만 그런 일은 과학적으로 불가능해!” “천만에. ” “하지만 있을 수 없는 일이잖나. 자연 법칙에 어긋나. ” “헤이스팅즈, 자네는 여전히 남을 의심하지 않는 아름다운 마음을 지니고 있군. 세월도 자네의 그 마음은 바꿔 놓지 못하는구먼! 자네는 한 가지 사실을 발견하면 곧바로 그 해결을 입에 담지. 자기 자신은 그것을 의식하지 못하지만!” 나는 무슨 소리인지 알 수가 없어 그를 쳐다보았다.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.215193510055542 Generator / grammar loss:-0.10970785468816757   similarity loss:-0.08810487389564514\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            " 포아로는 하지만 유감스럽게도 일에 성공하지 낳고 있지. 관찰했다. 그는 때보다 조금도 거의 먹었잖나. 더 웃어 보였다. ” 검은빛에서 검은빛으로 일은 불가능해!” 있을 일이잖나.\n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "하지만 유감스럽게도 과학은 아직 암탉을 현대 취미에 알맞도록 하는 일에 성공하지 못하고 있네.닭들이 지금도 여전히 크기와 빛깔이 서로 다른 달걀을 낳고 있지.” 나는 애정어린 눈길로 오랜 친구를 관찰했다.자연 법칙에 어긋나.자네는 한 가지 사실을 발견하면 곧바로 그 해결을 입에 담지.\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "하지만 유감스럽게도 과학은 아직 암탉을 현대 취미에 알맞도록 하는 일에 성공하지 못하고 있네. 전에 만났을 때보다 흰머리가 더 적어졌다고 해도 좋을 정도일세, 그런 일이 있을 수 있다면. ” 헤이스팅즈, 자네는 여전히 남을 의심하지 않는 아름다운 마음을 지니고 있군.\n",
            "--------------------------------------------------\n",
            "besm_bert summary:\n",
            "하지만 유감스럽게도 과학은 아직 암탉을 현대 취미에 알맞도록 하는 일에 성공하지 못하고 있네. 그는 굉장히 활기가 넘쳐 전에 만났을 때보다 조금도 더 나이먹은 것같이 보이지 않았다. “ 헤이스팅즈, 자네는 여전히 남을 의심하지 않는 아름다운 마음을 지니고 있군.\n",
            "--------------------------------------------------\n",
            "         method  comp ratio     intro      body    ending       var     total  \\\n",
            "0      SAM+WGAN    0.159236  0.479789  0.511701  0.397760  0.002303  0.471137   \n",
            "1  BERT+LexRank    0.253185  0.394299  0.104906  0.211800  0.014276  0.194853   \n",
            "2          BESM    0.237261  0.489392  0.490315  0.436441  0.000634  0.473968   \n",
            "3   BESM+kobert    0.232484  0.542992  0.474982  0.462911  0.001243  0.484963   \n",
            "\n",
            "    grammar  \n",
            "0  0.923598  \n",
            "1  0.999028  \n",
            "2  0.999039  \n",
            "3  0.999038  \n",
            "Current result ==================================================\n",
            "Sample count: 2\n",
            "         method  comp rate     intro      body  conclusion   isthmus  \\\n",
            "0      SAM+WGAN   0.146866  0.481721  0.436755    0.507641  0.006605   \n",
            "1  BERT+LexRank   0.217455  0.284209  0.185077    0.237008  0.008031   \n",
            "2          BESM   0.201279  0.549812  0.497408    0.366394  0.008819   \n",
            "3   BESM+kobert   0.221992  0.576613  0.480604    0.380646  0.008839   \n",
            "\n",
            "   simlirality  grammarity  \n",
            "0     0.467014    0.956918  \n",
            "1     0.220483    0.999033  \n",
            "2     0.468585    0.999031  \n",
            "3     0.469819    0.999032  \n",
            "==================================================\n",
            "3 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "그는 잠자코 침실로 들어가더니 병을 하나 들고 돌아와 나에게 건네 주었다. 나는 까닭을 모르는 채 그 병을 보았다. 병에는 이렇게 씌어 있었다. 르비비 - 머리칼의 자연스러운 빛깔을 회색, 밤색, 빨강, 노랑, 갈색, 검은 색의 여섯 가지 색조로 되살린다. 르비비는 염료가 아니다. 나는 소리쳤다. “포아로, 머리를 염색하고 있구먼!” “아, 겨우 알아차린 모양이군!” “그래서 자네 머리가 전에 돌아왔을 때보다 훨씬 검어 보였단 말인가?” “그렇지. ” 놀라움이 가라앉자 나는 말했다. “그럼, 다음에 돌아왔을 때에는 가짜 수염이라도 달고 있을게 아닌가? 아니면 지금도 가짜 수염인가?” 포아로는 움찔했다. 수염은 늘 그가 세심하게 신경쓰는 부분이다. 그는 수염을 터무니없이 자랑했다. 그런데 내 말이 그의 아픈 데를 찌른 것이다. “아닐세, 당치도 않아. 그런 날은 되도록 오지 않기를 비네. 가짜 수염이라니? 끔찍한 소리를!” 그의 수염이 진짜인 것을 증명하기 위해 힘주어 잡아당겨 보였다. “과연 아직 숱이 꽤 많군. ” “그렇지? 온 런던을 다 찾아봐도 나에게 맞는 가짜 수염은 있을 리 없네.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:1.9521147012710571 Generator / grammar loss:-0.08671412616968155   similarity loss:-0.0915035828948021\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            " 잠자코 들어가더니 하나 건네 주었다. 머리칼의 “아, 겨우 모양이군!” 돌아왔을 때보다 훨씬 “그렇지. 말했다. 아닌가? 수염인가?” 신경쓰는 비네. 나에게 없네.\n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "” “그렇지?나는 소리쳤다.그는 잠자코 침실로 들어가더니 병을 하나 들고 돌아와 나에게 건네 주었다.병에는 이렇게 씌어 있었다.\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "그는 잠자코 침실로 들어가더니 병을 하나 들고 돌아와 나에게 건네 주었다. 르비비 - 머리칼의 자연스러운 빛깔을 회색, 밤색, 빨강, 노랑, 갈색, 검은 색의 여섯 가지 색조로 되살린다.르비비는 염료가 아니다.\n",
            "--------------------------------------------------\n",
            "besm_bert summary:\n",
            "그는 잠자코 침실로 들어가더니 병을 하나 들고 돌아와 나에게 건네 주었다. 르비비 - 머리칼의 자연스러운 빛깔을 회색, 밤색, 빨강, 노랑, 갈색, 검은 색의 여섯 가지 색조로 되살린다.르비비는 염료가 아니다.\n",
            "--------------------------------------------------\n",
            "         method  comp ratio     intro      body    ending       var     total  \\\n",
            "0      SAM+WGAN    0.163993  0.447204  0.626516  0.662552  0.008870  0.601465   \n",
            "1  BERT+LexRank    0.126560  0.594878  0.207621  0.146262  0.039443  0.266665   \n",
            "2          BESM    0.208556  0.726457  0.286528  0.259698  0.045791  0.366465   \n",
            "3   BESM+kobert    0.208556  0.726457  0.286528  0.259698  0.045791  0.366465   \n",
            "\n",
            "    grammar  \n",
            "0  0.950295  \n",
            "1  0.998670  \n",
            "2  0.999012  \n",
            "3  0.999012  \n",
            "Current result ==================================================\n",
            "Sample count: 3\n",
            "         method  comp rate     intro      body  conclusion   isthmus  \\\n",
            "0      SAM+WGAN   0.152575  0.470215  0.500009    0.559278  0.007360   \n",
            "1  BERT+LexRank   0.187156  0.387766  0.192592    0.206759  0.018502   \n",
            "2          BESM   0.203705  0.608694  0.427114    0.330829  0.021143   \n",
            "3   BESM+kobert   0.217513  0.626561  0.415912    0.340330  0.021156   \n",
            "\n",
            "   simlirality  grammarity  \n",
            "0     0.511831    0.954710  \n",
            "1     0.235877    0.998912  \n",
            "2     0.434545    0.999025  \n",
            "3     0.435367    0.999025  \n",
            "==================================================\n",
            "4 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "” 꽤 우쭐대는군 하고 나는 마음속으로 생각했다. 그러나 나는 그런 소리를 해서 포아로의 기분을 상하게 할 생각은 전혀 없었다. 그 대신 그가 아직도 때로 일을 하는지 물어 보았다. “자네가 몇 해 전 은퇴한 것은 알고 있지만……” “그렇네. 대대적으로 호박을 가꾸기 위해서! 그런데 곧 살인 사건이 일어나 호박들에게 멸망으로의 행진을 시키고 만 셈일세. 그 뒤부터는, 자네가 뭐라고 할지 잘 알지만 나는 자진해서 고별 공연을 여는 프리마돈나가 됐네. 물론 그 고별 공연이 끝없이 되풀이되고 있지만 말일세. ” 나는 웃었다, “실로 그대로라네. 그때마다 나는 이것을 마지막이라고 하지. 그런데 안돼. 다른 사건이 일어나거든. 그래서 나는 인정하지 않을 수 없다네. 나는 은퇴를 바라지 않는다고. 이 조그만 회색 뇌세포는 쓰지 않으면 녹슬어 버리니까. ” “알았네. 적당히 운동을 시키고 있다는 거로군. ” “맞아, 요즘의 에르큘 포아로는 범죄의 진수밖에 다루지 않네. ” “그 진수는 충분히 있던가?” “꽤 있지. 바로 저번 사건 같은 경우는 위태로울 뻔했었어.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.3773484230041504 Generator / grammar loss:-0.12135651707649231   similarity loss:-0.08316410332918167\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "없었다. 그가 곧 행진을 잘 됐네. 물론 “실로 그대로라네. 그때마다 마지막이라고 안돼. 일어나거든. 그래서 뇌세포는 녹슬어 버리니까. “알았네.\n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "” “맞아, 요즘의 에르큘 포아로는 범죄의 진수밖에 다루지 않네.그 뒤부터는, 자네가 뭐라고 할지 잘 알지만 나는 자진해서 고별 공연을 여는 프리마돈나가 됐네.나는 은퇴를 바라지 않는다고.이 조그만 회색 뇌세포는 쓰지 않으면 녹슬어 버리니까.그런데 안돼.\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "그러나 나는 그런 소리를 해서 포아로의 기분을 상하게 할 생각은 전혀 없었다. 자네가 몇 해 전 은퇴한 것은 알고 있지만……” “그렇네.대대적으로 호박을 가꾸기 위해서!\n",
            "--------------------------------------------------\n",
            "besm_bert summary:\n",
            "그러나 나는 그런 소리를 해서 포아로의 기분을 상하게 할 생각은 전혀 없었다. 자네가 몇 해 전 은퇴한 것은 알고 있지만……” “그렇네.대대적으로 호박을 가꾸기 위해서!\n",
            "--------------------------------------------------\n",
            "         method  comp ratio     intro      body    ending       var     total  \\\n",
            "0      SAM+WGAN    0.150558  0.466536  0.573695  0.565978  0.002381  0.549948   \n",
            "1  BERT+LexRank    0.263941  0.256045  0.274003  0.245911  0.000135  0.261984   \n",
            "2          BESM    0.174721  0.602274  0.345120  0.324094  0.015995  0.390243   \n",
            "3   BESM+kobert    0.174721  0.602274  0.345120  0.324094  0.015995  0.390243   \n",
            "\n",
            "    grammar  \n",
            "0  0.981966  \n",
            "1  0.999033  \n",
            "2  0.999023  \n",
            "3  0.999023  \n",
            "Current result ==================================================\n",
            "Sample count: 4\n",
            "         method  comp rate     intro      body  conclusion   isthmus  \\\n",
            "0      SAM+WGAN   0.152071  0.469295  0.518430    0.560953  0.006115   \n",
            "1  BERT+LexRank   0.206352  0.354836  0.212945    0.216547  0.013910   \n",
            "2          BESM   0.196459  0.607089  0.406616    0.329145  0.019856   \n",
            "3   BESM+kobert   0.206815  0.620489  0.398214    0.336271  0.019866   \n",
            "\n",
            "   simlirality  grammarity  \n",
            "0     0.521360    0.961524  \n",
            "1     0.242404    0.998942  \n",
            "2     0.423469    0.999024  \n",
            "3     0.424086    0.999025  \n",
            "==================================================\n",
            "5 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "” “실패했나?” 포아로는 놀라운 듯했다. “당치도 않네. 그렇지만 이 내가, 이 에르큘 포아로가 하마터면 살해될 뻔했었지. ” 나는 휘파람을 불었다. “대담한 범인이로군. ” “대담하다기보다 무모하지. 그래, 진짜 무모한 녀석이었어. 하지만 그 이야기는 그만두세. 그런데 헤이스팅즈, 알겠나? 나는 여러 가지 뜻에서 자네를 내 마스코트로 생각하고 있네. ” “정말인가? 어떤 뜻에서?” 포아로는 내 물음에는 직접 대답하지 않고 이야기를 계속했다. “자네가 온다는 이야기를 들으면 나는 곧 무언가 일어나겠군 하고 생각된다네. 예전처럼 둘이서 수사하지 않겠나. 하지만 만일 그렇게 한다면 평범한 사건은 안돼. 뭔가 이렇게……. ” 그는 흥분해서 손을 파도치듯 움직였다. “머리를 잔뜩 쓰게 하는, 미묘하고 피이누(섬세)한 것이 아니면 안 되지. ” 피아누라는 번역하기 어려운 말에 가득한 풍미를 곁들이는 듯한 말투였다. “포아로, 남이 들으면 마치 리츠에서 저녁 식사라도 주문하고 있는 줄로 생각하겠네.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.1899092197418213 Generator / grammar loss:-0.09586405754089355   similarity loss:-0.07681576162576675\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "” 휘파람을 범인이로군. 하지만 그만두세. 계속했다. “자네가 들으면 않겠나. 사건은 안돼. 이렇게……. 움직였다. 아니면 생각하겠네.\n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "“포아로, 남이 들으면 마치 리츠에서 저녁 식사라도 주문하고 있는 줄로 생각하겠네.나는 여러 가지 뜻에서 자네를 내 마스코트로 생각하고 있네.” 피아누라는 번역하기 어려운 말에 가득한 풍미를 곁들이는 듯한 말투였다.그런데 헤이스팅즈, 알겠나?\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "자네가 온다는 이야기를 들으면 나는 곧 무언가 일어나겠군 하고 생각된다네. 포아로, 남이 들으면 마치 리츠에서 저녁 식사라도 주문하고 있는 줄로 생각하겠네.\n",
            "--------------------------------------------------\n",
            "besm_bert summary:\n",
            "자네가 온다는 이야기를 들으면 나는 곧 무언가 일어나겠군 하고 생각된다네. 예전처럼 둘이서 수사하지 않겠나.하지만 만일 그렇게 한다면 평범한 사건은 안돼. 피아누라는 번역하기 어려운 말에 가득한 풍미를 곁들이는 듯한 말투였다. “\n",
            "--------------------------------------------------\n",
            "         method  comp ratio     intro      body    ending       var     total  \\\n",
            "0      SAM+WGAN    0.148810  0.575530  0.491906  0.506864  0.001326  0.513118   \n",
            "1  BERT+LexRank    0.267857  0.206440  0.245220  0.355161  0.003968  0.270446   \n",
            "2          BESM    0.172619  0.226682  0.318580  0.463892  0.009537  0.343794   \n",
            "3   BESM+kobert    0.253968  0.459526  0.498303  0.609212  0.004023  0.523820   \n",
            "\n",
            "    grammar  \n",
            "0  0.909339  \n",
            "1  0.999036  \n",
            "2  0.999009  \n",
            "3  0.993899  \n",
            "Current result ==================================================\n",
            "Sample count: 5\n",
            "         method  comp rate     intro      body  conclusion   isthmus  \\\n",
            "0      SAM+WGAN   0.151419  0.490542  0.513125    0.550135  0.005157   \n",
            "1  BERT+LexRank   0.218653  0.325157  0.219400    0.244270  0.011922   \n",
            "2          BESM   0.191691  0.531007  0.389009    0.356094  0.017792   \n",
            "3   BESM+kobert   0.216246  0.588296  0.418232    0.390859  0.016697   \n",
            "\n",
            "   simlirality  grammarity  \n",
            "0     0.519712    0.951087  \n",
            "1     0.248012    0.998961  \n",
            "2     0.407534    0.999021  \n",
            "3     0.444033    0.998000  \n",
            "==================================================\n",
            "6 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "” 그는 한숨을 쉬었다. “범죄란 주문할 수 있는 게 아닌데 말일세. 정말이야. 그렇지만 나는 운을 믿겠네. 운명이라 해도 좋아. 내 곁에 붙어 있으면서 내가 용서받을 수 없는 실책을 저지르는 걸 막아주는 게 자네 운명이야. ” “용서받을 수 없는 실책이란 뭔가?” “명백한 것을 놓치는 것이지. ” 나는 이 말을 가슴속에서 되풀이해 보았으나 핵심을 잡을 수 없었다. 나는 밝게 미소지으며 말했다. “그런데 그 진수라고 할 만한 범죄는 아직 일어나지 않았나?” “적어도 아직은. 왜냐하면……. ” 그는 말을 끊었다. 이마에 난처한 듯한 주름이 잡혔다. 그 손은 내가 생각없이 접어버린 물건을 무의식중에 펴고 있었다. 그는 천천히 말했다. “뚜렷이 알 수는 없지만……. ” 그 말투에 어떤 이상한 게 느껴져 나는 놀라며 그의 얼굴을 보았다. 가로진 주름은 아직 남아 있었다. 그는 갑자기 결심한 듯 고개를 끄덕이고 창 가까이의 책상 쪽으로 방을 가로질러 갔다. 책상 속의 것은 말할 나위도 없이 잘 분류되고 정리되어 손을 넣기만 하면 kq로 필요한 서류를 꺼낼 수 있었다.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.2624216079711914 Generator / grammar loss:-0.13140547275543213   similarity loss:-0.10501114279031754\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "그는 한숨을 믿겠네. 내가 용서받을 수 저지르는 걸 운명이야. 것이지. 없었다. 그 내가 있었다. 알 없지만……. 그 말투에 나는 놀라며 보았다.\n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "책상 속의 것은 말할 나위도 없이 잘 분류되고 정리되어 손을 넣기만 하면 kq로 필요한 서류를 꺼낼 수 있었다.그는 갑자기 결심한 듯 고개를 끄덕이고 창 가까이의 책상 쪽으로 방을 가로질러 갔다.“범죄란 주문할 수 있는 게 아닌데 말일세.” 그는 한숨을 쉬었다.\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "내 곁에 붙어 있으면서 내가 용서받을 수 없는 실책을 저지르는 걸 막아주는 게 자네 운명이야. ” “ 그 손은 내가 생각없이 접어버린 물건을 무의식중에 펴고 있었다.그는 천천히 말했다. “ 그는 갑자기 결심한 듯 고개를 끄덕이고 창 가까이의 책상 쪽으로 방을 가로질러 갔다.\n",
            "--------------------------------------------------\n",
            "besm_bert summary:\n",
            "내 곁에 붙어 있으면서 내가 용서받을 수 없는 실책을 저지르는 걸 막아주는 게 자네 운명이야. ” “ 그 손은 내가 생각없이 접어버린 물건을 무의식중에 펴고 있었다.그는 천천히 말했다. “\n",
            "--------------------------------------------------\n",
            "         method  comp ratio     intro      body    ending       var     total  \\\n",
            "0      SAM+WGAN    0.149171  0.627850  0.574320  0.550683  0.001042  0.577935   \n",
            "1  BERT+LexRank    0.268877  0.210096  0.203510  0.350942  0.004624  0.249057   \n",
            "2          BESM    0.281768  0.350113  0.468322  0.519054  0.005010  0.459900   \n",
            "3   BESM+kobert    0.193370  0.446302  0.580410  0.371630  0.007461  0.490954   \n",
            "\n",
            "    grammar  \n",
            "0  0.973503  \n",
            "1  0.999019  \n",
            "2  0.999005  \n",
            "3  0.988661  \n",
            "Current result ==================================================\n",
            "Sample count: 6\n",
            "         method  comp rate     intro      body  conclusion   isthmus  \\\n",
            "0      SAM+WGAN   0.151044  0.513427  0.523325    0.550227  0.004471   \n",
            "1  BERT+LexRank   0.227024  0.305980  0.216752    0.262049  0.010705   \n",
            "2          BESM   0.206704  0.500858  0.402227    0.383254  0.015662   \n",
            "3   BESM+kobert   0.212433  0.564631  0.445261    0.387654  0.015158   \n",
            "\n",
            "   simlirality  grammarity  \n",
            "0     0.529416    0.954823  \n",
            "1     0.248186    0.998971  \n",
            "2     0.416262    0.999019  \n",
            "3     0.451853    0.996443  \n",
            "==================================================\n",
            "7 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "그는 한 통의 뜯어진 편지를 손에 들고 내 쪽으로 천천히 되돌아왔다. 그리고 그것에 눈길을 한 번 주더니 나에게 내밀며 말했다. “자네는 이걸 어떻게 생각하나?” 나는 어떤 흥미를 가지고 그것을 바았다. 그것은 좀 두꺼운 흰 편지지에 활자체로 씌어 있었다. 에르큘 포아로여, 너는 자만에 빠져 있는 게 아닐까. 갸엾은 우리 멍청이 영국 경찰이 감당하지 못하는 어려운 사건을 해결할 수 있는 건 자신이라고? 명민한 포아로여, 너의 명민함을 어디 한 번 보여 다오. 하지만 너에게는 이 호두가 너무 딱딱할걸. 이 달 21일, 앤도버(Andover)를 경계하라. 이만. ABC 나는 잠시 봉투에 눈길을 주었다. 역시 활자체로 씌어 있었다. 내가 소인에 주의를 돌리고 있는 것을 보자 그가 말했다. “소인은 서중앙 제1국일세. 그래, 어떻게 생각하나?” 나는 어깨를 으쓱해 보이며 편지를 돌려주었다. “아마도 미치광이 짓이겠지. ” “그뿐인가?” “자네한테는 미치광이로 여겨지지 않는다는 건가?” “아니, 그렇게 여겨지네. ” 그의 말투는 진지했다. 나는 호기심을 느끼며 그를 보았다. “자네는 이 편지를 진지하게 받아들이고 있는 모양이군, 포아로.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:1.9810421466827393 Generator / grammar loss:-0.09112455695867538   similarity loss:-0.09302041679620743\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            " 어떻게 나는 에르큘 포아로여, 해결할 포아로여, 호두가 딱딱할걸. 이만. 나는 그가 생각하나?” 보이며 편지를 짓이겠지. 이 진지하게 있는 모양이군, 포아로.\n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "이만.갸엾은 우리 멍청이 영국 경찰이 감당하지 못하는 어려운 사건을 해결할 수 있는 건 자신이라고?하지만 너에게는 이 호두가 너무 딱딱할걸.이 달 21일, 앤도버(Andover)를 경계하라.\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "그것은 좀 두꺼운 흰 편지지에 활자체로 씌어 있었다.에르큘 포아로여, 너는 자만에 빠져 있는 게 아닐까. 갸엾은 우리 멍청이 영국 경찰이 감당하지 못하는 어려운 사건을 해결할 수 있는 건 자신이라고?\n",
            "--------------------------------------------------\n",
            "besm_bert summary:\n",
            "그것은 좀 두꺼운 흰 편지지에 활자체로 씌어 있었다.에르큘 포아로여, 너는 자만에 빠져 있는 게 아닐까. 갸엾은 우리 멍청이 영국 경찰이 감당하지 못하는 어려운 사건을 해결할 수 있는 건 자신이라고?\n",
            "--------------------------------------------------\n",
            "         method  comp ratio     intro      body    ending       var     total  \\\n",
            "0      SAM+WGAN    0.152659  0.519191  0.568588  0.567619  0.000532  0.558418   \n",
            "1  BERT+LexRank    0.181818  0.183497  0.283425  0.193003  0.002028  0.236313   \n",
            "2          BESM    0.190395  0.436673  0.395327  0.302113  0.003167  0.375632   \n",
            "3   BESM+kobert    0.190395  0.436673  0.395327  0.302113  0.003167  0.375632   \n",
            "\n",
            "    grammar  \n",
            "0  0.863206  \n",
            "1  0.999057  \n",
            "2  0.999039  \n",
            "3  0.999039  \n",
            "Current result ==================================================\n",
            "Sample count: 7\n",
            "         method  comp rate     intro      body  conclusion   isthmus  \\\n",
            "0      SAM+WGAN   0.151275  0.514250  0.529791    0.552711  0.003909   \n",
            "1  BERT+LexRank   0.220566  0.288482  0.226276    0.252185  0.009466   \n",
            "2          BESM   0.204374  0.491689  0.401242    0.371663  0.013877   \n",
            "3   BESM+kobert   0.209285  0.546351  0.438128    0.375434  0.013445   \n",
            "\n",
            "   simlirality  grammarity  \n",
            "0     0.533559    0.941735  \n",
            "1     0.246490    0.998983  \n",
            "2     0.410458    0.999022  \n",
            "3     0.440964    0.996814  \n",
            "==================================================\n",
            "8 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "” “미치광이란 진지하게 다루어야 하지. 미치광이는 아주 위험한 존재니까. ” “그렇지, 물론 그렇네. 나는 그 점을 생각지 못했어. 그러나 내 말은, 어쩐지 우스꽝스러운 장난같은 생각이 든다는 걸세. 누군가, 8이라는 숫자에 하나가 더 많은 것 같은 우쭐해진 주정꾼 바보 말이네. ” “뭐라고? 아홉이란 말인가? 그건 대체 무슨 뜻이지?” “아니, 그냥 말장난일세. 취한 녀석이라는 뜻이지. 아니, 그보다도 지나치게 마셔서 고주망태가 된 녀석이라는 뜻일세. ” “고맙네, 헤이스팅즈. 그 <취한다>는 말이라면 나도 알고 있네. 자네 말대로 그 이상의 뜻은 없는지도 모르지만. ‘ 나는 그의 불만스러운 말투에 자극되어 물어 보았다. “그럼, 자네는 무엇이 있다고 생각하나?” 포아로는 의심스러운 듯 머리를 흔들었지만 아무 말도 하지 않았다. 나는 물었다. “그래서 자네는 어떻게 했나?” “어떻게 할 수 있었겠나? 재프 경감에게 보였을 뿐이지. 그는 자네와 같은 의견이었어.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.035175085067749 Generator / grammar loss:-0.09290975332260132   similarity loss:-0.08939187973737717\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "나는 생각지 말은, 뜻이지?” “아니, 그냥 녀석이라는 고주망태가 나도 알고 있네. 자네 보았다. 생각하나?” 뿐이지.\n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "미치광이는 아주 위험한 존재니까.재프 경감에게 보였을 뿐이지.아홉이란 말인가?” “미치광이란 진지하게 다루어야 하지.\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "나는 그 점을 생각지 못했어.그러나 내 말은, 어쩐지 우스꽝스러운 장난같은 생각이 든다는 걸세. 누군가, 8이라는 숫자에 하나가 더 많은 것 같은 우쭐해진 주정꾼 바보 말이네. ” “\n",
            "--------------------------------------------------\n",
            "besm_bert summary:\n",
            "나는 그 점을 생각지 못했어.그러나 내 말은, 어쩐지 우스꽝스러운 장난같은 생각이 든다는 걸세. 누군가, 8이라는 숫자에 하나가 더 많은 것 같은 우쭐해진 주정꾼 바보 말이네. ” “\n",
            "--------------------------------------------------\n",
            "         method  comp ratio     intro      body    ending       var     total  \\\n",
            "0      SAM+WGAN    0.134969  0.502203  0.536732  0.580140  0.001017  0.542848   \n",
            "1  BERT+LexRank    0.132924  0.357364  0.157886  0.121417  0.010755  0.186841   \n",
            "2          BESM    0.208589  0.470520  0.608479  0.418833  0.006408  0.523993   \n",
            "3   BESM+kobert    0.208589  0.470520  0.608479  0.418833  0.006408  0.523993   \n",
            "\n",
            "    grammar  \n",
            "0  0.820664  \n",
            "1  0.998984  \n",
            "2  0.995235  \n",
            "3  0.995235  \n",
            "Current result ==================================================\n",
            "Sample count: 8\n",
            "         method  comp rate     intro      body  conclusion   isthmus  \\\n",
            "0      SAM+WGAN   0.149236  0.512744  0.530658    0.556140  0.003547   \n",
            "1  BERT+LexRank   0.209611  0.297093  0.217728    0.235839  0.009627   \n",
            "2          BESM   0.204901  0.489043  0.427146    0.377559  0.012943   \n",
            "3   BESM+kobert   0.209198  0.536872  0.459422    0.380859  0.012565   \n",
            "\n",
            "   simlirality  grammarity  \n",
            "0     0.534720    0.926601  \n",
            "1     0.239034    0.998983  \n",
            "2     0.424649    0.998548  \n",
            "3     0.451343    0.996617  \n",
            "==================================================\n",
            "9 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "할 짓 없는 녀석의 장난이라고 말일세. 그것이 그의 표현이었는데, 런던 경찰국에서는 거의 날마다 이런 것을 받는다는군. 나도 그 바람에 휘말려 들었다는 거였어. ” “하지만 자네는 이 편지를 진지하게 생각하고 있잖은가?” 포아로는 천천히 대답했다. “아무래도 이 편지에는 내 마음에 들지 않는 게 있어, 헤이스팅즈. ” 그 말투가 묘하게 인상적이었다. “그래, 자네 의견은?” 그는 고개를 젓고 그 편지를 들어올려 다시 책상 속에 넣어 버렸다. “자네가 그토록 진지하게 생각한다면 왜 아무 일도 하지 않고 있는 건가?” “여전히 활동가로군, 자네는! 하지만 대체 어떻게 할 수 있겠나? 지방 경찰에도 편지를 보였지만 역시 진지하게 여겨 주지 않았어. 지문도 없고, 편지를 낸 사람에 대한 단서도 없으니. ” “그렇다면 자네 육감 말고는 아무것도 없단 말인가?” “육감이 아닐세, 헤이스팅즈. 육감이란 나쁜 말이야. 내 지식이며 경험일세. 그 편지에 뭔가 이상한 게 있다고 가르쳐 주는 것은. ” 말이 막히자 그는 손짓을 해보였다. 그리고 또 머리를 흔들었다. “개미집에서 산을 만들어 내려 하고 있는지도 모르지만 말일세. 어쨌든 기다려 보는 수밖에 없어. ” “옳지, 21일은 금요일이군.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.364590883255005 Generator / grammar loss:-0.13069266080856323   similarity loss:-0.0938214510679245\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "짓 없는 말일세. 런던 경찰국에서는 날마다 받는다는군. 거였어. 자네는 천천히 “아무래도 헤이스팅즈. 자네 의견은?” 고개를 편지를 들어올려 버렸다. 주지 말이야. 경험일세.\n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "” “옳지, 21일은 금요일이군.그것이 그의 표현이었는데, 런던 경찰국에서는 거의 날마다 이런 것을 받는다는군.“개미집에서 산을 만들어 내려 하고 있는지도 모르지만 말일세.나도 그 바람에 휘말려 들었다는 거였어.\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "그것이 그의 표현이었는데, 런던 경찰국에서는 거의 날마다 이런 것을 받는다는군. 자네가 그토록 진지하게 생각한다면 왜 아무 일도 하지 않고 있는 건가?” “\n",
            "--------------------------------------------------\n",
            "besm_bert summary:\n",
            "그것이 그의 표현이었는데, 런던 경찰국에서는 거의 날마다 이런 것을 받는다는군. 자네가 그토록 진지하게 생각한다면 왜 아무 일도 하지 않고 있는 건가?” “\n",
            "--------------------------------------------------\n",
            "         method  comp ratio     intro      body    ending       var     total  \\\n",
            "0      SAM+WGAN    0.159278  0.718863  0.570060  0.430010  0.013910  0.557806   \n",
            "1  BERT+LexRank    0.193760  0.392384  0.129257  0.224416  0.011834  0.210430   \n",
            "2          BESM    0.142857  0.554238  0.393560  0.308699  0.010368  0.400237   \n",
            "3   BESM+kobert    0.142857  0.554238  0.393560  0.308699  0.010368  0.400237   \n",
            "\n",
            "    grammar  \n",
            "0  0.982520  \n",
            "1  0.999041  \n",
            "2  0.999015  \n",
            "3  0.999015  \n",
            "Current result ==================================================\n",
            "Sample count: 9\n",
            "         method  comp rate     intro      body  conclusion   isthmus  \\\n",
            "0      SAM+WGAN   0.150352  0.535647  0.535036    0.542125  0.004699   \n",
            "1  BERT+LexRank   0.207850  0.307681  0.207897    0.234570  0.009872   \n",
            "2          BESM   0.198007  0.496287  0.423414    0.369908  0.012657   \n",
            "3   BESM+kobert   0.201827  0.538802  0.452104    0.372841  0.012321   \n",
            "\n",
            "   simlirality  grammarity  \n",
            "0     0.537285    0.932814  \n",
            "1     0.235856    0.998989  \n",
            "2     0.421937    0.998600  \n",
            "3     0.445665    0.996883  \n",
            "==================================================\n",
            "10 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "앤도버에서 굉장한 강도 사건이라도 일어난다면 그야말로……. ” “아, 그렇다면 얼마나 기분전환이 되겠나. ” “기분전환이라고?” 나는 어이가 없었다. 그 자리에서 그 말은 너무나 이상스럽게 들렸다. 나는 항의했다. “강도는 스릴이 있을지 모르지만 기분전환이라고 할 수는 없어!” 포아로는 힘주어 고개를 저었다. “자네는 잘못 알고 있네. 자네는 내 말뜻을 모르고 있어. 내 마음을 차지하고 있는 더 큰 다른 염려에 비하면, 강도는 오히려 마음 놓을 수 있다는 걸세. ” “무슨 염려인가?” “살인이지. ‘ < 삽 화 > 앨릭잰더 보너퍼트 캐스트 씨는 의자에서 일어나 초라한 침실을 근시인 듯한 눈으로 둘러보았다. 답답스러운 자세로 앉아있었기 때문에 등이 완전히 뻣뻣해져 버렸다. 등을 쭉 펴고 기지개 켜는 그를 본 사람은, 그가 실제로는 키가 큰 사람임을 알았으리라. 그의 굽은 등과 근시처럼 기웃거리는 동작이 아주 다른 인상을 주고 있었다. 문 안쪽에 걸린 낡아빠진 외투로 다가가 주머니에서 싸구려 담뱃갑과 성냥을 꺼냈다. 담배에 불을 붙이고 지금까지 앉아있던 의자로 돌아왔다. 철도 안내서를 집어 들고 세밀히 보더니 이윽고 타이프된 이름 리스트를 훑어보기 시작했다. 그는 펜으로 그 리스트의 첫 번째 이름에 표시했다. 그것은 6월 20일 목요일의 일이었다. < 앤도버 살인 > 나는 그때 포아로가 받은 편지에 대한 그의 예감에 깊은 인상을 받은 건 사실이지만, 그 일은 내 머리에서 아주 사라져 버렸다고 해도 좋다.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.444972276687622 Generator / grammar loss:-0.14226622879505157   similarity loss:-0.09701221436262131\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "강도 “아, 얼마나 기분전환이 되겠나. 나는 그 이상스럽게 들렸다. 모르고 다른 염려에 근시처럼 세밀히 보더니 그것은 20일 < 앤도버 포아로가 받은 예감에 깊은 일은 아주 사라져 좋다.\n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "그것은 6월 20일 목요일의 일이었다.그는 펜으로 그 리스트의 첫 번째 이름에 표시했다.담배에 불을 붙이고 지금까지 앉아있던 의자로 돌아왔다.철도 안내서를 집어 들고 세밀히 보더니 이윽고 타이프된 이름 리스트를 훑어보기 시작했다.\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "내 마음을 차지하고 있는 더 큰 다른 염려에 비하면, 강도는 오히려 마음 놓을 수 있다는 걸세. ” “ 등을 쭉 펴고 기지개 켜는 그를 본 사람은, 그가 실제로는 키가 큰 사람임을 알았으리라. 그의 굽은 등과 근시처럼 기웃거리는 동작이 아주 다른 인상을 주고 있었다.\n",
            "--------------------------------------------------\n",
            "besm_bert summary:\n",
            "내 마음을 차지하고 있는 더 큰 다른 염려에 비하면, 강도는 오히려 마음 놓을 수 있다는 걸세. ” “ 등을 쭉 펴고 기지개 켜는 그를 본 사람은, 그가 실제로는 키가 큰 사람임을 알았으리라. < 앤도버 살인 > 나는 그때 포아로가 받은 편지에 대한 그의 예감에 깊은 인상을 받은 건 사실이지만, 그 일은 내 머리에서 아주 사라져 버렸다고 해도 좋다.\n",
            "--------------------------------------------------\n",
            "         method  comp ratio     intro      body    ending       var     total  \\\n",
            "0      SAM+WGAN    0.140921  0.668936  0.411998  0.287683  0.025203  0.426091   \n",
            "1  BERT+LexRank    0.173442  0.002094  0.005932  0.486895  0.051819  0.149453   \n",
            "2          BESM    0.201897  0.445014  0.592064  0.178029  0.029370  0.438444   \n",
            "3   BESM+kobert    0.265583  0.427589  0.456546  0.344562  0.002252  0.417159   \n",
            "\n",
            "    grammar  \n",
            "0  0.996800  \n",
            "1  0.998982  \n",
            "2  0.998998  \n",
            "3  0.999031  \n",
            "Current result ==================================================\n",
            "Sample count: 10\n",
            "         method  comp rate     intro      body  conclusion   isthmus  \\\n",
            "0      SAM+WGAN   0.149409  0.548976  0.522733    0.516681  0.006749   \n",
            "1  BERT+LexRank   0.204409  0.277122  0.187701    0.259802  0.014067   \n",
            "2          BESM   0.198396  0.491159  0.440279    0.350720  0.014328   \n",
            "3   BESM+kobert   0.208202  0.527680  0.452548    0.370013  0.011314   \n",
            "\n",
            "   simlirality  grammarity  \n",
            "0     0.526166    0.939213  \n",
            "1     0.227216    0.998989  \n",
            "2     0.423588    0.998640  \n",
            "3     0.442814    0.997098  \n",
            "==================================================\n",
            "11 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "실제로 21일이 되어 런던 경찰국의 재프 경감이 포아로를 찾아왔을 때 나는 겨우 그 일을 생각해 냈다. 이 사법 경찰관과는 이미 오래 전부터 알고 있었기 때문에 그는 나를 보자 진심으로 환영해 주었다. 그는 큰소리로 말했다. “여, 내가 헤이스팅즈 대위를 몰라볼 리 있겠습니까. 드디어 당신의 야만 지대에서 돌아오셨군요! 포아로 씨와 함께 계신 당신을 뵈니 정말 예전 그대로입니다 그려. 게다가 건강하신 듯 하군요. 머리가 좀 벗겨졌는가요? 그렇습니다, 누구나 그렇게 되지요. 나도 그렇습니다. ” 나는 좀 놀랐다. 머리 꼭대기에 머리칼이 덮이도록 빗어 두었기 때문에 벗겨진 곳이 눈에 띄지 않으리라 여기고 있었던 것이다. 그러나 재프 경감은 그런 점에 그리 머리가 잘 도는 편이 아니었다. 그래서 나는 좋은 얼굴로 아무도 젊어지는 사람은 없다는 데 동의했다. 재프 경감은 말했다. “그러나 이 포아로 씨만은 다릅니다. 헤어토닉의 좋은 광고가 되지요. 얼굴 구석구석이 한층 더 싱싱해졌습니다. 늘그막에 이르러 점점 더 각광받게 되셨으니 말입니다. 요즘의 유명한 사건에는 모조리 관계되어 계시지요.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.2726197242736816 Generator / grammar loss:-0.12393184006214142   similarity loss:-0.09649909287691116\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "재프 나는 그는 나를 말했다. “여, 내가 리 정말 예전 듯 하군요. 나도 도는 그래서 다릅니다. 되지요. 얼굴 구석구석이 말입니다. 모조리\n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "머리 꼭대기에 머리칼이 덮이도록 빗어 두었기 때문에 벗겨진 곳이 눈에 띄지 않으리라 여기고 있었던 것이다.그러나 재프 경감은 그런 점에 그리 머리가 잘 도는 편이 아니었다.실제로 21일이 되어 런던 경찰국의 재프 경감이 포아로를 찾아왔을 때 나는 겨우 그 일을 생각해 냈다.머리가 좀 벗겨졌는가요?\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "실제로 21일이 되어 런던 경찰국의 재프 경감이 포아로를 찾아왔을 때 나는 겨우 그 일을 생각해 냈다. 그래서 나는 좋은 얼굴로 아무도 젊어지는 사람은 없다는 데 동의했다.재프 경감은 말했다. “\n",
            "--------------------------------------------------\n",
            "besm_bert summary:\n",
            "실제로 21일이 되어 런던 경찰국의 재프 경감이 포아로를 찾아왔을 때 나는 겨우 그 일을 생각해 냈다. 이 사법 경찰관과는 이미 오래 전부터 알고 있었기 때문에 그는 나를 보자 진심으로 환영해 주었다. 여, 내가 헤이스팅즈 대위를 몰라볼 리 있겠습니까.드디어 당신의 야만 지대에서 돌아오셨군요!\n",
            "--------------------------------------------------\n",
            "         method  comp ratio     intro      body    ending       var     total  \\\n",
            "0      SAM+WGAN    0.140036  0.446721  0.496493  0.535682  0.001325  0.498296   \n",
            "1  BERT+LexRank    0.298025  0.286834  0.284170  0.217601  0.001026  0.264732   \n",
            "2          BESM    0.195691  0.572075  0.438657  0.388805  0.005986  0.450385   \n",
            "3   BESM+kobert    0.294434  0.738210  0.371531  0.349616  0.031771  0.438292   \n",
            "\n",
            "    grammar  \n",
            "0  0.921129  \n",
            "1  0.999038  \n",
            "2  0.988811  \n",
            "3  0.999000  \n",
            "Current result ==================================================\n",
            "Sample count: 11\n",
            "         method  comp rate     intro      body  conclusion   isthmus  \\\n",
            "0      SAM+WGAN   0.148557  0.539680  0.520347    0.518409  0.006256   \n",
            "1  BERT+LexRank   0.212919  0.278005  0.196471    0.255966  0.012881   \n",
            "2          BESM   0.198150  0.498515  0.440132    0.354182  0.013570   \n",
            "3   BESM+kobert   0.216042  0.546819  0.445183    0.368159  0.013174   \n",
            "\n",
            "   simlirality  grammarity  \n",
            "0     0.523632    0.937569  \n",
            "1     0.230626    0.998993  \n",
            "2     0.426024    0.997746  \n",
            "3     0.442403    0.997271  \n",
            "==================================================\n",
            "12 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "열차 사건, 공중에서의 사건, 사교계 살인 사건……. 정말이지 여기서기에 이분은 등장합니다. 은퇴하고 나서 훨씬 더 유명해지셨답니다. ” 포아로가 웃으며 말했다, “요전에도 헤이스팅즈에게 말했었지요. 나는 언제나 또다시 등장하는 프리마돈나 같다고“ “마지막에는 자신의 죽음을 탐정한다 해도 우스운 일이 아닐겁니다. 이건 기발한 생각인데, 정말. 책에 써둬야겠어. ” 재프 경감은 커다랗게 웃었다. 포아로는 내게 눈짓을 해보였다. “그것을 해야 할 사람은 우선 헤이스팅즈지요. ” 재프 경감은 웃었다. “하하하! 농담입니다, 농담입니다. ” 나는 그 생각이 어째서 악취미로 여겨졌다. 가엾게도 포아로는 점점 나이를 먹어 가고 있다. 죽음이 가까이 오는 것과 관계된 그 농담이 그에게 유쾌할 리 없을 것이다. 내 태도에 속마음이 나타나 있었던 모양이다. 재프 경감은 화재를 바꾸었다. “포아로 씨의 익명 편지에 대해 들으셨습니까?” 포아로가 말했다. “저번에 보여 줬지요.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.23047137260437 Generator / grammar loss:-0.12517908215522766   similarity loss:-0.10202910751104355\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            " 유명해지셨답니다. 헤이스팅즈에게 나는 탐정한다 써둬야겠어. 해보였다. 할 “하하하! 나는 그 생각이 여겨졌다. 유쾌할 것이다.\n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "책에 써둬야겠어.열차 사건, 공중에서의 사건, 사교계 살인 사건…….죽음이 가까이 오는 것과 관계된 그 농담이 그에게 유쾌할 리 없을 것이다.“포아로 씨의 익명 편지에 대해 들으셨습니까?” 포아로가 말했다.\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "포아로가 웃으며 말했다, “요전에도 헤이스팅즈에게 말했었지요.나는 언제나 또다시 등장하는 프리마돈나 같다고“ “마지막에는 자신의 죽음을 탐정한다 해도 우스운 일이 아닐겁니다. 나는 그 생각이 어째서 악취미로 여겨졌다.가엾게도 포아로는 점점 나이를 먹어 가고 있다.\n",
            "--------------------------------------------------\n",
            "besm_bert summary:\n",
            "포아로가 웃으며 말했다, “요전에도 헤이스팅즈에게 말했었지요.나는 언제나 또다시 등장하는 프리마돈나 같다고“ “마지막에는 자신의 죽음을 탐정한다 해도 우스운 일이 아닐겁니다. 나는 그 생각이 어째서 악취미로 여겨졌다.가엾게도 포아로는 점점 나이를 먹어 가고 있다.\n",
            "--------------------------------------------------\n",
            "         method  comp ratio     intro      body    ending       var     total  \\\n",
            "0      SAM+WGAN    0.146091  0.515062  0.545035  0.418821  0.002899  0.501176   \n",
            "1  BERT+LexRank    0.236626  0.255164  0.172279  0.276255  0.002014  0.220049   \n",
            "2          BESM    0.302469  0.436276  0.381169  0.416057  0.000518  0.402657   \n",
            "3   BESM+kobert    0.302469  0.436276  0.381169  0.416057  0.000518  0.402657   \n",
            "\n",
            "    grammar  \n",
            "0  0.950365  \n",
            "1  0.999044  \n",
            "2  0.998967  \n",
            "3  0.998967  \n",
            "Current result ==================================================\n",
            "Sample count: 12\n",
            "         method  comp rate     intro      body  conclusion   isthmus  \\\n",
            "0      SAM+WGAN   0.148351  0.537628  0.522404    0.510110  0.005976   \n",
            "1  BERT+LexRank   0.214895  0.276101  0.194455    0.257657  0.011976   \n",
            "2          BESM   0.206843  0.493329  0.435218    0.359339  0.012482   \n",
            "3   BESM+kobert   0.223244  0.537607  0.439848    0.372151  0.012119   \n",
            "\n",
            "   simlirality  grammarity  \n",
            "0     0.521761    0.938635  \n",
            "1     0.229745    0.998997  \n",
            "2     0.424077    0.997848  \n",
            "3     0.439091    0.997412  \n",
            "==================================================\n",
            "13 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "” 나는 소리쳤다. “아, 그렇지. 완전히 잊고 있었어. 문제의 날짜가 언제였지?” 재프 경감이 말했다. “21일입니다. 그래서 내가 조사해 보았지요. 어제가 21일이었기 때문에, 어젯밤 혹시나 싶어 앤도버를 불러 보았습니다. 그랬더니 역시 장난이었지요. 아무 일도 없었으니까요. 어린아이가 돌을 던져 쇼윈도가 하나 깨진 일과 술주정꾼의 규칙 위반이 두 건. 그래서 우리 벨기에인 친구분(포아로)이 처음으로 헛짚으신 게 되었다는 이야기입니다. ” 포아로는 인정했다. “확실히 한시름 놓았습니다. ” 재프 경감이 동정하듯 말했다. “많이 염려하고 계신 것 같았습니다만? 가엾게도, 우리는 그런 것을 날마다 몇십 통씩 받는답니다. 달리 아무 하릴없는 머리가 좀 이상한 사람들이 그런 것을 쓰지요. 그리 악의가 있는 건 아닙니다. 뭐, 일종의 흥분에서지요. ” 포아로가 말했다.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.215564489364624 Generator / grammar loss:-0.12685763835906982   similarity loss:-0.10521713644266129\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "소리쳤다. “아, 경감이 “21일입니다. 그래서 보았지요. 어제가 그랬더니 없었으니까요. 하나 그래서 한시름 경감이 말했다. 흥분에서지요.\n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "어린아이가 돌을 던져 쇼윈도가 하나 깨진 일과 술주정꾼의 규칙 위반이 두 건.그래서 우리 벨기에인 친구분(포아로)이 처음으로 헛짚으신 게 되었다는 이야기입니다.” 재프 경감이 동정하듯 말했다.“많이 염려하고 계신 것 같았습니다만?문제의 날짜가 언제였지?” 재프 경감이 말했다.“21일입니다.\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "어제가 21일이었기 때문에, 어젯밤 혹시나 싶어 앤도버를 불러 보았습니다. 그래서 우리 벨기에인 친구분(포아로)이 처음으로 헛짚으신 게 되었다는 이야기입니다. ”\n",
            "--------------------------------------------------\n",
            "besm_bert summary:\n",
            "어제가 21일이었기 때문에, 어젯밤 혹시나 싶어 앤도버를 불러 보았습니다. 그래서 우리 벨기에인 친구분(포아로)이 처음으로 헛짚으신 게 되었다는 이야기입니다. ”\n",
            "--------------------------------------------------\n",
            "         method  comp ratio     intro      body    ending       var     total  \\\n",
            "0      SAM+WGAN    0.178241  0.757084  0.556416  0.517003  0.011051  0.584726   \n",
            "1  BERT+LexRank    0.375000  0.084309  0.257293  0.176951  0.004996  0.198594   \n",
            "2          BESM    0.208333  0.552811  0.577939  0.409813  0.005483  0.522476   \n",
            "3   BESM+kobert    0.208333  0.552811  0.577939  0.409813  0.005483  0.522476   \n",
            "\n",
            "    grammar  \n",
            "0  0.959740  \n",
            "1  0.998997  \n",
            "2  0.995576  \n",
            "3  0.995576  \n",
            "Current result ==================================================\n",
            "Sample count: 13\n",
            "         method  comp rate     intro      body  conclusion   isthmus  \\\n",
            "0      SAM+WGAN   0.150651  0.554509  0.525021    0.510640  0.006367   \n",
            "1  BERT+LexRank   0.227211  0.261348  0.199289    0.251448  0.011439   \n",
            "2          BESM   0.206958  0.497904  0.446197    0.363221  0.011944   \n",
            "3   BESM+kobert   0.222097  0.538777  0.450471    0.375048  0.011609   \n",
            "\n",
            "   simlirality  grammarity  \n",
            "0     0.526604    0.940259  \n",
            "1     0.227348    0.998997  \n",
            "2     0.431646    0.997673  \n",
            "3     0.445505    0.997271  \n",
            "==================================================\n",
            "14 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "“그걸 그토록 진지하게 생각했던 건 정말 어리석은 짓이었습니다. 내가 코를 들이민 것은 새의 보금자리였던 셈이군요. ” 재프 경감이 말했다. “말과 벌을 혼동했던 겁니다. ” “뭐라고요?” “아니, 속담입니다. 자, 이제 가봐야겠군요. 이 가까이에 볼일이 있어서요. 도난품인 보석을 인수하러 왔지요. 그곳에 가는 길에 마음 놓으시도록 잠시 들렀던 겁니다. 회색 뇌세포를 뜻없이 써버리는 건 낭비니가요. ” 재프 경감은 기분좋게 웃으며 돌아갔다. 포아로가 말했다. “사람좋은 재프 경감은 그리 달라지지 않았지?” 나는 보복하듯 말했다. “아주 늙었군. 오소리같이 잿빛이 되었어. ” 포아로는 헛기침을 하고 나서 말했다. “헤이스팅즈, 아주 하찮은 장치가 있는데, 내 단골 이발사는 재간있는 사나이지. 머리에 그 장치를 붙이고 그 위에 자신의 머리칼을 벗어 놓는다네. 그건 가발이 아닐세, 잘 알겠지만. ” 나는 으르렁댔다.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.3092451095581055 Generator / grammar loss:-0.12003492563962936   similarity loss:-0.08886035531759262\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            " “그걸 건 정말 내가 “아니, 자, 가봐야겠군요. 가까이에 볼일이 있어서요. 말했다. “사람좋은 달라지지 않았지?”\n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "도난품인 보석을 인수하러 왔지요.회색 뇌세포를 뜻없이 써버리는 건 낭비니가요.그곳에 가는 길에 마음 놓으시도록 잠시 들렀던 겁니다.내가 코를 들이민 것은 새의 보금자리였던 셈이군요.\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "헤이스팅즈, 아주 하찮은 장치가 있는데, 내 단골 이발사는 재간있는 사나이지.\n",
            "--------------------------------------------------\n",
            "besm_bert summary:\n",
            "헤이스팅즈, 아주 하찮은 장치가 있는데, 내 단골 이발사는 재간있는 사나이지.\n",
            "--------------------------------------------------\n",
            "         method  comp ratio     intro      body    ending       var     total  \\\n",
            "0      SAM+WGAN    0.141612  0.320480  0.567967  0.468887  0.010343  0.488745   \n",
            "1  BERT+LexRank    0.220044  0.286580  0.251817  0.182143  0.001886  0.237868   \n",
            "2          BESM    0.093682  0.202661  0.228209  0.374317  0.005718  0.266932   \n",
            "3   BESM+kobert    0.093682  0.202661  0.228209  0.374317  0.005718  0.266932   \n",
            "\n",
            "    grammar  \n",
            "0  0.966156  \n",
            "1  0.999017  \n",
            "2  0.998940  \n",
            "3  0.998940  \n",
            "Current result ==================================================\n",
            "Sample count: 14\n",
            "         method  comp rate     intro      body  conclusion   isthmus  \\\n",
            "0      SAM+WGAN   0.150005  0.537793  0.528088    0.507658  0.006651   \n",
            "1  BERT+LexRank   0.226699  0.263150  0.203041    0.246498  0.010756   \n",
            "2          BESM   0.198867  0.476816  0.430626    0.364014  0.011499   \n",
            "3   BESM+kobert   0.212924  0.514769  0.434595    0.374995  0.011188   \n",
            "\n",
            "   simlirality  grammarity  \n",
            "0      0.52390    0.942108  \n",
            "1      0.22810    0.998999  \n",
            "2      0.41988    0.997764  \n",
            "3      0.43275    0.997390  \n",
            "==================================================\n",
            "15 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "“포아로, 분통 치미는 자네 이발사의 더러운 발견 따윈 아무래도 좋네. 대체 내 머리가 어떻다고 그런 소리를 하는 건가?” “아니, 아무렇지도 않아, 아무렇지도. ” “내가 대머리가 되어가고 있다는 건 아니겠지?” “물론 그런 건 아닐세! 그런 건……. ” “그 나라의 뜨거운 여름은 절로 얼마쯤 머리를 벗겨지게 하지만 말이야. 그냥 질좋은 헤어토닉이나 가져가지. ” “그게 좋겠군. ” “그렇다 해도 재프 경감 따위가 관여할 일은 아니야. 녀석은 언제나 기분좋지 않았지. 게다가 유머 센스도 없어. 사람이 앉으려고 할 때 의자를 잡아당겨지면 웃는 그런 사나이거든. ” “그러면 사람들은 대개 웃지. ” “모름지기 센스가 없단 말일세. ” “앉으려던 사람의 입장에서 본다면 확실히 그렇지. ” “그렇네. ” 나는 얼마쯤 기분을 돌리며 다시 말했다―머리칼이 적어졌다는 말에 내가 아주 민감해 있다는 것을 인정하지 않으면 안 되겠다. “익명 편지가 아무 일 없었다니 유감이군. ‘ “그것은 완전히 내 잘못 생각이었네. 그 편지에 어쩐지 피비린내나는 것 같은 느낌이 있었는데, 그러나 단순한 장난이었어. 아, 나도 나이 먹어 아무것도 아닌 일에 짖어대는 눈먼 개처럼 의심이 많아져 버렸나 보네.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.332427501678467 Generator / grammar loss:-0.11993356049060822   similarity loss:-0.08637949824333191\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "“포아로, 좋네. “물론 건……. ” “그 나라의 절로 머리를 하지만 ” ” 재프 경감 유머 사나이거든. 대개 센스가 “그렇네. 일 나이\n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "그냥 질좋은 헤어토닉이나 가져가지.” “그게 좋겠군.” “앉으려던 사람의 입장에서 본다면 확실히 그렇지.” “그렇네.사람이 앉으려고 할 때 의자를 잡아당겨지면 웃는 그런 사나이거든.\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "나는 얼마쯤 기분을 돌리며 다시 말했다―머리칼이 적어졌다는 말에 내가 아주 민감해 있다는 것을 인정하지 않으면 안 되겠다. “ 그 편지에 어쩐지 피비린내나는 것 같은 느낌이 있었는데, 그러나 단순한 장난이었어.\n",
            "--------------------------------------------------\n",
            "besm_bert summary:\n",
            "나는 얼마쯤 기분을 돌리며 다시 말했다―머리칼이 적어졌다는 말에 내가 아주 민감해 있다는 것을 인정하지 않으면 안 되겠다. “ 아, 나도 나이 먹어 아무것도 아닌 일에 짖어대는 눈먼 개처럼 의심이 많아져 버렸나 보네.\n",
            "--------------------------------------------------\n",
            "         method  comp ratio     intro      body    ending       var     total  \\\n",
            "0      SAM+WGAN    0.124795  0.490123  0.459126  0.420288  0.000816  0.453674   \n",
            "1  BERT+LexRank    0.165846  0.231311  0.342144  0.240685  0.002518  0.289540   \n",
            "2          BESM    0.192118  0.401859  0.345628  0.543765  0.006951  0.416316   \n",
            "3   BESM+kobert    0.198686  0.378314  0.339265  0.511452  0.005433  0.398731   \n",
            "\n",
            "    grammar  \n",
            "0  0.935316  \n",
            "1  0.999003  \n",
            "2  0.999021  \n",
            "3  0.999033  \n",
            "Current result ==================================================\n",
            "Sample count: 15\n",
            "         method  comp rate     intro      body  conclusion   isthmus  \\\n",
            "0      SAM+WGAN   0.148324  0.534615  0.523491    0.501833  0.006262   \n",
            "1  BERT+LexRank   0.222642  0.261028  0.212314    0.246111  0.010207   \n",
            "2          BESM   0.198417  0.471818  0.424960    0.375997  0.011196   \n",
            "3   BESM+kobert   0.211975  0.505672  0.428240    0.384093  0.010804   \n",
            "\n",
            "   simlirality  grammarity  \n",
            "0     0.519218    0.941656  \n",
            "1     0.232196    0.998999  \n",
            "2     0.419643    0.997848  \n",
            "3     0.430482    0.997500  \n",
            "==================================================\n",
            "16 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "” 나는 웃으며 말했다. “내가 도우려면, 우리는 다른 데서 온갖 진수가 모아진 멋진 범죄를 찾아내야만 되겠군. ” “자네는 요전에 내가 했던 말을 기억하고 있나? 만일 요리를 주문하듯 범죄를 주문할 수 있다면 어떤 것을 고르겠나?” 나는 좋아진 그의 기분에 휩쓸려 말했다. “그렇지, 메뉴를 잘 봐야 하지 않겠나. 강도? 위조지폐? 아니, 이런 건 안 돼? 이건 식물성 요리 같지? 역시 살인이 좋겠군. 피비린내나는 살인사건, 물론 여러 가지가 딸린 것으로. ” “옳지, 오르되브르(식사 전 또는 술안주로 먹는 가벼운 요리)로군. ” “피해자는 남자로 할까, 여자로 할까? 역시 남자가 좋겠어. 누군가 유명한 사람, 미국의 백만장자나 국무장관이나 신문사 사장쯤 되는 인물. 범행 현장은……그렇지, 훌륭한 낡은 도서관 같은 데가 어떨까? 분위기로서 이 이상의 것은 없네. 흉기는 기묘한 형태로 구부러진 단도 아니면, 뭔가 둔기 같은 것, 예를 들면 조각된 돌상이라든지……. ” 포아로는 한숨을 쉬었다. “그렇잖으면 물론 독약.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.4535558223724365 Generator / grammar loss:-0.12763217091560364   similarity loss:-0.081474170088768\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "나는 우리는 “자네는 만일 주문하듯 고르겠나?” 나는 기분에 휩쓸려 안 좋겠군. “옳지, 역시 유명한 백만장자나 신문사 인물. 없네.\n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "역시 남자가 좋겠어.누군가 유명한 사람, 미국의 백만장자나 국무장관이나 신문사 사장쯤 되는 인물.” “피해자는 남자로 할까, 여자로 할까?아니, 이런 건 안 돼?” 포아로는 한숨을 쉬었다.\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "내가 도우려면, 우리는 다른 데서 온갖 진수가 모아진 멋진 범죄를 찾아내야만 되겠군. ” “ 역시 남자가 좋겠어.누군가 유명한 사람, 미국의 백만장자나 국무장관이나 신문사 사장쯤 되는 인물.\n",
            "--------------------------------------------------\n",
            "besm_bert summary:\n",
            "내가 도우려면, 우리는 다른 데서 온갖 진수가 모아진 멋진 범죄를 찾아내야만 되겠군. ” “ 역시 남자가 좋겠어.누군가 유명한 사람, 미국의 백만장자나 국무장관이나 신문사 사장쯤 되는 인물. 흉기는 기묘한 형태로 구부러진 단도 아니면, 뭔가 둔기 같은 것, 예를 들면 조각된 돌상이라든지……. ”\n",
            "--------------------------------------------------\n",
            "         method  comp ratio     intro      body    ending       var     total  \\\n",
            "0      SAM+WGAN    0.142857  0.359273  0.392094  0.414743  0.000519  0.392325   \n",
            "1  BERT+LexRank    0.202703  0.137062  0.170831  0.228606  0.001429  0.181410   \n",
            "2          BESM    0.204633  0.437141  0.278188  0.327385  0.004415  0.324738   \n",
            "3   BESM+kobert    0.318533  0.558340  0.358646  0.598940  0.011030  0.470673   \n",
            "\n",
            "    grammar  \n",
            "0  0.975554  \n",
            "1  0.999038  \n",
            "2  0.999032  \n",
            "3  0.996944  \n",
            "Current result ==================================================\n",
            "Sample count: 16\n",
            "         method  comp rate     intro      body  conclusion   isthmus  \\\n",
            "0      SAM+WGAN   0.147983  0.523656  0.515278    0.496390  0.005903   \n",
            "1  BERT+LexRank   0.221396  0.253280  0.209721    0.245016  0.009658   \n",
            "2          BESM   0.198805  0.469651  0.415787    0.372959  0.010772   \n",
            "3   BESM+kobert   0.218635  0.508963  0.423890    0.397521  0.010819   \n",
            "\n",
            "   simlirality  grammarity  \n",
            "0     0.511287    0.943774  \n",
            "1     0.229022    0.999002  \n",
            "2     0.413711    0.997922  \n",
            "3     0.432994    0.997465  \n",
            "==================================================\n",
            "17 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "하지만 이것은 아무래도 너무 전문적인 것 같네. 그렇다면 깊은 밤에 메아리치는 권총 소리……이런 것으로 할까. 그리고 아름다운 여자 하나, 둘. ” 친구는 중얼거렸다. “그녀는 빨강머리겠지. ” “신통치 못한 농담이군. 물론 아름다운 여자 한 사람에게 잘못된 혐의가 씌워져야만 되겠지. 그리고 그녀와 젊은이 사이에 오해가 생기고. 물론 그 밖에도 몇 사람에게 혐의가 돌아가지 않으면 안 되네. 이를테면 피해자의 친구거나 경쟁 상대인 피부빛이 검고 위험한 타입의 중년 여자, 얌전한 비서. 이들이 유력한 혐의자인데, 거기에 행동거지가 무뚝뚝하고 성실한 사나이인 해고된 하인이라든지 사냥터 관리인 등이 두어 사람쯤 그리고 재프 경감 같은 얼치기 형사. 그래, 이쯤이면 되겠지. ” “그것이 자네가 말한 온갖 진수가 모아진 범죄인가?” “찬성하지 않는구먼?” 포아로는 한심스러운 듯 나를 보았다. “자네는 지금까지 씌어진 거의 모든 미스터리 소설의 아주 멋있는 줄거리를 만들어 주었네. ” “그럼, 자네라면 어떤 주문을 할 건가?” 포아로는 눈을 감고 의자에 기댔다. 그의 목소리는 입술 사이로 조용히 흘러나왔다. “아주 단순한 범죄, 복잡한 데가 조금도 없는 범죄. 조용한 가정 생활의 범죄……열광적이 아니고 아주 내밀스러운. ” “범죄에 내밀스러운 게 있을 수 있는가?” 포아로는 중얼거리듯 말했다. “네 사람이 앉아서 브리지를 하고 있네.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.4783127307891846 Generator / grammar loss:-0.1407381147146225   similarity loss:-0.0919622927904129\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "이것은 아무래도 그렇다면 하나, 둘. “그녀는 빨강머리겠지. 물론 그리고 그녀와 몇 친구거나 경쟁 비서. 거기에 해고된 자네가 범죄인가?” 아주 줄거리를 기댔다. 그의 복잡한 범죄.\n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "“네 사람이 앉아서 브리지를 하고 있네.그렇다면 깊은 밤에 메아리치는 권총 소리……이런 것으로 할까.그래, 이쯤이면 되겠지.하지만 이것은 아무래도 너무 전문적인 것 같네.\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "이를테면 피해자의 친구거나 경쟁 상대인 피부빛이 검고 위험한 타입의 중년 여자, 얌전한 비서. 자네는 지금까지 씌어진 거의 모든 미스터리 소설의 아주 멋있는 줄거리를 만들어 주었네.” “\n",
            "--------------------------------------------------\n",
            "besm_bert summary:\n",
            "이를테면 피해자의 친구거나 경쟁 상대인 피부빛이 검고 위험한 타입의 중년 여자, 얌전한 비서. 이들이 유력한 혐의자인데, 거기에 행동거지가 무뚝뚝하고 성실한 사나이인 해고된 하인이라든지 사냥터 관리인 등이 두어 사람쯤 그리고 재프 경감 같은 얼치기 형사.\n",
            "--------------------------------------------------\n",
            "         method  comp ratio     intro      body    ending       var     total  \\\n",
            "0      SAM+WGAN    0.145743  0.433754  0.546696  0.327629  0.008001  0.458387   \n",
            "1  BERT+LexRank    0.137085  0.382522  0.186761  0.221257  0.007280  0.236262   \n",
            "2          BESM    0.150072  0.325465  0.419658  0.228706  0.006077  0.343533   \n",
            "3   BESM+kobert    0.204906  0.343544  0.404463  0.244562  0.004342  0.344309   \n",
            "\n",
            "    grammar  \n",
            "0  0.995966  \n",
            "1  0.999043  \n",
            "2  0.999022  \n",
            "3  0.992904  \n",
            "Current result ==================================================\n",
            "Sample count: 17\n",
            "         method  comp rate     intro      body  conclusion   isthmus  \\\n",
            "0      SAM+WGAN   0.147851  0.518368  0.517127    0.486463  0.006026   \n",
            "1  BERT+LexRank   0.216436  0.260882  0.208371    0.243619  0.009519   \n",
            "2          BESM   0.195939  0.461170  0.416014    0.364474  0.010496   \n",
            "3   BESM+kobert   0.217827  0.499233  0.422747    0.388523  0.010438   \n",
            "\n",
            "   simlirality  grammarity  \n",
            "0     0.508176    0.946844  \n",
            "1     0.229448    0.999004  \n",
            "2     0.409583    0.997986  \n",
            "3     0.427777    0.997197  \n",
            "==================================================\n",
            "18 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "그리고 한 사람이 그 게임에 끼지 않고 벽난로 옆 의자에 앉아 있지. 밤이 깊어졌을 즈음 난롯불 옆에 앉아 있던 사나이가 죽은 것을 알게 되네. 네 사람 가운데 누군가가 손이 비게 되었을 때 죽인 것인데, 모두들 게임에 정신이 팔려 모르고 있었지. 자, 이것이 사건이네. 범인은 네 사람 가운데 누구일까?” (나, 아시겠죠? 다들<테이블위의카드>네요. ) “도무지 자극적인 데가 조금도 없는걸. ” 포아로는 비난하듯 눈길로 나를 보았다. “없지. 이상한 모양으로 구부러진 단도도, 협박도, 신상의 눈에서 훔쳐 낸 에메랄드도, 흔적을 알 수 없는 동양의 독약 같은 것도 없네. 헤이스팅즈, 자네는 아무래도 멜러 드라마 애호가로군. 자네는 하나의 살인이 아니라 연쇄적인 살인 쪽이 좋은 거지?” “그렇네, 책 속의 두 번째 살인은 경기가 좋아 보이던걸. 제1장에서 살인이 일어나 마지막 페이지 바로 앞까지 모두들의 알리바이가 성립되어 있다는 건……그래, 좀 따분하지. ‘ 전화가 울려 포아로가 일어나 받으러 갔다. “여보세요, 에르큘 포아로입니다. ‘ 잠시 말없이 듣고 있던 그의 얼굴빛이 달라졌다. 그의 대답은 짧게 토막토막 끊어졌다, “그랬군요……물론, 그렇지요……아, 가겠습니다……당연합니다……그야 당신 말대로겠지요. 그렇지요, 갖고 가겠습니다. 그럼, 곧. ” 그는 수화기를 내려놓고 방을 가로질러 내 곁으로 돌아왔다.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.391206741333008 Generator / grammar loss:-0.12604853510856628   similarity loss:-0.08641715347766876\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "게임에 팔려 이상한 살인은 일어나 페이지 바로 앞까지 받으러 갔다. “여보세요, ‘ 그의 얼굴빛이 달라졌다. 짧게 토막토막 끊어졌다, “그랬군요……물론, 말대로겠지요. 곧. 곁으로 돌아왔다. \n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "이상한 모양으로 구부러진 단도도, 협박도, 신상의 눈에서 훔쳐 낸 에메랄드도, 흔적을 알 수 없는 동양의 독약 같은 것도 없네.밤이 깊어졌을 즈음 난롯불 옆에 앉아 있던 사나이가 죽은 것을 알게 되네.자네는 하나의 살인이 아니라 연쇄적인 살인 쪽이 좋은 거지?” “그렇네, 책 속의 두 번째 살인은 경기가 좋아 보이던걸.다들<테이블위의카드>네요. )\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "밤이 깊어졌을 즈음 난롯불 옆에 앉아 있던 사나이가 죽은 것을 알게 되네. 이상한 모양으로 구부러진 단도도, 협박도, 신상의 눈에서 훔쳐 낸 에메랄드도, 흔적을 알 수 없는 동양의 독약 같은 것도 없네. 제1장에서 살인이 일어나 마지막 페이지 바로 앞까지 모두들의 알리바이가 성립되어 있다는 건……그래, 좀 따분하지. ‘\n",
            "--------------------------------------------------\n",
            "besm_bert summary:\n",
            "밤이 깊어졌을 즈음 난롯불 옆에 앉아 있던 사나이가 죽은 것을 알게 되네. 네 사람 가운데 누군가가 손이 비게 되었을 때 죽인 것인데, 모두들 게임에 정신이 팔려 모르고 있었지. 그의 대답은 짧게 토막토막 끊어졌다, “그랬군요……물론, 그렇지요……아, 가겠습니다……당연합니다……그야 당신 말대로겠지요.\n",
            "--------------------------------------------------\n",
            "         method  comp ratio     intro      body    ending       var     total  \\\n",
            "0      SAM+WGAN    0.156433  0.418130  0.426163  0.699783  0.017140  0.506642   \n",
            "1  BERT+LexRank    0.285088  0.267143  0.297484  0.009302  0.016717  0.204961   \n",
            "2          BESM    0.261696  0.671324  0.479500  0.476772  0.008295  0.517046   \n",
            "3   BESM+kobert    0.245614  0.745944  0.369573  0.609932  0.024214  0.516955   \n",
            "\n",
            "    grammar  \n",
            "0  0.936830  \n",
            "1  0.999016  \n",
            "2  0.993604  \n",
            "3  0.995715  \n",
            "Current result ==================================================\n",
            "Sample count: 18\n",
            "         method  comp rate     intro      body  conclusion   isthmus  \\\n",
            "0      SAM+WGAN   0.148328  0.512799  0.512073    0.498314  0.006644   \n",
            "1  BERT+LexRank   0.220250  0.261230  0.213322    0.230601  0.009918   \n",
            "2          BESM   0.199592  0.472845  0.419541    0.370712  0.010374   \n",
            "3   BESM+kobert   0.219371  0.512939  0.419793    0.400824  0.011203   \n",
            "\n",
            "   simlirality  grammarity  \n",
            "0     0.508090    0.946288  \n",
            "1     0.228087    0.999005  \n",
            "2     0.415553    0.997743  \n",
            "3     0.432731    0.997114  \n",
            "==================================================\n",
            "19 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "“재프 경감에게서 온 걸세, 헤이스팅즈. ” “그래서?” “경찰국으로 돌아가자마자 마침 앤도버에서 연락이 있었다는 거야. ” 나는 흥분하여 소리쳤다. “앤도버?” 포아로가 천천히 말했다. “노파가 하나 살해되었다는군. 애셔(Ascher)라는 이름으로, 담배와 신문을 파는 조그만 가게의 노파일세. ” 나는 얼마쯤 맥이 풀렸다. 앤도버라는 이름으로 부채질되었던 내 흥미는 어리둥절해졌다. 나는 뭔가 환상적인, 아주 색다른 것을 기대하고 있었는데! 조그만 담배 가게 노파가 살해된 일 따위는 아무래도 그리 신통찮다. 포아로는 여전히 느릿느릿한 무게있는 목소리로 말을 이었다. “앤도버 경찰에서는 범인을 체표할 수 있다고 생각하는 모양이야. ” 나는 다시 한 번 맥이 풀렸다. “노파는 그 남편과 사이가 나빴던 것 같네. 남편은 술꾼이며 질나쁜 녀석으로 종종 노파를 죽이겠다고 협박했었다는군. 그러나 그곳 경찰에서는 다른 점도 고려하여 내가 받은 익명의 편지를 보고 싶다는 거야. 나는 곧 자네와 함께 앤도버로 가겟다고 말해 두었네. ” 나는 얼마쯤 기운을 되찾았다. 시시하게 보일지라도 아무튼 범죄임에 틀림없다. 내가 범죄니 범인이니 하는 것에 관계하고부터 벌써 많은 세월이 흘렀다.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.3472237586975098 Generator / grammar loss:-0.13552340865135193   similarity loss:-0.10044573247432709\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            " “재프 경감에게서 걸세, 헤이스팅즈. ” “그래서?” 앤도버에서 연락이 나는 흥분하여 소리쳤다. 말했다. 조그만 뭔가 환상적인, 노파가 있다고 풀렸다. 그러나 흘렀다.\n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "“노파는 그 남편과 사이가 나빴던 것 같네.남편은 술꾼이며 질나쁜 녀석으로 종종 노파를 죽이겠다고 협박했었다는군.애셔(Ascher)라는 이름으로, 담배와 신문을 파는 조그만 가게의 노파일세.조그만 담배 가게 노파가 살해된 일 따위는 아무래도 그리 신통찮다.그러나 그곳 경찰에서는 다른 점도 고려하여 내가 받은 익명의 편지를 보고 싶다는 거야.\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "애셔(Ascher)라는 이름으로, 담배와 신문을 파는 조그만 가게의 노파일세. ” 그러나 그곳 경찰에서는 다른 점도 고려하여 내가 받은 익명의 편지를 보고 싶다는 거야.\n",
            "--------------------------------------------------\n",
            "besm_bert summary:\n",
            "애셔(ascher)라는 이름으로, 담배와 신문을 파는 조그만 가게의 노파일세. ” 그러나 그곳 경찰에서는 다른 점도 고려하여 내가 받은 익명의 편지를 보고 싶다는 거야.\n",
            "--------------------------------------------------\n",
            "         method  comp ratio     intro      body    ending       var     total  \\\n",
            "0      SAM+WGAN    0.155629  0.730064  0.444412  0.388091  0.022413  0.484646   \n",
            "1  BERT+LexRank    0.316225 -0.003079  0.255101  0.276348  0.016132  0.209839   \n",
            "2          BESM    0.155629  0.205396  0.288986  0.329535  0.002671  0.284432   \n",
            "3   BESM+kobert    0.155629  0.206035  0.289110  0.329535  0.002643  0.284622   \n",
            "\n",
            "    grammar  \n",
            "0  0.963879  \n",
            "1  0.999030  \n",
            "2  0.998953  \n",
            "3  0.998955  \n",
            "Current result ==================================================\n",
            "Sample count: 19\n",
            "         method  comp rate     intro      body  conclusion   isthmus  \\\n",
            "0      SAM+WGAN   0.148712  0.524234  0.508512    0.492513  0.007474   \n",
            "1  BERT+LexRank   0.225302  0.247319  0.215520    0.233009  0.010245   \n",
            "2          BESM   0.197278  0.458769  0.412670    0.368545  0.009968   \n",
            "3   BESM+kobert   0.216016  0.496786  0.412915    0.397071  0.010752   \n",
            "\n",
            "   simlirality  grammarity  \n",
            "0     0.506857    0.947214  \n",
            "1     0.227127    0.999006  \n",
            "2     0.408652    0.997807  \n",
            "3     0.424936    0.997211  \n",
            "==================================================\n",
            "20 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "나는 포아로의 다음 말을 거의 듣지 있지 않았다. 그러나 그것은 나중에 중요한 뜻을 지니고 내 기억 속에 되살아났다. 에르큘 포아로가 이렇게 말했다. “이것이 시작이다. ” < 철도 안내서 > 우리는 앤도버에서 글렌 형사의 마중을 받았다. 그는 키가 크고 머리칼이 아름다운 남자로 기분 좋은 미소를 떠올리고 있었다. 이야기를 간결이 하기 위해 사건의 사실만 간단히 밝혀 두는 게 좋으리라. 범죄는 22일 오전 1시에 그곳 순경에 의해 발견되었다. 순찰을 돌면서 가게 문을 밀어 보니 잠겨 있지 않았다. 안으로 들어가자 처음에는 아무도 없는 듯했으나, 계산대 쪽으로 회중전등을 돌리니 노파의 웅크린 시체가 눈에 들어왔다. 경찰의가 현장에 와 닿아 노파가 뒷머리를 강하게 얻어맞았음을 알아냈는데, 아마도 계산대 뒤의 선반에서 담배 봉지를 꺼내는 도중에 얻어맞은 듯했다. 범행은 일곱 시간 내지 아홉 시간 전에 행해진 것 같았다. 형사는 설명했다. “그러나 더 정확한 시간을 추정할 수 있습니다. 5시 30분에 담배를 사러 들어갔던 사나이가 있습니다. 그리고 6시 5분 좀 지나서 가게에 들어갔다가 아무도 없는 줄 알고 그냥 나온 다른 남자가 있습니다. 그러니까 범행 시간을 5시 30분에서 6시 5분 사이로 추정할 수 있지요. 이웃에서 애셔를 보았다고 말해 온 사람은 아직 없습니다. 그러나 물론 이제부터입니다. 그는 9시쯤 <스리크라운즈>에서 꽤 취해 있었습니다.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.502201557159424 Generator / grammar loss:-0.14643016457557678   similarity loss:-0.09511272609233856\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            " 나는 있지 않았다. 글렌 좋은 간결이 게 안으로 돌리니 웅크린 그리고 6시 지나서 아무도 없는 줄 알고 나온 다른 30분에서 애셔를 보았다고 말해 9시쯤 취해 있었습니다.\n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "이웃에서 애셔를 보았다고 말해 온 사람은 아직 없습니다.에르큘 포아로가 이렇게 말했다.그는 키가 크고 머리칼이 아름다운 남자로 기분 좋은 미소를 떠올리고 있었다.그는 9시쯤 <스리크라운즈>에서 꽤 취해 있었습니다.\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "그는 키가 크고 머리칼이 아름다운 남자로 기분 좋은 미소를 떠올리고 있었다. 경찰의가 현장에 와 닿아 노파가 뒷머리를 강하게 얻어맞았음을 알아냈는데, 아마도 계산대 뒤의 선반에서 담배 봉지를 꺼내는 도중에 얻어맞은 듯했다. 그리고 6시 5분 좀 지나서 가게에 들어갔다가 아무도 없는 줄 알고 그냥 나온 다른 남자가 있습니다.\n",
            "--------------------------------------------------\n",
            "besm_bert summary:\n",
            "그는 키가 크고 머리칼이 아름다운 남자로 기분 좋은 미소를 떠올리고 있었다. 그러니까 범행 시간을 5시 30분에서 6시 5분 사이로 추정할 수 있지요.\n",
            "--------------------------------------------------\n",
            "         method  comp ratio     intro      body    ending       var     total  \\\n",
            "0      SAM+WGAN    0.135977  0.316636  0.279770  0.361639  0.001121  0.311704   \n",
            "1  BERT+LexRank    0.168555  0.139560  0.238680  0.256438  0.002645  0.224183   \n",
            "2          BESM    0.256374  0.208297  0.422653  0.411568  0.009710  0.376456   \n",
            "3   BESM+kobert    0.118980  0.182882  0.287266  0.366385  0.005648  0.290125   \n",
            "\n",
            "    grammar  \n",
            "0  0.984746  \n",
            "1  0.998971  \n",
            "2  0.999005  \n",
            "3  0.999020  \n",
            "Current result ==================================================\n",
            "Sample count: 20\n",
            "         method  comp rate     intro      body  conclusion   isthmus  \\\n",
            "0      SAM+WGAN   0.148075  0.513854  0.497075    0.485969  0.007156   \n",
            "1  BERT+LexRank   0.222464  0.241931  0.216678    0.234180  0.009865   \n",
            "2          BESM   0.200233  0.446245  0.413169    0.370696  0.009955   \n",
            "3   BESM+kobert   0.211164  0.481091  0.406633    0.395537  0.010497   \n",
            "\n",
            "   simlirality  grammarity  \n",
            "0     0.497099    0.949091  \n",
            "1     0.226980    0.999004  \n",
            "2     0.407042    0.997866  \n",
            "3     0.418196    0.997302  \n",
            "==================================================\n",
            "21 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "체포하는 대로 곧 용의자로 잡아 둘 겁니다. ” 포아로가 물었다. “그리 호감주는 타입의 사나이가 아닌 모양이군요?” “싫은 사람입니다. ” “그는 자기 아내와 함께 살고 있지 않았던가요?” “그렇습니다. 몇 해 전에 헤어졌지요. 애셔는 독일 사람으로 한때 급사일을 한 적도 있었습니다만, 술을 너무 마셔서 차츰 그를 고용하는 곳이 없게 되었습니다. 그래서 그 부인이 일을 나가게 되었지요. 마지막으로 한 일은 미스 로즈라는 노부인의 요리사 겸 가정부였습니다. 급료를 받아 남편에게 꽤 많은 돈을 주었던 듯한데, 그는 몽땅 마셔 버리고는 자기 마누라가 일하는 곳으로 가서 소동을 벌이곤 했답니다. 그래서 애셔 부인은 미스 로즈네 농장으로 가서 일하게 되었습니다. 거기는 앤도버에서 3마일 떨어진 완전한 시골이어서 그도 그리 자주 찾아가지 못했지요. 미스 로즈가 세상을 떠나자 애셔 부인은 유산을 조금 받았습니다. 그래서 그 돈으로 담배와 신문을 파는 이 조그만 가게를 시작했습니다. 싸구려 담배와 얼마 안 되는 신문뿐이어서 겨우 먹고 사는 정도였지요. 애셔가 자주 찾아와 그녀에게 욕을 하곤 했는데, 그녀 쪽에서는 귀찮고 하니까 잔돈푼이나 줘서 쫓아 버리곤 했지요. 1주일에 15실링은 줬던 것 같습니다. ” 포아로가 물었다. “아이들은 있었소?” “없습니다. 조카딸이 하나 오버튼 가까이에서 일하고 있습니다. 아주 고집이 센 똑똑한 아가씨지요.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.4041388034820557 Generator / grammar loss:-0.12794533371925354   similarity loss:-0.08696750551462173\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "둘 ” “그리 타입의 사나이가 모양이군요?” “싫은 자기 아내와 살고 몇 해 헤어졌지요. 있었습니다만, 부인이 되었지요. 거기는 자주 유산을 조금 파는 조그만 잔돈푼이나 했지요.\n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "체포하는 대로 곧 용의자로 잡아 둘 겁니다.그래서 그 돈으로 담배와 신문을 파는 이 조그만 가게를 시작했습니다.1주일에 15실링은 줬던 것 같습니다.“그리 호감주는 타입의 사나이가 아닌 모양이군요?” “싫은 사람입니다.\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "애셔는 독일 사람으로 한때 급사일을 한 적도 있었습니다만, 술을 너무 마셔서 차츰 그를 고용하는 곳이 없게 되었습니다. 거기는 앤도버에서 3마일 떨어진 완전한 시골이어서 그도 그리 자주 찾아가지 못했지요. 싸구려 담배와 얼마 안 되는 신문뿐이어서 겨우 먹고 사는 정도였지요.애셔가 자주 찾아와 그녀에게 욕을 하곤 했는데, 그녀 쪽에서는 귀찮고 하니까 잔돈푼이나 줘서 쫓아 버리곤 했지요.\n",
            "--------------------------------------------------\n",
            "besm_bert summary:\n",
            "애셔는 독일 사람으로 한때 급사일을 한 적도 있었습니다만, 술을 너무 마셔서 차츰 그를 고용하는 곳이 없게 되었습니다. 급료를 받아 남편에게 꽤 많은 돈을 주었던 듯한데, 그는 몽땅 마셔 버리고는 자기 마누라가 일하는 곳으로 가서 소동을 벌이곤 했답니다. 거기는 앤도버에서 3마일 떨어진 완전한 시골이어서 그도 그리 자주 찾아가지 못했지요.\n",
            "--------------------------------------------------\n",
            "         method  comp ratio     intro      body    ending       var     total  \\\n",
            "0      SAM+WGAN    0.142037  0.387560  0.534521  0.379175  0.005089  0.458525   \n",
            "1  BERT+LexRank    0.175036  0.150935  0.217861  0.142296  0.001140  0.181806   \n",
            "2          BESM    0.309900  0.230511  0.542350  0.311870  0.017443  0.410838   \n",
            "3   BESM+kobert    0.272597  0.281762  0.538592  0.277069  0.014931  0.408769   \n",
            "\n",
            "    grammar  \n",
            "0  0.950800  \n",
            "1  0.998981  \n",
            "2  0.999026  \n",
            "3  0.999032  \n",
            "Current result ==================================================\n",
            "Sample count: 21\n",
            "         method  comp rate     intro      body  conclusion   isthmus  \\\n",
            "0      SAM+WGAN   0.147788  0.507840  0.498858    0.480883  0.007057   \n",
            "1  BERT+LexRank   0.220206  0.237598  0.216735    0.229805  0.009450   \n",
            "2          BESM   0.205455  0.435972  0.419321    0.367895  0.010312   \n",
            "3   BESM+kobert   0.214090  0.471599  0.412916    0.389896  0.010708   \n",
            "\n",
            "   simlirality  grammarity  \n",
            "0     0.495262    0.949172  \n",
            "1     0.224828    0.999003  \n",
            "2     0.407223    0.997922  \n",
            "3     0.417747    0.997384  \n",
            "==================================================\n",
            "22 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "” “그 애셔라는 사나이가 아내를 자주 협박했었다는 거지요?” “그렇습니다. 그는 술에 취하면 무섭게 변해서 아내의 머리를 박살내겠다는 둥 소리를 질러대곤 했답니다. 애셔 부인은 정말 끔찍한 일을 당한 거지요. ” “그녀는 몇 살이었소?” “60살이 다 되었지요. 아마. 훌륭하고 부지런한 사람이었습니다. ” 포아로는 신중하게 말했다. “그러면 그 애셔라는 사나이가 범인이라는 게 당신 의견이오?” 형사는 조심스럽게 헛기침을 했다. “그렇게 말하는 건 좀 성급한 판단입니다만, 프란츠 애셔가 지난밤에 어떻게 지냈는지 그 자신의 설명을 듣고 싶은 겁니다, 포아로 씨. 만일 만족할 만한 설명을 들을 수 있다면 좋겠지만, 그렇지 않으면……. ” 그는 꽤 의미심장하게 말을 끊었다. “가게에서는 아무것도 없어지지 않았소?” “네, 아무것도. 돈도 그대로 다 있고, 훔쳐 간 흔적이 전혀 없습니다. ” “그 애셔라는 사나이가 술에 취해 가게로 들어와 아내를 욕하다가 끝내 때려 죽였다는 거로군요?” “네, 그것이 가장 타당한 해석이겠지요. 그러나 당신이 받으셨다는 그 이상한 편지도 고려해 보고 싶습니다, 포아로 씨. 그것이 이 애셔라는 사나이로부터 보내진 것인지 어떤지 알 수 없으니까요. ” 포아로가 편지를 건네주자 형사는 이마를 찌푸리고 그것을 읽었다. 형사는 마침내 말했다. “아무래도 애셔가 쓴 것 같지는 않군요. 도대체 이 <우리> 영국 경찰이라는 말을 애셔가 쓸 턱이 없지요.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.448955774307251 Generator / grammar loss:-0.1347632259130478   similarity loss:-0.08908989280462265\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "” 애셔라는 아내를 자주 협박했었다는 거지요?” 무섭게 둥 질러대곤 거지요. “그녀는 살이었소?” 다 되었지요. 아마. “그러면 그 겁니다, 포아로 그는 “가게에서는 없어지지 않았소?” 아무것도.\n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "” “그녀는 몇 살이었소?” “60살이 다 되었지요.아마.돈도 그대로 다 있고, 훔쳐 간 흔적이 전혀 없습니다.“가게에서는 아무것도 없어지지 않았소?” “네, 아무것도.그는 술에 취하면 무섭게 변해서 아내의 머리를 박살내겠다는 둥 소리를 질러대곤 했답니다.\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "그는 술에 취하면 무섭게 변해서 아내의 머리를 박살내겠다는 둥 소리를 질러대곤 했답니다. 만일 만족할 만한 설명을 들을 수 있다면 좋겠지만, 그렇지 않으면……. ” 네, 그것이 가장 타당한 해석이겠지요.그러나 당신이 받으셨다는 그 이상한 편지도 고려해 보고 싶습니다, 포아로 씨.\n",
            "--------------------------------------------------\n",
            "besm_bert summary:\n",
            "그는 술에 취하면 무섭게 변해서 아내의 머리를 박살내겠다는 둥 소리를 질러대곤 했답니다. 네, 그것이 가장 타당한 해석이겠지요.그러나 당신이 받으셨다는 그 이상한 편지도 고려해 보고 싶습니다, 포아로 씨. 그것이 이 애셔라는 사나이로부터 보내진 것인지 어떤지 알 수 없으니까요. ”\n",
            "--------------------------------------------------\n",
            "         method  comp ratio     intro      body    ending       var     total  \\\n",
            "0      SAM+WGAN    0.152022  0.694152  0.517158  0.376980  0.016842  0.510503   \n",
            "1  BERT+LexRank    0.199442  0.431548  0.219090  0.157998  0.013744  0.243254   \n",
            "2          BESM    0.217573  0.561748  0.438635  0.445418  0.003193  0.465293   \n",
            "3   BESM+kobert    0.218968  0.597146  0.450107  0.600513  0.004917  0.524636   \n",
            "\n",
            "    grammar  \n",
            "0  0.993703  \n",
            "1  0.999014  \n",
            "2  0.999031  \n",
            "3  0.996974  \n",
            "Current result ==================================================\n",
            "Sample count: 22\n",
            "         method  comp rate     intro      body  conclusion   isthmus  \\\n",
            "0      SAM+WGAN   0.147980  0.516309  0.499690    0.476161  0.007502   \n",
            "1  BERT+LexRank   0.219262  0.246414  0.216842    0.226541  0.009645   \n",
            "2          BESM   0.206006  0.441689  0.420198    0.371419  0.009988   \n",
            "3   BESM+kobert   0.214312  0.477306  0.414607    0.399469  0.010445   \n",
            "\n",
            "   simlirality  grammarity  \n",
            "0     0.495955    0.951196  \n",
            "1     0.225666    0.999004  \n",
            "2     0.409863    0.997972  \n",
            "3     0.422605    0.997365  \n",
            "==================================================\n",
            "23 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "그야말로 각별히 교묘하게 행동하려는 게 아니었다면 말입니다. 게다가 그에겐 그만한 머리가 없습니다. 그는 이제 산송장입니다. 다 망가져 버렸지요. 이런 글을 쓰기에는 그의 손이 너무 떨릴걸요. 편지지도 잉크도 고급품이고. 그러나 편지에는 21일이라고 한 것은 이상하군요. 물론 우연의 일치겠지만요. ” “그렇겠지요. ” “하지만 이런 일치는 좋지 않습니다, 포아로 씨. 너무 딱 들어맞으니 말입니다. ” 그는 잠시 입을 다물고 있었다. 그의 이마에 주름이 잡혔다. “ABC. 대체 ABC란 어떤 녀석일까요? 메리 드로워―조카딸입니다만―가 좀 도움이 될지도 모르겠군요. 뭐 수고하시는 김에 말입니다. 이 편지만 없다면 나느 프란츠 애셔에게 내기를 걸어도 좋은데요. ” “애셔 부인의 경력은 알고 있소?” “그녀는 햄프셔 태생으로 처녀 때 런던에 나가 직장 생활을 했지요. 거기서 애셔를 만나 결혼했습니다.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.278534173965454 Generator / grammar loss:-0.09130097925662994   similarity loss:-0.063265360891819\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "그야말로 행동하려는 게 아니었다면 없습니다. 편지지도 고급품이고. 이상하군요. 씨. 딱 “ABC. 프란츠 있소?” 때 \n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "“ABC.대체 ABC란 어떤 녀석일까요?” “애셔 부인의 경력은 알고 있소?” “그녀는 햄프셔 태생으로 처녀 때 런던에 나가 직장 생활을 했지요.메리 드로워―조카딸입니다만―가 좀 도움이 될지도 모르겠군요.거기서 애셔를 만나 결혼했습니다.\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "Unexpected error: <class 'ValueError'>\n",
            "==================================================\n",
            "24 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "헤어진 것은 1922년으로, 그즈음 두 사람은 아직 런던에 있었지요. 그녀는 남자에게서 달아나 여기로 왔으나, 남자가 곧 알아차리고 따라와 귀찮게 굴었던 겁니다. ” 마침 거기에 순경이 들어왔다. “무슨 일인가, 브릭스?” “애셔를 연행해 왔습니다. ” “좋아. 이리로 데려오게. 어디 있던가?” “인입선의 화차 안에 숨어 있었습니다. ” “숨어 있었다고? 데려오게. ” 프란츠 애셔는 정말 보기 싫은, 초라한 인간의 표본이었다. 그는 엉엉 울고, 꾸벅꾸벅 절하고, 서슬이 시퍼래지기도 했다. 그 짓무른 눈을 이리저리 움직이며 모두들의 얼굴을 살폈다 “나를 어쩌자는 거야. 나는 아무 짓도 안 했어. 날 이런 데 데려오다니 너무하잖아. 네 놈들은 돼지야. 어쩌자는 거야?” 그의 태도가 갑자기 바뀌었다. “아니, 아니, 그게 아냐. 선생님들은 이 가엾은 늙은이에게 몹쓸 짓을 하고 있소. 심하게 대하고 있소. 누구나 이 가엾은 프란츠에게 심하게 군단 말야, 이 가엾은 프란츠에게.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.1842896938323975 Generator / grammar loss:-0.11370514333248138   similarity loss:-0.09522375464439392\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "왔으나, 굴었던 겁니다. 마침 연행해 왔습니다. ” 데려오게. 거야. 너무하잖아. 돼지야. 어쩌자는 “아니, 아냐. 이 몹쓸 있소. 있소.\n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "헤어진 것은 1922년으로, 그즈음 두 사람은 아직 런던에 있었지요.어디 있던가?” “인입선의 화차 안에 숨어 있었습니다.” “숨어 있었다고?나는 아무 짓도 안 했어.\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "그녀는 남자에게서 달아나 여기로 왔으나, 남자가 곧 알아차리고 따라와 귀찮게 굴었던 겁니다. ” 그 짓무른 눈을 이리저리 움직이며 모두들의 얼굴을 살폈다 “나를 어쩌자는 거야.\n",
            "--------------------------------------------------\n",
            "besm_bert summary:\n",
            "그녀는 남자에게서 달아나 여기로 왔으나, 남자가 곧 알아차리고 따라와 귀찮게 굴었던 겁니다. ” 그 짓무른 눈을 이리저리 움직이며 모두들의 얼굴을 살폈다 “나를 어쩌자는 거야.\n",
            "--------------------------------------------------\n",
            "         method  comp ratio     intro      body    ending       var     total  \\\n",
            "0      SAM+WGAN    0.156504  0.484786  0.626210  0.631075  0.004603  0.599385   \n",
            "1  BERT+LexRank    0.189024  0.337859  0.152321  0.042066  0.014897  0.156352   \n",
            "2          BESM    0.199187  0.414627  0.323743  0.395028  0.001525  0.363305   \n",
            "3   BESM+kobert    0.199187  0.414627  0.323743  0.395028  0.001525  0.363305   \n",
            "\n",
            "    grammar  \n",
            "0  0.967222  \n",
            "1  0.999001  \n",
            "2  0.998978  \n",
            "3  0.998978  \n",
            "Current result ==================================================\n",
            "Sample count: 23\n",
            "         method  comp rate     intro      body  conclusion   isthmus  \\\n",
            "0      SAM+WGAN   0.148351  0.514938  0.505191    0.482896  0.007376   \n",
            "1  BERT+LexRank   0.217947  0.250390  0.214037    0.218520  0.009874   \n",
            "2          BESM   0.205710  0.440512  0.416005    0.372445  0.009620   \n",
            "3   BESM+kobert   0.213654  0.474581  0.410656    0.399276  0.010057   \n",
            "\n",
            "   simlirality  grammarity  \n",
            "0     0.500452    0.951893  \n",
            "1     0.222652    0.999004  \n",
            "2     0.407838    0.998016  \n",
            "3     0.420027    0.997436  \n",
            "==================================================\n",
            "25 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "” 애셔는 울기 시작했다. 형사가 말했다. “그만해 두오, 애셔. 정신차려요. 당신에게 무슨 죄를 뒤집어씌우려는 건 아니오. 지금으로서는. 당신이 싫으면 아무 말 않아도 좋소. 만일 당신이 당신 아내 살해에 관계가 없다면 말이오. ” 애셔는 그 말을 가로막았다. 그 목소리는 비명 같았다. “나는 죽이지 않았어! 죽이지 않았어! 모두 엉터리야! 네 놈들은 거지같은 영국 돼지야. 모두들 내게 죄를 덮어씌우고 있어. 나는 죽이지 않았어, 죽이지 않았어. ” “당신은 늘 아내를 협박하고 있었잖소, 애셔?” “아니, 아니, 네 놈들은 알 리 없어. 그건 농담이었어. 나와 앨리스만이 알고 있는 농담이야. 앨리스는 그걸 알고 있었어.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.3289575576782227 Generator / grammar loss:-0.12227246165275574   similarity loss:-0.08907515555620193\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "정신차려요. 무슨 건 지금으로서는. 만일 말을 가로막았다. ” “당신은 협박하고 그건 앨리스만이\n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "네 놈들은 거지같은 영국 돼지야.모두들 내게 죄를 덮어씌우고 있어.” “당신은 늘 아내를 협박하고 있었잖소, 애셔?” “아니, 아니, 네 놈들은 알 리 없어.만일 당신이 당신 아내 살해에 관계가 없다면 말이오.그 목소리는 비명 같았다.\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "Unexpected error: <class 'ValueError'>\n",
            "==================================================\n",
            "26 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "” “우스운 농담이로군! 어젯밤 어디 있었는지 말할 수 있소, 애셔?” “말할 수 있고말고, 있고말고. 모두 이야기하지. 난 앨리스한테 가지 않았어. 친구들하고 있었어. 멋있는 친구들하고. <세븐 스타즈>에 있다가……그리고 나서 <레드 독>에 갔어. ” 그는 기침이 나와 말이 막혔다. “딕 윌러즈, 그도 함께 있었지. 커디 녀석도 그리고 조지도……플랫도, 그 밖의 놈들도 많이 있었어. 나는 앨리스에게 가지 않았어. 하느님께 맹세코 나는 사실을 말하고 있어. ” 그 소리는 비명이었다. 형사는 부하에게 눈짓을 했다. “데려가. 용의자를 구금시켜. ” 떨며 욕지거리를 퍼부어대는 그 불쾌한 노인이 나가 버리자 형사는 말했다. “아무래도 알 수 없군요. 그 편지만 없다면 저 늙은이의 짓이 분명한데요. ” “저 사람이 말하는 다른 남자들은 어떻소?” “나쁜 놈들입니다.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.393932819366455 Generator / grammar loss:-0.1146562322974205   similarity loss:-0.07474131882190704\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "어젯밤 애셔?” 이야기하지. 스타즈>에 갔어. “딕 그도 조지도……플랫도, 나는 말하고 소리는 비명이었다. 구금시켜. 형사는 분명한데요.\n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "<세븐 스타즈>에 있다가……그리고 나서 <레드 독>에 갔어.나는 앨리스에게 가지 않았어.멋있는 친구들하고.용의자를 구금시켜.\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "떨며 욕지거리를 퍼부어대는 그 불쾌한 노인이 나가 버리자 형사는 말했다. “\n",
            "--------------------------------------------------\n",
            "besm_bert summary:\n",
            "떨며 욕지거리를 퍼부어대는 그 불쾌한 노인이 나가 버리자 형사는 말했다. “\n",
            "--------------------------------------------------\n",
            "         method  comp ratio     intro      body    ending       var     total  \\\n",
            "0      SAM+WGAN    0.177156  0.455382  0.445545  0.408914  0.000400  0.436523   \n",
            "1  BERT+LexRank    0.160839  0.187674  0.175639  0.165993  0.000079  0.175152   \n",
            "2          BESM    0.097902  0.316464  0.304999  0.454074  0.004588  0.352014   \n",
            "3   BESM+kobert    0.097902  0.316464  0.304999  0.454074  0.004588  0.352014   \n",
            "\n",
            "    grammar  \n",
            "0  0.961064  \n",
            "1  0.998591  \n",
            "2  0.656096  \n",
            "3  0.656096  \n",
            "Current result ==================================================\n",
            "Sample count: 24\n",
            "         method  comp rate     intro      body  conclusion   isthmus  \\\n",
            "0      SAM+WGAN   0.149551  0.512457  0.502706    0.479813  0.007085   \n",
            "1  BERT+LexRank   0.215568  0.247777  0.212437    0.216332  0.009465   \n",
            "2          BESM   0.201218  0.435344  0.411380    0.375847  0.009411   \n",
            "3   BESM+kobert   0.208831  0.467993  0.406254    0.401559  0.009829   \n",
            "\n",
            "   simlirality  grammarity  \n",
            "0     0.497788    0.952275  \n",
            "1     0.220673    0.998986  \n",
            "2     0.405512    0.983769  \n",
            "3     0.417193    0.983213  \n",
            "==================================================\n",
            "27 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "모두 위증쯤은 손쉽게 할 녀석들이지요. 나도 저 늙은이가 그날 밤 어느 시간까지는 그들과 함께 있었다고 생각합니다. 그러니 6시 사이에 가게 언저리에서 저 늙은이를 본 사람이 있는지 없는지에 달렸다고 봐야겠지요. “ 포아로는 신중하게 머리를 저었다. “가게에서 아무것도 없어지지 않은 건 분명하지요?” 형사는 어깨를 으쓱했다. “그야 경우에 따라 다르겠지요. 담배 한두 갑이 없어졌는지도 모릅니다. 그러나 아무도 그런 일 때문에 사람을 죽이지는 않지요. ” “게다가 아무것도, 뭐라면 좋을까. 가지고 온 것이 없었다는, 그러니까 이상한, 그 장소에 어울리지 않는 그런 아무것도 거기에는 없었다는 거지요?” “철도 안내서가 있었습니다. ” “철도 안내서?” “그렇습니다. 계산대 위에 펼쳐진 채 뒤집혀 있었습니다. 꼭 누군가가 앤도버에서 떠나는 기차 편을 알아보고 있었던 것처럼. 그 할머니나 아니면 손님이 보고 있었다는 것이겠지요. ” “그런 것도 팔고 있었소?” 형사는 머리를 저었다. “1페니짜리 시간표를 팔고 있었습니다만, 그것은 큰 것이었으니까 스미스네 가게나 커다란 문방구점 같은 데서 다룰 겁니다. ” 포아로는 눈을 빛내며 몸을 앞으로 내밀었다. “철도 안내서라고 말했지요? <브레드쇼>던가요, <ABC>던가요?” 그러자 형사의 눈도 빛나기 시작했다. “정말, 그러고 보니 ABC였습니다.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.441568613052368 Generator / grammar loss:-0.1246090903878212   similarity loss:-0.07971301674842834\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "위증쯤은 나도 그날 시간까지는 있었다고 언저리에서 달렸다고 봐야겠지요. 포아로는 아무것도 없어지지 분명하지요?” 담배 모릅니다. 때문에 “게다가 안내서가 있었습니다. “철도 안내서?” “그렇습니다.\n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "“정말, 그러고 보니 ABC였습니다.담배 한두 갑이 없어졌는지도 모릅니다.” “게다가 아무것도, 뭐라면 좋을까.나도 저 늙은이가 그날 밤 어느 시간까지는 그들과 함께 있었다고 생각합니다.\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "나도 저 늙은이가 그날 밤 어느 시간까지는 그들과 함께 있었다고 생각합니다. 가지고 온 것이 없었다는, 그러니까 이상한, 그 장소에 어울리지 않는 그런 아무것도 거기에는 없었다는 거지요?” “\n",
            "--------------------------------------------------\n",
            "besm_bert summary:\n",
            "나도 저 늙은이가 그날 밤 어느 시간까지는 그들과 함께 있었다고 생각합니다. 가지고 온 것이 없었다는, 그러니까 이상한, 그 장소에 어울리지 않는 그런 아무것도 거기에는 없었다는 거지요?” “\n",
            "--------------------------------------------------\n",
            "         method  comp ratio     intro      body    ending       var     total  \\\n",
            "0      SAM+WGAN    0.163934  0.426001  0.476618  0.411886  0.000772  0.447075   \n",
            "1  BERT+LexRank    0.154993  0.322690  0.215640  0.146855  0.005234  0.216414   \n",
            "2          BESM    0.159463  0.537685  0.373626  0.175993  0.021866  0.347148   \n",
            "3   BESM+kobert    0.159463  0.537685  0.373626  0.175993  0.021866  0.347148   \n",
            "\n",
            "    grammar  \n",
            "0  0.977608  \n",
            "1  0.999020  \n",
            "2  0.999013  \n",
            "3  0.999013  \n",
            "Current result ==================================================\n",
            "Sample count: 25\n",
            "         method  comp rate     intro      body  conclusion   isthmus  \\\n",
            "0      SAM+WGAN   0.150126  0.508999  0.501662    0.477096  0.006833   \n",
            "1  BERT+LexRank   0.213145  0.250773  0.212565    0.213553  0.009296   \n",
            "2          BESM   0.199547  0.439437  0.409869    0.367852  0.009909   \n",
            "3   BESM+kobert   0.206856  0.470780  0.404949    0.392537  0.010311   \n",
            "\n",
            "   simlirality  grammarity  \n",
            "0     0.495760    0.953288  \n",
            "1     0.220503    0.998988  \n",
            "2     0.403178    0.984379  \n",
            "3     0.414391    0.983845  \n",
            "==================================================\n",
            "28 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "” < 조카딸의 이야기 > 이 사건에 대한 내 관심은 ABC 철도 안내서가 나왔을 때 비로서 일기 시작했다고 생각된다. 그때까지 나는 이 사건에 그리 열중하고 있지 않았다. 뒷골목의 노파 살해 같은 시시한 사건은 날마다 신문에 보도되는 흔해빠진 범죄여서 거의 주의를 끌지 못했던 것이다. 나는 마음속으로 익명 편지가 21일이라는 날짜를 지정한 일 따위는 우연의 일치에 지나지 않는다고 생각하고 있었다. 당연히 애셔 부인은 그 남편이 술에 취한 나머지 폭력을 휘둘러 희생된 것으로 여겼다. 그런데 지금 철도 안내서(철도역을 알파벳 순서로 나열했기 때문에 ABC라는 준말로 알려져 있음)가 등장하자 내 온몸에는 흥분의 전율이 일었다. 확실히 이것은 우연의 일치 같은 것 일 리 없다. 시시한 범죄가 새로운 양상을 띠기 시작했다. 애셔 부인을 살해하고 ABC 철도 안내서를 남기고 사라진 신비의 인간은 대체 누구인가? 경찰서를 나와 우리는 먼저 살해된 여자의 시체를 보러 시체 안치소로 갔다. 얼마 안 되는 머리칼을 이마 위로 가지런히 빗어 넘긴 노파의 주름잡힌 얼굴을 보고 있는 동안, 나는 이상한 느낌이 들기 시작했다. 너무나 평화로워 폭력 같은 것과는 거리가 먼 느낌이었다. 경관이 말했다. “누가 무엇으로 자기를 때렸는지 조금도 모르는 얼굴입니다. 카 의사가 그렇게 말하더군요. 오히려 그게 잘된 일이라고 생각합니다. 가엾게도, 깔끔한 사람이었는데. ” 포아로가 말했다. “옛날엔 아름다웠을 것 같군. ” 나는 믿을 수 없는 마음이 들어 중얼거렸다.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.454463243484497 Generator / grammar loss:-0.13683800399303436   similarity loss:-0.09058431535959244\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            " > 이 관심은 시시한 것이다. 일치에 알려져 일었다. 확실히 띠기 시작했다. 노파의 느낌이 들기 때렸는지 카 그렇게 말하더군요. 그게 가엾게도, 사람이었는데. ” 포아로가 말했다. “옛날엔 아름다웠을\n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "그런데 지금 철도 안내서(철도역을 알파벳 순서로 나열했기 때문에 ABC라는 준말로 알려져 있음)가 등장하자 내 온몸에는 흥분의 전율이 일었다.경관이 말했다.” 포아로가 말했다.“누가 무엇으로 자기를 때렸는지 조금도 모르는 얼굴입니다.카 의사가 그렇게 말하더군요.\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "” < 조카딸의 이야기 > 이 사건에 대한 내 관심은 ABC 철도 안내서가 나왔을 때 비로서 일기 시작했다고 생각된다. 애셔 부인을 살해하고 ABC 철도 안내서를 남기고 사라진 신비의 인간은 대체 누구인가? 얼마 안 되는 머리칼을 이마 위로 가지런히 빗어 넘긴 노파의 주름잡힌 얼굴을 보고 있는 동안, 나는 이상한 느낌이 들기 시작했다.\n",
            "--------------------------------------------------\n",
            "besm_bert summary:\n",
            "” < 조카딸의 이야기 > 이 사건에 대한 내 관심은 abc 철도 안내서가 나왔을 때 비로서 일기 시작했다고 생각된다. 뒷골목의 노파 살해 같은 시시한 사건은 날마다 신문에 보도되는 흔해빠진 범죄여서 거의 주의를 끌지 못했던 것이다.\n",
            "--------------------------------------------------\n",
            "         method  comp ratio     intro      body    ending       var     total  \\\n",
            "0      SAM+WGAN    0.148148  0.413042  0.376877  0.705535  0.021653  0.482707   \n",
            "1  BERT+LexRank    0.193122  0.339848  0.261928  0.177518  0.004394  0.252189   \n",
            "2          BESM    0.248677  0.549769  0.472760  0.258645  0.015170  0.423927   \n",
            "3   BESM+kobert    0.171958  0.672427  0.357894  0.184702  0.040756  0.368843   \n",
            "\n",
            "    grammar  \n",
            "0  0.989961  \n",
            "1  0.999009  \n",
            "2  0.999019  \n",
            "3  0.999023  \n",
            "Current result ==================================================\n",
            "Sample count: 26\n",
            "         method  comp rate     intro      body  conclusion   isthmus  \\\n",
            "0      SAM+WGAN   0.150050  0.505308  0.496863    0.485882  0.007403   \n",
            "1  BERT+LexRank   0.212375  0.254199  0.214463    0.212167  0.009108   \n",
            "2          BESM   0.201437  0.443681  0.412288    0.363652  0.010111   \n",
            "3   BESM+kobert   0.205514  0.478536  0.403139    0.384543  0.011482   \n",
            "\n",
            "   simlirality  grammarity  \n",
            "0     0.495258    0.954699  \n",
            "1     0.221722    0.998989  \n",
            "2     0.403976    0.984942  \n",
            "3     0.412640    0.984429  \n",
            "==================================================\n",
            "29 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "“그럴까. ‘ “그렇네. 자, 턱의 선이며 뼈 모양이며 머리 생김새를 잘 보게. ” 그는 덮개를 본래대로 해두면서 한숨을 쉬었다. 그리고 나서 우리는 시체 안치소를 나왔다. 다음에는 경찰의와 간단히 면담했다. 카 의사는 유능해 보이는 중년 사나이였다. 그는 활발하게 단정적인 말투로 이야기했다. “흉기는 발견되지 않았습니다. 그것이 무엇이었는지는 알 수 없지요. 무거운 지팡이, 몽둥이, 모래주머니 같은 것……그런 거라면 어느 것이나 들어맞습니다. ” “그런 타격을 가하려면 억센 힘이 필요합니까?” 의사는 날카로운 눈으로 포아로를 보았다. “그 말뜻은 몸을 떨어대는 70살의 노인으로서도 할 수 있느냐는 거지요? 네, 물론 할 수 있습니다. 흉기의 머리 부분에 충분한 무게를 주면 체력이 약한 사람도 바라는 결과를 얻을 수 있습니다. ” “그렇다면 범인은 남자일 수 있는 것과 마찬가지로 여자일 수도 있군요?” 이 말은 얼마쯤 의사를 놀라게 한 모양이었다. “여자도? 네, 그렇습니다. 이런 종류의 범죄를 여자와 관련시켜 생각해 볼 마음은 없었습니다만, 물론 할 수 있습니다. 완전히 가능합니다.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.477334499359131 Generator / grammar loss:-0.12361573427915573   similarity loss:-0.0749436691403389\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            " “그렇네. 자, 턱의 모양이며 ” 그는 그리고 시체 다음에는 의사는 유능해 이야기했다. 무엇이었는지는 없지요. 필요합니까?” 노인으로서도 그렇습니다.\n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "다음에는 경찰의와 간단히 면담했다.“흉기는 발견되지 않았습니다.” 그는 덮개를 본래대로 해두면서 한숨을 쉬었다.그리고 나서 우리는 시체 안치소를 나왔다.” “그렇다면 범인은 남자일 수 있는 것과 마찬가지로 여자일 수도 있군요?” 이 말은 얼마쯤 의사를 놀라게 한 모양이었다.\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "그는 덮개를 본래대로 해두면서 한숨을 쉬었다.그리고 나서 우리는 시체 안치소를 나왔다. 무거운 지팡이, 몽둥이, 모래주머니 같은 것……그런 거라면 어느 것이나 들어맞습니다. ” “\n",
            "--------------------------------------------------\n",
            "besm_bert summary:\n",
            "그는 덮개를 본래대로 해두면서 한숨을 쉬었다.그리고 나서 우리는 시체 안치소를 나왔다. 네, 물론 할 수 있습니다.흉기의 머리 부분에 충분한 무게를 주면 체력이 약한 사람도 바라는 결과를 얻을 수 있습니다. ” “ 이런 종류의 범죄를 여자와 관련시켜 생각해 볼 마음은 없었습니다만, 물론 할 수 있습니다.\n",
            "--------------------------------------------------\n",
            "         method  comp ratio     intro      body    ending       var     total  \\\n",
            "0      SAM+WGAN    0.150538  0.603150  0.579508  0.528719  0.000964  0.569000   \n",
            "1  BERT+LexRank    0.274194  0.097665  0.226777  0.189029  0.002938  0.189630   \n",
            "2          BESM    0.179211  0.629843  0.436748  0.373132  0.011915  0.456282   \n",
            "3   BESM+kobert    0.304659  0.445512  0.386905  0.591262  0.007382  0.459933   \n",
            "\n",
            "    grammar  \n",
            "0  0.989361  \n",
            "1  0.998999  \n",
            "2  0.995070  \n",
            "3  0.998991  \n",
            "Current result ==================================================\n",
            "Sample count: 27\n",
            "         method  comp rate     intro      body  conclusion   isthmus  \\\n",
            "0      SAM+WGAN   0.150068  0.508932  0.499924    0.487469  0.007164   \n",
            "1  BERT+LexRank   0.214664  0.248402  0.214919    0.211310  0.008879   \n",
            "2          BESM   0.200614  0.450576  0.413194    0.364003  0.010178   \n",
            "3   BESM+kobert   0.209186  0.477313  0.402538    0.392199  0.011330   \n",
            "\n",
            "   simlirality  grammarity  \n",
            "0     0.497989    0.955983  \n",
            "1     0.220533    0.998989  \n",
            "2     0.405913    0.985317  \n",
            "3     0.414391    0.984968  \n",
            "==================================================\n",
            "30 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "다만 심리적으로 말해서, 이건 여성의 범죄라고 할 수 없지요. ” 포아로도 그 말에 동의하여 열심히 고개를 끄덕였다. “그렇습니다. 그렇습니다. 확실히 있을 수 없는 일입니다. 그러나 모든 가능성을 염두해 두지 않으면 안 되니까요. 시체는 쓰러져 있었겠지요. 어떤 모습이었습니까?” 의사는 피해자의 위치를 세밀하게 우리에게 설명했다. 그의 말에 의하면, 타격이 주어졌을 때 그녀는 계산대 쪽으로 등을 돌리고―따라서 가해자에 대해서도―서 있었다고 한다. 머리를 얻어맞고 그녀는 계산대 뒤로 쭈그려 앉아 버려 가게에 들어온 사람 눈에 얼른 띄지 않았던 셈이다. 카 의사에게 인사하고 밖으로 나오자 포아로가 말했다. “이로써 애셔의 무죄 쪽으로 한 걸음 다가선 게 확실하네. 헤이스팅즈. 만일 그가 아내한테 덤벼들면서 협박한 거라면 그녀는 계산대를 사이에 두고 그와 마주서 있었을 걸세. 그런데 그녀는 가해자에게 등을 돌리고 있었지. 틀림없이 그녀는 손님에게 줄 파이프 담배나 궐련을 꺼내려 했던 걸 거야. ” 나는 조금 몸을 떨었다. “기분이 언짢군. ” 포아로는 무겁게 머리를 흔들었다. 그는 중얼거렸다.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.416602611541748 Generator / grammar loss:-0.12287955731153488   similarity loss:-0.08060057461261749\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            " 말해서, 이건 할 수 없지요. ” 열심히 고개를 “그렇습니다. 그렇습니다. 있었겠지요. 계산대 등을 한다. 말했다. 그런데 틀림없이\n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "틀림없이 그녀는 손님에게 줄 파이프 담배나 궐련을 꺼내려 했던 걸 거야.어떤 모습이었습니까?” 의사는 피해자의 위치를 세밀하게 우리에게 설명했다.만일 그가 아내한테 덤벼들면서 협박한 거라면 그녀는 계산대를 사이에 두고 그와 마주서 있었을 걸세.그런데 그녀는 가해자에게 등을 돌리고 있었지.머리를 얻어맞고 그녀는 계산대 뒤로 쭈그려 앉아 버려 가게에 들어온 사람 눈에 얼른 띄지 않았던 셈이다.\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "그의 말에 의하면, 타격이 주어졌을 때 그녀는 계산대 쪽으로 등을 돌리고―따라서 가해자에 대해서도―서 있었다고 한다. 머리를 얻어맞고 그녀는 계산대 뒤로 쭈그려 앉아 버려 가게에 들어온 사람 눈에 얼른 띄지 않았던 셈이다.\n",
            "--------------------------------------------------\n",
            "besm_bert summary:\n",
            "그의 말에 의하면, 타격이 주어졌을 때 그녀는 계산대 쪽으로 등을 돌리고―따라서 가해자에 대해서도―서 있었다고 한다. 만일 그가 아내한테 덤벼들면서 협박한 거라면 그녀는 계산대를 사이에 두고 그와 마주서 있었을 걸세.그런데 그녀는 가해자에게 등을 돌리고 있었지. 틀림없이 그녀는 손님에게 줄 파이프 담배나 궐련을 꺼내려 했던 걸 거야. ”\n",
            "--------------------------------------------------\n",
            "         method  comp ratio     intro      body    ending       var     total  \\\n",
            "0      SAM+WGAN    0.131907  0.796755  0.427816  0.500657  0.025455  0.523456   \n",
            "1  BERT+LexRank    0.390374 -0.059605  0.228442  0.124949  0.014194  0.139785   \n",
            "2          BESM    0.221034  0.028053  0.322740  0.202035  0.014631  0.227591   \n",
            "3   BESM+kobert    0.336898  0.516275  0.497997  0.633523  0.003605  0.542310   \n",
            "\n",
            "    grammar  \n",
            "0  0.983264  \n",
            "1  0.998994  \n",
            "2  0.998993  \n",
            "3  0.996906  \n",
            "Current result ==================================================\n",
            "Sample count: 28\n",
            "         method  comp rate     intro      body  conclusion   isthmus  \\\n",
            "0      SAM+WGAN   0.149420  0.519211  0.497348    0.487940  0.007818   \n",
            "1  BERT+LexRank   0.220940  0.237401  0.215402    0.208225  0.009069   \n",
            "2          BESM   0.201343  0.435486  0.409964    0.358219  0.010337   \n",
            "3   BESM+kobert   0.213747  0.478704  0.405947    0.400818  0.011054   \n",
            "\n",
            "   simlirality  grammarity  \n",
            "0     0.498898    0.956957  \n",
            "1     0.217649    0.998989  \n",
            "2     0.399545    0.985806  \n",
            "3     0.418960    0.985395  \n",
            "==================================================\n",
            "31 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "“가엾은 여자일세. ” 그리고 나서 그는 시계를 흘끗 보았다. “여기서 오버튼까지는 그리 멀지 않네. 거기 가서 노파의 조카딸을 만나 보는게 어떻겠나?” “범행 현장인 가게 쪽을 먼저 보는 게 좋지 않을까?” “그건 뒤로 미루고 싶네. 이유가 있어서. ” 그는 더 이상 설명하지 않았다. 잠시 뒤 우리는 자동차를 타고 오버튼 쪽으로 런던 행 도로를 달려갔다. 형사가 가르쳐 준 집은 마을에서 런던 쪽으로 1마일쯤 간 곳에 있었다. 훌륭한 집이었다. 벨을 누르자 아름다운 검은 머리의 아가씨가 나왔다. 지금까지 울고 있었던 듯 눈이 빨갰다. 포아로가 상냥하게 말했다. “아, 당신이 이 집 하녀인 메리 드로워 양이군요?” “그렇습니다. 제가 메리예요. ” “주인께서 허락해 주신다면 잠시 이야기를 좀 나누고 싶은데요. 이야기란 다름아닌 아가씨 아주머니인 애셔 부인에 대한 것입니다. ” “주인은 외출중이세요. 들어오셔도 그리 꾸중이 없으리라 생각됩니다. ” 그녀는 조그만 거실의 문을 열었다. 우리는 안으로 들어갔다.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.5204696655273438 Generator / grammar loss:-0.13607226312160492   similarity loss:-0.08280020952224731\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "“가엾은 ” 시계를 보는게 좋지 “그건 싶네. 그는 잠시 달려갔다. 마을에서 1마일쯤 있었다. 집이었다. 아가씨가 있었던 집 메리예요.\n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "지금까지 울고 있었던 듯 눈이 빨갰다.” 그리고 나서 그는 시계를 흘끗 보았다.” 그는 더 이상 설명하지 않았다.“가엾은 여자일세.\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "Unexpected error: <class 'ValueError'>\n",
            "==================================================\n",
            "32 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "포아로는 창가 의자에 앉아 날카롭게 아가씨의 얼굴을 보았다. “아주머니가 돌아가신 이야기는 물론 들었겠지요?” 아가씨는 고개를 끄덕였는데 눈물이 다시 새삼스럽게 솟아났다. “오늘 아침 경찰에서 오셨었어요. 아, 무서운 일이에요!가엾은 아주머니! 그토록 괴로운 나날을 보내고서 또 이런 일을 당하시다니……너무해요. ” “경찰이 앤도버로 오라고 하지 않았습니까?” “월요일에 심문을 받기로 되어 있어요. 하지만 저는 그리로 가면 있을 데가 없어요. 이젠 그 가게로 갈 수도 없고. 게다가 저 말고는 하녀가 없는데 주인에게 폐 끼치고 싶지도 않아요. ” 포아로는 부드럽게 물었다. “당신은 아주머니를 아주 좋아했었군요, 메리 양?” “정말 좋아했어요. 아주머니는 언제나 제게 잘해 주셨지요. 어머니가 돌아가신 뒤 저는 11살 때 런던의 아주머니 집으로 갔어요. 16살 때부터 돈벌이를 하러 나와 있었지만, 쉬는 날이면 꼭 아주머니에게 가곤 했어요. 아주머니는 그 독일사람 때문에 아주 애를 먹고 계셨어요. 그 남자를 아주머니는 늘 <나의 악마>라고 부르곤 하셨지요. 그는 아주머니가 있는 데는 어디든 와서 가만히 두지 않았어요. 돈만 빼앗아 가는 거지같은 짐승이에요. ” 아가씨의 말투는 아주 격렬했다.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.209115743637085 Generator / grammar loss:-0.13056069612503052   similarity loss:-0.10957242548465729\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "포아로는 날카롭게 아침 무서운 싶지도 “당신은 돌아가신 때 돈벌이를 하러 나와 있었지만, 꼭 아주머니는 애를 먹고 하셨지요. 와서 짐승이에요. 격렬했다. \n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "“오늘 아침 경찰에서 오셨었어요.” 포아로는 부드럽게 물었다.” “경찰이 앤도버로 오라고 하지 않았습니까?” “월요일에 심문을 받기로 되어 있어요.포아로는 창가 의자에 앉아 날카롭게 아가씨의 얼굴을 보았다.\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "그토록 괴로운 나날을 보내고서 또 이런 일을 당하시다니……너무해요. ” “ 어머니가 돌아가신 뒤 저는 11살 때 런던의 아주머니 집으로 갔어요.16살 때부터 돈벌이를 하러 나와 있었지만, 쉬는 날이면 꼭 아주머니에게 가곤 했어요.\n",
            "--------------------------------------------------\n",
            "besm_bert summary:\n",
            "그토록 괴로운 나날을 보내고서 또 이런 일을 당하시다니……너무해요. ” “ 어머니가 돌아가신 뒤 저는 11살 때 런던의 아주머니 집으로 갔어요.16살 때부터 돈벌이를 하러 나와 있었지만, 쉬는 날이면 꼭 아주머니에게 가곤 했어요.\n",
            "--------------------------------------------------\n",
            "         method  comp ratio     intro      body    ending       var     total  \\\n",
            "0      SAM+WGAN    0.139837  0.453998  0.391645  0.531165  0.003257  0.445971   \n",
            "1  BERT+LexRank    0.186992  0.324654  0.234238  0.139146  0.005737  0.223794   \n",
            "2          BESM    0.208130  0.372653  0.466699  0.527928  0.004078  0.466258   \n",
            "3   BESM+kobert    0.208130  0.372653  0.466699  0.527928  0.004078  0.466258   \n",
            "\n",
            "    grammar  \n",
            "0  0.965765  \n",
            "1  0.999029  \n",
            "2  0.999015  \n",
            "3  0.999015  \n",
            "Current result ==================================================\n",
            "Sample count: 29\n",
            "         method  comp rate     intro      body  conclusion   isthmus  \\\n",
            "0      SAM+WGAN   0.149089  0.516962  0.493703    0.489430  0.007660   \n",
            "1  BERT+LexRank   0.219769  0.240410  0.216052    0.205843  0.008954   \n",
            "2          BESM   0.201577  0.433319  0.411920    0.364071  0.010121   \n",
            "3   BESM+kobert   0.213554  0.475047  0.408042    0.405201  0.010814   \n",
            "\n",
            "   simlirality  grammarity  \n",
            "0     0.497073    0.957261  \n",
            "1     0.217861    0.998990  \n",
            "2     0.401845    0.986261  \n",
            "3     0.420591    0.985864  \n",
            "==================================================\n",
            "33 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "“아주머니는 법적 수단으로 그 남자의 압박에서 벗어나려고는 하지 않았습니까?” 아가씨는 단순하게, 그러나 딱 잘라 말했다. “아무래도 남편이었기 때문에 그럴 수가 없었지요. ” “메리 양, 그 남자는 아주머니를 협박했었지요?” “네, 아주 무서운 소리를 곧잘 했어요. 목을 부러뜨린다든가 하는 말들을. 저주스럽게 욕지거리를 해대면서. 독일 말과 영어 두 가지로요. 그렇지만 아주머니는 결혼했던 즈음에는 아주 멋있는 남자였다고 말씀하셨어요. 사람이 그렇게 된다는 것은 참으로 무서운 일이에요. ” “정말 그렇군요. 그런데 메리 양, 늘 그런 협박을 받고 있었다면 사건이 일어난 것을 알았을 때 그리 놀라지 않았겠군요?” “그래도 역시 놀랐어요. 아무튼 진짜로 하는 소리라고는 생각지 않았으니까요. 그저 말로만 해대는 것뿐 그 이상으로는 여기지 않았어요. 아주머니도 무서워하고 계셨던 것 같지 않아요. 아주머니가 대들면 개가 다리 사이로 꼬리를 감추듯 움츠러드는 것을 본 적도 있어요. 오히려 그쪽에서 아주머니를 무서워하고 있을 정도였지요. ” “그런데도 아주머니는 돈을 주고 있었습니까?” “남편인걸요. ” “그렇군요, 아까도 그렇게 말했었지요. ” 포아로는 잠시 말을 끊었다가 다시 계속했다. “그렇다면 결국 그 남자는 아주머니를 죽이지 않았다는 거로군요?” “죽이지 않았다고요?” 그녀는 눈을 크게 떠보였다. “그렇습니다.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.4727649688720703 Generator / grammar loss:-0.1288776695728302   similarity loss:-0.08068985491991043\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "아가씨는 협박했었지요?” “네, 저주스럽게 영어 두 가지로요. 그렇지만 즈음에는 말씀하셨어요. 된다는 일이에요. 그리 놀라지 않았겠군요?” “그래도 역시 놀랐어요. 아까도 말했었지요. “그렇습니다.\n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "독일 말과 영어 두 가지로요.“그렇습니다.” “정말 그렇군요.“아무래도 남편이었기 때문에 그럴 수가 없었지요.\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "“아주머니는 법적 수단으로 그 남자의 압박에서 벗어나려고는 하지 않았습니까?” 그렇지만 아주머니는 결혼했던 즈음에는 아주 멋있는 남자였다고 말씀하셨어요. 아주머니가 대들면 개가 다리 사이로 꼬리를 감추듯 움츠러드는 것을 본 적도 있어요.오히려 그쪽에서 아주머니를 무서워하고 있을 정도였지요. ” “\n",
            "--------------------------------------------------\n",
            "besm_bert summary:\n",
            "“아주머니는 법적 수단으로 그 남자의 압박에서 벗어나려고는 하지 않았습니까?” 그렇지만 아주머니는 결혼했던 즈음에는 아주 멋있는 남자였다고 말씀하셨어요.\n",
            "--------------------------------------------------\n",
            "         method  comp ratio     intro      body    ending       var     total  \\\n",
            "0      SAM+WGAN    0.160584  0.320911  0.446809  0.583945  0.011538  0.462770   \n",
            "1  BERT+LexRank    0.089051  0.326343  0.159848  0.133054  0.007311  0.185109   \n",
            "2          BESM    0.242336  0.540753  0.495388  0.592881  0.001587  0.533709   \n",
            "3   BESM+kobert    0.124088  0.523365  0.259854  0.273133  0.014692  0.316540   \n",
            "\n",
            "    grammar  \n",
            "0  0.994110  \n",
            "1  0.998986  \n",
            "2  0.995258  \n",
            "3  0.999016  \n",
            "Current result ==================================================\n",
            "Sample count: 30\n",
            "         method  comp rate     intro      body  conclusion   isthmus  \\\n",
            "0      SAM+WGAN   0.149472  0.510427  0.492140    0.492581  0.007790   \n",
            "1  BERT+LexRank   0.215412  0.243274  0.214178    0.203417  0.008899   \n",
            "2          BESM   0.202936  0.436900  0.414702    0.371698  0.009837   \n",
            "3   BESM+kobert   0.210571  0.476658  0.403102    0.400799  0.010943   \n",
            "\n",
            "   simlirality  grammarity  \n",
            "0     0.495930    0.958489  \n",
            "1     0.216769    0.998990  \n",
            "2     0.406240    0.986561  \n",
            "3     0.417122    0.986303  \n",
            "==================================================\n",
            "34 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "누군가 다른 사람이 아가씨 아주머니를 죽였다는 말입니다. ……달리 짐작되는 사람 없습니까?” 그녀는 한층 더 놀란 듯 그의 얼굴을 보았다. “알 수 없어요. 하지만 그런 일이 있을 수 있을까요?” “당신 아주머니가 무서워한 다른 사람은 없었습니까?” 메리는 고개를 저었다. “아주머니는 남을 무서워하지 않으셨어요. 말솜씨가 좋아 누구에게나 맞설 수 있으셨어요. ” “아주머니에게 악의를 품고 있는 어떤 사람에 대한 이야기를 해준 일은 없습니까?” “네, 없어요. ” “익명의 편지를 받은 일도” “무슨 편지라고요?” “개인적인 서명이 없는 편지로, 예를 들어 그저 ABC라는 서명만 있는. ” 그는 아가씨의 얼굴을 찬찬히 들여다보고 있었는데, 그녀는 분명 난처해하는 모습이었다. 그녀는 묘한 표정으로 고개를 저었다. “아가씨 말고 또 다른 친척이 있습니까?” “지금은 없어요. 열 남매였는데 자란 사람은 셋뿐이었지요. 톰 아저씨는 전쟁터에서 돌아가시고, 해리 아저씨는 남아메리카로 가버리셔서 소식을 몰라요. 그리고 또 제 어머니는 돌아가셨기 때문에 저밖에 없어요. ” “아주머니는 저축을 했었습니까? 돈을 모으고 있었습니까?” “은행에 조금 있어요. 매장 비용만 된다면 하고 곧잘 말씀하곤 하셨지요. 그리고는 겨우 그럭저럭 살아 나가셨어요. 그 늙어빠진 악마가 있으니 안 그렇겠어요. ” 포아로는 생각 깊게 고개를 끄덕였다.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.36403226852417 Generator / grammar loss:-0.1369277834892273   similarity loss:-0.1001143604516983\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "누군가 사람이 짐작되는 “알 없어요. 수 “당신 말솜씨가 받은 일도” “무슨 없어요. 사람은 전쟁터에서 몰라요. 또 제 “아주머니는 있었습니까?” 있어요. 하셨지요. 그 늙어빠진 안\n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "말솜씨가 좋아 누구에게나 맞설 수 있으셨어요.톰 아저씨는 전쟁터에서 돌아가시고, 해리 아저씨는 남아메리카로 가버리셔서 소식을 몰라요.돈을 모으고 있었습니까?” “은행에 조금 있어요.열 남매였는데 자란 사람은 셋뿐이었지요.\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "아주머니에게 악의를 품고 있는 어떤 사람에 대한 이야기를 해준 일은 없습니까?” “ 그는 아가씨의 얼굴을 찬찬히 들여다보고 있었는데, 그녀는 분명 난처해하는 모습이었다.\n",
            "--------------------------------------------------\n",
            "besm_bert summary:\n",
            "아주머니에게 악의를 품고 있는 어떤 사람에 대한 이야기를 해준 일은 없습니까?” “ 개인적인 서명이 없는 편지로, 예를 들어 그저 abc라는 서명만 있는. ”\n",
            "--------------------------------------------------\n",
            "         method  comp ratio     intro      body    ending       var     total  \\\n",
            "0      SAM+WGAN    0.147445  0.504576  0.415939  0.475914  0.001364  0.451659   \n",
            "1  BERT+LexRank    0.179562  0.125089  0.276957  0.175443  0.003989  0.216129   \n",
            "2          BESM    0.137226  0.423818  0.358041  0.211395  0.007884  0.327202   \n",
            "3   BESM+kobert    0.128467  0.432954  0.424171  0.325686  0.002365  0.396382   \n",
            "\n",
            "    grammar  \n",
            "0  0.974543  \n",
            "1  0.998822  \n",
            "2  0.999014  \n",
            "3  0.990487  \n",
            "Current result ==================================================\n",
            "Sample count: 31\n",
            "         method  comp rate     intro      body  conclusion   isthmus  \\\n",
            "0      SAM+WGAN   0.149407  0.510239  0.489682    0.492043  0.007582   \n",
            "1  BERT+LexRank   0.214255  0.239462  0.216203    0.202515  0.008741   \n",
            "2          BESM   0.200816  0.436478  0.412875    0.366527  0.009774   \n",
            "3   BESM+kobert   0.207923  0.475248  0.403782    0.398376  0.010666   \n",
            "\n",
            "   simlirality  grammarity  \n",
            "0     0.494502    0.959007  \n",
            "1     0.216749    0.998985  \n",
            "2     0.403691    0.986963  \n",
            "3     0.416453    0.986438  \n",
            "==================================================\n",
            "35 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "그는 아가씨에게 말한다기 보다 혼잣말처럼 중얼거렸다. “지금으로선 어둠 속에 있는 것 같군. 방향도 잡을 수 없어. 만일 좀더 뚜렷해진다면……. ” 그는 일어섰다. “만일 아가씨한테 볼일이 생기면 여기로 편지하지요. 메리 양. ” “사실을 말씀드리면, 저는 여기를 나갈 생각으로 있어요. 시골을 그리 좋아하지 않거든요. 아주머니 곁에 있는 게 마음 든든히 여겨져 여기 있었던 거예요. 그러나 이젠……. ” 그 눈에 다시 눈물이 솟았다. “이제는 여기 있을 이유가 없어져 런던으로 되돌아가려고 해요. 그곳이 제게는 더 재미있는 걸요. ” “그럼, 그리고 가게 될 때에는 주소를 가르쳐 주십시오. 이것이 제 명함입니다. ” 그는 아가씨에게 명함을 건네주었다. 그녀는 곤혹스러운 듯 이마에 주름을 지으며 그것을 보았다. “그럼, 선생님은……경찰과는 관계가 없으신가요?” “나는 사립탐정입니다. ” 그녀는 선 채로 잠시 말없이 그를 쳐다보았다.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.4397149085998535 Generator / grammar loss:-0.12510675191879272   similarity loss:-0.08040550351142883\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "속에 있는 것 잡을 편지하지요. 말씀드리면, 저는 그리 든든히 여겨져 거예요. 눈에 가게 될 주십시오.\n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "“그럼, 선생님은……경찰과는 관계가 없으신가요?” “나는 사립탐정입니다.이것이 제 명함입니다.” 그는 아가씨에게 명함을 건네주었다.” 그 눈에 다시 눈물이 솟았다.\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "Unexpected error: <class 'ValueError'>\n",
            "==================================================\n",
            "36 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "이윽고 그녀가 말했다. “뭔가 의심스러운 점이라고 있으신지요?” “그렇습니다, 아가씨. 좀 이상한 점이 있지요. 아마 앞으로 아가씨에게 도움 받을 일이 있을지도 모르겠습니다. ” “저는, 저는 무엇이든 하겠어요. 아주머니가 살해되시다니, 옳은 일이 아니니까요. ” 그것은 기묘한 표현이었다. 그러나 꽤 감동적이었다. 우리는 곧 자동차를 타고 앤도버로 돌아갔다. < 범행 현장 > 참극이 일어난 곳은 큰길에서 좁은 골목이었다. 애셔 부인의 가게는 그 중간쯤의 오른쪽에 있었다. 그 골목에 들어섰을 때, 포아로는 흘끗 시계를 보았다. 그래서 나는 그가 범행 현장으로 가는 시간을 지금까지 미룬 까닭을 알았다. 꼭 5시 30분이 되어 있었다. 그는 되도록 어젯밤의 상황을 재현하려 생각하고 있었던 것이다. 그러나 그것이 그의 목적이었다면 실패했다. 이 때 골목은 어젯밤의 그림자를 거의 전해주고 있지 않았다. 그곳에는 가난한 사람들 집에 섞여 조그만 가게가 몇 채 줄지어 있었다. 다른 때 같으면 이 언저리의 가난한 몇몇 사람들이 그곳을 오가고 또 찻길이나 보도 위에서는 몇 명의 아이들이 놀고 있을 뿐이었다. 그런데 이때는 많은 사람들이 쭉 둘러서서 집인지 가게를 보고 있었다.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.4267547130584717 Generator / grammar loss:-0.13088871538639069   similarity loss:-0.08754729479551315\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "이윽고 말했다. “뭔가 아가씨. 좀 하겠어요. 살해되시다니, 그것은 앤도버로 돌아갔다. 범행 일어난 곳은 오른쪽에 포아로는 꼭 30분이 있었다. 그런데 사람들이 쭉\n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "아주머니가 살해되시다니, 옳은 일이 아니니까요.꼭 5시 30분이 되어 있었다.그는 되도록 어젯밤의 상황을 재현하려 생각하고 있었던 것이다.우리는 곧 자동차를 타고 앤도버로 돌아갔다.그래서 나는 그가 범행 현장으로 가는 시간을 지금까지 미룬 까닭을 알았다.\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "그래서 나는 그가 범행 현장으로 가는 시간을 지금까지 미룬 까닭을 알았다. 다른 때 같으면 이 언저리의 가난한 몇몇 사람들이 그곳을 오가고 또 찻길이나 보도 위에서는 몇 명의 아이들이 놀고 있을 뿐이었다.\n",
            "--------------------------------------------------\n",
            "besm_bert summary:\n",
            "그래서 나는 그가 범행 현장으로 가는 시간을 지금까지 미룬 까닭을 알았다. 다른 때 같으면 이 언저리의 가난한 몇몇 사람들이 그곳을 오가고 또 찻길이나 보도 위에서는 몇 명의 아이들이 놀고 있을 뿐이었다.\n",
            "--------------------------------------------------\n",
            "         method  comp ratio     intro      body    ending       var     total  \\\n",
            "0      SAM+WGAN    0.151414  0.692585  0.506301  0.318734  0.023294  0.487288   \n",
            "1  BERT+LexRank    0.236273  0.122896  0.253095  0.232889  0.003273  0.220994   \n",
            "2          BESM    0.189684  0.178675  0.309311  0.512894  0.018913  0.344259   \n",
            "3   BESM+kobert    0.189684  0.178675  0.309311  0.512894  0.018913  0.344259   \n",
            "\n",
            "    grammar  \n",
            "0  0.973905  \n",
            "1  0.999029  \n",
            "2  0.999027  \n",
            "3  0.999027  \n",
            "Current result ==================================================\n",
            "Sample count: 32\n",
            "         method  comp rate     intro      body  conclusion   isthmus  \\\n",
            "0      SAM+WGAN   0.149470  0.515937  0.490201    0.486627  0.008073   \n",
            "1  BERT+LexRank   0.214943  0.235819  0.217356    0.203464  0.008570   \n",
            "2          BESM   0.200468  0.428422  0.409638    0.371101  0.010059   \n",
            "3   BESM+kobert   0.207353  0.465980  0.400830    0.401955  0.010924   \n",
            "\n",
            "   simlirality  grammarity  \n",
            "0     0.494276    0.959472  \n",
            "1     0.216881    0.998986  \n",
            "2     0.401834    0.987340  \n",
            "3     0.414197    0.986831  \n",
            "==================================================\n",
            "37 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "그것이 어느 집인지는 곧 알 수 있었다. 우리가 본 것은 한 사람이 살해된 곳을 아주 흥미롭게 보고 있는 여느 사람들의 무리였다. 가까이 다가감에 따라 확실히 그렇다는 것을 알 수 있었다. 블라인드를 내린 그을음 낀 듯한 구멍가게 앞에 젊은 순경이 애를 먹고 있는 듯한 얼굴로 서서 사람들에게 저리 가라고 딱딱하게 명령하고 있었다. 그는 동료의 도움을 받아 모여 있는 사라들을 해산시키기 시작했다. 꽤 많은 사람들이 불평스럽게 한숨을 쉬며 저마다 자기네 일로 돌아갔다. 그러나 곧 또 다른 사람들이 몰려와 살인 현장을 똑똑히 봐두려는 듯 그 자리를 다시 차지했다. 포아로는 사람들로부터 조금 떨어져 섰다. 그가 서 있는 곳에서는 문 위에 씌어진 글자를 똑똑히 볼 수 있었다. 포아로는 그것을 입속에서 되풀이했다. “A 애셔. 그렇지, 어쩌면……. ” 그는 말을 끊었다. “가세, 헤이스팅즈. 안으로 들어가 보세. ” 나는 기다리고 있던 바였다. 우리는 사람들을 헤치고 젊은 순경에게로 갔다. 포아로는 형사에게서 받아 둔 소개장을 내보였다. 순경은 머리를 끄덕이며 우리를 안으로 들여보내기 위해 문의 자물쇠를 열었다. 우리는 구경꾼들의 호기심에 찬 눈길을 받으며 안으로 들어갔다.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.3570408821105957 Generator / grammar loss:-0.13140229880809784   similarity loss:-0.09531152248382568\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            " 그것이 여느 일로 차지했다. 사람들로부터 조금 떨어져 있는 문 글자를 수 안으로 들어가 보세. 나는 젊은 포아로는 머리를 끄덕이며 들어갔다.\n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "블라인드를 내린 그을음 낀 듯한 구멍가게 앞에 젊은 순경이 애를 먹고 있는 듯한 얼굴로 서서 사람들에게 저리 가라고 딱딱하게 명령하고 있었다.그는 동료의 도움을 받아 모여 있는 사라들을 해산시키기 시작했다.” 그는 말을 끊었다.꽤 많은 사람들이 불평스럽게 한숨을 쉬며 저마다 자기네 일로 돌아갔다.포아로는 형사에게서 받아 둔 소개장을 내보였다.\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "우리가 본 것은 한 사람이 살해된 곳을 아주 흥미롭게 보고 있는 여느 사람들의 무리였다. 그러나 곧 또 다른 사람들이 몰려와 살인 현장을 똑똑히 봐두려는 듯 그 자리를 다시 차지했다. 순경은 머리를 끄덕이며 우리를 안으로 들여보내기 위해 문의 자물쇠를 열었다.\n",
            "--------------------------------------------------\n",
            "besm_bert summary:\n",
            "우리가 본 것은 한 사람이 살해된 곳을 아주 흥미롭게 보고 있는 여느 사람들의 무리였다. 블라인드를 내린 그을음 낀 듯한 구멍가게 앞에 젊은 순경이 애를 먹고 있는 듯한 얼굴로 서서 사람들에게 저리 가라고 딱딱하게 명령하고 있었다.그는 동료의 도움을 받아 모여 있는 사라들을 해산시키기 시작했다.\n",
            "--------------------------------------------------\n",
            "         method  comp ratio     intro      body    ending       var     total  \\\n",
            "0      SAM+WGAN    0.131012  0.308833  0.451638  0.516093  0.007501  0.442413   \n",
            "1  BERT+LexRank    0.318408  0.270088  0.264005  0.238005  0.000194  0.257421   \n",
            "2          BESM    0.240464  0.501167  0.309861  0.568391  0.011995  0.425681   \n",
            "3   BESM+kobert    0.273632  0.651751  0.294804  0.273852  0.030073  0.359908   \n",
            "\n",
            "    grammar  \n",
            "0  0.996228  \n",
            "1  0.999029  \n",
            "2  0.998992  \n",
            "3  0.999024  \n",
            "Current result ==================================================\n",
            "Sample count: 33\n",
            "         method  comp rate     intro      body  conclusion   isthmus  \\\n",
            "0      SAM+WGAN   0.148910  0.509661  0.489033    0.487520  0.008056   \n",
            "1  BERT+LexRank   0.218079  0.236858  0.218770    0.204511  0.008316   \n",
            "2          BESM   0.201680  0.430626  0.406615    0.377079  0.010118   \n",
            "3   BESM+kobert   0.209361  0.471610  0.397617    0.398073  0.011504   \n",
            "\n",
            "   simlirality  grammarity  \n",
            "0     0.492705    0.960586  \n",
            "1     0.218110    0.998988  \n",
            "2     0.402556    0.987693  \n",
            "3     0.412552    0.987200  \n",
            "==================================================\n",
            "38 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "블라인드가 내려져 있어 안은 어두웠다. 순경이 전등 스위치를 찾아내어 당겼다. 그러나 전구의 촉수가 낮아 안은 여전히 어두웠다. 나는 가게 안을 빙 둘러보았다. 지저분하고 좁은 곳으로 몇 권의 싸구려 잡지가 흩어져 있고 어제 신문에는 하루치 먼지가 쌓여 있었다. 계산대 뒤에는 천장까지 선반이 매어져 파이프 담배며 궐련 봉지가 놓여 있었다. 박하가 든 과자와 사탕병도 있었다. 흔해빠진 구멍가게로 다른 데에도 몇천 군데나 있는 그런 곳이었다. 순경은 느릿한 햄프셔 사투리로 상황을 설명했다. “거기 계산대 뒤에 웅크린 채 쓰러져 있었지요. 할머니는 자신이 습격당하는 것을 모르고 있었다고 의사 선생님이 말씀하셨습니다. 아마 선반으로 막 손을 내민 순간이었는지도 모르지요. ” “손에는 아무것도 없었소?” “없었습니다. 다만 곁에 <플레이어즈>꾸러미가 하나 떨어져 있었지요. ” 포아로는 고개를 끄덕였다. 그의 눈은 그 좁은 가게를 탐색하듯 둘러보았다. 아무것도 없다. “그런데 철도 안내서는 어디에?” “여기입니다. ” 순경은 계산대 위를 가리켰다. “바로 앤도버 있는 데가 펼쳐진 채 뒤집혀져 있었습니다.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.4079718589782715 Generator / grammar loss:-0.12458596378564835   similarity loss:-0.0832083523273468\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "어두웠다. 당겼다. 싸구려 흩어져 있고 쌓여 있었다. 그런 손을 없었소?” 가게를 둘러보았다. “그런데 순경은 계산대 가리켰다. 데가 \n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "순경이 전등 스위치를 찾아내어 당겼다.아무것도 없다.할머니는 자신이 습격당하는 것을 모르고 있었다고 의사 선생님이 말씀하셨습니다.박하가 든 과자와 사탕병도 있었다.\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "나는 가게 안을 빙 둘러보았다.지저분하고 좁은 곳으로 몇 권의 싸구려 잡지가 흩어져 있고 어제 신문에는 하루치 먼지가 쌓여 있었다. 계산대 뒤에는 천장까지 선반이 매어져 파이프 담배며 궐련 봉지가 놓여 있었다.\n",
            "--------------------------------------------------\n",
            "besm_bert summary:\n",
            "나는 가게 안을 빙 둘러보았다.지저분하고 좁은 곳으로 몇 권의 싸구려 잡지가 흩어져 있고 어제 신문에는 하루치 먼지가 쌓여 있었다. 할머니는 자신이 습격당하는 것을 모르고 있었다고 의사 선생님이 말씀하셨습니다.\n",
            "--------------------------------------------------\n",
            "         method  comp ratio     intro      body    ending       var     total  \\\n",
            "0      SAM+WGAN    0.133215  0.534286  0.432847  0.577605  0.003680  0.496562   \n",
            "1  BERT+LexRank    0.161634  0.202199  0.287148  0.060252  0.008761  0.202089   \n",
            "2          BESM    0.207815  0.307616  0.461808  0.222294  0.009825  0.359116   \n",
            "3   BESM+kobert    0.207815  0.307278  0.487159  0.195944  0.014395  0.363819   \n",
            "\n",
            "    grammar  \n",
            "0  0.963372  \n",
            "1  0.998985  \n",
            "2  0.999000  \n",
            "3  0.999002  \n",
            "Current result ==================================================\n",
            "Sample count: 34\n",
            "         method  comp rate     intro      body  conclusion   isthmus  \\\n",
            "0      SAM+WGAN   0.148449  0.510385  0.487380    0.490170  0.007927   \n",
            "1  BERT+LexRank   0.216418  0.235838  0.220781    0.200268  0.008329   \n",
            "2          BESM   0.201861  0.427008  0.408238    0.372527  0.010109   \n",
            "3   BESM+kobert   0.209316  0.466776  0.400250    0.392128  0.011589   \n",
            "\n",
            "   simlirality  grammarity  \n",
            "0     0.492818    0.960668  \n",
            "1     0.217639    0.998988  \n",
            "2     0.401279    0.988025  \n",
            "3     0.411119    0.987548  \n",
            "==================================================\n",
            "39 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "런던 행 기차를 보고 있었던 것 같습니다. 그렇다면 그는 앤도버 사람이 아닙니다. 그러나 물론 철도 안내서는 살인과 관계없는 다른 사람이 잃어버리고 간 거라고 생각할 수도 있습니다. ” 내가 물어 보았다. “지문은?” 순경은 머리를 저었다. “곧바로 모두 조사해 보았지만 없었지요. ” 포아로가 물었다. “계산대에도?” “굉장히 많았습니다. 모두 함께 뒤섞여 뒤죽박죽되어 있었지요. ” “그 속에 애셔의 지문은?” “아직 알 수 없습니다. ” 포아로는 고개를 끄덕이고 나서 죽은 사람이 가게 안에서 살고 있었느냐고 물었다. “그렇습니다. 안쪽 문을 지나면 그곳으로 들어가게 됩니다. 함께 가드렸으면 좋겠습니다만, 저는 여기 있지 않으면 안 돼서……. ” 포아로는 문을 열고 들어갔다. 나도 그 뒤를 따라갔다. 가게 안은 부엌 딸린 조그만 거실로 되어 있었다. 그곳은 깨끗하게 정리되어 있었지만 음침한 느낌이 들었으며 가구도 거의 없었다. 벽난로 위에 사진이 몇 장 있었다. 내가 다가가서 들여다보자 포아로도 옆으로 왔다.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.5124011039733887 Generator / grammar loss:-0.12660890817642212   similarity loss:-0.07420135289430618\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "런던 보고 있었던 안내서는 살인과 관계없는 수도 물어 보았다. 포아로가 모두 고개를 끄덕이고 안에서 살고 “그렇습니다. 들어가게 됩니다.\n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "런던 행 기차를 보고 있었던 것 같습니다.가게 안은 부엌 딸린 조그만 거실로 되어 있었다.” 내가 물어 보았다.“지문은?” 순경은 머리를 저었다.그러나 물론 철도 안내서는 살인과 관계없는 다른 사람이 잃어버리고 간 거라고 생각할 수도 있습니다.\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "그러나 물론 철도 안내서는 살인과 관계없는 다른 사람이 잃어버리고 간 거라고 생각할 수도 있습니다. ” 포아로는 고개를 끄덕이고 나서 죽은 사람이 가게 안에서 살고 있었느냐고 물었다. “\n",
            "--------------------------------------------------\n",
            "besm_bert summary:\n",
            "그러나 물론 철도 안내서는 살인과 관계없는 다른 사람이 잃어버리고 간 거라고 생각할 수도 있습니다. ” 그곳은 깨끗하게 정리되어 있었지만 음침한 느낌이 들었으며 가구도 거의 없었다.\n",
            "--------------------------------------------------\n",
            "         method  comp ratio     intro      body    ending       var     total  \\\n",
            "0      SAM+WGAN    0.147573  0.433823  0.411196  0.467225  0.000530  0.432530   \n",
            "1  BERT+LexRank    0.264078  0.333706  0.208885  0.194017  0.003924  0.229389   \n",
            "2          BESM    0.201942  0.595372  0.466505  0.365759  0.008831  0.462054   \n",
            "3   BESM+kobert    0.196117  0.467602  0.265198  0.356111  0.006851  0.332953   \n",
            "\n",
            "    grammar  \n",
            "0  0.994861  \n",
            "1  0.998922  \n",
            "2  0.988796  \n",
            "3  0.999009  \n",
            "Current result ==================================================\n",
            "Sample count: 35\n",
            "         method  comp rate     intro      body  conclusion   isthmus  \\\n",
            "0      SAM+WGAN   0.148424  0.508198  0.485204    0.489514  0.007716   \n",
            "1  BERT+LexRank   0.217780  0.238635  0.220441    0.200089  0.008203   \n",
            "2          BESM   0.201863  0.431819  0.409903    0.372333  0.010073   \n",
            "3   BESM+kobert   0.208939  0.466800  0.396392    0.391099  0.011454   \n",
            "\n",
            "   simlirality  grammarity  \n",
            "0     0.491096    0.961645  \n",
            "1     0.217974    0.998986  \n",
            "2     0.403015    0.988047  \n",
            "3     0.408885    0.987875  \n",
            "==================================================\n",
            "40 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "사진은 모두 세 장이었다. 한 장은 오늘 오후에 만난 아가씨 메리 드로워의 싸구려 사진이었다. 그녀는 가장 좋은 옷을 입고 얼굴에 부자연스러운 미소를 떠올리고 있었다. 포즈를 취한 이런 사진은 표정을 엉망으로 만들기 때문에 스냅 사진 쪽이 훨씬 좋다. 두 번째 것은 더 고급스러운 것으로, 꽤 나이든 머리가 희끗희끗한 부인을 기교적으로 흐릿하게 찍은 사진이었다. 털목도리를 두르고 있었다. 나는 아마도 미스 로즈일 거라고 생각했다. 즉 애셔 부인에게 장사를 시작할 수 있도록 돈을 물려준 사람이다. 세 번째 사진은 아주 오래된 것으로 누렇게 빛이 바래 있었다. 얼마쯤 구식으로 보이는 것으로 팔짱낀 젊은 남녀가 찍혀있었다. 남자는 단춧구멍에 꽃을 꽂고 있으며, 전체적으로 고풍스러움이 느껴지는 딱딱한 사진이었다. 포아로가 말했다. “아마도 결혼 기념사진인 모양이군. 보게, 헤이스팅즈. 그녀는 아름다웠을 거라고 내가 말했잖나. ” 그 말대로였다. 시대에 뒤떨어진 머리 모양과 기묘한 옷 때문에 좀 이상해 보이긴 했지만 이목구비가 또렷하고 반듯한 아가씨의 아름다움은 의심할 바가 없었다. 나는 옆에 있는 다른 한 인물을 자세히 보았는데, 이 군인 같은 모습의 말쑥한 젊은이가 그 초라한 애셔였다고는 도저히 생각되지 않았다. 나는 그 곁눈질을 하는 주정꾼 노인과 피로에 지친 얼굴의 죽은 노파를 생각해 내고 세월의 무자비함에 몸을 떨었다. 그 거실로부터 2층의 두 방으로 층계가 이어져 있었다.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.43034291267395 Generator / grammar loss:-0.13516995310783386   similarity loss:-0.09145242720842361\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            " 사진은 세 오늘 오후에 만난 아가씨 메리 싸구려 사진이었다. 미소를 떠올리고 좋다. 더 나이든 희끗희끗한 사진이었다. 남자는 단춧구멍에 전체적으로 고풍스러움이 아름다웠을 내가 말대로였다. 기묘한 무자비함에 떨었다.\n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "그 거실로부터 2층의 두 방으로 층계가 이어져 있었다.사진은 모두 세 장이었다.” 그 말대로였다.포아로가 말했다.\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "포즈를 취한 이런 사진은 표정을 엉망으로 만들기 때문에 스냅 사진 쪽이 훨씬 좋다. 시대에 뒤떨어진 머리 모양과 기묘한 옷 때문에 좀 이상해 보이긴 했지만 이목구비가 또렷하고 반듯한 아가씨의 아름다움은 의심할 바가 없었다.\n",
            "--------------------------------------------------\n",
            "besm_bert summary:\n",
            "포즈를 취한 이런 사진은 표정을 엉망으로 만들기 때문에 스냅 사진 쪽이 훨씬 좋다. 두 번째 것은 더 고급스러운 것으로, 꽤 나이든 머리가 희끗희끗한 부인을 기교적으로 흐릿하게 찍은 사진이었다.\n",
            "--------------------------------------------------\n",
            "         method  comp ratio     intro      body    ending       var     total  \\\n",
            "0      SAM+WGAN    0.166205  0.637122  0.418359  0.457801  0.009063  0.473944   \n",
            "1  BERT+LexRank    0.087258  0.262255  0.138299  0.214380  0.002605  0.185915   \n",
            "2          BESM    0.171745  0.518924  0.290211  0.420207  0.008773  0.374953   \n",
            "3   BESM+kobert    0.149584  0.467219  0.341312  0.382018  0.002752  0.378705   \n",
            "\n",
            "    grammar  \n",
            "0  0.979253  \n",
            "1  0.998698  \n",
            "2  0.998993  \n",
            "3  0.998996  \n",
            "Current result ==================================================\n",
            "Sample count: 36\n",
            "         method  comp rate     intro      body  conclusion   isthmus  \\\n",
            "0      SAM+WGAN   0.148918  0.511779  0.483347    0.488633  0.007753   \n",
            "1  BERT+LexRank   0.214155  0.239291  0.218159    0.200486  0.008048   \n",
            "2          BESM   0.201026  0.434238  0.406578    0.373663  0.010037   \n",
            "3   BESM+kobert   0.207290  0.466812  0.394862    0.390846  0.011212   \n",
            "\n",
            "   simlirality  grammarity  \n",
            "0     0.490619    0.962134  \n",
            "1     0.217084    0.998978  \n",
            "2     0.402236    0.988351  \n",
            "3     0.408047    0.988184  \n",
            "==================================================\n",
            "41 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "하나는 빈방으로 가구도 없고, 다른 하나는 죽은 노파의 침실이었다. 경찰이 조사한 뒤여서 그 흔적이 그대로 있었다. 침대에는 털이 빠진 낡은 담요가 두 장 있었다. 한 서랍에는 알뜰히 기워진 속옷 몇 벌, 또 한 서랍에는 요리책 종류, ≪녹색의 오아시스≫라는 제목의 표지가 달린 책, 번쩍거리는 싸구려 새 양말 한 컬레?그것은 번쩍거리는 싸구려였다?사기 그릇 장식 한 쌍?드레스덴 도자기로 된 깨어진 양치기며 파랑과 노랑점이 있는 개?나무못에 걸린 검은 레인코트와 털 자켓. 이러한 것들이 죽은 애셔 부인이 이 세상에 남긴 재산이었다. 무언가 개인적인 메모 같은 게 있었다 해도 경찰이 가져가 버렸을 것이다. 포아로가 중얼거렸다. “가엾게도. 자, 헤이스팅즈, 여기에는 이제 아무것도 없네. ” 다른 길로 나서자 그는 잠시 망설이더니 길을 건넜다. 바로 애셔 부인의 가게 맞은편에 야채 가게가 있었다. 안에 있는 물건보다 밖에 내놓은 물건이 더 많은 그런 종류의 가게였다. 포아로는 낮은 소리로 내게 몇 마디 일러두고 혼자 가게에 들어갔다. 나는 잠시 뒤 따라 들어갔다. 그는 막 상추를 사고 있는 중이었다. 나는 딸기를 1파운드 샀다. 포아로는 물건을 싸주는 뚱뚱한 아주머니와 큰소리로 이야기하고 있었다. “그 살인 사건이 일어난 곳이 바로 댁 맞은편이었군요. 이런 끔찍한 일이 있나. 얼마나 놀랐겠습니까!” 그 뚱뚱한 여자는 살인 사건 이야기에는 이제 질린 것 같았다.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.4976115226745605 Generator / grammar loss:-0.13872742652893066   similarity loss:-0.08789955824613571\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            " 하나는 가구도 흔적이 있었다. 속옷 한 서랍에는 오아시스≫라는 양말 컬레?그것은 장식 깨어진 양치기며 털 것들이 죽은 애셔 부인이 이 같은 게 중얼거렸다. 혼자 싸주는 뚱뚱한 여자는\n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "나는 딸기를 1파운드 샀다.이런 끔찍한 일이 있나.안에 있는 물건보다 밖에 내놓은 물건이 더 많은 그런 종류의 가게였다.침대에는 털이 빠진 낡은 담요가 두 장 있었다.\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "한 서랍에는 알뜰히 기워진 속옷 몇 벌, 또 한 서랍에는 요리책 종류, ≪녹색의 오아시스≫라는 제목의 표지가 달린 책, 번쩍거리는 싸구려 새 양말 한 컬레?그것은 번쩍거리는 싸구려였다?사기 그릇 장식 한 쌍?드레스덴 도자기로 된 깨어진 양치기며 파랑과 노랑점이 있는 개?나무못에 걸린 검은 레인코트와 털 자켓.이러한 것들이 죽은 애셔 부인이 이 세상에 남긴 재산이었다.\n",
            "--------------------------------------------------\n",
            "besm_bert summary:\n",
            "한 서랍에는 알뜰히 기워진 속옷 몇 벌, 또 한 서랍에는 요리책 종류, ≪녹색의 오아시스≫라는 제목의 표지가 달린 책, 번쩍거리는 싸구려 새 양말 한 컬레?그것은 번쩍거리는 싸구려였다?사기 그릇 장식 한 쌍?드레스덴 도자기로 된 깨어진 양치기며 파랑과 노랑점이 있는 개?나무못에 걸린 검은 레인코트와 털 자켓.이러한 것들이 죽은 애셔 부인이 이 세상에 남긴 재산이었다.\n",
            "--------------------------------------------------\n",
            "         method  comp ratio     intro      body    ending       var     total  \\\n",
            "0      SAM+WGAN    0.143258  0.516542  0.291644  0.334674  0.009501  0.349532   \n",
            "1  BERT+LexRank    0.130618  0.294117  0.137771  0.289008  0.005260  0.214411   \n",
            "2          BESM    0.289326  0.388312  0.167909  0.161514  0.011117  0.210071   \n",
            "3   BESM+kobert    0.289326  0.388312  0.167909  0.161514  0.011117  0.210071   \n",
            "\n",
            "    grammar  \n",
            "0  0.972124  \n",
            "1  0.999020  \n",
            "2  0.998947  \n",
            "3  0.998947  \n",
            "Current result ==================================================\n",
            "Sample count: 37\n",
            "         method  comp rate     intro      body  conclusion   isthmus  \\\n",
            "0      SAM+WGAN   0.148765  0.511908  0.478166    0.484472  0.007801   \n",
            "1  BERT+LexRank   0.211897  0.240773  0.215987    0.202879  0.007973   \n",
            "2          BESM   0.203413  0.432997  0.400127    0.367929  0.010066   \n",
            "3   BESM+kobert   0.209507  0.464690  0.388728    0.384648  0.011209   \n",
            "\n",
            "   simlirality  grammarity  \n",
            "0     0.486806    0.962404  \n",
            "1     0.217011    0.998979  \n",
            "2     0.397042    0.988638  \n",
            "3     0.402696    0.988475  \n",
            "==================================================\n",
            "42 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "그날은 그녀에게 있어 너무 길었던 모양이다. “이 법석거리는 구경꾼들을 어떻게 좀 할 수 없을까요? 대체 무엇을 그렇게 보는 것일까요?” 포아로가 말했다. “어젯밤에는 꽤 달랐을 테지요?아주머니는 범인이 가게로 들어가는 걸 보시지 못했습니까? 키가 큰 훌륭한 남자로 수염이 있었다지요? 러시아인이라든가 뭐 그렇다는 이야기던데요?” 여자가 날카롭게 돌아보았다. “뭐라고요? 러시아인이 했다고요?” “경찰이 체포했다던데요. ” “정말이에요?” 여자는 흥분해서 입이 가벼워졌다. “외국 사람인가요?” “그렇습니다. 나는 틀림없이 아주머니가 어젯밤 그 남자를 본 줄 알았지요. ” “아니, 그럴 기회가 없었어요. 그래요, 저녁 무렵의 한창 바쁜 때여서 일을 끝내고 돌아가는 사람들이 많이 비나가니까요. 키가 크고 수염이 난 훌륭한 남자라니……아니에요. 그런 사람이 이 언저리에 있었다고는 생각되지 않는데요. ” 그래서 내가 대사를 받았다. 나는 포아로에게 말했다. “실례지만, 당신이 잘못 들은 게 아닙니까? 키가 작고 얼굴빛이 검은 남자라고 나는 들었습니다만.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.204296350479126 Generator / grammar loss:-0.10772813856601715   similarity loss:-0.087227001786232\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            " 그날은 그녀에게 너무 법석거리는 말했다. 보시지 큰 수염이 러시아인이라든가 날카롭게 가벼워졌다. 나는 줄 “아니, 나는 아닙니까? \n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "러시아인이 했다고요?” “경찰이 체포했다던데요.그래요, 저녁 무렵의 한창 바쁜 때여서 일을 끝내고 돌아가는 사람들이 많이 비나가니까요.키가 크고 수염이 난 훌륭한 남자라니……아니에요.키가 큰 훌륭한 남자로 수염이 있었다지요?나는 틀림없이 아주머니가 어젯밤 그 남자를 본 줄 알았지요.\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "어젯밤에는 꽤 달랐을 테지요?아주머니는 범인이 가게로 들어가는 걸 보시지 못했습니까? 그래요, 저녁 무렵의 한창 바쁜 때여서 일을 끝내고 돌아가는 사람들이 많이 비나가니까요.키가 크고 수염이 난 훌륭한 남자라니……아니에요.\n",
            "--------------------------------------------------\n",
            "besm_bert summary:\n",
            "어젯밤에는 꽤 달랐을 테지요?아주머니는 범인이 가게로 들어가는 걸 보시지 못했습니까? 그래요, 저녁 무렵의 한창 바쁜 때여서 일을 끝내고 돌아가는 사람들이 많이 비나가니까요.키가 크고 수염이 난 훌륭한 남자라니……아니에요.\n",
            "--------------------------------------------------\n",
            "         method  comp ratio     intro      body    ending       var     total  \\\n",
            "0      SAM+WGAN    0.138318  0.580874  0.411272  0.486619  0.004814  0.467796   \n",
            "1  BERT+LexRank    0.295327  0.138646  0.280979  0.106737  0.005737  0.200240   \n",
            "2          BESM    0.231776  0.328760  0.385354  0.227985  0.004236  0.326825   \n",
            "3   BESM+kobert    0.231776  0.328760  0.385354  0.227985  0.004236  0.326825   \n",
            "\n",
            "    grammar  \n",
            "0  0.955407  \n",
            "1  0.998629  \n",
            "2  0.998984  \n",
            "3  0.998984  \n",
            "Current result ==================================================\n",
            "Sample count: 38\n",
            "         method  comp rate     intro      body  conclusion   isthmus  \\\n",
            "0      SAM+WGAN   0.148490  0.513723  0.476405    0.484529  0.007722   \n",
            "1  BERT+LexRank   0.214092  0.238085  0.217697    0.200348  0.007914   \n",
            "2          BESM   0.204159  0.430254  0.399739    0.364247  0.009913   \n",
            "3   BESM+kobert   0.210093  0.461113  0.388639    0.380526  0.011026   \n",
            "\n",
            "   simlirality  grammarity  \n",
            "0     0.486306    0.962220  \n",
            "1     0.216570    0.998970  \n",
            "2     0.395194    0.988910  \n",
            "3     0.400700    0.988751  \n",
            "==================================================\n",
            "43 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "” 그리하여 이 뚱뚱한 여자에다 여윈 남편과 쇳소리 내는 심부름꾼 아이까지 합쳐 재미있는 토론이 시작되었다. 키 작은 검은 얼굴의 남자가 네 사람이나 목격된 이야기가 나오고, 쇳소리 내는 심부름꾼 아이는 키가 큰 훌륭한 남자를 보았지만 그에게는 수염이 없었다고 유감스러운 듯 덧붙였다. 겨우 쇼핑이 끝나 우리는 거짓말을 한 채 그대로 가게를 나왔다. 나는 얼마쯤 비난을 섞어 물었다. “대체 그건 무슨 연극이었나, 포아로?” “나는 다만 낯선 사람이 저쪽 가게로 들어갔는지 어떤지 듣고 싶었던 것뿐일세. ” “그럼, 그렇게 물어보면 되잖나, 그런 엉터리 같은 소리 하지 말고. ” “아니, 자네가 말하는 것처럼 그냥 물어 보아서는 아무 대답도 얻을 수 없다네. 자네는 자신도 영국 사람이면서, 그냥 물어보는 질문에 반발하는 게 영국 사람의 기질이라는 걸 모르고 있는 모양이군. 그것은 반드시 의심하는 마음을 불러일으켜 결과는 완강한 침묵으로 끝난다네. 이 사람들에게 뭘 물어보게나, 그들은 조가비처럼 입을 다물어 버리지. 그렇지만 이상하고 터무니없는 어떤 말을 한 가지 꺼내 거기서 자네가 반대되는 말이라도 해보이면, 금방 이야기가 풀려나온다네. 그런 방법으로 우리는 문제의 시각이 바쁜 때였다는 것, 그래서 누구나 자기 일 말고는 신경 쓸 수 없으며 많은 사람이 길을 지나가고 있었던 때임을 알게 된 거야. 우리의 살인범은 좋은 시간을 택했다는 말이 되네, 헤이스팅즈. ” 그는 말을 끊었다. 그리고는 엄격하게 나무라는 듯한 말투로 덧붙였다. “자네는 상식이라는 걸 갖고 있지 않는 것 같군, 헤이스팅즈. 무엇이든 사라고 했더니 하필이면 딸기를 고르다니! 보게, 벌써 포장지에서 물이 배어 나와 그 좋은 옷을 버리게 하고 있잖나. ” 정말 그의 말대로였으므로 나는 좀 당황했다. 나는 급히 한 아이에게 딸기를 줘버렸다.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:1.9103740453720093 Generator / grammar loss:-0.08959800750017166   similarity loss:-0.09856661409139633\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "그리하여 쇳소리 아이까지 재미있는 검은 얼굴의 쇳소리 아이는 키가 남자를 보았지만 그에게는 없었다고 덧붙였다. 겨우 그건 포아로?” “나는 낯선 들어갔는지 싶었던 엉터리 하지 아무 사람이면서, 반발하는 게 결과는 침묵으로 끝난다네. 버리지. 한 쓸\n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "무엇이든 사라고 했더니 하필이면 딸기를 고르다니!우리의 살인범은 좋은 시간을 택했다는 말이 되네, 헤이스팅즈.” 그리하여 이 뚱뚱한 여자에다 여윈 남편과 쇳소리 내는 심부름꾼 아이까지 합쳐 재미있는 토론이 시작되었다.그런 방법으로 우리는 문제의 시각이 바쁜 때였다는 것, 그래서 누구나 자기 일 말고는 신경 쓸 수 없으며 많은 사람이 길을 지나가고 있었던 때임을 알게 된 거야.\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "” 그리하여 이 뚱뚱한 여자에다 여윈 남편과 쇳소리 내는 심부름꾼 아이까지 합쳐 재미있는 토론이 시작되었다. 키 작은 검은 얼굴의 남자가 네 사람이나 목격된 이야기가 나오고, 쇳소리 내는 심부름꾼 아이는 키가 큰 훌륭한 남자를 보았지만 그에게는 수염이 없었다고 유감스러운 듯 덧붙였다. 그럼, 그렇게 물어보면 되잖나, 그런 엉터리 같은 소리 하지 말고. ” “\n",
            "--------------------------------------------------\n",
            "besm_bert summary:\n",
            "” 그리하여 이 뚱뚱한 여자에다 여윈 남편과 쇳소리 내는 심부름꾼 아이까지 합쳐 재미있는 토론이 시작되었다. 아니, 자네가 말하는 것처럼 그냥 물어 보아서는 아무 대답도 얻을 수 없다네. 그런 방법으로 우리는 문제의 시각이 바쁜 때였다는 것, 그래서 누구나 자기 일 말고는 신경 쓸 수 없으며 많은 사람이 길을 지나가고 있었던 때임을 알게 된 거야.\n",
            "--------------------------------------------------\n",
            "         method  comp ratio     intro      body    ending       var     total  \\\n",
            "0      SAM+WGAN    0.152150  0.494548  0.559310  0.362788  0.006686  0.487401   \n",
            "1  BERT+LexRank    0.232635  0.411492  0.238185  0.330130  0.005012  0.300430   \n",
            "2          BESM    0.221610  0.711161  0.450046  0.371778  0.021054  0.478789   \n",
            "3   BESM+kobert    0.214994  0.522187  0.535943  0.275813  0.014284  0.455153   \n",
            "\n",
            "    grammar  \n",
            "0  0.818964  \n",
            "1  0.999032  \n",
            "2  0.996828  \n",
            "3  0.999026  \n",
            "Current result ==================================================\n",
            "Sample count: 39\n",
            "         method  comp rate     intro      body  conclusion   isthmus  \\\n",
            "0      SAM+WGAN   0.148584  0.513231  0.478531    0.481407  0.007695   \n",
            "1  BERT+LexRank   0.214568  0.242531  0.218222    0.203676  0.007839   \n",
            "2          BESM   0.204607  0.437457  0.401029    0.364440  0.010198   \n",
            "3   BESM+kobert   0.210219  0.462679  0.392416    0.377841  0.011110   \n",
            "\n",
            "   simlirality  grammarity  \n",
            "0     0.486334    0.958547  \n",
            "1     0.218720    0.998971  \n",
            "2     0.397338    0.989113  \n",
            "3     0.402096    0.989015  \n",
            "==================================================\n",
            "44 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "그 아이는 깜짝 놀라 좀 경계하는 빛이 되었다. 포아로도 상추를 주자 아이는 완전히 당황한 모양이었다. 포아로는 설교를 계속했다. “허름한 야채 가게에서는 딸기 같은걸 사면 안돼. 딸기란 막 따온 게 아니면 물이 배어 나오지. 바나나, 사과, 양배추, 이런 것들이라면 그래도 좀 낫지만, 딸기는 안 되네. ” 나는 변명하듯 말했다. “막 들어서자 생각이 났으니 어쩌나. ” 포아로는 엄숙하게 대답했다. “그건 자네 상상력이 모자라기 때문일세,” 그는 보도에서 걸음을 멈췄다. 애셔 부인 가게 오른쪽에 있는 집 딸린 가게는 비어 있었다. 창에 <세놓음>이라고 씌어 있었다. 반대쪽 옆집에는 때낀 모슬린 커튼이 내려져 있었다. 포아로는 그 집 쪽으로 걸어갔는데 벨이 없어서 노커를 힘차게 몇 번이나 두드렸다. 한참 있다가 코를 훌쩍거리는 지저분한 아이가 문을 열었다. 포아로가 말했다. “안녕, 어머니 계시니?” “네?” 아이는 불쾌하고 의심스럽게 우리를 보았다. 포아로가 말했다. “네 어머니 말이야. ” 아이는 이 말을 알아듣는 데 5분의 1분쯤 걸렸다.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.423219919204712 Generator / grammar loss:-0.11804119497537613   similarity loss:-0.07506996393203735\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "그래도 ” 말했다. 들어서자 생각이 났으니 어쩌나. 대답했다. “그건 보도에서 걸음을 멈췄다. 오른쪽에 비어 씌어 있었다. 포아로가 걸렸다.\n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "바나나, 사과, 양배추, 이런 것들이라면 그래도 좀 낫지만, 딸기는 안 되네.“허름한 야채 가게에서는 딸기 같은걸 사면 안돼.딸기란 막 따온 게 아니면 물이 배어 나오지.반대쪽 옆집에는 때낀 모슬린 커튼이 내려져 있었다.포아로는 설교를 계속했다.\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "허름한 야채 가게에서는 딸기 같은걸 사면 안돼.딸기란 막 따온 게 아니면 물이 배어 나오지. 바나나, 사과, 양배추, 이런 것들이라면 그래도 좀 낫지만, 딸기는 안 되네. ”\n",
            "--------------------------------------------------\n",
            "besm_bert summary:\n",
            "허름한 야채 가게에서는 딸기 같은걸 사면 안돼.딸기란 막 따온 게 아니면 물이 배어 나오지. 바나나, 사과, 양배추, 이런 것들이라면 그래도 좀 낫지만, 딸기는 안 되네. ”\n",
            "--------------------------------------------------\n",
            "         method  comp ratio     intro      body    ending       var     total  \\\n",
            "0      SAM+WGAN    0.146067  0.279582  0.449567  0.480700  0.007813  0.424910   \n",
            "1  BERT+LexRank    0.256554  0.350203  0.261164  0.065087  0.014185  0.220149   \n",
            "2          BESM    0.181648  0.471039  0.438160  0.461920  0.000192  0.451863   \n",
            "3   BESM+kobert    0.181648  0.471039  0.438160  0.461920  0.000192  0.451863   \n",
            "\n",
            "    grammar  \n",
            "0  0.968446  \n",
            "1  0.999036  \n",
            "2  0.995608  \n",
            "3  0.995608  \n",
            "Current result ==================================================\n",
            "Sample count: 40\n",
            "         method  comp rate     intro      body  conclusion   isthmus  \\\n",
            "0      SAM+WGAN   0.148521  0.507390  0.477807    0.481390  0.007698   \n",
            "1  BERT+LexRank   0.215617  0.245223  0.219296    0.200211  0.007998   \n",
            "2          BESM   0.204033  0.438296  0.401957    0.366877  0.009948   \n",
            "3   BESM+kobert   0.209505  0.462888  0.393560    0.379943  0.010837   \n",
            "\n",
            "   simlirality  grammarity  \n",
            "0     0.484798    0.958794  \n",
            "1     0.218756    0.998973  \n",
            "2     0.398701    0.989275  \n",
            "3     0.403340    0.989180  \n",
            "==================================================\n",
            "45 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "이윽고 아이는 층계 쪽을 향해 소리쳤다. “엄마, 손님. ” 그리고는 어두컴컴한 안쪽으로 들어가 버렸다. 딱딱한 얼굴을 한 여자가 난간 너머로 내려다보고 나서 층계를 내려왔다. “시간 낭비예요. ” 여자가 말을 시작했으나, 포아로가 가로막았다. 그는 모자를 벗고 정중하게 인사했다. “안녕하십니까, 아주머니. 저는 <이브닝 프리커>의 기자인데 살해된 이웃집의 애셔 부인에 대해 기사가 될 만한 것을 얻으러 왔습니다. 사례금으로 5파운드 드리지요. ” 화난 목소리를 억누르고 여자는 머리를 쓰다듬고 치마를 잡아당기며 층계를 내려왔다. “자, 안으로 들어오세요. 이쪽으로. 어서 앉으세요. ” 그 조그만 방은 커다란 모조 자코비언 식 가구로 어수선하여 우리는 가까스로 안으로 들어가 딱딱한 긴 의자에 앉았다. 여자는 이야기하기 시작했다. “죄송해요. 조금 전에 그런 실례되는 말을 드려서요. 그렇지만 우리가 얼마나 성가신 꼴을 당하고 있는지 도저히 모르실 거예요. 아무튼 여러 사람들이 진공청소기니 양말이니 향로 주머니니 뭐니 온갖 잡동사니들을 팔러 온답니다.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.4729421138763428 Generator / grammar loss:-0.13059203326702118   similarity loss:-0.08238545805215836\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "층계 그리고는 낭비예요. ” “안녕하십니까, 애셔 대해 얻으러 5파운드 ” 목소리를 억누르고 쓰다듬고 잡아당기며 내려왔다. 어서 조그만 앉았다.\n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "저는 <이브닝 프리커>의 기자인데 살해된 이웃집의 애셔 부인에 대해 기사가 될 만한 것을 얻으러 왔습니다.아무튼 여러 사람들이 진공청소기니 양말이니 향로 주머니니 뭐니 온갖 잡동사니들을 팔러 온답니다.사례금으로 5파운드 드리지요.이쪽으로.\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "저는 <이브닝 프리커>의 기자인데 살해된 이웃집의 애셔 부인에 대해 기사가 될 만한 것을 얻으러 왔습니다. 화난 목소리를 억누르고 여자는 머리를 쓰다듬고 치마를 잡아당기며 층계를 내려왔다. “ 아무튼 여러 사람들이 진공청소기니 양말이니 향로 주머니니 뭐니 온갖 잡동사니들을 팔러 온답니다.\n",
            "--------------------------------------------------\n",
            "besm_bert summary:\n",
            "저는 <이브닝 프리커>의 기자인데 살해된 이웃집의 애셔 부인에 대해 기사가 될 만한 것을 얻으러 왔습니다. 그 조그만 방은 커다란 모조 자코비언 식 가구로 어수선하여 우리는 가까스로 안으로 들어가 딱딱한 긴 의자에 앉았다.\n",
            "--------------------------------------------------\n",
            "         method  comp ratio     intro      body    ending       var     total  \\\n",
            "0      SAM+WGAN    0.149533  0.354941  0.446191  0.393614  0.001399  0.412168   \n",
            "1  BERT+LexRank    0.248598  0.168332  0.156425  0.212848  0.000590  0.175733   \n",
            "2          BESM    0.300935  0.484552  0.366142  0.422842  0.002338  0.406834   \n",
            "3   BESM+kobert    0.231776  0.265177  0.345478  0.332145  0.001235  0.325418   \n",
            "\n",
            "    grammar  \n",
            "0  0.968176  \n",
            "1  0.999020  \n",
            "2  0.998984  \n",
            "3  0.999021  \n",
            "Current result ==================================================\n",
            "Sample count: 41\n",
            "         method  comp rate     intro      body  conclusion   isthmus  \\\n",
            "0      SAM+WGAN   0.148545  0.503671  0.477036    0.479249  0.007545   \n",
            "1  BERT+LexRank   0.216422  0.243348  0.217763    0.200520  0.007817   \n",
            "2          BESM   0.206396  0.439424  0.401083    0.368242  0.009762   \n",
            "3   BESM+kobert   0.210048  0.458066  0.392387    0.378777  0.010602   \n",
            "\n",
            "   simlirality  grammarity  \n",
            "0     0.483027    0.959023  \n",
            "1     0.217707    0.998974  \n",
            "2     0.398899    0.989512  \n",
            "3     0.401440    0.989420  \n",
            "==================================================\n",
            "46 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "그들은 정말 말솜씨가 좋고 점잖게 보이지요. 이름도 한 번 들으면 금방 외워서 이쪽은 파울러 부인이고, 저쪽은 누구라느니 하며 말예요. ” 재치있게 그 이름을 잡아서 포아로가 말했다. “갑작스러운 이야기입니다만, 파울러 부인, 우리가 부탁드린 일을 들어주시겠습니까?” “글쎄요. ” 그러나 이미 5파운드가 파울러 부인의 눈앞에 유혹하듯 어른거리고 있다. “애셔 부인은 알고 있지만, 글로 쓰는 일이고 보면. ” 포아로는 얼른 안심시키듯 그녀 쪽에서는 아무것도 하지 않아도 되며, 그녀로부터 사실 이야기를 들은 다음 기사는 자기 쪽에서 쓴다고 이야기해 주었다. 이에 용기를 얻어 파울러 부인은 자진해서 기억이며 억측이며 소문 따위를 이것저것 이야기해 주었다. 애셔 부인은 사람들을 멀리하며 살았다. 이웃과 어울리는 일이 거의 없었고, 그 가엾은 d자에게는 여러 가지 근심거리가 있었다. 그것은 누구나 모두 잘 알고 있는 일이었다. 프란츠 애셔는 벌써 형무소에 처넣어야 마땅할 그런 남자였다. 그러나 애셔 부인이 그를 무서워하고 있었던 건 아니다. 그녀가 화를 내면 굉장했다. 그리고 언제나 솜씨 있게 잘 응수해 왔다. 하지만 그런 일이 일어나다니……. 즉 일이 되어갈 데까지 가버린 것이다. 파울러 부인은 몇 번이고 되풀이 그녀에게 이야기했었다. “그 남자는 언젠가 당신에게 무서운 짓을 할 거예요. 내 말을 잘 기억해 둬요.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.1934783458709717 Generator / grammar loss:-0.13267643749713898   similarity loss:-0.11326789855957031\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "이쪽은 일이고 사실 이것저것 그 애셔는 부인이 아니다. 그녀가 내면 굉장했다. 그리고 잘 응수해 왔다. 즉 일이 파울러 부인은 몇 번이고 그녀에게 짓을 둬요.\n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "프란츠 애셔는 벌써 형무소에 처넣어야 마땅할 그런 남자였다.이웃과 어울리는 일이 거의 없었고, 그 가엾은 d자에게는 여러 가지 근심거리가 있었다.애셔 부인은 사람들을 멀리하며 살았다.“그 남자는 언젠가 당신에게 무서운 짓을 할 거예요.\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "이름도 한 번 들으면 금방 외워서 이쪽은 파울러 부인이고, 저쪽은 누구라느니 하며 말예요. ” 이에 용기를 얻어 파울러 부인은 자진해서 기억이며 억측이며 소문 따위를 이것저것 이야기해 주었다.\n",
            "--------------------------------------------------\n",
            "besm_bert summary:\n",
            "이름도 한 번 들으면 금방 외워서 이쪽은 파울러 부인이고, 저쪽은 누구라느니 하며 말예요. ” 그러나 이미 5파운드가 파울러 부인의 눈앞에 유혹하듯 어른거리고 있다. “ 포아로는 얼른 안심시키듯 그녀 쪽에서는 아무것도 하지 않아도 되며, 그녀로부터 사실 이야기를 들은 다음 기사는 자기 쪽에서 쓴다고 이야기해 주었다.\n",
            "--------------------------------------------------\n",
            "         method  comp ratio     intro      body    ending       var     total  \\\n",
            "0      SAM+WGAN    0.128467  0.668793  0.479827  0.655767  0.007426  0.570402   \n",
            "1  BERT+LexRank    0.191241  0.078313  0.319538  0.141274  0.010437  0.217814   \n",
            "2          BESM    0.156204  0.636954  0.385599  0.387479  0.013936  0.436434   \n",
            "3   BESM+kobert    0.258394  0.636954  0.517610  0.408372  0.008714  0.508707   \n",
            "\n",
            "    grammar  \n",
            "0  0.989273  \n",
            "1  0.999017  \n",
            "2  0.998889  \n",
            "3  0.998936  \n",
            "Current result ==================================================\n",
            "Sample count: 42\n",
            "         method  comp rate     intro      body  conclusion   isthmus  \\\n",
            "0      SAM+WGAN   0.148067  0.507603  0.477102    0.483451  0.007542   \n",
            "1  BERT+LexRank   0.215822  0.239418  0.220186    0.199109  0.007880   \n",
            "2          BESM   0.205201  0.444127  0.400715    0.368700  0.009862   \n",
            "3   BESM+kobert   0.211199  0.462325  0.395368    0.379481  0.010557   \n",
            "\n",
            "   simlirality  grammarity  \n",
            "0     0.485107    0.959743  \n",
            "1     0.217709    0.998975  \n",
            "2     0.399793    0.989736  \n",
            "3     0.403994    0.989646  \n",
            "==================================================\n",
            "47 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "” 마침내 그 남자는 일을 저지르고 말았다. 그리고 그녀, 파울러 부인은 바로 이웃에 살면서 아무 소리도 못 들은 것이다. 잠시 사이를 두고 나서 포아로가 물었다. 애셔 부인은 어떤 이상한 편지?이를테면 개인적인 서명이 없는?예를 들어 ABC라는 서명이 든 편지를 받은 일이 없는가?파울러 부인은 유감스러운 듯 없다고 대답했다. “당신이 이야기하시는 그런 일은 저도 알고 있어요. 익명 편지라는 거지요. 큰소리로 말하기가 뭣할 정도로 창피스러운 게 가득 씌어 있는……네, 물론 프란츠 애셔가 그런 것을 썼는지 어떤지 저는 몰라요. 물론 썼다고 해도 애셔 부인이 제게 말했을 리 없고요. 뭐라고요? 철도 안내, ABC 철도 안내서라고요? 아니오, 그런 건 못 보았어요. 그리고 만일 애셔 부인에게 그런 게 보내져 왔다면 저한테 꼭 말해 줬을 거예요. 이번 사건을 들었을 때 전 하마터면 쓰러질 뻔했어요. 딸 에디가 알려 줬지요. ‘엄마, 옆 가게에 순경들이 많이 와 있어. ’라고 말예요. 정말 놀랐어요. 그 말을 듣고 전 말했지요. ‘저 아주머니는 그 집에 혼자 사는 게 아니었어.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.471155881881714 Generator / grammar loss:-0.14267800748348236   similarity loss:-0.09466061741113663\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "그 남자는 그리고 이웃에 잠시 사이를 두고 애셔 어떤 개인적인 서명이 받은 일이 없는가?파울러 대답했다. “당신이 창피스러운 것을 저는 몰라요. 보았어요.\n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "철도 안내, ABC 철도 안내서라고요?‘엄마, 옆 가게에 순경들이 많이 와 있어.“당신이 이야기하시는 그런 일은 저도 알고 있어요.큰소리로 말하기가 뭣할 정도로 창피스러운 게 가득 씌어 있는……네, 물론 프란츠 애셔가 그런 것을 썼는지 어떤지 저는 몰라요.\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "그리고 그녀, 파울러 부인은 바로 이웃에 살면서 아무 소리도 못 들은 것이다. 애셔 부인은 어떤 이상한 편지?이를테면 개인적인 서명이 없는?예를 들어 ABC라는 서명이 든 편지를 받은 일이 없는가?파울러 부인은 유감스러운 듯 없다고 대답했다. “\n",
            "--------------------------------------------------\n",
            "besm_bert summary:\n",
            "그리고 그녀, 파울러 부인은 바로 이웃에 살면서 아무 소리도 못 들은 것이다. 애셔 부인은 어떤 이상한 편지?이를테면 개인적인 서명이 없는?예를 들어 abc라는 서명이 든 편지를 받은 일이 없는가?파울러 부인은 유감스러운 듯 없다고 대답했다. “ 그리고 만일 애셔 부인에게 그런 게 보내져 왔다면 저한테 꼭 말해 줬을 거예요.\n",
            "--------------------------------------------------\n",
            "         method  comp ratio     intro      body    ending       var     total  \\\n",
            "0      SAM+WGAN    0.156364  0.507657  0.412378  0.468511  0.001529  0.448274   \n",
            "1  BERT+LexRank    0.260000  0.183686  0.228546  0.217236  0.000363  0.216181   \n",
            "2          BESM    0.249091  0.666078  0.471434  0.517530  0.006897  0.524192   \n",
            "3   BESM+kobert    0.330909  0.645168  0.490032  0.383274  0.011561  0.489032   \n",
            "\n",
            "    grammar  \n",
            "0  0.992442  \n",
            "1  0.999007  \n",
            "2  0.988720  \n",
            "3  0.999015  \n",
            "Current result ==================================================\n",
            "Sample count: 43\n",
            "         method  comp rate     intro      body  conclusion   isthmus  \\\n",
            "0      SAM+WGAN   0.148260  0.507604  0.475597    0.483104  0.007402   \n",
            "1  BERT+LexRank   0.216850  0.238122  0.220380    0.199531  0.007705   \n",
            "2          BESM   0.206222  0.449289  0.402359    0.372161  0.009793   \n",
            "3   BESM+kobert   0.213983  0.466577  0.397570    0.379570  0.010581   \n",
            "\n",
            "   simlirality  grammarity  \n",
            "0     0.484251    0.960504  \n",
            "1     0.217674    0.998976  \n",
            "2     0.402686    0.989712  \n",
            "3     0.405971    0.989864  \n",
            "==================================================\n",
            "48 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "그 조카딸이라도 함께 있었더라면 좋았을걸. 주정꾼 남자란 정말 허기진 늑대나 다름없으니까. 그 아주머니 남편은 짐승과 다를 바 없어. 나는 그 아주머니한테 몇 번이나 말했었는데, 결국 내 말대로 되어 버렸구나!그 남자는 언젠가 심한 짓을 할 거라고 말했는데. ’ 그 남자는 진짜로 해치운 거예요. 남자란 술을 마시면 무슨 짓을 할지 모르니까요. 이 살인이 그걸 말해 주고 있잖아요. ” 그녀는 숨을 헐떡이며 이야기를 끝냈다. 포아로가 물었다. “그 애셔라는 남자가 가게로 들어가는 것은 아무도 못 본 셈이군요?” 파울러 부인은 경멸하는 듯 콧방귀를 뀌며 말했다. “그야 아무도 못 보도록 들어가는 게 당연하지요. “ 그러나 그녀는 애셔가 어떻게 남의 눈에 띄지 않고 들어갈 수 있었는지에 대해선 설명해 주지 못했다. 그 집에는 뒷문이 없다고 그녀는 말했다. 또 애셔가 이 가까이에 잘 알려져 있다는 데에도 동의했다. “그렇지만 그는 교수형에 처해지기 싫으니까 용케 숨어 들어간 거예요. ” 포아로는 얼마동안 이야기를 이끌어 나가다가 파울러 부인이 알고 있는 이야기를 몇 번이나 되풀이하는 것을 깨닫자 그 면담을 끝내고 약속한 돈을 주었다. 길을 나서자 나는 말했다. “5파운드는 너무 비싼데, 포아로. ” “그렇지, 그것만으로는.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.526634693145752 Generator / grammar loss:-0.14607320725917816   similarity loss:-0.09213928878307343\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "그 남편은 말했었는데, 말대로 남자는 심한 짓을 할 거예요. 또 가까이에 잘 동의했다. “그렇지만 싫으니까 부인이 있는 길을 나서자 너무 포아로. ” “그렇지, 그것만으로는.\n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "길을 나서자 나는 말했다.포아로가 물었다.그 조카딸이라도 함께 있었더라면 좋았을걸.이 살인이 그걸 말해 주고 있잖아요.\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "나는 그 아주머니한테 몇 번이나 말했었는데, 결국 내 말대로 되어 버렸구나!그 남자는 언젠가 심한 짓을 할 거라고 말했는데. ’ 포아로는 얼마동안 이야기를 이끌어 나가다가 파울러 부인이 알고 있는 이야기를 몇 번이나 되풀이하는 것을 깨닫자 그 면담을 끝내고 약속한 돈을 주었다.\n",
            "--------------------------------------------------\n",
            "besm_bert summary:\n",
            "나는 그 아주머니한테 몇 번이나 말했었는데, 결국 내 말대로 되어 버렸구나!그 남자는 언젠가 심한 짓을 할 거라고 말했는데. ’ 그러나 그녀는 애셔가 어떻게 남의 눈에 띄지 않고 들어갈 수 있었는지에 대해선 설명해 주지 못했다.\n",
            "--------------------------------------------------\n",
            "         method  comp ratio     intro      body    ending       var     total  \\\n",
            "0      SAM+WGAN    0.153239  0.416916  0.406434  0.514848  0.002384  0.441055   \n",
            "1  BERT+LexRank    0.104265  0.385438  0.155831  0.155620  0.011726  0.201689   \n",
            "2          BESM    0.244866  0.422892  0.333033  0.381768  0.001349  0.365625   \n",
            "3   BESM+kobert    0.200632  0.422892  0.500702  0.331261  0.004796  0.434308   \n",
            "\n",
            "    grammar  \n",
            "0  0.991657  \n",
            "1  0.998800  \n",
            "2  0.999031  \n",
            "3  0.999021  \n",
            "Current result ==================================================\n",
            "Sample count: 44\n",
            "         method  comp rate     intro      body  conclusion   isthmus  \\\n",
            "0      SAM+WGAN   0.148373  0.505543  0.474025    0.483825  0.007288   \n",
            "1  BERT+LexRank   0.214291  0.241470  0.218913    0.198533  0.007796   \n",
            "2          BESM   0.207100  0.448689  0.400784    0.372379  0.009601   \n",
            "3   BESM+kobert   0.213679  0.465584  0.399914    0.378472  0.010449   \n",
            "\n",
            "   simlirality  grammarity  \n",
            "0     0.483269    0.961212  \n",
            "1     0.217310    0.998972  \n",
            "2     0.401843    0.989924  \n",
            "3     0.406615    0.990072  \n",
            "==================================================\n",
            "49 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "‘ “자네는 그녀가 이야기한 이상의 것을 알고 있다고 생각하나?” “우리는 지금 무엇을 물어야 좋을지 모르는 기묘한 위치에 놓여 있네. 우리는 어둠 속에서 숨바꼭질하고 있는 어린이들과도 같은 걸세. 우리는 손을 내밀어 찾고 있지. 파울러 부인은 자기가 알고 있다고 여기는 일들을 우리에게 말해줬네. 더욱이 꽤 억측을 해가면서. 그러나 언젠가 그 진술이 쓸모 있게 될 걸세. 5파운드를 투자한 건 결국 그 언젠가를 위해서라네. ” 나는 요점을 잘 잡을 수가 없었다. 그리고 마침 그때 우리는 글렌 형사와 마주쳤다. < 두 증인 > 글렌 형사는 좀 핼쑥해져 있는 듯 했다. 그는 오후 내내 담배 가게에 들어간 사람들 리스트를 만들고 있었던 모양이다. 포아로가 물었다. “결국은 눈에 띈 사람이 아무도 없다는 거로군요?” “아니, 보기는 본 모양입니다. 흘끔거리는 것 같은 느낌의 키가 큰 남자 셋, 시커먼 수염의 키 작은 남자 넷, 턱수염이 있는 사람 둘, 뚱뚱한 사람 셋, 모두 낯선 사람들로, 증언을 믿는다면 다 어딘지 수상쩍은 데가 있는 이들뿐입니다. 권총을 든 복면한 갱 한 무리가 범행을 저지르는 걸 보았다는 사람이 없는 게 이상할 정도입니다. ” 포아로는 동정적인 미소를 지었다. “애셔라는 사나이를 본 사람은 없던가요?” “없습니다. 이것도 그에게 유리한 점입니다. 저는 지금 막 서장님에게, 이것을 런던 경찰국에서 맡아야 할 일이라고 이야기하고 오는 참입니다. 이건 지방적인 범죄가 아닙니다.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.531792402267456 Generator / grammar loss:-0.13938488066196442   similarity loss:-0.08489635586738586\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "그녀가 “우리는 좋을지 모르는 어둠 속에서 내밀어 찾고 파울러 부인은 일들을 말해줬네. 더욱이 들어간 리스트를 물었다. 없다는 모양입니다. 흘끔거리는 남자 사람 사람 걸 지었다. 런던 이건 아닙니다.\n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "그는 오후 내내 담배 가게에 들어간 사람들 리스트를 만들고 있었던 모양이다.저는 지금 막 서장님에게, 이것을 런던 경찰국에서 맡아야 할 일이라고 이야기하고 오는 참입니다.이건 지방적인 범죄가 아닙니다.5파운드를 투자한 건 결국 그 언젠가를 위해서라네.\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "파울러 부인은 자기가 알고 있다고 여기는 일들을 우리에게 말해줬네.더욱이 꽤 억측을 해가면서. 흘끔거리는 것 같은 느낌의 키가 큰 남자 셋, 시커먼 수염의 키 작은 남자 넷, 턱수염이 있는 사람 둘, 뚱뚱한 사람 셋, 모두 낯선 사람들로, 증언을 믿는다면 다 어딘지 수상쩍은 데가 있는 이들뿐입니다.권총을 든 복면한 갱 한 무리가 범행을 저지르는 걸 보았다는 사람이 없는 게 이상할 정도입니다. ” 저는 지금 막 서장님에게, 이것을 런던 경찰국에서 맡아야 할 일이라고 이야기하고 오는 참입니다.\n",
            "--------------------------------------------------\n",
            "besm_bert summary:\n",
            "파울러 부인은 자기가 알고 있다고 여기는 일들을 우리에게 말해줬네.더욱이 꽤 억측을 해가면서. 그는 오후 내내 담배 가게에 들어간 사람들 리스트를 만들고 있었던 모양이다. 흘끔거리는 것 같은 느낌의 키가 큰 남자 셋, 시커먼 수염의 키 작은 남자 넷, 턱수염이 있는 사람 둘, 뚱뚱한 사람 셋, 모두 낯선 사람들로, 증언을 믿는다면 다 어딘지 수상쩍은 데가 있는 이들뿐입니다.권총을 든 복면한 갱 한 무리가 범행을 저지르는 걸 보았다는 사람이 없는 게 이상할 정도입니다. ”\n",
            "--------------------------------------------------\n",
            "         method  comp ratio     intro      body    ending       var     total  \\\n",
            "0      SAM+WGAN    0.152263  0.552478  0.463807  0.347859  0.007020  0.446757   \n",
            "1  BERT+LexRank    0.192044  0.099539  0.144613  0.161658  0.000687  0.140712   \n",
            "2          BESM    0.378601  0.542296  0.349804  0.441173  0.006181  0.415713   \n",
            "3   BESM+kobert    0.363512  0.587391  0.510371  0.429172  0.004173  0.501415   \n",
            "\n",
            "    grammar  \n",
            "0  0.992406  \n",
            "1  0.999036  \n",
            "2  0.999032  \n",
            "3  0.996973  \n",
            "Current result ==================================================\n",
            "Sample count: 45\n",
            "         method  comp rate     intro      body  conclusion   isthmus  \\\n",
            "0      SAM+WGAN   0.148460  0.506586  0.473798    0.480804  0.007282   \n",
            "1  BERT+LexRank   0.213797  0.238316  0.217262    0.197713  0.007638   \n",
            "2          BESM   0.210911  0.450769  0.399651    0.373908  0.009525   \n",
            "3   BESM+kobert   0.217009  0.468291  0.402368    0.379598  0.010310   \n",
            "\n",
            "   simlirality  grammarity  \n",
            "0     0.482457    0.961905  \n",
            "1     0.215608    0.998973  \n",
            "2     0.402152    0.990126  \n",
            "3     0.408722    0.990226  \n",
            "==================================================\n",
            "50 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "” 포아로는 신중하게 말했다. “나도 그렇게 생각하오. ” “포아로 씨, 싫은 사건입니다. 참으로 싫은 사건입니다. 저는 아무래도 마음에 들지 않습니다. ” 우리는 런던으로 돌아가기 전에 두 사람을 더 만났다. 하나는 제임즈 패트리지라는 인물이었다. 패트리지 씨는 애셔 부인이 살아 있는 동안 맨 마지막으로 만난 사람이었다. 그는 5시 30분에 그녀 가게에서 물건을 샀던 것이다. 페트리지 씨는 몸집 작은 빈약한 남자로 은행원이었다. 코안경은 걸친 무뚝뚝하고 빼빼 마른 느낌의 사나이였으나 말씨는 또박또박했다. 그는 자기에게 잘 어울리는 깨끗한 작은 집에 살고 있었다. 내 친구가 내민 명함을 보며 그는 말했다. “네, 포아로 씨. 글렌 형사에게서 들으셨습니까? 무슨 도움이 될까요, 포아로 씨?” “패트리지 씨, 당신은 살아있는 애셔 부인을 맨 마지막으로 만난 분이시니까요. ” 패트리지 씨는 두 손을 마주대고 미심쩍은 수표라도 들여다보듯 포아로를 보았다. “그것이 토론의 여지가 있는 점입니다, 포아로 씨. 제 다음에도 더 많은 손님이 애셔 부인한테서 물건을 샀을지 모르니 말입니다. ” “그렇더라도 지금으로선 아직 신고해 온 사람이 없습니다.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.453137159347534 Generator / grammar loss:-0.1388217955827713   similarity loss:-0.09270790964365005\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "” 포아로는 생각하오. “포아로 싫은 사건입니다. 참으로 우리는 돌아가기 더 만났다. 하나는 제임즈 씨는 맨 빈약한 느낌의 사나이였으나 또박또박했다. “그것이 \n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "그는 5시 30분에 그녀 가게에서 물건을 샀던 것이다.“나도 그렇게 생각하오.그는 자기에게 잘 어울리는 깨끗한 작은 집에 살고 있었다.참으로 싫은 사건입니다.저는 아무래도 마음에 들지 않습니다.\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "패트리지 씨는 애셔 부인이 살아 있는 동안 맨 마지막으로 만난 사람이었다. 코안경은 걸친 무뚝뚝하고 빼빼 마른 느낌의 사나이였으나 말씨는 또박또박했다.\n",
            "--------------------------------------------------\n",
            "besm_bert summary:\n",
            "패트리지 씨는 애셔 부인이 살아 있는 동안 맨 마지막으로 만난 사람이었다. 패트리지 씨는 두 손을 마주대고 미심쩍은 수표라도 들여다보듯 포아로를 보았다. “\n",
            "--------------------------------------------------\n",
            "         method  comp ratio     intro      body    ending       var     total  \\\n",
            "0      SAM+WGAN    0.151877  0.812305  0.501326  0.415500  0.029059  0.537774   \n",
            "1  BERT+LexRank    0.184300  0.123815  0.227500  0.103749  0.002941  0.169638   \n",
            "2          BESM    0.143345  0.186226  0.394107  0.374558  0.008785  0.346666   \n",
            "3   BESM+kobert    0.148464  0.436992  0.390959  0.556019  0.004837  0.449684   \n",
            "\n",
            "    grammar  \n",
            "0  0.980826  \n",
            "1  0.999031  \n",
            "2  0.997315  \n",
            "3  0.988742  \n",
            "Current result ==================================================\n",
            "Sample count: 46\n",
            "         method  comp rate     intro      body  conclusion   isthmus  \\\n",
            "0      SAM+WGAN   0.148534  0.513232  0.474397    0.479384  0.007755   \n",
            "1  BERT+LexRank   0.213155  0.235827  0.217485    0.195671  0.007536   \n",
            "2          BESM   0.209442  0.445018  0.399530    0.373922  0.009509   \n",
            "3   BESM+kobert   0.215519  0.467611  0.402120    0.383434  0.010191   \n",
            "\n",
            "   simlirality  grammarity  \n",
            "0     0.483660    0.962316  \n",
            "1     0.214609    0.998974  \n",
            "2     0.400945    0.990282  \n",
            "3     0.409612    0.990193  \n",
            "==================================================\n",
            "51 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "” 패트리지 씨는 헛기침을 했다. “그들은 시민의 의무에 대한 관념을 갖고 있지 않으니까요, 포아로 씨. ” 그는 부엉이처럼 코안경 너머로 우리를 보았다. 포아로가 중얼거렸다. “정말 그렇습니다. 당신은 자진해서 경찰에 신고하셨습니까?” “그럼요, 저는 이 무서운 사건 이야기를 듣자 곧 제 진술이 도움이 될지도 모른다고 생각했습니다. 그래서 바로 신고했지요. ” 포아로는 엄숙하게 말했다. “정말 훌륭한 마음씨입니다. 저에게도 그 이야기를 되풀이 들려주실 수 있으시겠지요?” “알겠습니다. 저는 집으로 돌아오는 길이었는데, 정각 5시 30분에……. ” “실례입니다만, 어째서 그토록 정확하게 시간을 알고 계십니까?” 패트리지 씨는 방해를 받아 기분이 좀 상한 모양이었다. “교회 시계가 울렸습니다. 저는 제 시계를 보고 1분 늦는 것을 알았지요. 그때가 바로 애셔 부인 가게로 들어가기 직전이었습니다. ” “거기서 자주 물건을 사셨습니까?” “네, 자주 샀습니다. 집으로 돌아오는 길목이니까요. 1주일에 한두 번씩 저는 <존 코튼>을 순한 것으로 2온스씩 사고 있습니다. ” “애셔 부인을 알고 계셨습니까? 그녀의 가정에 대해서라든지 과거에 대해?” “전혀 모릅니다.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.3087401390075684 Generator / grammar loss:-0.11273819953203201   similarity loss:-0.0816153734922409\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "” 의무에 포아로 우리를 보았다. 중얼거렸다. “정말 그렇습니다. “그럼요, 제 될지도 ” 저에게도 “알겠습니다. 정각 상한 시계가 울렸습니다.\n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "“그들은 시민의 의무에 대한 관념을 갖고 있지 않으니까요, 포아로 씨.1주일에 한두 번씩 저는 <존 코튼>을 순한 것으로 2온스씩 사고 있습니다.” 그는 부엉이처럼 코안경 너머로 우리를 보았다.” 포아로는 엄숙하게 말했다.\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "그럼요, 저는 이 무서운 사건 이야기를 듣자 곧 제 진술이 도움이 될지도 모른다고 생각했습니다. 저는 제 시계를 보고 1분 늦는 것을 알았지요.그때가 바로 애셔 부인 가게로 들어가기 직전이었습니다. ” “\n",
            "--------------------------------------------------\n",
            "besm_bert summary:\n",
            "그럼요, 저는 이 무서운 사건 이야기를 듣자 곧 제 진술이 도움이 될지도 모른다고 생각했습니다. 저는 제 시계를 보고 1분 늦는 것을 알았지요.그때가 바로 애셔 부인 가게로 들어가기 직전이었습니다. ” “\n",
            "--------------------------------------------------\n",
            "         method  comp ratio     intro      body    ending       var     total  \\\n",
            "0      SAM+WGAN    0.133779  0.457725  0.628511  0.334909  0.014495  0.506273   \n",
            "1  BERT+LexRank    0.207358  0.276641  0.108462  0.269782  0.006040  0.190494   \n",
            "2          BESM    0.190635  0.331757  0.592236  0.359949  0.013622  0.470454   \n",
            "3   BESM+kobert    0.190635  0.331757  0.592236  0.359949  0.013622  0.470454   \n",
            "\n",
            "    grammar  \n",
            "0  0.984299  \n",
            "1  0.999037  \n",
            "2  0.995295  \n",
            "3  0.995295  \n",
            "Current result ==================================================\n",
            "Sample count: 47\n",
            "         method  comp rate     intro      body  conclusion   isthmus  \\\n",
            "0      SAM+WGAN   0.148220  0.512051  0.477676    0.476310  0.007899   \n",
            "1  BERT+LexRank   0.213032  0.236696  0.215165    0.197247  0.007504   \n",
            "2          BESM   0.209042  0.442609  0.403630    0.373625  0.009596   \n",
            "3   BESM+kobert   0.214989  0.464720  0.406165    0.382934  0.010264   \n",
            "\n",
            "   simlirality  grammarity  \n",
            "0     0.484141    0.962784  \n",
            "1     0.214096    0.998976  \n",
            "2     0.402424    0.990389  \n",
            "3     0.410907    0.990302  \n",
            "==================================================\n",
            "52 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "사는 물건이나 또는 날씨에 대해 몇 마디 나눈 것 말고는 이야기한 일이 없습니다. ” “그녀의 생명을 위협하는 말을 자주 했었던 주정꾼 남편에 대해 알고 계셨습니까?” “아니오, 그 사람에 대해서는 아무것도 모릅니다. ” “그러나 당신도 얼굴은 알고 계셨겠지요. 어제 여느 때와 다른 어떤 기색은 없었습니까?흥분해 있었다던가, 화를 내고 있었다던가?” 패트리지 씨는 생각해 보더니 대답했다. “내가 아느 한에서는 여느 때와 다른 점이 전혀 없었습니다. ” 포아로는 일어섰다. “패트리지 씨, 질문에 대답해 주셔서 고맙습니다. 그런데 댁은 혹시 ABC가 없는지요? 런던으로 가는 시간표를 좀 보고 싶어서요. ” 그가 말한 선반 위에는 ABC와 함께 브래드쇼, 주식연감, 케리의 인명록 그리고 현대 인명록 및 지방 신사록 등이 있었다. 포아로는 ABC를 들고 기차시간을 살펴보는 시늉을 한 다음 패트리지 씨에게 고맙다는 인사를 하고 나왔다. 또 다른 한 사람은 앨버트 리딜로, 이 또한 색다른 사람이었다. 앨버트 리딜 씨는 철도 인부였다. 그의 신경질적인 아내가 접시 씻는 소리며, 그 집 개가 으르렁대는 소리며, 리딜 씨 자신의 노골적인 적의 등과 더불어 이야기가 진행되었다. 그는 넓적한 얼굴에 의심 많은 눈을 한 크고 우둥퉁한 거인으로, 고기든 파이를 아주 진한 차와 함께 집어삼키고 있었다. 그는 찻잔 가장자리께로부터 화난 듯한 얼굴로 우리를 노려보고 있었다. 그는 으르렁거렸다. “필요한 말은 다 한 줄로 아는데, 대체 나와 무슨 관계가 있다는거요? 나는 경찰에 다 말해줬소.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.4778292179107666 Generator / grammar loss:-0.11056773364543915   similarity loss:-0.061843179166316986\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            " 생명을 자주 모릅니다. ” 다른 어떤 패트리지 대답했다. 한에서는 점이 전혀 없었습니다. ” 포아로는 일어섰다. 주셔서 고맙습니다. 위에는 ABC를 패트리지 한 사람은 리딜 철도 인부였다. 으르렁거렸다.\n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "그런데 댁은 혹시 ABC가 없는지요?그는 넓적한 얼굴에 의심 많은 눈을 한 크고 우둥퉁한 거인으로, 고기든 파이를 아주 진한 차와 함께 집어삼키고 있었다.런던으로 가는 시간표를 좀 보고 싶어서요.그는 찻잔 가장자리께로부터 화난 듯한 얼굴로 우리를 노려보고 있었다.\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "사는 물건이나 또는 날씨에 대해 몇 마디 나눈 것 말고는 이야기한 일이 없습니다. ” “ 그녀의 생명을 위협하는 말을 자주 했었던 주정꾼 남편에 대해 알고 계셨습니까?” “ 그가 말한 선반 위에는 ABC와 함께 브래드쇼, 주식연감, 케리의 인명록 그리고 현대 인명록 및 지방 신사록 등이 있었다.\n",
            "--------------------------------------------------\n",
            "besm_bert summary:\n",
            "사는 물건이나 또는 날씨에 대해 몇 마디 나눈 것 말고는 이야기한 일이 없습니다. ” “ 포아로는 abc를 들고 기차시간을 살펴보는 시늉을 한 다음 패트리지 씨에게 고맙다는 인사를 하고 나왔다. 그는 넓적한 얼굴에 의심 많은 눈을 한 크고 우둥퉁한 거인으로, 고기든 파이를 아주 진한 차와 함께 집어삼키고 있었다.\n",
            "--------------------------------------------------\n",
            "         method  comp ratio     intro      body    ending       var     total  \\\n",
            "0      SAM+WGAN    0.147287  0.340862  0.536146  0.444992  0.006365  0.469743   \n",
            "1  BERT+LexRank    0.189922  0.108351  0.153961  0.383368  0.014482  0.213661   \n",
            "2          BESM    0.213178  0.546926  0.294954  0.306087  0.013513  0.348688   \n",
            "3   BESM+kobert    0.226098  0.454240  0.383536  0.449088  0.001036  0.417342   \n",
            "\n",
            "    grammar  \n",
            "0  0.965805  \n",
            "1  0.998963  \n",
            "2  0.999001  \n",
            "3  0.998979  \n",
            "Current result ==================================================\n",
            "Sample count: 48\n",
            "         method  comp rate     intro      body  conclusion   isthmus  \\\n",
            "0      SAM+WGAN   0.148201  0.508485  0.478894    0.475658  0.007867   \n",
            "1  BERT+LexRank   0.212551  0.234022  0.213890    0.201125  0.007650   \n",
            "2          BESM   0.209128  0.444782  0.401366    0.372218  0.009678   \n",
            "3   BESM+kobert   0.215221  0.464502  0.405694    0.384312  0.010072   \n",
            "\n",
            "   simlirality  grammarity  \n",
            "0     0.483841    0.962847  \n",
            "1     0.214087    0.998975  \n",
            "2     0.401305    0.990568  \n",
            "3     0.411041    0.990483  \n",
            "==================================================\n",
            "53 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "그런데 이번엔 또 외국놈 따위에게 다시 한 번 말하지 않으면 안 된다는 거요?” 포아로는 재빨리 내 쪽으로 흥미가 끌리는 듯한 눈짓을 보내고 나서 입을 열었다. “정말이지 안 되셨습니다. 그렇지만 할 수 없잖습니까? 어쨌든 살인 사건이니까요. 아주 신중하게 하지 않으면 안 되지요. ” 앨버트의 아내가 신경질적으로 말했다. “이분들이 듣고 싶어하시는 것을 모조리 이야기하는 게 좋아요. ” 거인이 소리쳤다. “잠자코 있어. ” 포아로가 솜씨 좋게 끼어들었다. “당신은 자진해서 경찰에 가신 게 아니잖습니까. ” “어째서 그런 짓을 해야 되는 거요? 그런 건 내 일이 아니잖소. ” 포아로는 아무렇지도 않게 말했다. “생각할 나름이지요. 살인이 일어났고 경찰은 가게에 왔던 사람을 알고 싶어했습니다. 저는 당신이 자진해서 신고하시는 편이 뭐랄까, 자연스럽다고 생각되는데요. ” “나한테는 일이 있소. 스스로 자진해서 가지 않았다니, 그렇게 말하면 곤란한데. ” “하지만 당신이 애셔 부인 가게로 들어가는 것을 본 사람이 있습니다.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.433051586151123 Generator / grammar loss:-0.1379595249891281   similarity loss:-0.09395790100097656\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "내 신경질적으로 “잠자코 있어. ” 포아로가 끼어들었다. 가신 건 아니잖소. “생각할 살인이 일어났고 알고 자연스럽다고 생각되는데요. 그렇게 곤란한데.\n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "살인이 일어났고 경찰은 가게에 왔던 사람을 알고 싶어했습니다.“잠자코 있어.” 거인이 소리쳤다.” 앨버트의 아내가 신경질적으로 말했다.\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "그런데 이번엔 또 외국놈 따위에게 다시 한 번 말하지 않으면 안 된다는 거요?” 저는 당신이 자진해서 신고하시는 편이 뭐랄까, 자연스럽다고 생각되는데요. ” “\n",
            "--------------------------------------------------\n",
            "besm_bert summary:\n",
            "그런데 이번엔 또 외국놈 따위에게 다시 한 번 말하지 않으면 안 된다는 거요?” 포아로는 재빨리 내 쪽으로 흥미가 끌리는 듯한 눈짓을 보내고 나서 입을 열었다. “\n",
            "--------------------------------------------------\n",
            "         method  comp ratio     intro      body    ending       var     total  \\\n",
            "0      SAM+WGAN    0.161850  0.609372  0.506393  0.449439  0.004381  0.509902   \n",
            "1  BERT+LexRank    0.144509  0.162671  0.144190  0.222621  0.001121  0.171416   \n",
            "2          BESM    0.171484  0.442424  0.430036  0.496790  0.000841  0.452540   \n",
            "3   BESM+kobert    0.175337  0.518600  0.413361  0.372980  0.003768  0.422295   \n",
            "\n",
            "    grammar  \n",
            "0  0.996105  \n",
            "1  0.997696  \n",
            "2  0.989614  \n",
            "3  0.963113  \n",
            "Current result ==================================================\n",
            "Sample count: 49\n",
            "         method  comp rate     intro      body  conclusion   isthmus  \\\n",
            "0      SAM+WGAN   0.148479  0.510544  0.479455    0.475123  0.007796   \n",
            "1  BERT+LexRank   0.211162  0.232566  0.212467    0.201564  0.007516   \n",
            "2          BESM   0.208360  0.444734  0.401951    0.374760  0.009498   \n",
            "3   BESM+kobert   0.214407  0.465606  0.405850    0.384081  0.009943   \n",
            "\n",
            "   simlirality  grammarity  \n",
            "0     0.484373    0.963526  \n",
            "1     0.213216    0.998949  \n",
            "2     0.402350    0.990549  \n",
            "3     0.411271    0.989924  \n",
            "==================================================\n",
            "54 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "그래서 경찰은 당신을 만나러 오지 않으면 안 되었던 것입니다. 그런데 경찰은 당신 이야기에 만족했습니까?” 앨버트는 사납게 되물었다. “어째서 만족하지 않겠소?” 포아로는 다만 어깨를 으쓱했을 뿐이었다. “대체 뭘 냄새 맡으려는 거요. 당신은. 나한테서 뭘 끄집어낼 수 있을 리 없잖소. 그 노파를 죽인 게 누군지 모두들 알고 있어. 그 남편이잖소?” “그렇지만 그날 밤 그는 그곳에 있지 않았고, 당신은 있었지요. ‘ “나한테 죄를 뒤집어씌우려는 거요, 당신? 잘됐어, 이거 잘해 봐야겠군. 대체 내가 그런 짓을 해야 될 이유가 어디 있소? 그 늙은이의 피로 얼룩진 담배를 한 갑 훔치려고? 내가 남들이 말하는 피에 굶주린 살인광이란 말이오? 이 내가?” 그는 위협하듯 의자에서 일어섰다. 그의 아내가 양 같은 소리를 질렀다. “버트, 버트, 그런 말을 해선 안 돼요. 버트, 그런 말을 하면 모두들……. ” 포아로가 말했다. “좀 침착하십시오. 저는 그저 당신이 그 가게에 가셨었다는 이야기를 듣고 싶었던 것뿐입니다.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.1932191848754883 Generator / grammar loss:-0.12371939420700073   similarity loss:-0.10433702915906906\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "그래서 당신을 오지 사납게 “어째서 포아로는 다만 뭘 맡으려는 거요. 당신은. 수 게 뒤집어씌우려는 “버트, 버트, 그런 것뿐입니다.\n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "그 늙은이의 피로 얼룩진 담배를 한 갑 훔치려고?“좀 침착하십시오.그래서 경찰은 당신을 만나러 오지 않으면 안 되었던 것입니다.그 노파를 죽인 게 누군지 모두들 알고 있어.\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "Unexpected error: <class 'ValueError'>\n",
            "==================================================\n",
            "55 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "그런데 그걸 거부하면 저에게는 어쩐지, 뭐라고 하나, 좀 이상한 기분이 드는군요. ” “내가 거부한다고 누가 말했소?” 리딜은 다시 의자에 앉았다. “이야기해 주겠소. ‘ “가게에 들어가셨던 게 6시였지요?” “그렇소. 사실은 1. 2분 지나 있었소. 골든 프레이크를 한 갑 사려고. 내가 문을 밀자……. ” “그러니까, 즉 가게 문이 닫혀 있었다는 거로군요?” “그렇소. 나는 벌써 가게를 닫았나 하고 생각했소. 그런데 그게 아니었소. 안으로 들어가니 아무도 없었소. 그래서 계산대를 쾅 두드리고는 잠시 기다려 보았소. 그래도 아무도 나오지 않길래 나는 밖으로 나왔소. ” “계산대 뒤에 쓰러져 있는 시체는 못 보셨군요?” “못 보았소. 다른 사람도 못 봤을 거요, 찾기라도 하지 않았다면. ” “철도 안내서는 있었습니까?” “있었소, 책장이 펼쳐져서 말이오. 그래서 나는 생각했소. 이 할머니, 너무 급하게 나가느라 문잠그는 걸 잊었나 보다고. ” “그래서 당신은 철도 안내서를 건드리거나 움직여 보셨군요?” “당치도 않소, 누가 그런 짓을 하겠소.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.379554510116577 Generator / grammar loss:-0.12764503061771393   similarity loss:-0.08922381699085236\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "좀 말했소?” “가게에 있었소. 한 문이 있었다는 나는 아무도 없었소. 밖으로 나왔소. “못 찾기라도 “철도 있었습니까?” 말이오. 생각했소.\n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "골든 프레이크를 한 갑 사려고.2분 지나 있었소.그런데 그게 아니었소.“이야기해 주겠소.\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "그런데 그걸 거부하면 저에게는 어쩐지, 뭐라고 하나, 좀 이상한 기분이 드는군요. ” “\n",
            "--------------------------------------------------\n",
            "besm_bert summary:\n",
            "그런데 그걸 거부하면 저에게는 어쩐지, 뭐라고 하나, 좀 이상한 기분이 드는군요. ” “\n",
            "--------------------------------------------------\n",
            "         method  comp ratio     intro      body    ending       var     total  \\\n",
            "0      SAM+WGAN    0.148218  0.436992  0.451300  0.579282  0.004092  0.486833   \n",
            "1  BERT+LexRank    0.091932  0.215170  0.245545  0.225747  0.000158  0.233531   \n",
            "2          BESM    0.091932  0.543959  0.426088  0.367169  0.005402  0.431986   \n",
            "3   BESM+kobert    0.091932  0.543959  0.426088  0.367169  0.005402  0.431986   \n",
            "\n",
            "    grammar  \n",
            "0  0.962518  \n",
            "1  0.998253  \n",
            "2  0.989553  \n",
            "3  0.989553  \n",
            "Current result ==================================================\n",
            "Sample count: 50\n",
            "         method  comp rate     intro      body  conclusion   isthmus  \\\n",
            "0      SAM+WGAN   0.148474  0.509073  0.478892    0.477206  0.007722   \n",
            "1  BERT+LexRank   0.208777  0.232218  0.213129    0.202047  0.007369   \n",
            "2          BESM   0.206032  0.446718  0.402434    0.374608  0.009416   \n",
            "3   BESM+kobert   0.211957  0.467173  0.406255    0.383743  0.009852   \n",
            "\n",
            "   simlirality  grammarity  \n",
            "0     0.484422    0.963506  \n",
            "1     0.213622    0.998935  \n",
            "2     0.402943    0.990529  \n",
            "3     0.411685    0.989917  \n",
            "==================================================\n",
            "56 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "지금 말한 일밖에 하지 않았소. ” “당신이 거기 들어가기 전에 누가 나오는 건 못 보셨습니까?” “못 보았소. 내가 말하고 싶은 건, 어째서 나에게 누명을 씌우려고……. ” 포아로는 일어섰다. “아무도 그러지 않습니다. 아직 지금 단계에서는. 그럼, 안녕히 계십시오. ” 그는 멍하니 입을 벌린 채 있는 사나이를 뒤에 남겨 두고 나왔다. 나는 그 뒤를 따랐다. 길로 나오자 그는 시계를 보았다. “빨리 가면 7시 2분 기차를 탈 수 있겠군. 자, 서둘러 가세. ‘ < 두 번째 편지 > 나는 열심히 물었다. “그래서?” 우리는 우리 말고는 아무도 없는 1등 차칸에 앉아 있었다. 기차는 급행으로 막 앤도버를 떠난 참이었다. 포아로가 말했다. “범죄는 빨강 머리에 왼쪽 눈이 사팔뜨기인 중키의 사나이에 의해 저질러졌네. 그 사나이는 오른쪽 다리를 조금 절고, 왼쪽 어때 밑에 점이 있지. ” 나는 소리쳤다. “포아로!” 한순간 나는 정말로 믿어 버렸던 것이다.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.263277292251587 Generator / grammar loss:-0.12474145740270615   similarity loss:-0.09826003760099411\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "지금 말한 일밖에 하지 않았소. 거기 “못 보았소. 나에게 씌우려고……. 보았다. 탈 자, 서둘러 < 나는 열심히 말했다.\n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "그 사나이는 오른쪽 다리를 조금 절고, 왼쪽 어때 밑에 점이 있지.“범죄는 빨강 머리에 왼쪽 눈이 사팔뜨기인 중키의 사나이에 의해 저질러졌네.“그래서?” 우리는 우리 말고는 아무도 없는 1등 차칸에 앉아 있었다.기차는 급행으로 막 앤도버를 떠난 참이었다.길로 나오자 그는 시계를 보았다.\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "우리는 우리 말고는 아무도 없는 1등 차칸에 앉아 있었다.기차는 급행으로 막 앤도버를 떠난 참이었다. 범죄는 빨강 머리에 왼쪽 눈이 사팔뜨기인 중키의 사나이에 의해 저질러졌네.\n",
            "--------------------------------------------------\n",
            "besm_bert summary:\n",
            "우리는 우리 말고는 아무도 없는 1등 차칸에 앉아 있었다.기차는 급행으로 막 앤도버를 떠난 참이었다. 범죄는 빨강 머리에 왼쪽 눈이 사팔뜨기인 중키의 사나이에 의해 저질러졌네.\n",
            "--------------------------------------------------\n",
            "         method  comp ratio     intro      body    ending       var     total  \\\n",
            "0      SAM+WGAN    0.141372  0.702510  0.539977  0.394059  0.015872  0.528708   \n",
            "1  BERT+LexRank    0.332640  0.161837  0.161680  0.298036  0.004127  0.202618   \n",
            "2          BESM    0.203742  0.272268  0.253242  0.417116  0.005355  0.306209   \n",
            "3   BESM+kobert    0.203742  0.272268  0.253242  0.417116  0.005355  0.306209   \n",
            "\n",
            "    grammar  \n",
            "0  0.984165  \n",
            "1  0.998924  \n",
            "2  0.997970  \n",
            "3  0.997970  \n",
            "Current result ==================================================\n",
            "Sample count: 51\n",
            "         method  comp rate     intro      body  conclusion   isthmus  \\\n",
            "0      SAM+WGAN   0.148335  0.512866  0.480090    0.475576  0.007882   \n",
            "1  BERT+LexRank   0.211206  0.230838  0.212120    0.203929  0.007306   \n",
            "2          BESM   0.205987  0.443298  0.399509    0.375442  0.009336   \n",
            "3   BESM+kobert   0.211796  0.463351  0.403255    0.384397  0.009764   \n",
            "\n",
            "   simlirality  grammarity  \n",
            "0     0.485291    0.963911  \n",
            "1     0.213406    0.998935  \n",
            "2     0.401046    0.990675  \n",
            "3     0.409617    0.990075  \n",
            "==================================================\n",
            "57 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "그러나 곧 이 친구의 장난기 어린 눈빛이 사실을 가르쳐 주었다. 나는 되풀이했다. 이번에는 나무라듯이 “포아로!” “자네는 어떻게 하자는 건가? 자네는 나에게 충성스러운 개같이 헌신적인 눈길을 보내면서 셜록 홈즈 같은 해결을 바라고 있네. 그런데 진상은 말일세. 살인범이 어떤 사니이며, 어디에 살고, 어떻게 하면 잡을 수 있는지 나는 도무지 알 수 없네. ” 나는 중얼거렸다. “녀석이 무슨 단서라도 남겨 줬더라면. ‘ 그렇지, 단서. 언제나 자네 마음을 끄는 건 그 단서라는 걸세. 유감스럽게도 그 사나이는 담배를 피워 담뱃재를 남겨 둬 주지도 않았고, 야릇한 모양의 징을 박은 신 자국도 남겨 주지 않았네. 그렇지, 그는 그리 친절하지 않았어. 그러나 적어도 철도 안내서가 있잖나. 그 ABC야말로 자네의 단서가 아니겠나!“ “그가 실수해서 그것을 남겨 뒀다고 생각하나?” “물론 그렇지는 않네. 일부러 두고 간 걸세. 지문 상태를 보면 알 수 있지. ” “지문이 없었잖나?” “바로 그걸세. 어제는 어떤 밤이었나? 더운 6월의 밤이었지. 이런 밤에 장갑을 끼고 다니는 사나이가 있을까?\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.4254846572875977 Generator / grammar loss:-0.14632628858089447   similarity loss:-0.10311789065599442\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "그러나 사실을 하자는 자네는 나에게 해결을 바라고 있네. 말일세. 박은 자국도 일부러 간 걸세. 상태를 보면 “지문이 없었잖나?” 그걸세. 어떤 사나이가\n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "더운 6월의 밤이었지.살인범이 어떤 사니이며, 어디에 살고, 어떻게 하면 잡을 수 있는지 나는 도무지 알 수 없네.그러나 적어도 철도 안내서가 있잖나.유감스럽게도 그 사나이는 담배를 피워 담뱃재를 남겨 둬 주지도 않았고, 야릇한 모양의 징을 박은 신 자국도 남겨 주지 않았네.\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "자네는 나에게 충성스러운 개같이 헌신적인 눈길을 보내면서 셜록 홈즈 같은 해결을 바라고 있네.그런데 진상은 말일세. 살인범이 어떤 사니이며, 어디에 살고, 어떻게 하면 잡을 수 있는지 나는 도무지 알 수 없네. ”\n",
            "--------------------------------------------------\n",
            "besm_bert summary:\n",
            "자네는 나에게 충성스러운 개같이 헌신적인 눈길을 보내면서 셜록 홈즈 같은 해결을 바라고 있네.그런데 진상은 말일세. 살인범이 어떤 사니이며, 어디에 살고, 어떻게 하면 잡을 수 있는지 나는 도무지 알 수 없네. ”\n",
            "--------------------------------------------------\n",
            "         method  comp ratio     intro      body    ending       var     total  \\\n",
            "0      SAM+WGAN    0.153153  0.499548  0.452040  0.502059  0.000529  0.476547   \n",
            "1  BERT+LexRank    0.277477  0.095438  0.251706  0.215154  0.004454  0.209487   \n",
            "2          BESM    0.214414  0.622718  0.472904  0.297320  0.017684  0.450191   \n",
            "3   BESM+kobert    0.214414  0.622718  0.472904  0.297320  0.017684  0.450191   \n",
            "\n",
            "    grammar  \n",
            "0  0.993840  \n",
            "1  0.999029  \n",
            "2  0.995588  \n",
            "3  0.995588  \n",
            "Current result ==================================================\n",
            "Sample count: 52\n",
            "         method  comp rate     intro      body  conclusion   isthmus  \\\n",
            "0      SAM+WGAN   0.148428  0.512609  0.479550    0.476085  0.007740   \n",
            "1  BERT+LexRank   0.212480  0.228234  0.212882    0.204145  0.007251   \n",
            "2          BESM   0.206149  0.446748  0.400920    0.373939  0.009497   \n",
            "3   BESM+kobert   0.211847  0.466416  0.404594    0.382722  0.009916   \n",
            "\n",
            "   simlirality  grammarity  \n",
            "0     0.485122    0.964486  \n",
            "1     0.213331    0.998937  \n",
            "2     0.401992    0.990769  \n",
            "3     0.410397    0.990181  \n",
            "==================================================\n",
            "58 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "그런 사나이는 곧 눈에 띄지. 그러니까 ABC에 지문이 없었다면 주의깊게 닦아 낸 게 틀림없네. 죄없는 남자라면 지문을 남겨 두겠지만, 죄가 있는 자는 남기지 않네. 그러므로 우리의 살인범은 그것을 일부러 남겨두고 간 걸세. 그러나 그 때문에 이것이 또 한 단서가 되지. ABC는 누군가가 사서 갖다 두었다……이런 가능성이 있는 셈일세. ” “그 방법으로 무엇을 알 수 있나?” “사실을 말하면, 헤이스팅즈. 나는 그리 희망을 가지고 있지 않네. 이 사나이, 이 미지의 X라는 사나이는 확실히 자기 능력에 자부심을 갖고 있네. 그는 뒤를 밟힐 그런 따위의 표시를 남겨 두지 않아. ” “그렇다면 ABC는 전혀 희망이 없는가?” “자네가 말하는 뜻에서는. ” “다른 뜻에서라면 있다는 건가?” 포아로는 곧바로 대답하지 않았다. 이윽고 그는 천천히 말했다. “그 답은 <있다>일세. 우리는 지금 미지의 인물과 마주하고 있네. 상대는 어둠 속에 있고, 언제까지나 어둠 속에 있으려 하지. 그러나 일의 성질로 보아 그는 자기에게 빛을 비추지 않고는 견디지 못할 걸세. 어떤 뜻에서는 이미 많은 것을 알고 있지. 나에게는 그의 모습이 흐릿하게 형태를 갖추어 오는 게 보인다네. 올바른 활자체를 달필로 쓸 수 있는 사나이?그것을 부당하게 느끼며 싸워 온 사나이가 내 눈에 보이네.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.411684274673462 Generator / grammar loss:-0.1311788707971573   similarity loss:-0.08941374719142914\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "그런 사나이는 눈에 띄지. 지문이 없었다면 닦아 낸 게 죄없는 자는 않네. 살인범은 그것을 걸세. 때문에 또 사서 X라는 능력에 “그렇다면 말하는 뜻에서는. ”\n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "ABC는 누군가가 사서 갖다 두었다……이런 가능성이 있는 셈일세.올바른 활자체를 달필로 쓸 수 있는 사나이?그것을 부당하게 느끼며 싸워 온 사나이가 내 눈에 보이네.” “그렇다면 ABC는 전혀 희망이 없는가?” “자네가 말하는 뜻에서는.어떤 뜻에서는 이미 많은 것을 알고 있지.\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "그러므로 우리의 살인범은 그것을 일부러 남겨두고 간 걸세.그러나 그 때문에 이것이 또 한 단서가 되지. 올바른 활자체를 달필로 쓸 수 있는 사나이?그것을 부당하게 느끼며 싸워 온 사나이가 내 눈에 보이네.\n",
            "--------------------------------------------------\n",
            "besm_bert summary:\n",
            "그러므로 우리의 살인범은 그것을 일부러 남겨두고 간 걸세.그러나 그 때문에 이것이 또 한 단서가 되지. 이 사나이, 이 미지의 x라는 사나이는 확실히 자기 능력에 자부심을 갖고 있네.\n",
            "--------------------------------------------------\n",
            "         method  comp ratio     intro      body    ending       var     total  \\\n",
            "0      SAM+WGAN    0.136086  0.782654  0.417893  0.428541  0.028729  0.494040   \n",
            "1  BERT+LexRank    0.237003  0.324332  0.281168  0.263336  0.000656  0.284451   \n",
            "2          BESM    0.174312  0.533744  0.287474  0.407462  0.010110  0.372724   \n",
            "3   BESM+kobert    0.155963  0.595724  0.342680  0.337920  0.014502  0.391861   \n",
            "\n",
            "    grammar  \n",
            "0  0.971818  \n",
            "1  0.999027  \n",
            "2  0.999019  \n",
            "3  0.999011  \n",
            "Current result ==================================================\n",
            "Sample count: 53\n",
            "         method  comp rate     intro      body  conclusion   isthmus  \\\n",
            "0      SAM+WGAN   0.148195  0.517705  0.478387    0.475188  0.008136   \n",
            "1  BERT+LexRank   0.212943  0.230047  0.214170    0.205262  0.007126   \n",
            "2          BESM   0.205548  0.448389  0.398780    0.374572  0.009508   \n",
            "3   BESM+kobert   0.210792  0.468856  0.403426    0.381877  0.010003   \n",
            "\n",
            "   simlirality  grammarity  \n",
            "0     0.485291    0.964625  \n",
            "1     0.214673    0.998939  \n",
            "2     0.401439    0.990925  \n",
            "3     0.410047    0.990347  \n",
            "==================================================\n",
            "59 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "자신을 주장하고 남의 관심을 끌고 싶은 마음속 충동이 점점 강해지고, 사건이며 사물이 그것을 부숴 버려 한층 더 비굴한 감정을 쌓아 올려 간 것이 내 눈에는 보이네. 그리하여 내부의 성냥이 이 화약을 실은 열차에 불을 붙이게 된 걸세. ‘ 나는 반대했다. 그런 것은 모두 억측에 지나지 않잖나. 실제로는 아무 쓸모도 없어. “ “자네는 성냥 끄트러기라든가 담뱃재라든가 징 박은 구두 쪽이 마음에 드는가 보군. 그러나 적어도 우리는 스스로 실제적인 질문을 해보지 않으면 안 되네. 어째서 ABC인가? 어째서 애셔 부인인가? 어째서 앤도버인가?” “그 여자의 과거 생활은 아주 단순해 보이네. ” 나는 생각에 잠겼다. “그 두 남자와의 면담은 실망이었어. 그들은 우리가 이미 알고 있는 것 이상의 일은 아무것도 말하지 못했잖아. ” “사실을 말하면 나는 그들에게 큰 기대를 걸고 있지 않았네. 그러나 살인 후보자로서의 두 사람의 가능성을 무시할 수도 없었지. ‘ “자네는 정말로……. ” “적어도 범인이 앤도버 또는 그 언저리에 살고 있을 가능성은 있는 걸세. 그것이 어째서 앤도버인가 하는 우리들의 질문에 대한 가능한 대답이 되네. 게다가 그날 그 시간 가게에 있었던 것으로 알려진 사나이가 둘이나 있는 걸세. 그 어느 쪽이 범인일지도 모르잖나.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.526705265045166 Generator / grammar loss:-0.13651283085346222   similarity loss:-0.08257132768630981\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "관심을 점점 버려 감정을 올려 간 것이 보이네. 이 실은 불을 붙이게 아무 담뱃재라든가 보군. 그러나 우리는 실제적인 “그 여자의 두 실망이었어. 우리가 정말로…….\n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "그리하여 내부의 성냥이 이 화약을 실은 열차에 불을 붙이게 된 걸세.게다가 그날 그 시간 가게에 있었던 것으로 알려진 사나이가 둘이나 있는 걸세.어째서 ABC인가?“그 두 남자와의 면담은 실망이었어.\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "자신을 주장하고 남의 관심을 끌고 싶은 마음속 충동이 점점 강해지고, 사건이며 사물이 그것을 부숴 버려 한층 더 비굴한 감정을 쌓아 올려 간 것이 내 눈에는 보이네. 그들은 우리가 이미 알고 있는 것 이상의 일은 아무것도 말하지 못했잖아. ” “\n",
            "--------------------------------------------------\n",
            "besm_bert summary:\n",
            "자신을 주장하고 남의 관심을 끌고 싶은 마음속 충동이 점점 강해지고, 사건이며 사물이 그것을 부숴 버려 한층 더 비굴한 감정을 쌓아 올려 간 것이 내 눈에는 보이네. 게다가 그날 그 시간 가게에 있었던 것으로 알려진 사나이가 둘이나 있는 걸세.\n",
            "--------------------------------------------------\n",
            "         method  comp ratio     intro      body    ending       var     total  \\\n",
            "0      SAM+WGAN    0.143750  0.540220  0.394053  0.309739  0.009066  0.397992   \n",
            "1  BERT+LexRank    0.173437  0.273625  0.140452  0.161990  0.003407  0.173548   \n",
            "2          BESM    0.214062  0.577444  0.431163  0.382758  0.006849  0.445897   \n",
            "3   BESM+kobert    0.212500  0.476028  0.184535  0.396194  0.015127  0.306331   \n",
            "\n",
            "    grammar  \n",
            "0  0.991290  \n",
            "1  0.999033  \n",
            "2  0.995231  \n",
            "3  0.999019  \n",
            "Current result ==================================================\n",
            "Sample count: 54\n",
            "         method  comp rate     intro      body  conclusion   isthmus  \\\n",
            "0      SAM+WGAN   0.148112  0.518122  0.476825    0.472124  0.008153   \n",
            "1  BERT+LexRank   0.212212  0.230854  0.212805    0.204461  0.007058   \n",
            "2          BESM   0.205706  0.450779  0.399379    0.374723  0.009459   \n",
            "3   BESM+kobert   0.210824  0.468989  0.399373    0.382142  0.010098   \n",
            "\n",
            "   simlirality  grammarity  \n",
            "0     0.483674    0.965118  \n",
            "1     0.213911    0.998940  \n",
            "2     0.402263    0.991005  \n",
            "3     0.408127    0.990508  \n",
            "==================================================\n",
            "60 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "그리고 그 가운데 어느 쪽인가가 범인이 아님을 알리는 표시는 아직 아무것도 나타나지 않았으니 말일세. ‘ 나는 인정했다. “그 꼴사나운 짐승 같은 리딜일지도 모르지. ” “그런데 나는 리딜은 풀어줘도 좋다고 생각하고 있네. 그는 신경질적이고 큰소리를 치며 분명 초조해 있었어. ” “그러나 그것은 확실히……. ” “그 ABC 편지를 쓰는 그런 자와는 정반대의 성격일세. 자신감과 자부심이 우리가 찾고 있는 특징이지. ” “누군가 자신의 중대성을 알리고 싶어하는 사람이란 말인가?” “아마도 그럴 걸세. 그러나 어떤 종류의 사람들은 신경질적이고 겸손한 속에 오히려 크나큰 허영심과 자기만족을 숨기고 있기도 하지. ” “그 몸집 작은 패트리지 씨는 어떤가?” “그 사나이 쪽이 그런 타입에 가까워. 그 이상은 말할 수 없지만. 그는 마치 그 편지를 쓴 자가 할 것 같은 행동을 취하고 있었지. 바로 경찰에 갔고, 자기를 돋보이려 했으며, 자기 위치를 즐기고 있었거든. ” “정말로 그렇게 생각하나?” “아니, 헤이스팅즈. 내 개인적으로는 범인이 앤도버 밖에서 왔다고 생각하지만 어떤 수사도 소홀히 할 수 없네. 그리고 나는 언제나 <그>라고 말하고 있지만, 여성이 관계해 있을 가능성도 빼놓을 수 없네. ” “설마!” “물론 공격 수법으로 보아선 남자일세. 그러나 익명 편지란 남자보다 오히려 여자에 의해 잘 씌어지는 법이지. 이 사실을 머리에 넣어두지 않으면 안 되네.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.437723159790039 Generator / grammar loss:-0.146023228764534   similarity loss:-0.10153119266033173\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "그리고 그 범인이 아직 나타나지 ‘ 나는 인정했다. “그 꼴사나운 짐승 같은 ” “그런데 생각하고 있네. 그는 ” “그러나 그것은 ABC 자와는 성격일세. 걸세. 하지. 수 없네.\n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "” “그 ABC 편지를 쓰는 그런 자와는 정반대의 성격일세.그러나 익명 편지란 남자보다 오히려 여자에 의해 잘 씌어지는 법이지.‘ 나는 인정했다.이 사실을 머리에 넣어두지 않으면 안 되네.\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "그리고 그 가운데 어느 쪽인가가 범인이 아님을 알리는 표시는 아직 아무것도 나타나지 않았으니 말일세. ‘ 그리고 나는 언제나 <그>라고 말하고 있지만, 여성이 관계해 있을 가능성도 빼놓을 수 없네. ” “\n",
            "--------------------------------------------------\n",
            "besm_bert summary:\n",
            "그리고 그 가운데 어느 쪽인가가 범인이 아님을 알리는 표시는 아직 아무것도 나타나지 않았으니 말일세. ‘ 그런데 나는 리딜은 풀어줘도 좋다고 생각하고 있네.그는 신경질적이고 큰소리를 치며 분명 초조해 있었어. ” “ 바로 경찰에 갔고, 자기를 돋보이려 했으며, 자기 위치를 즐기고 있었거든.” “\n",
            "--------------------------------------------------\n",
            "         method  comp ratio     intro      body    ending       var     total  \\\n",
            "0      SAM+WGAN    0.141044  0.642430  0.491857  0.436208  0.007588  0.505277   \n",
            "1  BERT+LexRank    0.148096  0.170011  0.243813  0.344757  0.005130  0.259336   \n",
            "2          BESM    0.160790  0.592258  0.364934  0.494975  0.008672  0.449411   \n",
            "3   BESM+kobert    0.232722  0.588496  0.471930  0.369877  0.007977  0.464627   \n",
            "\n",
            "    grammar  \n",
            "0  0.988344  \n",
            "1  0.999039  \n",
            "2  0.995240  \n",
            "3  0.999011  \n",
            "Current result ==================================================\n",
            "Sample count: 55\n",
            "         method  comp rate     intro      body  conclusion   isthmus  \\\n",
            "0      SAM+WGAN   0.147984  0.520382  0.477098    0.471471  0.008143   \n",
            "1  BERT+LexRank   0.211046  0.229748  0.213369    0.207012  0.007022   \n",
            "2          BESM   0.204889  0.453352  0.398753    0.376910  0.009445   \n",
            "3   BESM+kobert   0.211222  0.471161  0.400692    0.381919  0.010059   \n",
            "\n",
            "   simlirality  grammarity  \n",
            "0     0.484067    0.965541  \n",
            "1     0.214737    0.998942  \n",
            "2     0.403120    0.991082  \n",
            "3     0.409154    0.990662  \n",
            "==================================================\n",
            "61 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "” 나는 잠시 입을 다물고 있다가 말했다. “이번엔 뭘 하면 되나?” “오, 정력가 헤이스팅즈여. ” 포아로는 나에게 미소를 보냈다. “아니, 정말 뭘 하지?” “아무것도. ” “아무것도?” 내 목소리에는 뚜렷한 실망이 나타나 있었다. “내가 마술사인가, 마법사인가? 내게 뭘 시키고 싶은가?” 마음속으로 사태를 잘 생각해 보고 나서 나는 대답하기 힘들다는 것을 알았다. 그러나 나는 뭔가 하지 않으면 안 된다. 발밑에 풀이 나게 해선 안 된다는 확신을 가지고 있었다. 나는 말했다. “ABC도 있고, 편지지도 있고, 봉투도 있고……. ” “그 점에서는 물론 여러 가지 수배가 되어 있네. 경찰은 그런 종류의 수사를 하는 데 자유스러운 여러 가지 수단을 갖고 있지. 그런 점에서 무엇이 발견된다면 그들이 찾아내 줄 테니 걱정할 것 없네. ” 그래서 나 또한 만족하는 수밖에 없었다. 그뒤 며칠동안 이상하게도 포아로는 사건에 대한 토론을 피하는 듯했다. 내가 그 문제를 꺼내려 하면 못 참겠는지 손을 흔들며 말머리를 돌려 버렸다. 나는 그 까닭을 깊이 생각해 보기를 은근히 두려워하고 있었다. 애셔 부인 살해에 대해서는 포아로도 자신의 패배를 인정하고 있었다. ABC가 그에게 도전했고, 그리고 이겼다.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.291031837463379 Generator / grammar loss:-0.11968646198511124   similarity loss:-0.09037520736455917\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            " ” 말했다. “이번엔 하면 되나?” “오, 헤이스팅즈여. 포아로는 정말 뭘 “아무것도. 뚜렷한 마법사인가? 내게 시키고 알았다. 뭔가 말했다. 수배가 버렸다.\n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "“내가 마술사인가, 마법사인가?경찰은 그런 종류의 수사를 하는 데 자유스러운 여러 가지 수단을 갖고 있지.“ABC도 있고, 편지지도 있고, 봉투도 있고…….ABC가 그에게 도전했고, 그리고 이겼다.\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "마음속으로 사태를 잘 생각해 보고 나서 나는 대답하기 힘들다는 것을 알았다. 경찰은 그런 종류의 수사를 하는 데 자유스러운 여러 가지 수단을 갖고 있지.\n",
            "--------------------------------------------------\n",
            "besm_bert summary:\n",
            "마음속으로 사태를 잘 생각해 보고 나서 나는 대답하기 힘들다는 것을 알았다. 내가 그 문제를 꺼내려 하면 못 참겠는지 손을 흔들며 말머리를 돌려 버렸다.\n",
            "--------------------------------------------------\n",
            "         method  comp ratio     intro      body    ending       var     total  \\\n",
            "0      SAM+WGAN    0.144481  0.702590  0.506746  0.437148  0.012629  0.525035   \n",
            "1  BERT+LexRank    0.178571  0.083921  0.238218  0.130865  0.004171  0.175153   \n",
            "2          BESM    0.137987  0.341557  0.471788  0.424944  0.002901  0.431689   \n",
            "3   BESM+kobert    0.137987  0.318436  0.322052  0.506024  0.007672  0.376520   \n",
            "\n",
            "    grammar  \n",
            "0  0.972454  \n",
            "1  0.999016  \n",
            "2  0.999015  \n",
            "3  0.999007  \n",
            "Current result ==================================================\n",
            "Sample count: 56\n",
            "         method  comp rate     intro      body  conclusion   isthmus  \\\n",
            "0      SAM+WGAN   0.147921  0.523635  0.477628    0.470858  0.008223   \n",
            "1  BERT+LexRank   0.210466  0.227144  0.213812    0.205652  0.006972   \n",
            "2          BESM   0.203694  0.451355  0.400057    0.377768  0.009328   \n",
            "3   BESM+kobert   0.209914  0.468434  0.399288    0.384135  0.010017   \n",
            "\n",
            "   simlirality  grammarity  \n",
            "0     0.484798    0.965664  \n",
            "1     0.214030    0.998944  \n",
            "2     0.403630    0.991223  \n",
            "3     0.408571    0.990811  \n",
            "==================================================\n",
            "62 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "잇따른 성공에 익숙해 있던 내 친구는 자기 실패에 민감했다. 그런 만큼 그는 이 문제에 대한 토론을 참을 수 없었던 것이다. 그것은 분명 위대한 남자의 왜소함을 나타내는 일임에 틀림없지만, 아무리 냉정한 사람일지라도 성공했을 때 흥분되는 것은 흔히 있는 일이다. 포아로의 경우는 그 흥분이 몇 해나 계속 되고 있었다. 포아로의 경우는 그 흥분이 몇 해나 계속 되고 있었다. 그 결과 지금에야 겨우 눈을 뜨게 되었다 해도 그리 이상할 것은 없으리라. 나는 친구의 약점을 존중하여 사건에 대해 그 이상 이야기하는 것을 삼갔다. 심문 보고는 신문에서 읽었다. 그것은 무척 간단한 것으로, ABC 편지에 대해서도 아무 언급이 없었다. 배심원 평결은 한 사람 또는 몇 사람의 알 수 없는 인물에 의한 살인으로 되어 있었다. 이 사건은 신문의 여러 기사들 속에서 그리 주의를 끌지 못했다. 이야깃거리가 될 듯한 데도, 구경거리가 될 듯한 데도 없었다. 뒷골목의 노파 살해 따윈 더 스릴 있는 화제 때문에 곧 흐지부지되어 버리는 것이다. 사실을 말하면, 사건은 내 머리 속에서도 사라져 가고 있었다. 그것은 포아로가 실패했다고 생각하는 게 싫었기 때문이라고도 할 수 있다. 그런데 7월 25일이 되어 사건은 갑자기 되살아났다. 나는 주말에 요크셔에 가 있었기 때문에 이틀쯤 포아로를 만나지 못했다. 월요일 오후에 돌아왔는데, 그 편지는 6시 우편으로 배달되었다. 나는 문제의 봉투를 뜯어 펼쳐 보았을 때 포아로가 갑자기 날카롭게 숨을 들이 쉬었던 것을 기억하고 있다. “왔네.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.3846516609191895 Generator / grammar loss:-0.14043587446212769   similarity loss:-0.10148563981056213\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            " 내 민감했다. 그는 이 참을 수 없었던 것이다. 그것은 사람일지라도 일이다. 포아로의 이상할 심문 한 주의를 못했다. 이야깃거리가 내 속에서도 사라져 되어 갑자기 나는 포아로를 만나지 못했다. 오후에 “왔네.\n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "월요일 오후에 돌아왔는데, 그 편지는 6시 우편으로 배달되었다.“왔네.그런데 7월 25일이 되어 사건은 갑자기 되살아났다.그것은 무척 간단한 것으로, ABC 편지에 대해서도 아무 언급이 없었다.\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "그것은 분명 위대한 남자의 왜소함을 나타내는 일임에 틀림없지만, 아무리 냉정한 사람일지라도 성공했을 때 흥분되는 것은 흔히 있는 일이다. 배심원 평결은 한 사람 또는 몇 사람의 알 수 없는 인물에 의한 살인으로 되어 있었다. 나는 문제의 봉투를 뜯어 펼쳐 보았을 때 포아로가 갑자기 날카롭게 숨을 들이 쉬었던 것을 기억하고 있다. “\n",
            "--------------------------------------------------\n",
            "besm_bert summary:\n",
            "그것은 분명 위대한 남자의 왜소함을 나타내는 일임에 틀림없지만, 아무리 냉정한 사람일지라도 성공했을 때 흥분되는 것은 흔히 있는 일이다. 나는 문제의 봉투를 뜯어 펼쳐 보았을 때 포아로가 갑자기 날카롭게 숨을 들이 쉬었던 것을 기억하고 있다. “\n",
            "--------------------------------------------------\n",
            "         method  comp ratio     intro      body    ending       var     total  \\\n",
            "0      SAM+WGAN    0.153342  0.512182  0.489242  0.458696  0.000480  0.484666   \n",
            "1  BERT+LexRank    0.141547  0.069567  0.249306  0.386371  0.016829  0.254478   \n",
            "2          BESM    0.243775  0.622193  0.414700  0.543467  0.007315  0.494829   \n",
            "3   BESM+kobert    0.179554  0.622193  0.294700  0.516802  0.018632  0.426829   \n",
            "\n",
            "    grammar  \n",
            "0  0.983406  \n",
            "1  0.999014  \n",
            "2  0.993886  \n",
            "3  0.988902  \n",
            "Current result ==================================================\n",
            "Sample count: 57\n",
            "         method  comp rate     intro      body  conclusion   isthmus  \\\n",
            "0      SAM+WGAN   0.148016  0.523434  0.477832    0.470645  0.008087   \n",
            "1  BERT+LexRank   0.209257  0.224379  0.214435    0.208822  0.007144   \n",
            "2          BESM   0.204398  0.454353  0.400314    0.380675  0.009293   \n",
            "3   BESM+kobert   0.209382  0.471132  0.397453    0.386463  0.010168   \n",
            "\n",
            "   simlirality  grammarity  \n",
            "0     0.484796    0.965975  \n",
            "1     0.214740    0.998945  \n",
            "2     0.405230    0.991270  \n",
            "3     0.408892    0.990778  \n",
            "==================================================\n",
            "63 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "” 그가 말했다. 나는 그를 쳐다보았으나 잘 알 수가 없었다. “뭐가 왔다는 건가?” “ABC 사건의 제2장일세. ” 나는 잠시 멍해진 채 그를 보고 있엇다. 사건은 완전히 내 기억에서 떨어져 나가 있었던 것이다. “읽어보게. ” 포아로는 나에게 편지를 건네주었다. 전과 마찬가지로 좋은 편지지에 활자체로 씌어 있었다. 친애하는 포아로여, 대체 어떻게 된 건가? 첫 번째 게임은 내 승리다. 앤도버 사건은 실로 잘 되었잖은가? 그러나 재미는 이제 시작이다. 이번에는 벡스힐 바닷가로 주의를 돌리도록. 날짜는 오는 25일. 이 얼마나 유쾌한 일인가! 이만. ABC 나는 소리쳤다. “이런, 포아로! 이 미치광이는 또 다른 범죄를 저지르려는 게 아닌가?” “물론이지, 헤이스팅즈. 자네는 어떻게 생각하고 있었나?\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.3237075805664062 Generator / grammar loss:-0.10751805454492569   similarity loss:-0.0748601034283638\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            " 건가?” 사건의 제2장일세. 그를 내 떨어져 나가 “읽어보게. 포아로여, 실로 바닷가로\n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "날짜는 오는 25일.이 얼마나 유쾌한 일인가!전과 마찬가지로 좋은 편지지에 활자체로 씌어 있었다.이만.나는 그를 쳐다보았으나 잘 알 수가 없었다.\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "나는 잠시 멍해진 채 그를 보고 있엇다.사건은 완전히 내 기억에서 떨어져 나가 있었던 것이다. “\n",
            "--------------------------------------------------\n",
            "besm_bert summary:\n",
            "나는 잠시 멍해진 채 그를 보고 있엇다.사건은 완전히 내 기억에서 떨어져 나가 있었던 것이다. “\n",
            "--------------------------------------------------\n",
            "         method  comp ratio     intro      body    ending       var     total  \\\n",
            "0      SAM+WGAN    0.123737  0.402240  0.394627  0.412583  0.000054  0.401536   \n",
            "1  BERT+LexRank    0.204545  0.232221  0.318607  0.073131  0.010337  0.227687   \n",
            "2          BESM    0.136364  0.662386  0.399030  0.496337  0.011822  0.480893   \n",
            "3   BESM+kobert    0.136364  0.662386  0.399030  0.496337  0.011822  0.480893   \n",
            "\n",
            "    grammar  \n",
            "0  0.969740  \n",
            "1  0.998862  \n",
            "2  0.961957  \n",
            "3  0.961957  \n",
            "Current result ==================================================\n",
            "Sample count: 58\n",
            "         method  comp rate     intro      body  conclusion   isthmus  \\\n",
            "0      SAM+WGAN   0.147598  0.521345  0.476397    0.469644  0.007949   \n",
            "1  BERT+LexRank   0.209176  0.224514  0.216231    0.206483  0.007200   \n",
            "2          BESM   0.203225  0.457939  0.400292    0.382669  0.009336   \n",
            "3   BESM+kobert   0.208123  0.474429  0.397480    0.388357  0.010196   \n",
            "\n",
            "   simlirality  grammarity  \n",
            "0     0.483361    0.966040  \n",
            "1     0.214963    0.998943  \n",
            "2     0.406535    0.990765  \n",
            "3     0.410133    0.990281  \n",
            "==================================================\n",
            "64 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "앤도버 사건 하나로 끝날 줄 여겼나? 자네는 내가 말한 걸 기억하고 있겠지. <무서운 시작이다>라고. ” “무서운 일이군. ” “그렇네, 무서운 일일세. ” “우리는 살인광을 상대하고 있어. ” “바로 그렇네. ” 그의 냉정함은 어떤 극적인 태도보다도 인상적이었다. 나는 편지를 돌려주며 몸을 떨었다. 다음날 아침, 담당자들의 회의가 열렸다. 서섹스 주 경찰서장, 범죄 수사과장, 앤도버의 글렌 형사, 서섹스 경찰의 카터 경감, 재프 경감과 크롬이라는 이름의 젊은 형사, 그리고 저명한 정신과의 솜프슨 박사가 한 자리에 모였다. 편지의 소인은 햄스티드로 되어 있었지만, 포아로의 의견으로 이것은 그리 중요시되지 않았다. 사건은 충분히 검토되었다. 솜프슨 박사는 인상 좋은 중년 신사로, 그 풍부한 학식에도 불구하고 직업상의 전문용어를 피해 아주 평범한 말을 쓰도록 마음 쓰고 있었다. 범죄 수사과장이 말했다. “이 두 편지가 같은 필적임은 틀림없습니다. 둘 다 한 인물에 의해 씌어진 겁니다. 그리고 그 인물이 앤도버 살인 사건에 관련해 있는 것도 확실합니다. ” “과연 그렇습니다. 우리는 지금 또다른 명백한 두 번째의 계획적 살인 예고를 받고 있습니다.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.339205026626587 Generator / grammar loss:-0.1329026073217392   similarity loss:-0.09865112602710724\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            " 앤도버 하나로 끝날 여겼나? ” “그렇네, 일일세. 상대하고 ” ” 냉정함은 어떤 극적인 태도보다도 인상적이었다. 다음날 열렸다. 검토되었다. “이 그렇습니다.\n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "솜프슨 박사는 인상 좋은 중년 신사로, 그 풍부한 학식에도 불구하고 직업상의 전문용어를 피해 아주 평범한 말을 쓰도록 마음 쓰고 있었다.범죄 수사과장이 말했다.편지의 소인은 햄스티드로 되어 있었지만, 포아로의 의견으로 이것은 그리 중요시되지 않았다.” 그의 냉정함은 어떤 극적인 태도보다도 인상적이었다.다음날 아침, 담당자들의 회의가 열렸다.\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "서섹스 주 경찰서장, 범죄 수사과장, 앤도버의 글렌 형사, 서섹스 경찰의 카터 경감, 재프 경감과 크롬이라는 이름의 젊은 형사, 그리고 저명한 정신과의 솜프슨 박사가 한 자리에 모였다. 그리고 그 인물이 앤도버 살인 사건에 관련해 있는 것도 확실합니다. ” “\n",
            "--------------------------------------------------\n",
            "besm_bert summary:\n",
            "서섹스 주 경찰서장, 범죄 수사과장, 앤도버의 글렌 형사, 서섹스 경찰의 카터 경감, 재프 경감과 크롬이라는 이름의 젊은 형사, 그리고 저명한 정신과의 솜프슨 박사가 한 자리에 모였다. 편지의 소인은 햄스티드로 되어 있었지만, 포아로의 의견으로 이것은 그리 중요시되지 않았다. 솜프슨 박사는 인상 좋은 중년 신사로, 그 풍부한 학식에도 불구하고 직업상의 전문용어를 피해 아주 평범한 말을 쓰도록 마음 쓰고 있었다.범죄 수사과장이 말했다. “\n",
            "--------------------------------------------------\n",
            "         method  comp ratio     intro      body    ending       var     total  \\\n",
            "0      SAM+WGAN    0.152284  0.598070  0.543099  0.465810  0.002943  0.530906   \n",
            "1  BERT+LexRank    0.323181  0.117389  0.329498  0.123643  0.009712  0.225320   \n",
            "2          BESM    0.245347  0.434844  0.423609  0.651441  0.010994  0.494206   \n",
            "3   BESM+kobert    0.416244  0.474295  0.609693  0.446849  0.005067  0.533760   \n",
            "\n",
            "    grammar  \n",
            "0  0.989618  \n",
            "1  0.999012  \n",
            "2  0.995308  \n",
            "3  0.993889  \n",
            "Current result ==================================================\n",
            "Sample count: 59\n",
            "         method  comp rate     intro      body  conclusion   isthmus  \\\n",
            "0      SAM+WGAN   0.147677  0.522645  0.477528    0.469579  0.007864   \n",
            "1  BERT+LexRank   0.211108  0.222699  0.218151    0.205079  0.007242   \n",
            "2          BESM   0.203939  0.457548  0.400687    0.387224  0.009364   \n",
            "3   BESM+kobert   0.211650  0.474427  0.401077    0.389349  0.010109   \n",
            "\n",
            "   simlirality  grammarity  \n",
            "0     0.484166    0.966440  \n",
            "1     0.215139    0.998945  \n",
            "2     0.408021    0.990842  \n",
            "3     0.412228    0.990342  \n",
            "==================================================\n",
            "65 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "그 살인은 오는 25일 벡스힐로 예정되어 있습니다. 어떤 수단을 취하면 좋겠습니까?” 서섹스 주 경찰서장이 자기 경감 쪽을 보았다. “카터, 어떻게 해야 할까?” 카터 경감은 무겁게 고개를 저었다. “어렵군요, 예정된 피해자에 대한 최소한의 단서도 없습니다. 정직하고 공정하게 말해서 과연 우리가 어떤 수단을 취할 수 있겠습니까?” 포아로가 나섰다. “힌트가 있습니다. ” 모두의 얼굴이 그에게로 돌려졌다. “예정된 피해자의 이름은 B로 시작된다고 여겨집니다. ” 수사과장이 의심스러운 듯 말했다. “그것은 다만 생각일 따름이지요. ” 솜프슨 박사가 생각에 잠겨 말했다. “알파벡 콤플렉스군요. ” “나는 단지 가능성으로 말하고 있는 겁니다. 그 이상은 아니지요. 이 생각은 지난달에 살해된 그 불운한 여자의 가게 문에 애셔라는 글자가 씌어져 있는 것을 보았을 때 떠오른 겁니다. 벡스힐이라고 장소를 정한 편지를 보고 피해자도 알파벳순으로 정해지리라는 게 하나의 가능성으로 떠올랐지요. ” “그것은 확실히 가능성이 있습니다. 그러나 동시에 애셔라는 이름은 우연의 일치였는지도 모릅니다. 이번 피해자의 이름이 무엇이든 또 가게를 가진 노파일지도 모르지요. 알겠습니까?\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.3641538619995117 Generator / grammar loss:-0.12937508523464203   similarity loss:-0.09254907816648483\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "예정되어 좋겠습니까?” 쪽을 보았다. 돌려졌다. 피해자의 “그것은 ” 박사가 “나는 겁니다. 그 이상은 이 생각은 여자의 문에 떠오른 겁니다. 이름이 알겠습니까?\n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "” 모두의 얼굴이 그에게로 돌려졌다.그 이상은 아니지요.이 생각은 지난달에 살해된 그 불운한 여자의 가게 문에 애셔라는 글자가 씌어져 있는 것을 보았을 때 떠오른 겁니다.그 살인은 오는 25일 벡스힐로 예정되어 있습니다.“알파벡 콤플렉스군요.\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "어렵군요, 예정된 피해자에 대한 최소한의 단서도 없습니다.정직하고 공정하게 말해서 과연 우리가 어떤 수단을 취할 수 있겠습니까?” 이 생각은 지난달에 살해된 그 불운한 여자의 가게 문에 애셔라는 글자가 씌어져 있는 것을 보았을 때 떠오른 겁니다.\n",
            "--------------------------------------------------\n",
            "besm_bert summary:\n",
            "어렵군요, 예정된 피해자에 대한 최소한의 단서도 없습니다.정직하고 공정하게 말해서 과연 우리가 어떤 수단을 취할 수 있겠습니까?” 이 생각은 지난달에 살해된 그 불운한 여자의 가게 문에 애셔라는 글자가 씌어져 있는 것을 보았을 때 떠오른 겁니다.\n",
            "--------------------------------------------------\n",
            "         method  comp ratio     intro      body    ending       var     total  \\\n",
            "0      SAM+WGAN    0.151007  0.307478  0.441422  0.455165  0.004438  0.418756   \n",
            "1  BERT+LexRank    0.226510  0.336779  0.064977  0.316430  0.015280  0.194773   \n",
            "2          BESM    0.229866  0.359552  0.087027  0.322685  0.014574  0.212229   \n",
            "3   BESM+kobert    0.229866  0.359552  0.087027  0.322685  0.014574  0.212229   \n",
            "\n",
            "    grammar  \n",
            "0  0.927695  \n",
            "1  0.999034  \n",
            "2  0.999018  \n",
            "3  0.999018  \n",
            "Current result ==================================================\n",
            "Sample count: 60\n",
            "         method  comp rate     intro      body  conclusion   isthmus  \\\n",
            "0      SAM+WGAN   0.147733  0.519059  0.476926    0.469338  0.007807   \n",
            "1  BERT+LexRank   0.211365  0.224600  0.215598    0.206935  0.007376   \n",
            "2          BESM   0.204371  0.455915  0.395460    0.386149  0.009451   \n",
            "3   BESM+kobert   0.211954  0.472512  0.395843    0.388238  0.010184   \n",
            "\n",
            "   simlirality  grammarity  \n",
            "0     0.483076    0.965794  \n",
            "1     0.214799    0.998946  \n",
            "2     0.404757    0.990978  \n",
            "3     0.408895    0.990487  \n",
            "==================================================\n",
            "66 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "우리는 한 미치광이를 상대하고 있습니다. 상대는 동기에 대한 실마리를 아무것도 나타내 보이고 있지 않습니다. ” 카터 경감이 의심스러운 듯 물었다. “미치광이에게도 동기가 있을까요?” “물론 있습니다. 편집광의 특징 가운데 하나는 아주 논리적이라는 겁니다. 그는 자신이 목사, 의사 도는 담배 가게 노파라도 좋은데, 이들을 죽이게끔 신에 의해 정해져 있다고 믿지요. 그 배후에는 하나같이 어떤 완전하고도 타당한 이유가 있는 법입니다. 그러니 우리는 알파벳 같은 것에 정신을 팔면 안 됩니다. 앤도버 다음이 벡스힐인 것은 아마 우연의 일치에 지나지 않을 겁니다. ” “우리는 적어도 그 경계만은 할 수 있는 셈이네, 카터. 특히 조그만 가게의 B로 시작되는 이름에 주의하여, 혼자서 경영하는 조그만 담배 가게라든가 신문 가게를 지키게. 그 밖에는 달리 우리가 할 수 있는 일이 없어. 낯선 사람을 특히 주의해야 할 것은 물론이지만. ” 카터 경감은 신음 소리를 냈다. “학교의 방학이 시작되었는데 말입니까? 이번 주일에는 그곳으로 굉장한 인파가 몰릴 겁니다. ” 경찰서장이 날카롭게 말했다. “우리는 할 수 있는 건 다 해야만 되네. ” 이번에는 글렌 형사가 말했다. “애셔 사건에 관계있는 사람은 제가 지키지요.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.573218584060669 Generator / grammar loss:-0.12909477949142456   similarity loss:-0.0701211541891098\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "미치광이를 실마리를 나타내 물었다. “물론 특징 가운데 논리적이라는 그는 의사 좋은데, 정해져 그 타당한 이유가 있는 알파벳 것에 팔면 됩니다. 담배\n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "그는 자신이 목사, 의사 도는 담배 가게 노파라도 좋은데, 이들을 죽이게끔 신에 의해 정해져 있다고 믿지요.이번 주일에는 그곳으로 굉장한 인파가 몰릴 겁니다.특히 조그만 가게의 B로 시작되는 이름에 주의하여, 혼자서 경영하는 조그만 담배 가게라든가 신문 가게를 지키게.상대는 동기에 대한 실마리를 아무것도 나타내 보이고 있지 않습니다.\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "그는 자신이 목사, 의사 도는 담배 가게 노파라도 좋은데, 이들을 죽이게끔 신에 의해 정해져 있다고 믿지요. 앤도버 다음이 벡스힐인 것은 아마 우연의 일치에 지나지 않을 겁니다. ” “\n",
            "--------------------------------------------------\n",
            "besm_bert summary:\n",
            "그는 자신이 목사, 의사 도는 담배 가게 노파라도 좋은데, 이들을 죽이게끔 신에 의해 정해져 있다고 믿지요. 앤도버 다음이 벡스힐인 것은 아마 우연의 일치에 지나지 않을 겁니다. ” “\n",
            "--------------------------------------------------\n",
            "         method  comp ratio     intro      body    ending       var     total  \\\n",
            "0      SAM+WGAN    0.133441  0.494021  0.343181  0.200014  0.014410  0.330399   \n",
            "1  BERT+LexRank    0.300643  0.168889  0.224390  0.057232  0.004832  0.163142   \n",
            "2          BESM    0.165595  0.335005  0.437246  0.338979  0.002236  0.387318   \n",
            "3   BESM+kobert    0.165595  0.335005  0.437246  0.338979  0.002236  0.387318   \n",
            "\n",
            "    grammar  \n",
            "0  0.980495  \n",
            "1  0.999034  \n",
            "2  0.995275  \n",
            "3  0.995275  \n",
            "Current result ==================================================\n",
            "Sample count: 61\n",
            "         method  comp rate     intro      body  conclusion   isthmus  \\\n",
            "0      SAM+WGAN   0.147498  0.518649  0.474733    0.464923  0.007915   \n",
            "1  BERT+LexRank   0.212828  0.223687  0.215742    0.204480  0.007334   \n",
            "2          BESM   0.203735  0.453932  0.396145    0.385375  0.009333   \n",
            "3   BESM+kobert   0.211194  0.470258  0.396521    0.387430  0.010053   \n",
            "\n",
            "   simlirality  grammarity  \n",
            "0     0.480573    0.966035  \n",
            "1     0.213953    0.998947  \n",
            "2     0.404471    0.991049  \n",
            "3     0.408541    0.990565  \n",
            "==================================================\n",
            "67 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "패트리지와 리딜 두 증인과 물론 애셔도. 그들이 앤도버를 떠나면 미행시키겠습니다. ” 그리고 나서 두세 가지 제안과 얼마쯤 산만한 대화가 오간 뒤 회의는 끝났다. 나는 강을 따라 걸으며 말했다. “포아로, 이 범죄를 예방할 수 있을까?” 그는 야윈 얼굴을 내 쪽으로 돌렸다. “한 사람의 광기에 대해, 이렇게 사람 들끊는 정상적인 거리에서? 나는 걱정일세, 헤이스팅즈. 아주 걱정이네. 살인광 잭의 그 오래 계속된 성공을 기억하고 있겠지!” “무서운 일이군. ” “헤이스팅즈, 광기란 무서운 거라네. 나는 걱정일세. 아주 걱정이야. ” < 벡스힐 바닷가 살인 > 나는 지금도 7월 25일 아침, 잠에서 깨어난 무렵의 일을 기억하고 있다. 그것은 아마 7시 30분쯤이었다고 생각된다. 포아로가 침대 옆에 서서 가만히 내 어깨를 흔들고 있었다. 그의 얼굴을 한 번 보자 나는 곧 반쯤 잠든 상태에서 눈을 떴다. 나는 얼른 일어나면서 물었다. “무슨 일인가?” 그는 아주 간단하게 대답했지만, 그의 짧은 말 속에는 풍부한 감동이 담겨 있었다. “일어났네. ” 나는 소리쳤다.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.325648784637451 Generator / grammar loss:-0.13799966871738434   similarity loss:-0.10514233261346817\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "물론 떠나면 미행시키겠습니다. 두세 헤이스팅즈. 잭의 광기란 살인 나는 기억하고 서서 어깨를 곧 얼른 물었다. “무슨 아주 대답했지만, 속에는 있었다. “일어났네.\n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "나는 강을 따라 걸으며 말했다.“포아로, 이 범죄를 예방할 수 있을까?” 그는 야윈 얼굴을 내 쪽으로 돌렸다.패트리지와 리딜 두 증인과 물론 애셔도.” < 벡스힐 바닷가 살인 > 나는 지금도 7월 25일 아침, 잠에서 깨어난 무렵의 일을 기억하고 있다.” 그리고 나서 두세 가지 제안과 얼마쯤 산만한 대화가 오간 뒤 회의는 끝났다.\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "그리고 나서 두세 가지 제안과 얼마쯤 산만한 대화가 오간 뒤 회의는 끝났다. < 벡스힐 바닷가 살인 > 나는 지금도 7월 25일 아침, 잠에서 깨어난 무렵의 일을 기억하고 있다.\n",
            "--------------------------------------------------\n",
            "besm_bert summary:\n",
            "그리고 나서 두세 가지 제안과 얼마쯤 산만한 대화가 오간 뒤 회의는 끝났다. 그것은 아마 7시 30분쯤이었다고 생각된다.포아로가 침대 옆에 서서 가만히 내 어깨를 흔들고 있었다. 그는 아주 간단하게 대답했지만, 그의 짧은 말 속에는 풍부한 감동이 담겨 있었다. “\n",
            "--------------------------------------------------\n",
            "         method  comp ratio     intro      body    ending       var     total  \\\n",
            "0      SAM+WGAN    0.167897  0.490329  0.421934  0.602155  0.005518  0.489679   \n",
            "1  BERT+LexRank    0.341328  0.434652  0.249999  0.287152  0.006359  0.298075   \n",
            "2          BESM    0.182657  0.424039  0.265169  0.291006  0.004845  0.304694   \n",
            "3   BESM+kobert    0.271218  0.467402  0.323989  0.698940  0.023863  0.465157   \n",
            "\n",
            "    grammar  \n",
            "0  0.973921  \n",
            "1  0.994359  \n",
            "2  0.999023  \n",
            "3  0.993918  \n",
            "Current result ==================================================\n",
            "Sample count: 62\n",
            "         method  comp rate     intro      body  conclusion   isthmus  \\\n",
            "0      SAM+WGAN   0.147827  0.518192  0.473882    0.467137  0.007876   \n",
            "1  BERT+LexRank   0.214901  0.227089  0.216295    0.205814  0.007319   \n",
            "2          BESM   0.203395  0.453450  0.394032    0.383853  0.009260   \n",
            "3   BESM+kobert   0.212162  0.470212  0.395351    0.392454  0.010276   \n",
            "\n",
            "   simlirality  grammarity  \n",
            "0     0.480720    0.966162  \n",
            "1     0.215309    0.998873  \n",
            "2     0.402862    0.991177  \n",
            "3     0.409454    0.990619  \n",
            "==================================================\n",
            "68 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "“뭐라고? 하지만 오늘은 25일이잖나. ” “어젯밤. 아니, 오늘 아침 일찍 일어났네. ” 내가 침대에서 튀어 일어나 재빨리 옷을 입자 그는 지금 막 전화로 들은 이야기를 간간히 들려주었다. “젊은 여자의 시체가 벡스힐 바닷가에서 발견됐네. 그녀는 일리저버스 버너드(Barnard)라는 이름의 카페 여급사로 밝혀졌네. 이 아가씨는 최근 갓 지은 조그만 방갈로에서 부모와 함께 살고 있었지. 검시 결과에 의하면 12시에서 새벽 1시 사이에 살해된 모양일세. ” 나는 면도를 하며 물었다. “그러나 이것이 그 범죄라는 건 확실한가?” “벡스힐 행 기차 시간표가 있는 데가 펼쳐진 ABC 철도 안내서가 시체 밑에서 나왔네. ” 나는 손이 떨렸다. “무서운 이야기로군. ” “조심하게, 헤이스팅즈. 내 방에서 또 하나의 사건이 일어나면 참을 수 없으니까. ” 나는 얼마쯤 맥이 풀려 턱의 피를 닦았다. 그리고 물었다. “우리들의 전투 계획은?” “이제 곧 경찰차가 우리를 데리러 오게 되어 있네. 자네 커피는 이리로 가져오도록 시켰네. 출발을 늦출 수 없으니까.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.539182662963867 Generator / grammar loss:-0.12767226994037628   similarity loss:-0.07238766551017761\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "하지만 오늘은 25일이잖나. “어젯밤. 아침 일어났네. ” 발견됐네. 여급사로 밝혀졌네. 아가씨는 모양일세. 면도를 물었다. 기차 이야기로군. 닦았다. 자네\n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "이 아가씨는 최근 갓 지은 조그만 방갈로에서 부모와 함께 살고 있었지.“우리들의 전투 계획은?” “이제 곧 경찰차가 우리를 데리러 오게 되어 있네.하지만 오늘은 25일이잖나.“젊은 여자의 시체가 벡스힐 바닷가에서 발견됐네.\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "내가 침대에서 튀어 일어나 재빨리 옷을 입자 그는 지금 막 전화로 들은 이야기를 간간히 들려주었다. “ 그녀는 일리저버스 버너드(Barnard)라는 이름의 카페 여급사로 밝혀졌네.\n",
            "--------------------------------------------------\n",
            "besm_bert summary:\n",
            "내가 침대에서 튀어 일어나 재빨리 옷을 입자 그는 지금 막 전화로 들은 이야기를 간간히 들려주었다. “ 그녀는 일리저버스 버너드(barnard)라는 이름의 카페 여급사로 밝혀졌네.\n",
            "--------------------------------------------------\n",
            "         method  comp ratio     intro      body    ending       var     total  \\\n",
            "0      SAM+WGAN    0.162921  0.892325  0.512515  0.389698  0.045775  0.551632   \n",
            "1  BERT+LexRank    0.232210  0.105685  0.189211  0.168461  0.001261  0.166281   \n",
            "2          BESM    0.187266  0.290399  0.369269  0.319357  0.001061  0.338522   \n",
            "3   BESM+kobert    0.187266  0.283376  0.367192  0.313272  0.001203  0.334253   \n",
            "\n",
            "    grammar  \n",
            "0  0.977920  \n",
            "1  0.999040  \n",
            "2  0.998889  \n",
            "3  0.998884  \n",
            "Current result ==================================================\n",
            "Sample count: 63\n",
            "         method  comp rate     intro      body  conclusion   isthmus  \\\n",
            "0      SAM+WGAN   0.148067  0.524131  0.474495    0.465908  0.008478   \n",
            "1  BERT+LexRank   0.215176  0.225162  0.215865    0.205221  0.007222   \n",
            "2          BESM   0.203139  0.450862  0.393639    0.382830  0.009130   \n",
            "3   BESM+kobert   0.211767  0.467246  0.394904    0.391198  0.010132   \n",
            "\n",
            "   simlirality  grammarity  \n",
            "0     0.481846    0.966349  \n",
            "1     0.214531    0.998876  \n",
            "2     0.401841    0.991300  \n",
            "3     0.408261    0.990751  \n",
            "==================================================\n",
            "69 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "” 20분 뒤 우리는 속력 빠른 경찰차를 타고 템즈 강을 건너 런던을 벗어났다. 경찰차에는 크롬 형사가 함께 타고 있었다. 지난번 회의에 참석했었던 이 사건 담당 형사였다. 크롬 형사는 재프 경감과는 다른 타입의 경관이었다. 훨씬 젊고 말수가 적은 남자였다. 교양과 지식을 지녔으나, 내 기호로 말하면 얼마쯤 자기만족에 빠져있는 듯했다. 그는 최근에 있었던 일련의 어린이 살해 사건으로, 지금 브로드무어에 들어가 있는 범인을 끈질기게 추적해 이름을 떨친 참이었다. 그는 분명 이번 사건을 맡는 데 알맞은 인물이었으나, 그것을 그 자신이 지나치게 의식하고 있는 듯 생각되었다. 포아로를 대하는 그의 태도에는 좀 잘난 체하는 데가 있고, 얼마쯤 자의식적인 공립학교 식 방법으로 젊은 사람이 연장자를 대하는 것같이 그에게 복종하고 있었다. 그가 말했다. “저는 솜프슨 박사와 많은 이야기를 했습니다. 그분은 연속 살인 사건에 아주 흥미를 갖고 계시지요. 그것은 특수하게 비틀린 심성의 산물입니다. 물론 비전문가로서는 그가 의학적 견지에 대해 보이는 세부적인 점은 이해할 수 없지요. ” 그는 헛기침을 했다. “사실 저의 지난번 사건으로 말하면, 그 기사를 읽으셨는지 모르겠습니다만, 머스윌 힐 여학교 학생 메이벌 호머 사건 말입니다. 그 캐퍼라는 사나이는 무서운 녀석이었습니다. 그 범죄를 그의 짓이라고 밝혀내기까지 참으로 힘이 들었습니다. 아무튼 세 사람째였으니 말입니다. 아주 멀쩡해 보였지요.\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.4818503856658936 Generator / grammar loss:-0.12554554641246796   similarity loss:-0.07639432698488235\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            " 뒤 우리는 빠른 경찰차를 타고 템즈 런던을 함께 타고 회의에 참석했었던 담당 크롬 형사는 재프 타입의 경관이었다. 훨씬 젊고 말수가 적은 남자였다. 학생\n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "” 20분 뒤 우리는 속력 빠른 경찰차를 타고 템즈 강을 건너 런던을 벗어났다.“사실 저의 지난번 사건으로 말하면, 그 기사를 읽으셨는지 모르겠습니다만, 머스윌 힐 여학교 학생 메이벌 호머 사건 말입니다.경찰차에는 크롬 형사가 함께 타고 있었다.물론 비전문가로서는 그가 의학적 견지에 대해 보이는 세부적인 점은 이해할 수 없지요.” 그는 헛기침을 했다.\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "” 20분 뒤 우리는 속력 빠른 경찰차를 타고 템즈 강을 건너 런던을 벗어났다. 그는 분명 이번 사건을 맡는 데 알맞은 인물이었으나, 그것을 그 자신이 지나치게 의식하고 있는 듯 생각되었다.\n",
            "--------------------------------------------------\n",
            "besm_bert summary:\n",
            "” 20분 뒤 우리는 속력 빠른 경찰차를 타고 템즈 강을 건너 런던을 벗어났다. 교양과 지식을 지녔으나, 내 기호로 말하면 얼마쯤 자기만족에 빠져있는 듯했다. 그는 최근에 있었던 일련의 어린이 살해 사건으로, 지금 브로드무어에 들어가 있는 범인을 끈질기게 추적해 이름을 떨친 참이었다.\n",
            "--------------------------------------------------\n",
            "         method  comp ratio     intro      body    ending       var     total  \\\n",
            "0      SAM+WGAN    0.118949  0.522936  0.369678  0.268704  0.010924  0.370037   \n",
            "1  BERT+LexRank    0.272476  0.444615  0.171666  0.162187  0.017151  0.223412   \n",
            "2          BESM    0.146611  0.425698  0.472762  0.302276  0.005168  0.412204   \n",
            "3   BESM+kobert    0.219917  0.485778  0.566188  0.343387  0.008487  0.483266   \n",
            "\n",
            "    grammar  \n",
            "0  0.968796  \n",
            "1  0.999047  \n",
            "2  0.999052  \n",
            "3  0.999034  \n",
            "Current result ==================================================\n",
            "Sample count: 64\n",
            "         method  comp rate     intro      body  conclusion   isthmus  \\\n",
            "0      SAM+WGAN   0.147612  0.524112  0.472857    0.462826  0.008516   \n",
            "1  BERT+LexRank   0.216071  0.228591  0.215174    0.204549  0.007378   \n",
            "2          BESM   0.202256  0.450469  0.394875    0.381571  0.009068   \n",
            "3   BESM+kobert   0.211894  0.467536  0.397581    0.390451  0.010106   \n",
            "\n",
            "   simlirality  grammarity  \n",
            "0     0.480099    0.966387  \n",
            "1     0.214670    0.998879  \n",
            "2     0.402003    0.991421  \n",
            "3     0.409433    0.990880  \n",
            "==================================================\n",
            "70 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "하지만 여러 가지 테스트라는 게 있잖습니까. 아시겠지요, 유도심문이라는 것을. 물론 아주 새로운 것이어서 전에는 별로 문제되지 않았던 겁니다. 한 번 잡아들이면 이미 문제없습니다!이쪽이 알고 있다는 걸 알게 되면 상대방은 그만 손을 들지요. 상대는 완전히 이쪽이 하는 대로 따라옵니다. ” 포아로가 말했다. “우리 때에도 그런 일은 흔히 있었지요. ” 크롬 형사는 그를 돌아보고 대화를 계속하는 것처럼 입속으로 말했다. “아, 그렇습니까?” 잠시 침묵이 이어졌다. 뉴크로스 역을 지났을 즈음 크롬이 말했다. “이 사건에 대해 무언가 들어주고 싶은 게 있으시면 말씀하십시오. ” “그럼, 죽은 아가씨에 대해 이야기해 주겠소?” “그녀는 23살로 카페 <진저 캣>의 여급사로 일하고 있었습니다. ” “아니, 그런 점이 아니라, 이를테면 그녀는 아름다웠다든가……. ” 크롬 형사는 당할 수 없다는 투로 말했다. “그런 일에 대해서는 전혀 들은 게 없습니다. ” 그의 몸짓은 이렇게 말하고 있었다. 이거 정말, 외국인이란 모두 이렇다니까! 포아로의 눈에 재미있어 하는 빛이 슬며시 떠올랐다. “그런 사실이 당신에게는 중요하게 보이지 않소?\n",
            "------------------------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.313047170639038 Generator / grammar loss:-0.13558095693588257   similarity loss:-0.1040167510509491\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "문제없습니다!이쪽이 있었지요. “아, 크롬이 사건에 싶은 게 아가씨에 ” 당할 수 전혀 들은 게 없습니다. ” 정말, 포아로의 눈에 재미있어 떠올랐다.\n",
            "--------------------------------------------------\n",
            "bert_lexrank summary:\n",
            "” “그럼, 죽은 아가씨에 대해 이야기해 주겠소?” “그녀는 23살로 카페 <진저 캣>의 여급사로 일하고 있었습니다.“그런 일에 대해서는 전혀 들은 게 없습니다.” “아니, 그런 점이 아니라, 이를테면 그녀는 아름다웠다든가…….” 크롬 형사는 당할 수 없다는 투로 말했다.포아로의 눈에 재미있어 하는 빛이 슬며시 떠올랐다.\n",
            "--------------------------------------------------\n",
            "besm summary:\n",
            "한 번 잡아들이면 이미 문제없습니다!이쪽이 알고 있다는 걸 알게 되면 상대방은 그만 손을 들지요.\n",
            "--------------------------------------------------\n",
            "besm_bert summary:\n",
            "한 번 잡아들이면 이미 문제없습니다!이쪽이 알고 있다는 걸 알게 되면 상대방은 그만 손을 들지요.\n",
            "--------------------------------------------------\n",
            "         method  comp ratio     intro      body    ending       var     total  \\\n",
            "0      SAM+WGAN    0.145329  0.506491  0.427722  0.577719  0.003753  0.488475   \n",
            "1  BERT+LexRank    0.311419  0.110574  0.218690  0.268787  0.004359  0.212096   \n",
            "2          BESM    0.093426  0.386339  0.292677  0.294018  0.001922  0.311812   \n",
            "3   BESM+kobert    0.093426  0.386339  0.292677  0.294018  0.001922  0.311812   \n",
            "\n",
            "    grammar  \n",
            "0  0.929732  \n",
            "1  0.999029  \n",
            "2  0.999026  \n",
            "3  0.999026  \n",
            "Current result ==================================================\n",
            "Sample count: 65\n",
            "         method  comp rate     intro      body  conclusion   isthmus  \\\n",
            "0      SAM+WGAN   0.147577  0.523841  0.472163    0.464594  0.008443   \n",
            "1  BERT+LexRank   0.217538  0.226776  0.215228    0.205537  0.007331   \n",
            "2          BESM   0.200581  0.449482  0.393303    0.380224  0.008958   \n",
            "3   BESM+kobert   0.210072  0.466287  0.395967    0.388967  0.009980   \n",
            "\n",
            "   simlirality  grammarity  \n",
            "0     0.480228    0.965823  \n",
            "1     0.214630    0.998881  \n",
            "2     0.400615    0.991538  \n",
            "3     0.407931    0.991005  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>method</th>\n",
              "      <th>comp rate</th>\n",
              "      <th>intro</th>\n",
              "      <th>body</th>\n",
              "      <th>conclusion</th>\n",
              "      <th>isthmus</th>\n",
              "      <th>simlirality</th>\n",
              "      <th>grammarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SAM+WGAN</td>\n",
              "      <td>0.147577</td>\n",
              "      <td>0.523841</td>\n",
              "      <td>0.472163</td>\n",
              "      <td>0.464594</td>\n",
              "      <td>0.008443</td>\n",
              "      <td>0.480228</td>\n",
              "      <td>0.965823</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BERT+LexRank</td>\n",
              "      <td>0.217538</td>\n",
              "      <td>0.226776</td>\n",
              "      <td>0.215228</td>\n",
              "      <td>0.205537</td>\n",
              "      <td>0.007331</td>\n",
              "      <td>0.214630</td>\n",
              "      <td>0.998881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>BESM</td>\n",
              "      <td>0.200581</td>\n",
              "      <td>0.449482</td>\n",
              "      <td>0.393303</td>\n",
              "      <td>0.380224</td>\n",
              "      <td>0.008958</td>\n",
              "      <td>0.400615</td>\n",
              "      <td>0.991538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>BESM+kobert</td>\n",
              "      <td>0.210072</td>\n",
              "      <td>0.466287</td>\n",
              "      <td>0.395967</td>\n",
              "      <td>0.388967</td>\n",
              "      <td>0.009980</td>\n",
              "      <td>0.407931</td>\n",
              "      <td>0.991005</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         method  comp rate     intro      body  conclusion   isthmus  \\\n",
              "0      SAM+WGAN   0.147577  0.523841  0.472163    0.464594  0.008443   \n",
              "1  BERT+LexRank   0.217538  0.226776  0.215228    0.205537  0.007331   \n",
              "2          BESM   0.200581  0.449482  0.393303    0.380224  0.008958   \n",
              "3   BESM+kobert   0.210072  0.466287  0.395967    0.388967  0.009980   \n",
              "\n",
              "   simlirality  grammarity  \n",
              "0     0.480228    0.965823  \n",
              "1     0.214630    0.998881  \n",
              "2     0.400615    0.991538  \n",
              "3     0.407931    0.991005  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Oj2diLc-mAa"
      },
      "source": [
        "## 한국어 Sample Test (with frame token)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUb6xK7Cigry",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8194ad00-d129-452f-e0ca-ef443ad71fb1"
      },
      "source": [
        "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
        "\n",
        "test_result = {}\n",
        "test_result['SAM+WGAN']=[]\n",
        "\n",
        "step = 0\n",
        "for intro,body,end in ko_docs:\n",
        "    step += 1\n",
        "    print(\"=\" * 50)\n",
        "    print(str(step),\"/\",len(ko_docs))\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    org_text_1 = intro\n",
        "    org_text_2 = body\n",
        "    org_text_3 = end\n",
        "\n",
        "    try:\n",
        "        df1,dct1 = sam_wgan('',[org_text_1,org_text_2,org_text_3],init_bias=1.0,display= False)\n",
        "        if dct1['grammar'][0] > 0.0:\n",
        "\n",
        "            test_result['SAM+WGAN'].append(get_features(dct1))\n",
        "            #result = pd.concat([df1, df2, df3, df4, df5, df6 ], ignore_index=True)\n",
        "            #result = pd.concat([df1, df2, df3, df5, df6 ], ignore_index=True)\n",
        "            \n",
        "            print(df1)\n",
        "            \n",
        "            print(\"Current result\",\"=\" * 50)\n",
        "            print(\"Sample count:\",len(test_result['SAM+WGAN']))\n",
        "            print(get_test_statistics(test_result))\n",
        "        \n",
        "    except KeyboardInterrupt as ki:\n",
        "        raise ki\n",
        "    except :\n",
        "        print(\"Unexpected error:\", sys.exc_info()[0])\n",
        "        #raise e\n",
        "        pass\n",
        "\n",
        "get_test_statistics(test_result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "1 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "이 이야기에서는 내가 직접 입회한 사건이나 장면만을 이야기하는 전의 내 방법을 바꿔 보았다. 그래서 몇몇 장은 3인칭으로 씌어 있다. 이제부터의 각 장에서 이야기되는 사건들은 모두 내가 확증 할 수 있었던 것임을 밝혀둔다. 여러 인물들의 생각이나 감정을 서술하는 데 있어 얼마쯤 내가 시인의 특권을 행사했다 해도 그것은 아주 정확을 기해서 한 일이다. 또한 그것들은 모두 내 친구 에르큘 포아로의 검토를 받았음을 덧붙여 둔다. 끝으로, 나는 이 이상한 연쇄 범죄의 결과로서 일어나는 부차적인 인간관계에 대해 너무 많은 이야기를 했는지도 모른다. 하지만 인간적, 개인적 요소란 빠뜨려선 안 되는 것이다. 에르큘 포아로가 언젠가 과장된 몸짓으로 나에게 가르쳐 준 일이 있다. 로맨스란 범죄의 부산물일 경우가 있다고. ABC 수수께끼의 해결에 대해 말한다면, 에르큘 포아로는 이제까지 그가 다뤄 온 어느 사건과도 다른 방법으로 문제에 뛰어들어 그 진정한 천재성을 발휘했다고 말해도 좋으리라. < 편지 > 1935년 6월, 나는 남아메리카의 내 농장에서 떠나 여섯 달쯤 머무를 예정으로 귀국했다. 그때는 어려웠던 시대로, 다른 사람들과 마찬가지로 우리 역시 세계적인 불황에 어려움을 겪고 있었다. 영국에서 나 자신이 손대지 않으면 도저히 잘되어 나가지 않을 것 같은 볼일이 여러 가지 있었다. 농장 관리를 위해 아내가 뒤에 남았다. 영국에 와 닿아 내가 맨 먼저 한 일의 하나는 말할 나위도 없이 오랜 친구인 에르큘 포아로를 찾아간 것이었다. 그는 런던의 어떤 최신형 아파트에 살고 있었다. 내가 그것을 지적하며, 그가 이 특별한 건물을 고른 것은 완전히 그 기하학적이 겉모습과 넓이 때문일 거라고 말하자 그는 고개를 끄덕였다. “그러나 아주 기분 좋게 균형이 잡혀 있지. 그렇게 생각되지 않나?” 나는 좀 너무 모난 것같이 생각된다고 말했다. 그리고 오래된 농담이 생각나 이 아파트에서는 암탉에게 네모난 달걀을 낳게 할 수 있을 듯하다고 말했다.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/251       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/250       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/249       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/248       \n",
            "Negative tokens: ['전의' '몇몇' '할' '있었던' '행사했다' '나는' '했는지도' '언젠가' '뛰어들어' '사람들과' '볼일이' '일의'\n",
            " '그가' '고른' '거라고']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 249/250       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 248/249       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 247/248       \n",
            "Peak count: 13\n",
            "Frame tokens: 직접 이제부터의 사건들은 한 있다. 있다고. 그가 말해도 있었다. 있었다. 내가 것이었다. 말했다. \n",
            "\n",
            "Similarity : 0.36380188284323656\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.3022871017456055 Generator / grammar loss:-0.1700814813375473   similarity loss:-0.139619380235672\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "직접 이제부터의 각 사건들은 내가 특권을 기해서 한 친구 나는 일이 있다. 도저히 잘되어 나가지 볼일이 있었다. 내가 먼저 한 것이었다. 내가 고른 기하학적이 거라고 말하자 끄덕였다. “그러나 아주 좋게 잡혀 나는 좀 너무 것같이 생각나 있을 듯하다고 말했다.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.148871  0.491361  0.409355  0.538013  0.002828  0.464353   \n",
            "\n",
            "    grammar  \n",
            "0  0.961231  \n",
            "Current result ==================================================\n",
            "Sample count: 1\n",
            "     method  comp rate     intro      body  conclusion   isthmus  simlirality  \\\n",
            "0  SAM+WGAN   0.148871  0.491361  0.409355    0.538013  0.002828     0.464353   \n",
            "\n",
            "   grammarity  \n",
            "0    0.961231  \n",
            "==================================================\n",
            "2 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "포아로는 크게 웃었다. “아니, 자네는 아직도 그걸 기억하고 있나? 하지만 유감스럽게도 과학은 아직 암탉을 현대 취미에 알맞도록 하는 일에 성공하지 못하고 있네. 닭들이 지금도 여전히 크기와 빛깔이 서로 다른 달걀을 낳고 있지. ” 나는 애정어린 눈길로 오랜 친구를 관찰했다. 그는 굉장히 활기가 넘쳐 전에 만났을 때보다 조금도 더 나이먹은 것같이 보이지 않았다. “자네는 정말 건강해 보이는군, 포아로. 거의 나이를 안 먹었잖나. 전에 만났을 때보다 흰머리가 더 적어졌다고 해도 좋을 정도일세, 그런 일이 있을 수 있다면. ” 포아로는 나에게 빙그레 웃어 보였다. “어째서 그런 일이 있을 수 있겠나? 진짜 그 말대로인데. ” “자네 머리는 검은빛에서 잿빛이 되는 대신 잿빛에서 검은빛으로 된단 말인가?” “그렇다네. ” “그렇지만 그런 일은 과학적으로 불가능해!” “천만에. ” “하지만 있을 수 없는 일이잖나. 자연 법칙에 어긋나. ” “헤이스팅즈, 자네는 여전히 남을 의심하지 않는 아름다운 마음을 지니고 있군. 세월도 자네의 그 마음은 바꿔 놓지 못하는구먼! 자네는 한 가지 사실을 발견하면 곧바로 그 해결을 입에 담지. 자기 자신은 그것을 의식하지 못하지만!” 나는 무슨 소리인지 알 수가 없어 그를 쳐다보았다.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/160       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/159       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/158       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/157       \n",
            "Negative tokens: ['아직' '”' '그는' '”' '여전히' '자네는' '의식하지']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 158/159       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 157/158       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 156/157       \n",
            "Peak count: 9\n",
            "Frame tokens: “아니, 않았다. 나이를 “어째서 진짜 ” ” 있군. 쳐다보았다. \n",
            "\n",
            "Similarity : 0.4230735324477164\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.412827968597412 Generator / grammar loss:-0.1959313601255417   similarity loss:-0.15404678881168365\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "포아로는 “아니, 기억하고 성공하지 있지. 관찰했다. 포아로. 거의 나이를 안 더 웃어 보였다. “어째서 진짜 검은빛에서 검은빛으로 ” ” 있을 일이잖나. 법칙에 있군. 자기 그것을 나는 쳐다보았다.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.176752  0.431242  0.593779  0.480171  0.004635  0.527189   \n",
            "\n",
            "    grammar  \n",
            "0  0.950727  \n",
            "Current result ==================================================\n",
            "Sample count: 2\n",
            "     method  comp rate     intro      body  conclusion   isthmus  simlirality  \\\n",
            "0  SAM+WGAN   0.162811  0.461301  0.501567    0.509092  0.003732     0.495771   \n",
            "\n",
            "   grammarity  \n",
            "0    0.955979  \n",
            "==================================================\n",
            "3 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "그는 잠자코 침실로 들어가더니 병을 하나 들고 돌아와 나에게 건네 주었다. 나는 까닭을 모르는 채 그 병을 보았다. 병에는 이렇게 씌어 있었다. 르비비 - 머리칼의 자연스러운 빛깔을 회색, 밤색, 빨강, 노랑, 갈색, 검은 색의 여섯 가지 색조로 되살린다. 르비비는 염료가 아니다. 나는 소리쳤다. “포아로, 머리를 염색하고 있구먼!” “아, 겨우 알아차린 모양이군!” “그래서 자네 머리가 전에 돌아왔을 때보다 훨씬 검어 보였단 말인가?” “그렇지. ” 놀라움이 가라앉자 나는 말했다. “그럼, 다음에 돌아왔을 때에는 가짜 수염이라도 달고 있을게 아닌가? 아니면 지금도 가짜 수염인가?” 포아로는 움찔했다. 수염은 늘 그가 세심하게 신경쓰는 부분이다. 그는 수염을 터무니없이 자랑했다. 그런데 내 말이 그의 아픈 데를 찌른 것이다. “아닐세, 당치도 않아. 그런 날은 되도록 오지 않기를 비네. 가짜 수염이라니? 끔찍한 소리를!” 그의 수염이 진짜인 것을 증명하기 위해 힘주어 잡아당겨 보였다. “과연 아직 숱이 꽤 많군. ” “그렇지? 온 런던을 다 찾아봐도 나에게 맞는 가짜 수염은 있을 리 없네.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/141       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/140       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/139       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/138       \n",
            "Negative tokens: ['병을' '병에는' '르비비' '르비비는' '수염이라도' '수염인가?”' '수염을' '수염이라니?' '수염이' '숱이' '수염은']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 139/140       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 138/139       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 137/138       \n",
            "Peak count: 8\n",
            "Frame tokens: 머리가 가짜 수염은 터무니없이 가짜 “과연 가짜 없네. \n",
            "\n",
            "Similarity : 0.4292594483236668\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.2233152389526367 Generator / grammar loss:-0.20469599962234497   similarity loss:-0.18227098882198334\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            " 채 머리칼의 “아, 겨우 머리가 돌아왔을 때보다 놀라움이 말했다. 지금도 가짜 수염인가?” 수염은 터무니없이 되도록 비네. 가짜 증명하기 잡아당겨 “과연 찾아봐도 가짜 없네.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.174688  0.323768  0.561792  0.636586  0.017789  0.536625   \n",
            "\n",
            "    grammar  \n",
            "0  0.926488  \n",
            "Current result ==================================================\n",
            "Sample count: 3\n",
            "     method  comp rate     intro      body  conclusion   isthmus  simlirality  \\\n",
            "0  SAM+WGAN    0.16677  0.415457  0.521642     0.55159  0.008418     0.509389   \n",
            "\n",
            "   grammarity  \n",
            "0    0.946149  \n",
            "==================================================\n",
            "4 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "” 꽤 우쭐대는군 하고 나는 마음속으로 생각했다. 그러나 나는 그런 소리를 해서 포아로의 기분을 상하게 할 생각은 전혀 없었다. 그 대신 그가 아직도 때로 일을 하는지 물어 보았다. “자네가 몇 해 전 은퇴한 것은 알고 있지만……” “그렇네. 대대적으로 호박을 가꾸기 위해서! 그런데 곧 살인 사건이 일어나 호박들에게 멸망으로의 행진을 시키고 만 셈일세. 그 뒤부터는, 자네가 뭐라고 할지 잘 알지만 나는 자진해서 고별 공연을 여는 프리마돈나가 됐네. 물론 그 고별 공연이 끝없이 되풀이되고 있지만 말일세. ” 나는 웃었다, “실로 그대로라네. 그때마다 나는 이것을 마지막이라고 하지. 그런데 안돼. 다른 사건이 일어나거든. 그래서 나는 인정하지 않을 수 없다네. 나는 은퇴를 바라지 않는다고. 이 조그만 회색 뇌세포는 쓰지 않으면 녹슬어 버리니까. ” “알았네. 적당히 운동을 시키고 있다는 거로군. ” “맞아, 요즘의 에르큘 포아로는 범죄의 진수밖에 다루지 않네. ” “그 진수는 충분히 있던가?” “꽤 있지. 바로 저번 사건 같은 경우는 위태로울 뻔했었어.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/138       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/137       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/136       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/135       \n",
            "Negative tokens: ['그러나' '그' '“자네가' '있지만……”' '그런데' '멸망으로의' '잘' '고별' '그때마다' '그래서' '”']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 136/137       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 135/136       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 134/135       \n",
            "Peak count: 7\n",
            "Frame tokens: 우쭐대는군 셈일세. 말일세. ” ” 있지. 뻔했었어. \n",
            "\n",
            "Similarity : 0.445318707063046\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.270016670227051 Generator / grammar loss:-0.18682748079299927   similarity loss:-0.1596599519252777\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "우쭐대는군 마음속으로 때로 곧 시키고 만 셈일세. 자네가 뭐라고 물론 말일세. 그때마다 마지막이라고 인정하지 녹슬어 ” “알았네. ” 진수는 있지. 뻔했었어.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.163569  0.518055  0.504338  0.547731  0.000328  0.520099   \n",
            "\n",
            "    grammar  \n",
            "0  0.968985  \n",
            "Current result ==================================================\n",
            "Sample count: 4\n",
            "     method  comp rate     intro      body  conclusion   isthmus  simlirality  \\\n",
            "0  SAM+WGAN    0.16597  0.441107  0.517316    0.550625  0.006395     0.512067   \n",
            "\n",
            "   grammarity  \n",
            "0    0.951858  \n",
            "==================================================\n",
            "5 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "” “실패했나?” 포아로는 놀라운 듯했다. “당치도 않네. 그렇지만 이 내가, 이 에르큘 포아로가 하마터면 살해될 뻔했었지. ” 나는 휘파람을 불었다. “대담한 범인이로군. ” “대담하다기보다 무모하지. 그래, 진짜 무모한 녀석이었어. 하지만 그 이야기는 그만두세. 그런데 헤이스팅즈, 알겠나? 나는 여러 가지 뜻에서 자네를 내 마스코트로 생각하고 있네. ” “정말인가? 어떤 뜻에서?” 포아로는 내 물음에는 직접 대답하지 않고 이야기를 계속했다. “자네가 온다는 이야기를 들으면 나는 곧 무언가 일어나겠군 하고 생각된다네. 예전처럼 둘이서 수사하지 않겠나. 하지만 만일 그렇게 한다면 평범한 사건은 안돼. 뭔가 이렇게……. ” 그는 흥분해서 손을 파도치듯 움직였다. “머리를 잔뜩 쓰게 하는, 미묘하고 피이누(섬세)한 것이 아니면 안 되지. ” 피아누라는 번역하기 어려운 말에 가득한 풍미를 곁들이는 듯한 말투였다. “포아로, 남이 들으면 마치 리츠에서 저녁 식사라도 주문하고 있는 줄로 생각하겠네.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/118       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/117       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/116       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/115       \n",
            "Negative tokens: ['“당치도' '하지만' '그런데' '“정말인가?' '하지만' '어려운']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 116/117       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 115/116       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 114/115       \n",
            "Peak count: 6\n",
            "Frame tokens: 듯했다. 그렇지만 ” 뭔가 말투였다. 생각하겠네. \n",
            "\n",
            "Similarity : 0.4317683975812677\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.221489429473877 Generator / grammar loss:-0.15761414170265198   similarity loss:-0.13537397980690002\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "듯했다. 그렇지만 휘파람을 범인이로군. ” 하지만 그만두세. “자네가 들으면 않겠나. 사건은 안돼. 뭔가 이렇게……. 움직였다. 듯한 말투였다. 생각하겠네.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.172619  0.580648  0.491729  0.559733  0.001441  0.529914   \n",
            "\n",
            "    grammar  \n",
            "0  0.914614  \n",
            "Current result ==================================================\n",
            "Sample count: 5\n",
            "     method  comp rate     intro      body  conclusion   isthmus  simlirality  \\\n",
            "0  SAM+WGAN     0.1673  0.469015  0.512199    0.552447  0.005404     0.515636   \n",
            "\n",
            "   grammarity  \n",
            "0    0.944409  \n",
            "==================================================\n",
            "6 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "” 그는 한숨을 쉬었다. “범죄란 주문할 수 있는 게 아닌데 말일세. 정말이야. 그렇지만 나는 운을 믿겠네. 운명이라 해도 좋아. 내 곁에 붙어 있으면서 내가 용서받을 수 없는 실책을 저지르는 걸 막아주는 게 자네 운명이야. ” “용서받을 수 없는 실책이란 뭔가?” “명백한 것을 놓치는 것이지. ” 나는 이 말을 가슴속에서 되풀이해 보았으나 핵심을 잡을 수 없었다. 나는 밝게 미소지으며 말했다. “그런데 그 진수라고 할 만한 범죄는 아직 일어나지 않았나?” “적어도 아직은. 왜냐하면……. ” 그는 말을 끊었다. 이마에 난처한 듯한 주름이 잡혔다. 그 손은 내가 생각없이 접어버린 물건을 무의식중에 펴고 있었다. 그는 천천히 말했다. “뚜렷이 알 수는 없지만……. ” 그 말투에 어떤 이상한 게 느껴져 나는 놀라며 그의 얼굴을 보았다. 가로진 주름은 아직 남아 있었다. 그는 갑자기 결심한 듯 고개를 끄덕이고 창 가까이의 책상 쪽으로 방을 가로질러 갔다. 책상 속의 것은 말할 나위도 없이 잘 분류되고 정리되어 손을 넣기만 하면 kq로 필요한 서류를 꺼낼 수 있었다.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/145       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/144       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/143       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/142       \n",
            "Negative tokens: ['실책이란' '보았으나' '“그런데' '이마에' '생각없이' '느껴져' '듯']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 143/144       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 142/143       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 141/142       \n",
            "Peak count: 8\n",
            "Frame tokens: 정말이야. 운명이라 것이지. 그 왜냐하면……. 천천히 ” 있었다. \n",
            "\n",
            "Similarity : 0.5221758014466584\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.388674259185791 Generator / grammar loss:-0.19979779422283173   similarity loss:-0.1604296863079071\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "그는 정말이야. 믿겠네. 운명이라 내가 용서받을 수 운명이야. 것이지. 끊었다. 이마에 그 손은 내가 있었다. 천천히 알 없지만……. ” 말투에 보았다. 아직 끄덕이고 있었다.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro     body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.180479  0.584447  0.61287  0.536127  0.001004  0.584163   \n",
            "\n",
            "    grammar  \n",
            "0  0.984584  \n",
            "Current result ==================================================\n",
            "Sample count: 6\n",
            "     method  comp rate     intro      body  conclusion   isthmus  simlirality  \\\n",
            "0  SAM+WGAN   0.169496  0.488254  0.528977    0.549727  0.004671     0.527057   \n",
            "\n",
            "   grammarity  \n",
            "0    0.951105  \n",
            "==================================================\n",
            "7 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "그는 한 통의 뜯어진 편지를 손에 들고 내 쪽으로 천천히 되돌아왔다. 그리고 그것에 눈길을 한 번 주더니 나에게 내밀며 말했다. “자네는 이걸 어떻게 생각하나?” 나는 어떤 흥미를 가지고 그것을 바았다. 그것은 좀 두꺼운 흰 편지지에 활자체로 씌어 있었다. 에르큘 포아로여, 너는 자만에 빠져 있는 게 아닐까. 갸엾은 우리 멍청이 영국 경찰이 감당하지 못하는 어려운 사건을 해결할 수 있는 건 자신이라고? 명민한 포아로여, 너의 명민함을 어디 한 번 보여 다오. 하지만 너에게는 이 호두가 너무 딱딱할걸. 이 달 21일, 앤도버(Andover)를 경계하라. 이만. ABC 나는 잠시 봉투에 눈길을 주었다. 역시 활자체로 씌어 있었다. 내가 소인에 주의를 돌리고 있는 것을 보자 그가 말했다. “소인은 서중앙 제1국일세. 그래, 어떻게 생각하나?” 나는 어깨를 으쓱해 보이며 편지를 돌려주었다. “아마도 미치광이 짓이겠지. ” “그뿐인가?” “자네한테는 미치광이로 여겨지지 않는다는 건가?” “아니, 그렇게 여겨지네. ” 그의 말투는 진지했다. 나는 호기심을 느끼며 그를 보았다. “자네는 이 편지를 진지하게 받아들이고 있는 모양이군, 포아로.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/143       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/142       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/141       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/140       \n",
            "Negative tokens: ['편지를' '번' '명민함을' '눈길을' '생각하나?”' '“아마도' '호기심을' '“자네는']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 141/142       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 140/141       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 139/140       \n",
            "Peak count: 8\n",
            "Frame tokens: 에르큘 아닐까. 자신이라고? 내가 말했다. 돌려주었다. ” 포아로. \n",
            "\n",
            "Similarity : 0.4016976032262092\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.175910472869873 Generator / grammar loss:-0.17727985978126526   similarity loss:-0.1596432328224182\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "두꺼운 에르큘 빠져 아닐까. 멍청이 자신이라고? 나는 역시 내가 돌리고 말했다. 그래, 어떻게 생각하나?” 어깨를 으쓱해 편지를 돌려주었다. ” “자네한테는 건가?” “아니, 말투는 포아로.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.181818  0.472454  0.448379  0.536249  0.001375  0.479555   \n",
            "\n",
            "    grammar  \n",
            "0  0.983851  \n",
            "Current result ==================================================\n",
            "Sample count: 7\n",
            "     method  comp rate     intro      body  conclusion  isthmus  simlirality  \\\n",
            "0  SAM+WGAN   0.171256  0.485996  0.517463    0.547801   0.0042     0.520271   \n",
            "\n",
            "   grammarity  \n",
            "0    0.955783  \n",
            "==================================================\n",
            "8 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "” “미치광이란 진지하게 다루어야 하지. 미치광이는 아주 위험한 존재니까. ” “그렇지, 물론 그렇네. 나는 그 점을 생각지 못했어. 그러나 내 말은, 어쩐지 우스꽝스러운 장난같은 생각이 든다는 걸세. 누군가, 8이라는 숫자에 하나가 더 많은 것 같은 우쭐해진 주정꾼 바보 말이네. ” “뭐라고? 아홉이란 말인가? 그건 대체 무슨 뜻이지?” “아니, 그냥 말장난일세. 취한 녀석이라는 뜻이지. 아니, 그보다도 지나치게 마셔서 고주망태가 된 녀석이라는 뜻일세. ” “고맙네, 헤이스팅즈. 그 <취한다>는 말이라면 나도 알고 있네. 자네 말대로 그 이상의 뜻은 없는지도 모르지만. ‘ 나는 그의 불만스러운 말투에 자극되어 물어 보았다. “그럼, 자네는 무엇이 있다고 생각하나?” 포아로는 의심스러운 듯 머리를 흔들었지만 아무 말도 하지 않았다. 나는 물었다. “그래서 자네는 어떻게 했나?” “어떻게 할 수 있었겠나? 재프 경감에게 보였을 뿐이지. 그는 자네와 같은 의견이었어.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/118       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/117       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/116       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/115       \n",
            "Negative tokens: ['”' '그러나' '어쩐지' '<취한다>는' '자네' '했나?”' '있었겠나?' '그는']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 116/117       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 115/116       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 114/115       \n",
            "Peak count: 6\n",
            "Frame tokens: ” 그건 말장난일세. 모르지만. 물었다. 의견이었어. \n",
            "\n",
            "Similarity : 0.5336671253147756\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.2845089435577393 Generator / grammar loss:-0.18830718100070953   similarity loss:-0.15966200828552246\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "물론 나는 그 생각지 말은, ” 그건 “아니, 그냥 말장난일세. 녀석이라는 나도 알고 모르지만. 보았다. 물었다. 뿐이지. 의견이었어.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio    intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.153374  0.50164  0.559133  0.592858  0.001418  0.557752   \n",
            "\n",
            "    grammar  \n",
            "0  0.943235  \n",
            "Current result ==================================================\n",
            "Sample count: 8\n",
            "     method  comp rate     intro      body  conclusion   isthmus  simlirality  \\\n",
            "0  SAM+WGAN   0.169021  0.487952  0.522672    0.553433  0.003852     0.524956   \n",
            "\n",
            "   grammarity  \n",
            "0    0.954214  \n",
            "==================================================\n",
            "9 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "할 짓 없는 녀석의 장난이라고 말일세. 그것이 그의 표현이었는데, 런던 경찰국에서는 거의 날마다 이런 것을 받는다는군. 나도 그 바람에 휘말려 들었다는 거였어. ” “하지만 자네는 이 편지를 진지하게 생각하고 있잖은가?” 포아로는 천천히 대답했다. “아무래도 이 편지에는 내 마음에 들지 않는 게 있어, 헤이스팅즈. ” 그 말투가 묘하게 인상적이었다. “그래, 자네 의견은?” 그는 고개를 젓고 그 편지를 들어올려 다시 책상 속에 넣어 버렸다. “자네가 그토록 진지하게 생각한다면 왜 아무 일도 하지 않고 있는 건가?” “여전히 활동가로군, 자네는! 하지만 대체 어떻게 할 수 있겠나? 지방 경찰에도 편지를 보였지만 역시 진지하게 여겨 주지 않았어. 지문도 없고, 편지를 낸 사람에 대한 단서도 없으니. ” “그렇다면 자네 육감 말고는 아무것도 없단 말인가?” “육감이 아닐세, 헤이스팅즈. 육감이란 나쁜 말이야. 내 지식이며 경험일세. 그 편지에 뭔가 이상한 게 있다고 가르쳐 주는 것은. ” 말이 막히자 그는 손짓을 해보였다. 그리고 또 머리를 흔들었다. “개미집에서 산을 만들어 내려 하고 있는지도 모르지만 말일세. 어쨌든 기다려 보는 수밖에 없어. ” “옳지, 21일은 금요일이군.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/153       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/152       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/151       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/150       \n",
            "Negative tokens: ['“하지만' '“아무래도' '그토록' '하지만' '있겠나?' '말고는' '육감이란' '편지에' '막히자']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 151/152       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 150/151       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 149/150       \n",
            "Peak count: 8\n",
            "Frame tokens: 녀석의 천천히 생각한다면 주지 없으니. 말인가?” 말일세. 금요일이군. \n",
            "\n",
            "Similarity : 0.4246868821117\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.4069156646728516 Generator / grammar loss:-0.1872703731060028   similarity loss:-0.14600294828414917\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "녀석의 이런 거였어. 생각하고 천천히 자네 버렸다. 생각한다면 하지만 진지하게 여겨 주지 않았어. 사람에 없으니. 아무것도 말인가?” “개미집에서 내려 모르지만 말일세. 없어. ” 금요일이군.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro     body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.175698  0.474876  0.49882  0.574567  0.001805  0.516755   \n",
            "\n",
            "    grammar  \n",
            "0  0.968161  \n",
            "Current result ==================================================\n",
            "Sample count: 9\n",
            "     method  comp rate     intro      body  conclusion   isthmus  simlirality  \\\n",
            "0  SAM+WGAN   0.169763  0.486499  0.520022    0.555782  0.003625     0.524045   \n",
            "\n",
            "   grammarity  \n",
            "0    0.955764  \n",
            "==================================================\n",
            "10 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "앤도버에서 굉장한 강도 사건이라도 일어난다면 그야말로……. ” “아, 그렇다면 얼마나 기분전환이 되겠나. ” “기분전환이라고?” 나는 어이가 없었다. 그 자리에서 그 말은 너무나 이상스럽게 들렸다. 나는 항의했다. “강도는 스릴이 있을지 모르지만 기분전환이라고 할 수는 없어!” 포아로는 힘주어 고개를 저었다. “자네는 잘못 알고 있네. 자네는 내 말뜻을 모르고 있어. 내 마음을 차지하고 있는 더 큰 다른 염려에 비하면, 강도는 오히려 마음 놓을 수 있다는 걸세. ” “무슨 염려인가?” “살인이지. ‘ < 삽 화 > 앨릭잰더 보너퍼트 캐스트 씨는 의자에서 일어나 초라한 침실을 근시인 듯한 눈으로 둘러보았다. 답답스러운 자세로 앉아있었기 때문에 등이 완전히 뻣뻣해져 버렸다. 등을 쭉 펴고 기지개 켜는 그를 본 사람은, 그가 실제로는 키가 큰 사람임을 알았으리라. 그의 굽은 등과 근시처럼 기웃거리는 동작이 아주 다른 인상을 주고 있었다. 문 안쪽에 걸린 낡아빠진 외투로 다가가 주머니에서 싸구려 담뱃갑과 성냥을 꺼냈다. 담배에 불을 붙이고 지금까지 앉아있던 의자로 돌아왔다. 철도 안내서를 집어 들고 세밀히 보더니 이윽고 타이프된 이름 리스트를 훑어보기 시작했다. 그는 펜으로 그 리스트의 첫 번째 이름에 표시했다. 그것은 6월 20일 목요일의 일이었다. < 앤도버 살인 > 나는 그때 포아로가 받은 편지에 대한 그의 예감에 깊은 인상을 받은 건 사실이지만, 그 일은 내 머리에서 아주 사라져 버렸다고 해도 좋다.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/187       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/186       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/185       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/184       \n",
            "Negative tokens: ['어이가' '기분전환이라고' '힘주어' '잘못' '모르고' '보너퍼트' '초라한' '답답스러운' '실제로는' '굽은' '인상을'\n",
            " '낡아빠진' '예감에' '사실이지만,' '아주']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 185/186       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 184/185       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 183/184       \n",
            "Peak count: 10\n",
            "Frame tokens: 일어난다면 되겠나. 이상스럽게 항의했다. 저었다. 강도는 걸세. “살인이지. 버렸다. 좋다. \n",
            "\n",
            "Similarity : 0.4532648989976308\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.5664846897125244 Generator / grammar loss:-0.18684269487857819   similarity loss:-0.12860193848609924\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "강도 일어난다면 되겠나. 나는 그 이상스럽게 항의했다. 수는 저었다. “자네는 모르고 다른 염려에 강도는 마음 놓을 걸세. “살인이지. 화 > 눈으로 버렸다. 펴고 그의 의자로 돌아왔다. 20일 예감에 사실이지만, 좋다.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body   ending       var     total  \\\n",
            "0  SAM+WGAN    0.166667  0.532266  0.561995  0.41671  0.003927  0.512464   \n",
            "\n",
            "    grammar  \n",
            "0  0.956622  \n",
            "Current result ==================================================\n",
            "Sample count: 10\n",
            "     method  comp rate     intro      body  conclusion   isthmus  simlirality  \\\n",
            "0  SAM+WGAN   0.169453  0.491076  0.524219    0.541874  0.003655     0.522887   \n",
            "\n",
            "   grammarity  \n",
            "0     0.95585  \n",
            "==================================================\n",
            "11 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "실제로 21일이 되어 런던 경찰국의 재프 경감이 포아로를 찾아왔을 때 나는 겨우 그 일을 생각해 냈다. 이 사법 경찰관과는 이미 오래 전부터 알고 있었기 때문에 그는 나를 보자 진심으로 환영해 주었다. 그는 큰소리로 말했다. “여, 내가 헤이스팅즈 대위를 몰라볼 리 있겠습니까. 드디어 당신의 야만 지대에서 돌아오셨군요! 포아로 씨와 함께 계신 당신을 뵈니 정말 예전 그대로입니다 그려. 게다가 건강하신 듯 하군요. 머리가 좀 벗겨졌는가요? 그렇습니다, 누구나 그렇게 되지요. 나도 그렇습니다. ” 나는 좀 놀랐다. 머리 꼭대기에 머리칼이 덮이도록 빗어 두었기 때문에 벗겨진 곳이 눈에 띄지 않으리라 여기고 있었던 것이다. 그러나 재프 경감은 그런 점에 그리 머리가 잘 도는 편이 아니었다. 그래서 나는 좋은 얼굴로 아무도 젊어지는 사람은 없다는 데 동의했다. 재프 경감은 말했다. “그러나 이 포아로 씨만은 다릅니다. 헤어토닉의 좋은 광고가 되지요. 얼굴 구석구석이 한층 더 싱싱해졌습니다. 늘그막에 이르러 점점 더 각광받게 되셨으니 말입니다. 요즘의 유명한 사건에는 모조리 관계되어 계시지요.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/140       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/139       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/138       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/137       \n",
            "Negative tokens: ['되어' '그는' '곳이' '좋은' '되셨으니']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 138/139       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 137/138       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 136/137       \n",
            "Peak count: 8\n",
            "Frame tokens: 주었다. 드디어 하군요. 그렇습니다, 그렇습니다. 것이다. 싱싱해졌습니다. 계시지요. \n",
            "\n",
            "Similarity : 0.4905595347079681\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.347499370574951 Generator / grammar loss:-0.2026877999305725   similarity loss:-0.1675817221403122\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "실제로 경찰국의 재프 나를 주었다. 말했다. 리 드디어 하군요. 벗겨졌는가요? 그렇습니다, 나도 그렇습니다. 그래서 얼굴로 말했다. “그러나 되지요. 얼굴 구석구석이 싱싱해졌습니다. 말입니다. 모조리 계시지요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.210054  0.453106  0.596627  0.613381  0.005174  0.572949   \n",
            "\n",
            "    grammar  \n",
            "0  0.984023  \n",
            "Current result ==================================================\n",
            "Sample count: 11\n",
            "     method  comp rate     intro      body  conclusion   isthmus  simlirality  \\\n",
            "0  SAM+WGAN   0.173144  0.487624  0.530802    0.548375  0.003793     0.527438   \n",
            "\n",
            "   grammarity  \n",
            "0    0.958411  \n",
            "==================================================\n",
            "12 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "열차 사건, 공중에서의 사건, 사교계 살인 사건……. 정말이지 여기서기에 이분은 등장합니다. 은퇴하고 나서 훨씬 더 유명해지셨답니다. ” 포아로가 웃으며 말했다, “요전에도 헤이스팅즈에게 말했었지요. 나는 언제나 또다시 등장하는 프리마돈나 같다고“ “마지막에는 자신의 죽음을 탐정한다 해도 우스운 일이 아닐겁니다. 이건 기발한 생각인데, 정말. 책에 써둬야겠어. ” 재프 경감은 커다랗게 웃었다. 포아로는 내게 눈짓을 해보였다. “그것을 해야 할 사람은 우선 헤이스팅즈지요. ” 재프 경감은 웃었다. “하하하! 농담입니다, 농담입니다. ” 나는 그 생각이 어째서 악취미로 여겨졌다. 가엾게도 포아로는 점점 나이를 먹어 가고 있다. 죽음이 가까이 오는 것과 관계된 그 농담이 그에게 유쾌할 리 없을 것이다. 내 태도에 속마음이 나타나 있었던 모양이다. 재프 경감은 화재를 바꾸었다. “포아로 씨의 익명 편지에 대해 들으셨습니까?” 포아로가 말했다. “저번에 보여 줬지요.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/113       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/112       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/111       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/110       \n",
            "Negative tokens: ['자신의' '우스운' '”' '있었던' '“포아로']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 111/112       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 110/111       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 109/110       \n",
            "Peak count: 6\n",
            "Frame tokens: 정말이지 ” 포아로는 “하하하! 속마음이 줬지요. \n",
            "\n",
            "Similarity : 0.4519609675750982\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.131354808807373 Generator / grammar loss:-0.16617387533187866   similarity loss:-0.15301945805549622\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "정말이지 훨씬 유명해지셨답니다. ” 헤이스팅즈에게 나는 탐정한다 포아로는 해보였다. 할 “하하하! 그 생각이 여겨졌다. 유쾌할 것이다. 속마음이 말했다.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.174897  0.562476  0.553003  0.430698  0.003601  0.518206   \n",
            "\n",
            "    grammar  \n",
            "0  0.919874  \n",
            "Current result ==================================================\n",
            "Sample count: 12\n",
            "     method  comp rate     intro      body  conclusion   isthmus  simlirality  \\\n",
            "0  SAM+WGAN    0.17329  0.493862  0.532652    0.538569  0.003777     0.526669   \n",
            "\n",
            "   grammarity  \n",
            "0      0.9552  \n",
            "==================================================\n",
            "13 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "” 나는 소리쳤다. “아, 그렇지. 완전히 잊고 있었어. 문제의 날짜가 언제였지?” 재프 경감이 말했다. “21일입니다. 그래서 내가 조사해 보았지요. 어제가 21일이었기 때문에, 어젯밤 혹시나 싶어 앤도버를 불러 보았습니다. 그랬더니 역시 장난이었지요. 아무 일도 없었으니까요. 어린아이가 돌을 던져 쇼윈도가 하나 깨진 일과 술주정꾼의 규칙 위반이 두 건. 그래서 우리 벨기에인 친구분(포아로)이 처음으로 헛짚으신 게 되었다는 이야기입니다. ” 포아로는 인정했다. “확실히 한시름 놓았습니다. ” 재프 경감이 동정하듯 말했다. “많이 염려하고 계신 것 같았습니다만? 가엾게도, 우리는 그런 것을 날마다 몇십 통씩 받는답니다. 달리 아무 하릴없는 머리가 좀 이상한 사람들이 그런 것을 쓰지요. 그리 악의가 있는 건 아닙니다. 뭐, 일종의 흥분에서지요. ” 포아로가 말했다.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/101       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/100       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/99       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/98       \n",
            "Negative tokens: ['“아,' '그랬더니' '하나' '그래서' '되었다는' '”' '한시름' '달리' '뭐,']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 99/100       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 98/99       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 97/98       \n",
            "Peak count: 6\n",
            "Frame tokens: “21일입니다. ” 인정했다. 뭐, 흥분에서지요. 말했다. \n",
            "\n",
            "Similarity : 0.5350194938909592\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.2940261363983154 Generator / grammar loss:-0.20451724529266357   similarity loss:-0.17490001022815704\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "경감이 “21일입니다. 그래서 어제가 불러 없었으니까요. ” 인정했다. 한시름 재프 경감이 말했다. 계신 날마다 뭐, 흥분에서지요. ” 말했다.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.185185  0.698265  0.579837  0.520843  0.005443  0.585824   \n",
            "\n",
            "    grammar  \n",
            "0  0.954548  \n",
            "Current result ==================================================\n",
            "Sample count: 13\n",
            "     method  comp rate     intro      body  conclusion   isthmus  simlirality  \\\n",
            "0  SAM+WGAN   0.174205  0.509585  0.536281    0.537205  0.003905     0.531219   \n",
            "\n",
            "   grammarity  \n",
            "0    0.955149  \n",
            "==================================================\n",
            "14 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "“그걸 그토록 진지하게 생각했던 건 정말 어리석은 짓이었습니다. 내가 코를 들이민 것은 새의 보금자리였던 셈이군요. ” 재프 경감이 말했다. “말과 벌을 혼동했던 겁니다. ” “뭐라고요?” “아니, 속담입니다. 자, 이제 가봐야겠군요. 이 가까이에 볼일이 있어서요. 도난품인 보석을 인수하러 왔지요. 그곳에 가는 길에 마음 놓으시도록 잠시 들렀던 겁니다. 회색 뇌세포를 뜻없이 써버리는 건 낭비니가요. ” 재프 경감은 기분좋게 웃으며 돌아갔다. 포아로가 말했다. “사람좋은 재프 경감은 그리 달라지지 않았지?” 나는 보복하듯 말했다. “아주 늙었군. 오소리같이 잿빛이 되었어. ” 포아로는 헛기침을 하고 나서 말했다. “헤이스팅즈, 아주 하찮은 장치가 있는데, 내 단골 이발사는 재간있는 사나이지. 머리에 그 장치를 붙이고 그 위에 자신의 머리칼을 벗어 놓는다네. 그건 가발이 아닐세, 잘 알겠지만. ” 나는 으르렁댔다.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/109       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/108       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/107       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/106       \n",
            "Negative tokens: ['놓으시도록' '않았지?”' '”']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 107/108       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 106/107       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 105/106       \n",
            "Peak count: 6\n",
            "Frame tokens: ” 속담입니다. 말했다. ” 말했다. 으르렁댔다. \n",
            "\n",
            "Similarity : 0.4276316964680702\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.3286077976226807 Generator / grammar loss:-0.20295606553554535   similarity loss:-0.1697947084903717\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            " “그걸 정말 내가 ” “아니, 속담입니다. 가봐야겠군요. 말했다. 달라지지 않았지?” ” 하고 말했다. 사나이지. 그 나는 으르렁댔다.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.165577  0.345769  0.528169  0.568948  0.009416  0.503923   \n",
            "\n",
            "   grammar  \n",
            "0   0.9824  \n",
            "Current result ==================================================\n",
            "Sample count: 14\n",
            "     method  comp rate     intro      body  conclusion   isthmus  simlirality  \\\n",
            "0  SAM+WGAN   0.173589  0.497884  0.535702    0.539473  0.004299     0.529269   \n",
            "\n",
            "   grammarity  \n",
            "0    0.957096  \n",
            "==================================================\n",
            "15 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "“포아로, 분통 치미는 자네 이발사의 더러운 발견 따윈 아무래도 좋네. 대체 내 머리가 어떻다고 그런 소리를 하는 건가?” “아니, 아무렇지도 않아, 아무렇지도. ” “내가 대머리가 되어가고 있다는 건 아니겠지?” “물론 그런 건 아닐세! 그런 건……. ” “그 나라의 뜨거운 여름은 절로 얼마쯤 머리를 벗겨지게 하지만 말이야. 그냥 질좋은 헤어토닉이나 가져가지. ” “그게 좋겠군. ” “그렇다 해도 재프 경감 따위가 관여할 일은 아니야. 녀석은 언제나 기분좋지 않았지. 게다가 유머 센스도 없어. 사람이 앉으려고 할 때 의자를 잡아당겨지면 웃는 그런 사나이거든. ” “그러면 사람들은 대개 웃지. ” “모름지기 센스가 없단 말일세. ” “앉으려던 사람의 입장에서 본다면 확실히 그렇지. ” “그렇네. ” 나는 얼마쯤 기분을 돌리며 다시 말했다―머리칼이 적어졌다는 말에 내가 아주 민감해 있다는 것을 인정하지 않으면 안 되겠다. “익명 편지가 아무 일 없었다니 유감이군. ‘ “그것은 완전히 내 잘못 생각이었네. 그 편지에 어쩐지 피비린내나는 것 같은 느낌이 있었는데, 그러나 단순한 장난이었어. 아, 나도 나이 먹어 아무것도 아닌 일에 짖어대는 눈먼 개처럼 의심이 많아져 버렸나 보네.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/154       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/153       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/152       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/151       \n",
            "Negative tokens: ['그런' '아니겠지?”' '그런' '”' '기분을' '적어졌다는' '아무' '아닌']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 152/153       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 151/152       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 150/151       \n",
            "Peak count: 8\n",
            "Frame tokens: 그런 말이야. 않았지. 없어. 없단 생각이었네. 장난이었어. 보네. \n",
            "\n",
            "Similarity : 0.49486034362745346\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.4103124141693115 Generator / grammar loss:-0.18893688917160034   similarity loss:-0.14731501042842865\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "대머리가 그런 건……. ” “그 뜨거운 머리를 하지만 말이야. ” “그렇다 재프 않았지. 유머 없어. 사나이거든. 사람들은 대개 없단 “그렇네. “익명 생각이었네. 장난이었어. 보네.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.167488  0.631209  0.585819  0.542621  0.001308  0.581937   \n",
            "\n",
            "    grammar  \n",
            "0  0.981625  \n",
            "Current result ==================================================\n",
            "Sample count: 15\n",
            "     method  comp rate     intro      body  conclusion  isthmus  simlirality  \\\n",
            "0  SAM+WGAN   0.173182  0.506772  0.539043    0.539682   0.0041     0.532781   \n",
            "\n",
            "   grammarity  \n",
            "0    0.958731  \n",
            "==================================================\n",
            "16 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "” 나는 웃으며 말했다. “내가 도우려면, 우리는 다른 데서 온갖 진수가 모아진 멋진 범죄를 찾아내야만 되겠군. ” “자네는 요전에 내가 했던 말을 기억하고 있나? 만일 요리를 주문하듯 범죄를 주문할 수 있다면 어떤 것을 고르겠나?” 나는 좋아진 그의 기분에 휩쓸려 말했다. “그렇지, 메뉴를 잘 봐야 하지 않겠나. 강도? 위조지폐? 아니, 이런 건 안 돼? 이건 식물성 요리 같지? 역시 살인이 좋겠군. 피비린내나는 살인사건, 물론 여러 가지가 딸린 것으로. ” “옳지, 오르되브르(식사 전 또는 술안주로 먹는 가벼운 요리)로군. ” “피해자는 남자로 할까, 여자로 할까? 역시 남자가 좋겠어. 누군가 유명한 사람, 미국의 백만장자나 국무장관이나 신문사 사장쯤 되는 인물. 범행 현장은……그렇지, 훌륭한 낡은 도서관 같은 데가 어떨까? 분위기로서 이 이상의 것은 없네. 흉기는 기묘한 형태로 구부러진 단도 아니면, 뭔가 둔기 같은 것, 예를 들면 조각된 돌상이라든지……. ” 포아로는 한숨을 쉬었다. “그렇잖으면 물론 독약.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/130       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/129       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/128       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/127       \n",
            "Negative tokens: ['만일' '수' '것을' '강도?' '살인이' '또는' '범행' '분위기로서' '흉기는' '“그렇잖으면']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 128/129       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 127/128       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 126/127       \n",
            "Peak count: 7\n",
            "Frame tokens: 되겠군. 말했다. 피비린내나는 것으로. 요리)로군. 역시 독약. \n",
            "\n",
            "Similarity : 0.4395191262867242\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.7068848609924316 Generator / grammar loss:-0.19552917778491974   similarity loss:-0.12165472656488419\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "” 웃으며 도우려면, 우리는 되겠군. 고르겠나?” 말했다. 아니, 안 이건 식물성 역시 좋겠군. 피비린내나는 것으로. “옳지, 전 요리)로군. 역시 독약. \n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.167954  0.495579  0.460848  0.361386  0.003234  0.437956   \n",
            "\n",
            "    grammar  \n",
            "0  0.976477  \n",
            "Current result ==================================================\n",
            "Sample count: 16\n",
            "     method  comp rate     intro      body  conclusion   isthmus  simlirality  \\\n",
            "0  SAM+WGAN   0.172856  0.506073  0.534156    0.528539  0.004045     0.526854   \n",
            "\n",
            "   grammarity  \n",
            "0     0.95984  \n",
            "==================================================\n",
            "17 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "하지만 이것은 아무래도 너무 전문적인 것 같네. 그렇다면 깊은 밤에 메아리치는 권총 소리……이런 것으로 할까. 그리고 아름다운 여자 하나, 둘. ” 친구는 중얼거렸다. “그녀는 빨강머리겠지. ” “신통치 못한 농담이군. 물론 아름다운 여자 한 사람에게 잘못된 혐의가 씌워져야만 되겠지. 그리고 그녀와 젊은이 사이에 오해가 생기고. 물론 그 밖에도 몇 사람에게 혐의가 돌아가지 않으면 안 되네. 이를테면 피해자의 친구거나 경쟁 상대인 피부빛이 검고 위험한 타입의 중년 여자, 얌전한 비서. 이들이 유력한 혐의자인데, 거기에 행동거지가 무뚝뚝하고 성실한 사나이인 해고된 하인이라든지 사냥터 관리인 등이 두어 사람쯤 그리고 재프 경감 같은 얼치기 형사. 그래, 이쯤이면 되겠지. ” “그것이 자네가 말한 온갖 진수가 모아진 범죄인가?” “찬성하지 않는구먼?” 포아로는 한심스러운 듯 나를 보았다. “자네는 지금까지 씌어진 거의 모든 미스터리 소설의 아주 멋있는 줄거리를 만들어 주었네. ” “그럼, 자네라면 어떤 주문을 할 건가?” 포아로는 눈을 감고 의자에 기댔다. 그의 목소리는 입술 사이로 조용히 흘러나왔다. “아주 단순한 범죄, 복잡한 데가 조금도 없는 범죄. 조용한 가정 생활의 범죄……열광적이 아니고 아주 내밀스러운. ” “범죄에 내밀스러운 게 있을 수 있는가?” 포아로는 중얼거리듯 말했다. “네 사람이 앉아서 브리지를 하고 있네.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/168       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/167       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/166       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/165       \n",
            "Negative tokens: ['메아리치는' '아름다운' '오해가' '혐의가' '친구거나' '사람쯤' '범죄인가?”' '“자네는' '미스터리' '멋있는' '그의'\n",
            " '단순한' '있을' '중얼거리듯']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 166/167       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 165/166       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 164/165       \n",
            "Peak count: 9\n",
            "Frame tokens: 중얼거렸다. 못한 잘못된 이들이 이쯤이면 흘러나왔다. 범죄. 내밀스러운. 있네. \n",
            "\n",
            "Similarity : 0.42960332851699223\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.5492403507232666 Generator / grammar loss:-0.19223575294017792   similarity loss:-0.13586494326591492\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "이것은 아무래도 밤에 아름다운 하나, 둘. 중얼거렸다. “그녀는 빨강머리겠지. 못한 이들이 그래, 이쯤이면 되겠지. 아주 감고 흘러나왔다. 데가 없는 범죄. 내밀스러운 게 있는가?” 포아로는 앉아서 하고 있네.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio    intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.168831  0.53143  0.475164  0.542326  0.000866  0.506566   \n",
            "\n",
            "    grammar  \n",
            "0  0.991531  \n",
            "Current result ==================================================\n",
            "Sample count: 17\n",
            "     method  comp rate     intro      body  conclusion   isthmus  simlirality  \\\n",
            "0  SAM+WGAN   0.172619  0.507564  0.530686     0.52935  0.003858     0.525661   \n",
            "\n",
            "   grammarity  \n",
            "0    0.961705  \n",
            "==================================================\n",
            "18 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "그리고 한 사람이 그 게임에 끼지 않고 벽난로 옆 의자에 앉아 있지. 밤이 깊어졌을 즈음 난롯불 옆에 앉아 있던 사나이가 죽은 것을 알게 되네. 네 사람 가운데 누군가가 손이 비게 되었을 때 죽인 것인데, 모두들 게임에 정신이 팔려 모르고 있었지. 자, 이것이 사건이네. 범인은 네 사람 가운데 누구일까?” (나, 아시겠죠? 다들<테이블위의카드>네요. ) “도무지 자극적인 데가 조금도 없는걸. ” 포아로는 비난하듯 눈길로 나를 보았다. “없지. 이상한 모양으로 구부러진 단도도, 협박도, 신상의 눈에서 훔쳐 낸 에메랄드도, 흔적을 알 수 없는 동양의 독약 같은 것도 없네. 헤이스팅즈, 자네는 아무래도 멜러 드라마 애호가로군. 자네는 하나의 살인이 아니라 연쇄적인 살인 쪽이 좋은 거지?” “그렇네, 책 속의 두 번째 살인은 경기가 좋아 보이던걸. 제1장에서 살인이 일어나 마지막 페이지 바로 앞까지 모두들의 알리바이가 성립되어 있다는 건……그래, 좀 따분하지. ‘ 전화가 울려 포아로가 일어나 받으러 갔다. “여보세요, 에르큘 포아로입니다. ‘ 잠시 말없이 듣고 있던 그의 얼굴빛이 달라졌다. 그의 대답은 짧게 토막토막 끊어졌다, “그랬군요……물론, 그렇지요……아, 가겠습니다……당연합니다……그야 당신 말대로겠지요. 그렇지요, 갖고 가겠습니다. 그럼, 곧. ” 그는 수화기를 내려놓고 방을 가로질러 내 곁으로 돌아왔다.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/164       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/163       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/162       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/161       \n",
            "Negative tokens: ['그' '끼지' '자,' '자네는' '거지?”' '그의' '내']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 162/163       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 161/162       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 160/161       \n",
            "Peak count: 9\n",
            "Frame tokens: 자, 사건이네. 다들<테이블위의카드>네요. 없는걸. “없지. 따분하지. “그랬군요……물론, 곧. 돌아왔다. \n",
            "\n",
            "Similarity : 0.5319976462788151\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.4381494522094727 Generator / grammar loss:-0.1808730512857437   similarity loss:-0.13633625209331512\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "죽인 자, 이것이 사건이네. 범인은 사람 (나, 다들<테이블위의카드>네요. ) 데가 없는걸. “없지. 이상한 협박도, 에메랄드도, 알 없네. 따분하지. 받으러 그의 얼굴빛이 “그랬군요……물론, 말대로겠지요. 곧. 곁으로 돌아왔다. \n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.188596  0.472639  0.604457  0.632636  0.004863  0.586547   \n",
            "\n",
            "    grammar  \n",
            "0  0.949451  \n",
            "Current result ==================================================\n",
            "Sample count: 18\n",
            "     method  comp rate     intro      body  conclusion   isthmus  simlirality  \\\n",
            "0  SAM+WGAN   0.173506  0.505624  0.534784    0.535088  0.003914     0.529043   \n",
            "\n",
            "   grammarity  \n",
            "0    0.961024  \n",
            "==================================================\n",
            "19 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "“재프 경감에게서 온 걸세, 헤이스팅즈. ” “그래서?” “경찰국으로 돌아가자마자 마침 앤도버에서 연락이 있었다는 거야. ” 나는 흥분하여 소리쳤다. “앤도버?” 포아로가 천천히 말했다. “노파가 하나 살해되었다는군. 애셔(Ascher)라는 이름으로, 담배와 신문을 파는 조그만 가게의 노파일세. ” 나는 얼마쯤 맥이 풀렸다. 앤도버라는 이름으로 부채질되었던 내 흥미는 어리둥절해졌다. 나는 뭔가 환상적인, 아주 색다른 것을 기대하고 있었는데! 조그만 담배 가게 노파가 살해된 일 따위는 아무래도 그리 신통찮다. 포아로는 여전히 느릿느릿한 무게있는 목소리로 말을 이었다. “앤도버 경찰에서는 범인을 체표할 수 있다고 생각하는 모양이야. ” 나는 다시 한 번 맥이 풀렸다. “노파는 그 남편과 사이가 나빴던 것 같네. 남편은 술꾼이며 질나쁜 녀석으로 종종 노파를 죽이겠다고 협박했었다는군. 그러나 그곳 경찰에서는 다른 점도 고려하여 내가 받은 익명의 편지를 보고 싶다는 거야. 나는 곧 자네와 함께 앤도버로 가겟다고 말해 두었네. ” 나는 얼마쯤 기운을 되찾았다. 시시하게 보일지라도 아무튼 범죄임에 틀림없다. 내가 범죄니 범인이니 하는 것에 관계하고부터 벌써 많은 세월이 흘렀다.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/141       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/140       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/139       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/138       \n",
            "Negative tokens: ['걸세,' '앤도버에서' '“앤도버?”' '“노파가' '앤도버라는' '있었는데!' '“앤도버' '남편은' '곧' '앤도버로'\n",
            " '기운을' '관계하고부터']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 139/140       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 138/139       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 137/138       \n",
            "Peak count: 8\n",
            "Frame tokens: 살해되었다는군. 풀렸다. 어리둥절해졌다. “노파는 협박했었다는군. 되찾았다. 틀림없다. 흘렀다. \n",
            "\n",
            "Similarity : 0.463683113662672\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.2536778450012207 Generator / grammar loss:-0.15865226089954376   similarity loss:-0.13314710557460785\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "“재프 “그래서?” 앤도버에서 흥분하여 소리쳤다. 천천히 살해되었다는군. 풀렸다. 내 어리둥절해졌다. 환상적인, “노파는 협박했었다는군. 경찰에서는 고려하여 가겟다고 되찾았다. 시시하게 범죄임에 틀림없다. 내가 범인이니 흘렀다. \n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.211921  0.587932  0.535212  0.570748  0.000482  0.556417   \n",
            "\n",
            "    grammar  \n",
            "0  0.977785  \n",
            "Current result ==================================================\n",
            "Sample count: 19\n",
            "     method  comp rate     intro      body  conclusion   isthmus  simlirality  \\\n",
            "0  SAM+WGAN   0.175528  0.509956  0.534807    0.536965  0.003734     0.530484   \n",
            "\n",
            "   grammarity  \n",
            "0    0.961906  \n",
            "==================================================\n",
            "20 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "나는 포아로의 다음 말을 거의 듣지 있지 않았다. 그러나 그것은 나중에 중요한 뜻을 지니고 내 기억 속에 되살아났다. 에르큘 포아로가 이렇게 말했다. “이것이 시작이다. ” < 철도 안내서 > 우리는 앤도버에서 글렌 형사의 마중을 받았다. 그는 키가 크고 머리칼이 아름다운 남자로 기분 좋은 미소를 떠올리고 있었다. 이야기를 간결이 하기 위해 사건의 사실만 간단히 밝혀 두는 게 좋으리라. 범죄는 22일 오전 1시에 그곳 순경에 의해 발견되었다. 순찰을 돌면서 가게 문을 밀어 보니 잠겨 있지 않았다. 안으로 들어가자 처음에는 아무도 없는 듯했으나, 계산대 쪽으로 회중전등을 돌리니 노파의 웅크린 시체가 눈에 들어왔다. 경찰의가 현장에 와 닿아 노파가 뒷머리를 강하게 얻어맞았음을 알아냈는데, 아마도 계산대 뒤의 선반에서 담배 봉지를 꺼내는 도중에 얻어맞은 듯했다. 범행은 일곱 시간 내지 아홉 시간 전에 행해진 것 같았다. 형사는 설명했다. “그러나 더 정확한 시간을 추정할 수 있습니다. 5시 30분에 담배를 사러 들어갔던 사나이가 있습니다. 그리고 6시 5분 좀 지나서 가게에 들어갔다가 아무도 없는 줄 알고 그냥 나온 다른 남자가 있습니다. 그러니까 범행 시간을 5시 30분에서 6시 5분 사이로 추정할 수 있지요. 이웃에서 애셔를 보았다고 말해 온 사람은 아직 없습니다. 그러나 물론 이제부터입니다. 그는 9시쯤 <스리크라운즈>에서 꽤 취해 있었습니다.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/179       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/178       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/177       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/176       \n",
            "Negative tokens: ['나중에' '사건의' '듯했으나,' '시간' '시간을']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 177/178       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 176/177       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 175/176       \n",
            "Peak count: 10\n",
            "Frame tokens: 시작이다. 받았다. 이야기를 그곳 발견되었다. 들어가자 형사는 그냥 이제부터입니다. 있었습니다. \n",
            "\n",
            "Similarity : 0.4123344420876902\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.693338632583618 Generator / grammar loss:-0.17744579911231995   similarity loss:-0.10511518269777298\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            " 있지 않았다. 그러나 그것은 나중에 되살아났다. 이렇게 말했다. 시작이다. ” 우리는 앤도버에서 마중을 받았다. 좋은 두는 가게 눈에 행해진 시간을 지나서 남자가 없습니다. 그러나 이제부터입니다. 9시쯤 취해 있었습니다. \n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro     body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.177054  0.734224  0.43074  0.586248  0.015354  0.538089   \n",
            "\n",
            "    grammar  \n",
            "0  0.989356  \n",
            "Current result ==================================================\n",
            "Sample count: 20\n",
            "     method  comp rate     intro      body  conclusion   isthmus  simlirality  \\\n",
            "0  SAM+WGAN   0.175605  0.521169  0.529603    0.539429  0.004315     0.530864   \n",
            "\n",
            "   grammarity  \n",
            "0    0.963278  \n",
            "==================================================\n",
            "21 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "체포하는 대로 곧 용의자로 잡아 둘 겁니다. ” 포아로가 물었다. “그리 호감주는 타입의 사나이가 아닌 모양이군요?” “싫은 사람입니다. ” “그는 자기 아내와 함께 살고 있지 않았던가요?” “그렇습니다. 몇 해 전에 헤어졌지요. 애셔는 독일 사람으로 한때 급사일을 한 적도 있었습니다만, 술을 너무 마셔서 차츰 그를 고용하는 곳이 없게 되었습니다. 그래서 그 부인이 일을 나가게 되었지요. 마지막으로 한 일은 미스 로즈라는 노부인의 요리사 겸 가정부였습니다. 급료를 받아 남편에게 꽤 많은 돈을 주었던 듯한데, 그는 몽땅 마셔 버리고는 자기 마누라가 일하는 곳으로 가서 소동을 벌이곤 했답니다. 그래서 애셔 부인은 미스 로즈네 농장으로 가서 일하게 되었습니다. 거기는 앤도버에서 3마일 떨어진 완전한 시골이어서 그도 그리 자주 찾아가지 못했지요. 미스 로즈가 세상을 떠나자 애셔 부인은 유산을 조금 받았습니다. 그래서 그 돈으로 담배와 신문을 파는 이 조그만 가게를 시작했습니다. 싸구려 담배와 얼마 안 되는 신문뿐이어서 겨우 먹고 사는 정도였지요. 애셔가 자주 찾아와 그녀에게 욕을 하곤 했는데, 그녀 쪽에서는 귀찮고 하니까 잔돈푼이나 줘서 쫓아 버리곤 했지요. 1주일에 15실링은 줬던 것 같습니다. ” 포아로가 물었다. “아이들은 있었소?” “없습니다. 조카딸이 하나 오버튼 가까이에서 일하고 있습니다. 아주 고집이 센 똑똑한 아가씨지요.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/171       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/170       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/169       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/168       \n",
            "Negative tokens: ['”' '아내와' '없게' '나가게' '미스' '듯한데,' '몽땅' '마누라가' '시골이어서' '애셔가' '하곤' '잔돈푼이나'\n",
            " '버리곤' '조카딸이' '고집이']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 169/170       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 168/169       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 167/168       \n",
            "Peak count: 9\n",
            "Frame tokens: 헤어졌지요. 급사일을 로즈라는 가정부였습니다. 부인은 못했지요. 부인은 “없습니다. 아가씨지요. \n",
            "\n",
            "Similarity : 0.44149803609523275\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.590379238128662 Generator / grammar loss:-0.2030167430639267   similarity loss:-0.14216840267181396\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "“그리 타입의 사나이가 자기 살고 몇 해 헤어졌지요. 급사일을 한 미스 로즈라는 겸 가정부였습니다. 부인은 거기는 못했지요. 부인은 조금 조그만 사는 15실링은 “없습니다. 오버튼 아주 똑똑한 아가씨지요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.163558  0.307232  0.542587  0.535806  0.011965  0.493482   \n",
            "\n",
            "    grammar  \n",
            "0  0.984619  \n",
            "Current result ==================================================\n",
            "Sample count: 21\n",
            "     method  comp rate     intro      body  conclusion   isthmus  simlirality  \\\n",
            "0  SAM+WGAN   0.175031  0.510982  0.530222    0.539257  0.004679     0.529084   \n",
            "\n",
            "   grammarity  \n",
            "0    0.964295  \n",
            "==================================================\n",
            "22 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "” “그 애셔라는 사나이가 아내를 자주 협박했었다는 거지요?” “그렇습니다. 그는 술에 취하면 무섭게 변해서 아내의 머리를 박살내겠다는 둥 소리를 질러대곤 했답니다. 애셔 부인은 정말 끔찍한 일을 당한 거지요. ” “그녀는 몇 살이었소?” “60살이 다 되었지요. 아마. 훌륭하고 부지런한 사람이었습니다. ” 포아로는 신중하게 말했다. “그러면 그 애셔라는 사나이가 범인이라는 게 당신 의견이오?” 형사는 조심스럽게 헛기침을 했다. “그렇게 말하는 건 좀 성급한 판단입니다만, 프란츠 애셔가 지난밤에 어떻게 지냈는지 그 자신의 설명을 듣고 싶은 겁니다, 포아로 씨. 만일 만족할 만한 설명을 들을 수 있다면 좋겠지만, 그렇지 않으면……. ” 그는 꽤 의미심장하게 말을 끊었다. “가게에서는 아무것도 없어지지 않았소?” “네, 아무것도. 돈도 그대로 다 있고, 훔쳐 간 흔적이 전혀 없습니다. ” “그 애셔라는 사나이가 술에 취해 가게로 들어와 아내를 욕하다가 끝내 때려 죽였다는 거로군요?” “네, 그것이 가장 타당한 해석이겠지요. 그러나 당신이 받으셨다는 그 이상한 편지도 고려해 보고 싶습니다, 포아로 씨. 그것이 이 애셔라는 사나이로부터 보내진 것인지 어떤지 알 수 없으니까요. ” 포아로가 편지를 건네주자 형사는 이마를 찌푸리고 그것을 읽었다. 형사는 마침내 말했다. “아무래도 애셔가 쓴 것 같지는 않군요. 도대체 이 <우리> 영국 경찰이라는 말을 애셔가 쓸 턱이 없지요.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/174       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/173       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/172       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/171       \n",
            "Negative tokens: ['무섭게' '부지런한' '신중하게' '애셔라는' '헛기침을' '판단입니다만,' '애셔가' '지냈는지' '만일' '의미심장하게'\n",
            " '않았소?”' '애셔라는' '그러나' '이상한' '애셔라는' '것인지' '찌푸리고' '“아무래도']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 172/173       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 171/172       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 170/171       \n",
            "Peak count: 9\n",
            "Frame tokens: 애셔라는 했답니다. 아마. 씨. ” 없으니까요. 말했다. 애셔가 없지요. \n",
            "\n",
            "Similarity : 0.3820919707496613\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.5504372119903564 Generator / grammar loss:-0.19431906938552856   similarity loss:-0.13781878352165222\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "” 애셔라는 자주 둥 했답니다. 되었지요. 아마. 부지런한 당신 의견이오?” 씨. ” 그는 “가게에서는 아무것도. ” 취해 타당한 그 이 없으니까요. 찌푸리고 말했다. 애셔가 쓸 턱이 없지요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.149233  0.366047  0.520143  0.508884  0.004919  0.485946   \n",
            "\n",
            "    grammar  \n",
            "0  0.977998  \n",
            "Current result ==================================================\n",
            "Sample count: 22\n",
            "     method  comp rate     intro      body  conclusion  isthmus  simlirality  \\\n",
            "0  SAM+WGAN   0.173858  0.504394  0.529763    0.537876  0.00469     0.527123   \n",
            "\n",
            "   grammarity  \n",
            "0    0.964918  \n",
            "==================================================\n",
            "23 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "그야말로 각별히 교묘하게 행동하려는 게 아니었다면 말입니다. 게다가 그에겐 그만한 머리가 없습니다. 그는 이제 산송장입니다. 다 망가져 버렸지요. 이런 글을 쓰기에는 그의 손이 너무 떨릴걸요. 편지지도 잉크도 고급품이고. 그러나 편지에는 21일이라고 한 것은 이상하군요. 물론 우연의 일치겠지만요. ” “그렇겠지요. ” “하지만 이런 일치는 좋지 않습니다, 포아로 씨. 너무 딱 들어맞으니 말입니다. ” 그는 잠시 입을 다물고 있었다. 그의 이마에 주름이 잡혔다. “ABC. 대체 ABC란 어떤 녀석일까요? 메리 드로워―조카딸입니다만―가 좀 도움이 될지도 모르겠군요. 뭐 수고하시는 김에 말입니다. 이 편지만 없다면 나느 프란츠 애셔에게 내기를 걸어도 좋은데요. ” “애셔 부인의 경력은 알고 있소?” “그녀는 햄프셔 태생으로 처녀 때 런던에 나가 직장 생활을 했지요. 거기서 애셔를 만나 결혼했습니다.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/106       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/105       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/104       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/103       \n",
            "Negative tokens: ['그는' '너무' '그의' '수고하시는' '이' '없다면' '“그녀는']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 104/105       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 103/104       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 102/103       \n",
            "Peak count: 6\n",
            "Frame tokens: 말입니다. 그는 버렸지요. 일치겠지만요. 잡혔다. 결혼했습니다. \n",
            "\n",
            "Similarity : 0.438711912758314\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.581496238708496 Generator / grammar loss:-0.20983782410621643   similarity loss:-0.1499611884355545\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "그야말로 행동하려는 게 아니었다면 말입니다. 그는 버렸지요. 일치겠지만요. 들어맞으니 잠시 주름이 잡혔다. 대체 도움이 뭐 수고하시는 말입니다. 결혼했습니다.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio    intro      body    ending      var    total  \\\n",
            "0  SAM+WGAN    0.195991  0.59957  0.450424  0.490647  0.00397  0.49232   \n",
            "\n",
            "    grammar  \n",
            "0  0.983096  \n",
            "Current result ==================================================\n",
            "Sample count: 23\n",
            "     method  comp rate     intro      body  conclusion   isthmus  simlirality  \\\n",
            "0  SAM+WGAN   0.174821  0.508532  0.526314    0.535823  0.004659      0.52561   \n",
            "\n",
            "   grammarity  \n",
            "0    0.965708  \n",
            "==================================================\n",
            "24 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "헤어진 것은 1922년으로, 그즈음 두 사람은 아직 런던에 있었지요. 그녀는 남자에게서 달아나 여기로 왔으나, 남자가 곧 알아차리고 따라와 귀찮게 굴었던 겁니다. ” 마침 거기에 순경이 들어왔다. “무슨 일인가, 브릭스?” “애셔를 연행해 왔습니다. ” “좋아. 이리로 데려오게. 어디 있던가?” “인입선의 화차 안에 숨어 있었습니다. ” “숨어 있었다고? 데려오게. ” 프란츠 애셔는 정말 보기 싫은, 초라한 인간의 표본이었다. 그는 엉엉 울고, 꾸벅꾸벅 절하고, 서슬이 시퍼래지기도 했다. 그 짓무른 눈을 이리저리 움직이며 모두들의 얼굴을 살폈다 “나를 어쩌자는 거야. 나는 아무 짓도 안 했어. 날 이런 데 데려오다니 너무하잖아. 네 놈들은 돼지야. 어쩌자는 거야?” 그의 태도가 갑자기 바뀌었다. “아니, 아니, 그게 아냐. 선생님들은 이 가엾은 늙은이에게 몹쓸 짓을 하고 있소. 심하게 대하고 있소. 누구나 이 가엾은 프란츠에게 심하게 군단 말야, 이 가엾은 프란츠에게.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/120       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/119       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/118       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/117       \n",
            "Negative tokens: ['그즈음' '왔으나,' '”' '꾸벅꾸벅' '모두들의' '이런' '심하게' '심하게' '말야,']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 118/119       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 117/118       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 116/117       \n",
            "Peak count: 7\n",
            "Frame tokens: 굴었던 데려오게. 그는 그 너무하잖아. 돼지야. 프란츠에게. \n",
            "\n",
            "Similarity : 0.49776683362693164\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.413719892501831 Generator / grammar loss:-0.1954096555709839   similarity loss:-0.1534319370985031\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "왔으나, 굴었던 겁니다. 마침 연행해 있던가?” 데려오게. 그는 그 거야. 너무하잖아. 돼지야. “아니, 아냐. 이 몹쓸 있소. 있소. 가엾은 가엾은 프란츠에게.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body   ending       var     total  \\\n",
            "0  SAM+WGAN    0.182927  0.488805  0.612953  0.68741  0.006711  0.610461   \n",
            "\n",
            "    grammar  \n",
            "0  0.976715  \n",
            "Current result ==================================================\n",
            "Sample count: 24\n",
            "     method  comp rate    intro      body  conclusion   isthmus  simlirality  \\\n",
            "0  SAM+WGAN   0.175158  0.50771  0.529924    0.542139  0.004744     0.529146   \n",
            "\n",
            "   grammarity  \n",
            "0    0.966167  \n",
            "==================================================\n",
            "25 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "” 애셔는 울기 시작했다. 형사가 말했다. “그만해 두오, 애셔. 정신차려요. 당신에게 무슨 죄를 뒤집어씌우려는 건 아니오. 지금으로서는. 당신이 싫으면 아무 말 않아도 좋소. 만일 당신이 당신 아내 살해에 관계가 없다면 말이오. ” 애셔는 그 말을 가로막았다. 그 목소리는 비명 같았다. “나는 죽이지 않았어! 죽이지 않았어! 모두 엉터리야! 네 놈들은 거지같은 영국 돼지야. 모두들 내게 죄를 덮어씌우고 있어. 나는 죽이지 않았어, 죽이지 않았어. ” “당신은 늘 아내를 협박하고 있었잖소, 애셔?” “아니, 아니, 네 놈들은 알 리 없어. 그건 농담이었어. 나와 앨리스만이 알고 있는 농담이야. 앨리스는 그걸 알고 있었어.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/88       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/87       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/86       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/85       \n",
            "Negative tokens: ['“나는']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 86/87       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 85/86       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 84/85       \n",
            "Peak count: 5\n",
            "Frame tokens: 정신차려요. 지금으로서는. ” 모두 있었어. \n",
            "\n",
            "Similarity : 0.4111031955373643\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.489774227142334 Generator / grammar loss:-0.20413881540298462   similarity loss:-0.15414553880691528\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "정신차려요. 무슨 건 지금으로서는. ” 목소리는 모두 돼지야. ” “당신은 협박하고 “아니, 그건 앨리스는 있었어.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.182336  0.548421  0.536417  0.484819  0.000761  0.523338   \n",
            "\n",
            "   grammar  \n",
            "0  0.99311  \n",
            "Current result ==================================================\n",
            "Sample count: 25\n",
            "     method  comp rate     intro      body  conclusion   isthmus  simlirality  \\\n",
            "0  SAM+WGAN   0.175445  0.509338  0.530184    0.539846  0.004585     0.528913   \n",
            "\n",
            "   grammarity  \n",
            "0    0.967244  \n",
            "==================================================\n",
            "26 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "” “우스운 농담이로군! 어젯밤 어디 있었는지 말할 수 있소, 애셔?” “말할 수 있고말고, 있고말고. 모두 이야기하지. 난 앨리스한테 가지 않았어. 친구들하고 있었어. 멋있는 친구들하고. <세븐 스타즈>에 있다가……그리고 나서 <레드 독>에 갔어. ” 그는 기침이 나와 말이 막혔다. “딕 윌러즈, 그도 함께 있었지. 커디 녀석도 그리고 조지도……플랫도, 그 밖의 놈들도 많이 있었어. 나는 앨리스에게 가지 않았어. 하느님께 맹세코 나는 사실을 말하고 있어. ” 그 소리는 비명이었다. 형사는 부하에게 눈짓을 했다. “데려가. 용의자를 구금시켜. ” 떨며 욕지거리를 퍼부어대는 그 불쾌한 노인이 나가 버리자 형사는 말했다. “아무래도 알 수 없군요. 그 편지만 없다면 저 늙은이의 짓이 분명한데요. ” “저 사람이 말하는 다른 남자들은 어떻소?” “나쁜 놈들입니다.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/104       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/103       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/102       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/101       \n",
            "Negative tokens: ['“아무래도']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 102/103       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 101/102       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 100/101       \n",
            "Peak count: 6\n",
            "Frame tokens: 모두 친구들하고 있었지. “데려가. 없군요. 놈들입니다. \n",
            "\n",
            "Similarity : 0.5168125375589397\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.445662021636963 Generator / grammar loss:-0.1838645339012146   similarity loss:-0.1385379284620285\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "농담이로군! 어젯밤 애셔?” 모두 이야기하지. 친구들하고 친구들하고. “딕 있었지. 조지도……플랫도, 나는 말하고 비명이었다. “데려가. 없군요. 분명한데요. “나쁜 놈들입니다.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.230769  0.684963  0.614082  0.526735  0.004188  0.602054   \n",
            "\n",
            "    grammar  \n",
            "0  0.972748  \n",
            "Current result ==================================================\n",
            "Sample count: 26\n",
            "     method  comp rate     intro     body  conclusion   isthmus  simlirality  \\\n",
            "0  SAM+WGAN   0.177573  0.516093  0.53341    0.539342  0.004569     0.531726   \n",
            "\n",
            "   grammarity  \n",
            "0    0.967456  \n",
            "==================================================\n",
            "27 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "모두 위증쯤은 손쉽게 할 녀석들이지요. 나도 저 늙은이가 그날 밤 어느 시간까지는 그들과 함께 있었다고 생각합니다. 그러니 6시 사이에 가게 언저리에서 저 늙은이를 본 사람이 있는지 없는지에 달렸다고 봐야겠지요. “ 포아로는 신중하게 머리를 저었다. “가게에서 아무것도 없어지지 않은 건 분명하지요?” 형사는 어깨를 으쓱했다. “그야 경우에 따라 다르겠지요. 담배 한두 갑이 없어졌는지도 모릅니다. 그러나 아무도 그런 일 때문에 사람을 죽이지는 않지요. ” “게다가 아무것도, 뭐라면 좋을까. 가지고 온 것이 없었다는, 그러니까 이상한, 그 장소에 어울리지 않는 그런 아무것도 거기에는 없었다는 거지요?” “철도 안내서가 있었습니다. ” “철도 안내서?” “그렇습니다. 계산대 위에 펼쳐진 채 뒤집혀 있었습니다. 꼭 누군가가 앤도버에서 떠나는 기차 편을 알아보고 있었던 것처럼. 그 할머니나 아니면 손님이 보고 있었다는 것이겠지요. ” “그런 것도 팔고 있었소?” 형사는 머리를 저었다. “1페니짜리 시간표를 팔고 있었습니다만, 그것은 큰 것이었으니까 스미스네 가게나 커다란 문방구점 같은 데서 다룰 겁니다. ” 포아로는 눈을 빛내며 몸을 앞으로 내밀었다. “철도 안내서라고 말했지요? <브레드쇼>던가요, <ABC>던가요?” 그러자 형사의 눈도 빛나기 시작했다. “정말, 그러고 보니 ABC였습니다.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/154       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/153       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/152       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/151       \n",
            "Negative tokens: ['할' '“가게에서' '그런' '어울리지' '안내서?”' '시간표를' '가게나' '문방구점']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 152/153       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 151/152       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 150/151       \n",
            "Peak count: 8\n",
            "Frame tokens: 봐야겠지요. “그야 모릅니다. 좋을까. 있었습니다. 계산대 “철도 ABC였습니다. \n",
            "\n",
            "Similarity : 0.4040819737029029\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.4576776027679443 Generator / grammar loss:-0.15830597281455994   similarity loss:-0.11171320825815201\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "위증쯤은 나도 그날 있었다고 언저리에서 달렸다고 봐야겠지요. 아무것도 분명하지요?” “그야 담배 한두 모릅니다. 아무도 “게다가 좋을까. 안내서가 있었습니다. “철도 “그렇습니다. 계산대 누군가가 “철도 ABC였습니다.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio    intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.181818  0.43342  0.536456  0.417277  0.002787  0.480095   \n",
            "\n",
            "    grammar  \n",
            "0  0.957059  \n",
            "Current result ==================================================\n",
            "Sample count: 27\n",
            "     method  comp rate     intro      body  conclusion   isthmus  simlirality  \\\n",
            "0  SAM+WGAN    0.17773  0.513031  0.533523    0.534821  0.004503     0.529814   \n",
            "\n",
            "   grammarity  \n",
            "0    0.967071  \n",
            "==================================================\n",
            "28 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "” < 조카딸의 이야기 > 이 사건에 대한 내 관심은 ABC 철도 안내서가 나왔을 때 비로서 일기 시작했다고 생각된다. 그때까지 나는 이 사건에 그리 열중하고 있지 않았다. 뒷골목의 노파 살해 같은 시시한 사건은 날마다 신문에 보도되는 흔해빠진 범죄여서 거의 주의를 끌지 못했던 것이다. 나는 마음속으로 익명 편지가 21일이라는 날짜를 지정한 일 따위는 우연의 일치에 지나지 않는다고 생각하고 있었다. 당연히 애셔 부인은 그 남편이 술에 취한 나머지 폭력을 휘둘러 희생된 것으로 여겼다. 그런데 지금 철도 안내서(철도역을 알파벳 순서로 나열했기 때문에 ABC라는 준말로 알려져 있음)가 등장하자 내 온몸에는 흥분의 전율이 일었다. 확실히 이것은 우연의 일치 같은 것 일 리 없다. 시시한 범죄가 새로운 양상을 띠기 시작했다. 애셔 부인을 살해하고 ABC 철도 안내서를 남기고 사라진 신비의 인간은 대체 누구인가? 경찰서를 나와 우리는 먼저 살해된 여자의 시체를 보러 시체 안치소로 갔다. 얼마 안 되는 머리칼을 이마 위로 가지런히 빗어 넘긴 노파의 주름잡힌 얼굴을 보고 있는 동안, 나는 이상한 느낌이 들기 시작했다. 너무나 평화로워 폭력 같은 것과는 거리가 먼 느낌이었다. 경관이 말했다. “누가 무엇으로 자기를 때렸는지 조금도 모르는 얼굴입니다. 카 의사가 그렇게 말하더군요. 오히려 그게 잘된 일이라고 생각합니다. 가엾게도, 깔끔한 사람이었는데. ” 포아로가 말했다. “옛날엔 아름다웠을 것 같군. ” 나는 믿을 수 없는 마음이 들어 중얼거렸다.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/192       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/191       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/190       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/189       \n",
            "Negative tokens: ['그리' '살해' '시시한' '우연의' '나머지' '때문에' '우연의' '시시한' '신비의' '느낌이' '모르는' '믿을'\n",
            " '마음이']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 190/191       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 189/190       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 188/189       \n",
            "Peak count: 10\n",
            "Frame tokens: 생각된다. 범죄여서 지나지 당연히 시작했다. 경관이 오히려 사람이었는데. “옛날엔 중얼거렸다. \n",
            "\n",
            "Similarity : 0.4402707510619227\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.49914288520813 Generator / grammar loss:-0.1710434854030609   similarity loss:-0.12005233764648438\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "> 이 사건에 비로서 일기 시작했다고 생각된다. 일었다. 애셔 인간은 우리는 안치소로 얼마 머리칼을 보고 시작했다. 거리가 먼 경관이 얼굴입니다. 그렇게 말하더군요. 오히려 그게 생각합니다. 사람이었는데. ” “옛날엔 없는 중얼거렸다.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN     0.17328  0.423467  0.394591  0.586685  0.007153  0.457995   \n",
            "\n",
            "    grammar  \n",
            "0  0.982156  \n",
            "Current result ==================================================\n",
            "Sample count: 28\n",
            "     method  comp rate     intro      body  conclusion   isthmus  simlirality  \\\n",
            "0  SAM+WGAN   0.177572  0.509833  0.528561    0.536673  0.004598     0.527249   \n",
            "\n",
            "   grammarity  \n",
            "0     0.96761  \n",
            "==================================================\n",
            "29 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "“그럴까. ‘ “그렇네. 자, 턱의 선이며 뼈 모양이며 머리 생김새를 잘 보게. ” 그는 덮개를 본래대로 해두면서 한숨을 쉬었다. 그리고 나서 우리는 시체 안치소를 나왔다. 다음에는 경찰의와 간단히 면담했다. 카 의사는 유능해 보이는 중년 사나이였다. 그는 활발하게 단정적인 말투로 이야기했다. “흉기는 발견되지 않았습니다. 그것이 무엇이었는지는 알 수 없지요. 무거운 지팡이, 몽둥이, 모래주머니 같은 것……그런 거라면 어느 것이나 들어맞습니다. ” “그런 타격을 가하려면 억센 힘이 필요합니까?” 의사는 날카로운 눈으로 포아로를 보았다. “그 말뜻은 몸을 떨어대는 70살의 노인으로서도 할 수 있느냐는 거지요? 네, 물론 할 수 있습니다. 흉기의 머리 부분에 충분한 무게를 주면 체력이 약한 사람도 바라는 결과를 얻을 수 있습니다. ” “그렇다면 범인은 남자일 수 있는 것과 마찬가지로 여자일 수도 있군요?” 이 말은 얼마쯤 의사를 놀라게 한 모양이었다. “여자도? 네, 그렇습니다. 이런 종류의 범죄를 여자와 관련시켜 생각해 볼 마음은 없었습니다만, 물론 할 수 있습니다. 완전히 가능합니다.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/136       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/135       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/134       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/133       \n",
            "Negative tokens: ['그리고' '유능해' '그는' '“흉기는' '그것이' '무거운' '네,']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 134/135       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 133/134       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 132/133       \n",
            "Peak count: 7\n",
            "Frame tokens: “그렇네. 들어맞습니다. 물론 있습니다. “여자도? 수 가능합니다. \n",
            "\n",
            "Similarity : 0.46815005986550795\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.1196718215942383 Generator / grammar loss:-0.12390576303005219   similarity loss:-0.11192426830530167\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            " “그렇네. ” 그는 나왔다. 경찰의와 의사는 유능해 이야기했다. 무엇이었는지는 없지요. 모래주머니 같은 것……그런 것이나 들어맞습니다. 물론 있습니다. “여자도? 네, 그렇습니다.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.181004  0.557482  0.604389  0.668609  0.002075  0.614274   \n",
            "\n",
            "    grammar  \n",
            "0  0.983259  \n",
            "Current result ==================================================\n",
            "Sample count: 29\n",
            "     method  comp rate     intro      body  conclusion   isthmus  simlirality  \\\n",
            "0  SAM+WGAN    0.17769  0.511476  0.531176    0.541223  0.004511      0.53025   \n",
            "\n",
            "   grammarity  \n",
            "0    0.968149  \n",
            "==================================================\n",
            "30 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "다만 심리적으로 말해서, 이건 여성의 범죄라고 할 수 없지요. ” 포아로도 그 말에 동의하여 열심히 고개를 끄덕였다. “그렇습니다. 그렇습니다. 확실히 있을 수 없는 일입니다. 그러나 모든 가능성을 염두해 두지 않으면 안 되니까요. 시체는 쓰러져 있었겠지요. 어떤 모습이었습니까?” 의사는 피해자의 위치를 세밀하게 우리에게 설명했다. 그의 말에 의하면, 타격이 주어졌을 때 그녀는 계산대 쪽으로 등을 돌리고―따라서 가해자에 대해서도―서 있었다고 한다. 머리를 얻어맞고 그녀는 계산대 뒤로 쭈그려 앉아 버려 가게에 들어온 사람 눈에 얼른 띄지 않았던 셈이다. 카 의사에게 인사하고 밖으로 나오자 포아로가 말했다. “이로써 애셔의 무죄 쪽으로 한 걸음 다가선 게 확실하네. 헤이스팅즈. 만일 그가 아내한테 덤벼들면서 협박한 거라면 그녀는 계산대를 사이에 두고 그와 마주서 있었을 걸세. 그런데 그녀는 가해자에게 등을 돌리고 있었지. 틀림없이 그녀는 손님에게 줄 파이프 담배나 궐련을 꺼내려 했던 걸 거야. ” 나는 조금 몸을 떨었다. “기분이 언짢군. ” 포아로는 무겁게 머리를 흔들었다. 그는 중얼거렸다.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/137       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/136       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/135       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/134       \n",
            "Negative tokens: ['”' '돌리고―따라서' '쭈그려' '틀림없이']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 135/136       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 134/135       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 133/134       \n",
            "Peak count: 7\n",
            "Frame tokens: ” 셈이다. “이로써 헤이스팅즈. 걸세. “기분이 중얼거렸다. \n",
            "\n",
            "Similarity : 0.4277358067870861\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.551668643951416 Generator / grammar loss:-0.18061436712741852   similarity loss:-0.12398082762956619\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "이건 수 없지요. ” 그렇습니다. 그녀는 나오자 말했다. “이로써 걸음 헤이스팅즈. 협박한 걸세. 돌리고 있었지. 그녀는 손님에게 했던 “기분이 중얼거렸다. \n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.156863  0.778482  0.445023  0.495067  0.021558  0.526728   \n",
            "\n",
            "   grammar  \n",
            "0  0.98074  \n",
            "Current result ==================================================\n",
            "Sample count: 30\n",
            "     method  comp rate     intro      body  conclusion   isthmus  simlirality  \\\n",
            "0  SAM+WGAN   0.176996  0.520376  0.528304    0.539684  0.005079     0.530133   \n",
            "\n",
            "   grammarity  \n",
            "0    0.968569  \n",
            "==================================================\n",
            "31 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "“가엾은 여자일세. ” 그리고 나서 그는 시계를 흘끗 보았다. “여기서 오버튼까지는 그리 멀지 않네. 거기 가서 노파의 조카딸을 만나 보는게 어떻겠나?” “범행 현장인 가게 쪽을 먼저 보는 게 좋지 않을까?” “그건 뒤로 미루고 싶네. 이유가 있어서. ” 그는 더 이상 설명하지 않았다. 잠시 뒤 우리는 자동차를 타고 오버튼 쪽으로 런던 행 도로를 달려갔다. 형사가 가르쳐 준 집은 마을에서 런던 쪽으로 1마일쯤 간 곳에 있었다. 훌륭한 집이었다. 벨을 누르자 아름다운 검은 머리의 아가씨가 나왔다. 지금까지 울고 있었던 듯 눈이 빨갰다. 포아로가 상냥하게 말했다. “아, 당신이 이 집 하녀인 메리 드로워 양이군요?” “그렇습니다. 제가 메리예요. ” “주인께서 허락해 주신다면 잠시 이야기를 좀 나누고 싶은데요. 이야기란 다름아닌 아가씨 아주머니인 애셔 부인에 대한 것입니다. ” “주인은 외출중이세요. 들어오셔도 그리 꾸중이 없으리라 생각됩니다. ” 그녀는 조그만 거실의 문을 열었다. 우리는 안으로 들어갔다.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/128       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/127       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/126       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/125       \n",
            "Negative tokens: ['오버튼까지는' '거기' '먼저' '잠시' '오버튼' '상냥하게' '하녀인' '부인에']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 126/127       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 125/126       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 124/125       \n",
            "Peak count: 7\n",
            "Frame tokens: ” 집이었다. 드로워 ” 아주머니인 외출중이세요. 들어갔다. \n",
            "\n",
            "Similarity : 0.4683068083281646\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.582400321960449 Generator / grammar loss:-0.20313237607479095   similarity loss:-0.14315694570541382\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "” 시계를 보는게 좋지 “그건 싶네. ” 그는 집은 마을에서 1마일쯤 있었다. 집이었다. 드로워 제가 메리예요. ” “주인께서 아주머니인 “주인은 외출중이세요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.173828  0.561834  0.503197  0.526027  0.000582  0.521773   \n",
            "\n",
            "    grammar  \n",
            "0  0.990423  \n",
            "Current result ==================================================\n",
            "Sample count: 31\n",
            "     method  comp rate     intro      body  conclusion   isthmus  simlirality  \\\n",
            "0  SAM+WGAN   0.176893  0.521713  0.527494    0.539243  0.004934     0.529863   \n",
            "\n",
            "   grammarity  \n",
            "0    0.969274  \n",
            "==================================================\n",
            "32 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "포아로는 창가 의자에 앉아 날카롭게 아가씨의 얼굴을 보았다. “아주머니가 돌아가신 이야기는 물론 들었겠지요?” 아가씨는 고개를 끄덕였는데 눈물이 다시 새삼스럽게 솟아났다. “오늘 아침 경찰에서 오셨었어요. 아, 무서운 일이에요!가엾은 아주머니! 그토록 괴로운 나날을 보내고서 또 이런 일을 당하시다니……너무해요. ” “경찰이 앤도버로 오라고 하지 않았습니까?” “월요일에 심문을 받기로 되어 있어요. 하지만 저는 그리로 가면 있을 데가 없어요. 이젠 그 가게로 갈 수도 없고. 게다가 저 말고는 하녀가 없는데 주인에게 폐 끼치고 싶지도 않아요. ” 포아로는 부드럽게 물었다. “당신은 아주머니를 아주 좋아했었군요, 메리 양?” “정말 좋아했어요. 아주머니는 언제나 제게 잘해 주셨지요. 어머니가 돌아가신 뒤 저는 11살 때 런던의 아주머니 집으로 갔어요. 16살 때부터 돈벌이를 하러 나와 있었지만, 쉬는 날이면 꼭 아주머니에게 가곤 했어요. 아주머니는 그 독일사람 때문에 아주 애를 먹고 계셨어요. 그 남자를 아주머니는 늘 <나의 악마>라고 부르곤 하셨지요. 그는 아주머니가 있는 데는 어디든 와서 가만히 두지 않았어요. 돈만 빼앗아 가는 거지같은 짐승이에요. ” 아가씨의 말투는 아주 격렬했다.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/145       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/144       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/143       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/142       \n",
            "Negative tokens: ['아가씨의' '“아주머니가' '아가씨는' '눈물이' '아주머니!' '하녀가' '아주머니를' '아주머니는' '어머니가' '아주머니'\n",
            " '아주머니에게' '아주머니는' '아주머니가' '두지']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 143/144       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 142/143       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 141/142       \n",
            "Peak count: 8\n",
            "Frame tokens: 일이에요!가엾은 괴로운 당하시다니……너무해요. 주인에게 아주머니는 애를 ” 격렬했다. \n",
            "\n",
            "Similarity : 0.44384050066230163\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.351470470428467 Generator / grammar loss:-0.1929520070552826   similarity loss:-0.1574362963438034\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "의자에 날카롭게 아가씨의 “아주머니가 돌아가신 아가씨는 아침 일이에요!가엾은 괴로운 나날을 당하시다니……너무해요. 이젠 수도 없고. 주인에게 물었다. 하러 아주머니는 애를 먹고 짐승이에요. ” 격렬했다. \n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.185366  0.505792  0.499096  0.552723  0.000569  0.516523   \n",
            "\n",
            "    grammar  \n",
            "0  0.982917  \n",
            "Current result ==================================================\n",
            "Sample count: 32\n",
            "     method  comp rate     intro      body  conclusion   isthmus  simlirality  \\\n",
            "0  SAM+WGAN   0.177158  0.521216  0.526607    0.539665  0.004798     0.529446   \n",
            "\n",
            "   grammarity  \n",
            "0      0.9697  \n",
            "==================================================\n",
            "33 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "“아주머니는 법적 수단으로 그 남자의 압박에서 벗어나려고는 하지 않았습니까?” 아가씨는 단순하게, 그러나 딱 잘라 말했다. “아무래도 남편이었기 때문에 그럴 수가 없었지요. ” “메리 양, 그 남자는 아주머니를 협박했었지요?” “네, 아주 무서운 소리를 곧잘 했어요. 목을 부러뜨린다든가 하는 말들을. 저주스럽게 욕지거리를 해대면서. 독일 말과 영어 두 가지로요. 그렇지만 아주머니는 결혼했던 즈음에는 아주 멋있는 남자였다고 말씀하셨어요. 사람이 그렇게 된다는 것은 참으로 무서운 일이에요. ” “정말 그렇군요. 그런데 메리 양, 늘 그런 협박을 받고 있었다면 사건이 일어난 것을 알았을 때 그리 놀라지 않았겠군요?” “그래도 역시 놀랐어요. 아무튼 진짜로 하는 소리라고는 생각지 않았으니까요. 그저 말로만 해대는 것뿐 그 이상으로는 여기지 않았어요. 아주머니도 무서워하고 계셨던 것 같지 않아요. 아주머니가 대들면 개가 다리 사이로 꼬리를 감추듯 움츠러드는 것을 본 적도 있어요. 오히려 그쪽에서 아주머니를 무서워하고 있을 정도였지요. ” “그런데도 아주머니는 돈을 주고 있었습니까?” “남편인걸요. ” “그렇군요, 아까도 그렇게 말했었지요. ” 포아로는 잠시 말을 끊었다가 다시 계속했다. “그렇다면 결국 그 남자는 아주머니를 죽이지 않았다는 거로군요?” “죽이지 않았다고요?” 그녀는 눈을 크게 떠보였다. “그렇습니다.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/156       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/155       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/154       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/153       \n",
            "Negative tokens: ['“아무래도' '아주머니를' '아주머니는' '무서운' '그런데' '그런' '있었다면' '놀라지' '소리라고는' '아주머니도' '”'\n",
            " '잠시' '아주머니를']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 154/155       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 153/154       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 152/153       \n",
            "Peak count: 8\n",
            "Frame tokens: 했어요. 저주스럽게 아무튼 무서워하고 아주머니가 아주머니를 ” “그렇습니다. \n",
            "\n",
            "Similarity : 0.4784850659778326\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.4035513401031494 Generator / grammar loss:-0.1737399697303772   similarity loss:-0.1328233927488327\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "그 아가씨는 ” 아주머니를 협박했었지요?” 했어요. 저주스럽게 영어 두 가지로요. 그렇지만 즈음에는 일이에요. 놀라지 “그래도 역시 놀랐어요. 아무튼 아주머니도 무서워하고 아주머니가 아주머니를 ” “그렇습니다.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro     body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.170803  0.448726  0.48266  0.506591  0.000564  0.483053   \n",
            "\n",
            "    grammar  \n",
            "0  0.951992  \n",
            "Current result ==================================================\n",
            "Sample count: 33\n",
            "     method  comp rate     intro      body  conclusion  isthmus  simlirality  \\\n",
            "0  SAM+WGAN   0.176966  0.519019  0.525275    0.538662  0.00467      0.52804   \n",
            "\n",
            "   grammarity  \n",
            "0    0.969164  \n",
            "==================================================\n",
            "34 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "누군가 다른 사람이 아가씨 아주머니를 죽였다는 말입니다. ……달리 짐작되는 사람 없습니까?” 그녀는 한층 더 놀란 듯 그의 얼굴을 보았다. “알 수 없어요. 하지만 그런 일이 있을 수 있을까요?” “당신 아주머니가 무서워한 다른 사람은 없었습니까?” 메리는 고개를 저었다. “아주머니는 남을 무서워하지 않으셨어요. 말솜씨가 좋아 누구에게나 맞설 수 있으셨어요. ” “아주머니에게 악의를 품고 있는 어떤 사람에 대한 이야기를 해준 일은 없습니까?” “네, 없어요. ” “익명의 편지를 받은 일도” “무슨 편지라고요?” “개인적인 서명이 없는 편지로, 예를 들어 그저 ABC라는 서명만 있는. ” 그는 아가씨의 얼굴을 찬찬히 들여다보고 있었는데, 그녀는 분명 난처해하는 모습이었다. 그녀는 묘한 표정으로 고개를 저었다. “아가씨 말고 또 다른 친척이 있습니까?” “지금은 없어요. 열 남매였는데 자란 사람은 셋뿐이었지요. 톰 아저씨는 전쟁터에서 돌아가시고, 해리 아저씨는 남아메리카로 가버리셔서 소식을 몰라요. 그리고 또 제 어머니는 돌아가셨기 때문에 저밖에 없어요. ” “아주머니는 저축을 했었습니까? 돈을 모으고 있었습니까?” “은행에 조금 있어요. 매장 비용만 된다면 하고 곧잘 말씀하곤 하셨지요. 그리고는 겨우 그럭저럭 살아 나가셨어요. 그 늙어빠진 악마가 있으니 안 그렇겠어요. ” 포아로는 생각 깊게 고개를 끄덕였다.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/160       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/159       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/158       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/157       \n",
            "Negative tokens: ['아주머니를' '없습니까?”' '놀란' '아주머니가' '없었습니까?”' '“아주머니는' '“아주머니에게' '어떤' '없습니까?”'\n",
            " '없는' '아가씨의' '그녀는' '그녀는' '“아가씨' '돌아가시고,' '어머니는' '“아주머니는' '했었습니까?' '조금'\n",
            " '겨우' '늙어빠진' '안' '생각']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 158/159       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 157/158       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 156/157       \n",
            "Peak count: 9\n",
            "Frame tokens: 없어요. 무서워한 저었다. 저었다. 말고 없어요. 몰라요. 없어요. 끄덕였다. \n",
            "\n",
            "Similarity : 0.4032389159120163\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.404448986053467 Generator / grammar loss:-0.17271101474761963   similarity loss:-0.13170084357261658\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "누군가 사람이 없어요. “당신 무서워한 저었다. “네, ” 저었다. 말고 친척이 없어요. 사람은 전쟁터에서 남아메리카로 몰라요. 또 저밖에 없어요. “아주머니는 있었습니까?” 조금 있어요. 늙어빠진 안 ” 끄덕였다.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body   ending       var     total  \\\n",
            "0  SAM+WGAN    0.175182  0.517364  0.484054  0.55897  0.000939  0.513191   \n",
            "\n",
            "    grammar  \n",
            "0  0.967144  \n",
            "Current result ==================================================\n",
            "Sample count: 34\n",
            "     method  comp rate    intro      body  conclusion  isthmus  simlirality  \\\n",
            "0  SAM+WGAN   0.176913  0.51897  0.524063     0.53926  0.00456     0.527603   \n",
            "\n",
            "   grammarity  \n",
            "0    0.969104  \n",
            "==================================================\n",
            "35 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "그는 아가씨에게 말한다기 보다 혼잣말처럼 중얼거렸다. “지금으로선 어둠 속에 있는 것 같군. 방향도 잡을 수 없어. 만일 좀더 뚜렷해진다면……. ” 그는 일어섰다. “만일 아가씨한테 볼일이 생기면 여기로 편지하지요. 메리 양. ” “사실을 말씀드리면, 저는 여기를 나갈 생각으로 있어요. 시골을 그리 좋아하지 않거든요. 아주머니 곁에 있는 게 마음 든든히 여겨져 여기 있었던 거예요. 그러나 이젠……. ” 그 눈에 다시 눈물이 솟았다. “이제는 여기 있을 이유가 없어져 런던으로 되돌아가려고 해요. 그곳이 제게는 더 재미있는 걸요. ” “그럼, 그리고 가게 될 때에는 주소를 가르쳐 주십시오. 이것이 제 명함입니다. ” 그는 아가씨에게 명함을 건네주었다. 그녀는 곤혹스러운 듯 이마에 주름을 지으며 그것을 보았다. “그럼, 선생님은……경찰과는 관계가 없으신가요?” “나는 사립탐정입니다. ” 그녀는 선 채로 잠시 말없이 그를 쳐다보았다.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/113       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/112       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/111       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/110       \n",
            "Negative tokens: ['만일' '말씀드리면,' '“이제는' '될' '”' '그녀는' '주름을']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 111/112       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 110/111       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 109/110       \n",
            "Peak count: 6\n",
            "Frame tokens: 중얼거렸다. 만일 “만일 이젠……. 그녀는 쳐다보았다. \n",
            "\n",
            "Similarity : 0.37830775411397843\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.497178554534912 Generator / grammar loss:-0.18152521550655365   similarity loss:-0.13074351847171783\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            " 중얼거렸다. 만일 “만일 생기면 편지하지요. 양. 말씀드리면, 저는 거예요. 이젠……. 눈에 제 그녀는 곤혹스러운 듯 주름을 쳐다보았다.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var    total  \\\n",
            "0  SAM+WGAN     0.16453  0.435842  0.495635  0.424313  0.000977  0.46228   \n",
            "\n",
            "    grammar  \n",
            "0  0.971305  \n",
            "Current result ==================================================\n",
            "Sample count: 35\n",
            "     method  comp rate     intro      body  conclusion   isthmus  simlirality  \\\n",
            "0  SAM+WGAN   0.176559  0.516595  0.523251    0.535976  0.004457     0.525737   \n",
            "\n",
            "   grammarity  \n",
            "0    0.969167  \n",
            "==================================================\n",
            "36 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "이윽고 그녀가 말했다. “뭔가 의심스러운 점이라고 있으신지요?” “그렇습니다, 아가씨. 좀 이상한 점이 있지요. 아마 앞으로 아가씨에게 도움 받을 일이 있을지도 모르겠습니다. ” “저는, 저는 무엇이든 하겠어요. 아주머니가 살해되시다니, 옳은 일이 아니니까요. ” 그것은 기묘한 표현이었다. 그러나 꽤 감동적이었다. 우리는 곧 자동차를 타고 앤도버로 돌아갔다. < 범행 현장 > 참극이 일어난 곳은 큰길에서 좁은 골목이었다. 애셔 부인의 가게는 그 중간쯤의 오른쪽에 있었다. 그 골목에 들어섰을 때, 포아로는 흘끗 시계를 보았다. 그래서 나는 그가 범행 현장으로 가는 시간을 지금까지 미룬 까닭을 알았다. 꼭 5시 30분이 되어 있었다. 그는 되도록 어젯밤의 상황을 재현하려 생각하고 있었던 것이다. 그러나 그것이 그의 목적이었다면 실패했다. 이 때 골목은 어젯밤의 그림자를 거의 전해주고 있지 않았다. 그곳에는 가난한 사람들 집에 섞여 조그만 가게가 몇 채 줄지어 있었다. 다른 때 같으면 이 언저리의 가난한 몇몇 사람들이 그곳을 오가고 또 찻길이나 보도 위에서는 몇 명의 아이들이 놀고 있을 뿐이었다. 그런데 이때는 많은 사람들이 쭉 둘러서서 집인지 가게를 보고 있었다.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/149       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/148       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/147       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/146       \n",
            "Negative tokens: ['“뭔가' '좀' '아마' '그러나' '<' '일어난' '흘끗' '그래서' '미룬' '어젯밤의' '거의' '때' '몇']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 147/148       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 146/147       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 145/146       \n",
            "Peak count: 8\n",
            "Frame tokens: 이상한 있지요. 모르겠습니다. 표현이었다. 감동적이었다. 골목이었다. 있었다. 있었다. \n",
            "\n",
            "Similarity : 0.4673684537888263\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.518789768218994 Generator / grammar loss:-0.18725760281085968   similarity loss:-0.1341657042503357\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "말했다. 아가씨. 앞으로 모르겠습니다. 하겠어요. 아주머니가 표현이었다. 감동적이었다. 타고 앤도버로 일어난 곳은 좁은 골목이었다. 오른쪽에 가난한 이 또 몇 있을 뿐이었다. 그런데 사람들이 있었다.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.184692  0.621264  0.565471  0.492331  0.002787  0.554687   \n",
            "\n",
            "    grammar  \n",
            "0  0.987242  \n",
            "Current result ==================================================\n",
            "Sample count: 36\n",
            "     method  comp rate     intro      body  conclusion   isthmus  simlirality  \\\n",
            "0  SAM+WGAN   0.176785  0.519503  0.524423    0.534763  0.004411     0.526541   \n",
            "\n",
            "   grammarity  \n",
            "0    0.969669  \n",
            "==================================================\n",
            "37 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "그것이 어느 집인지는 곧 알 수 있었다. 우리가 본 것은 한 사람이 살해된 곳을 아주 흥미롭게 보고 있는 여느 사람들의 무리였다. 가까이 다가감에 따라 확실히 그렇다는 것을 알 수 있었다. 블라인드를 내린 그을음 낀 듯한 구멍가게 앞에 젊은 순경이 애를 먹고 있는 듯한 얼굴로 서서 사람들에게 저리 가라고 딱딱하게 명령하고 있었다. 그는 동료의 도움을 받아 모여 있는 사라들을 해산시키기 시작했다. 꽤 많은 사람들이 불평스럽게 한숨을 쉬며 저마다 자기네 일로 돌아갔다. 그러나 곧 또 다른 사람들이 몰려와 살인 현장을 똑똑히 봐두려는 듯 그 자리를 다시 차지했다. 포아로는 사람들로부터 조금 떨어져 섰다. 그가 서 있는 곳에서는 문 위에 씌어진 글자를 똑똑히 볼 수 있었다. 포아로는 그것을 입속에서 되풀이했다. “A 애셔. 그렇지, 어쩌면……. ” 그는 말을 끊었다. “가세, 헤이스팅즈. 안으로 들어가 보세. ” 나는 기다리고 있던 바였다. 우리는 사람들을 헤치고 젊은 순경에게로 갔다. 포아로는 형사에게서 받아 둔 소개장을 내보였다. 순경은 머리를 끄덕이며 우리를 안으로 들여보내기 위해 문의 자물쇠를 열었다. 우리는 구경꾼들의 호기심에 찬 눈길을 받으며 안으로 들어갔다.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/155       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/154       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/153       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/152       \n",
            "Negative tokens: ['다가감에' '듯한' '앞에' '몰려와' '그가' '들어가' '받으며']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 153/154       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 152/153       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 151/152       \n",
            "Peak count: 8\n",
            "Frame tokens: 꽤 돌아갔다. 차지했다. 애셔. 안으로 바였다. 우리는 들어갔다. \n",
            "\n",
            "Similarity : 0.46150342566536984\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.3017630577087402 Generator / grammar loss:-0.16436952352523804   similarity loss:-0.1339610517024994\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "그것이 알 있는 사람들의 구멍가게 사람들에게 꽤 돌아갔다. 수 애셔. 끊었다. 안으로 들어가 보세. 나는 있던 바였다. 젊은 포아로는 머리를 끄덕이며 우리는 들어갔다. \n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.155887  0.468315  0.554569  0.680279  0.007575  0.575031   \n",
            "\n",
            "   grammar  \n",
            "0  0.95975  \n",
            "Current result ==================================================\n",
            "Sample count: 37\n",
            "     method  comp rate     intro      body  conclusion   isthmus  simlirality  \\\n",
            "0  SAM+WGAN   0.176221  0.518119  0.525238    0.538696  0.004497     0.527852   \n",
            "\n",
            "   grammarity  \n",
            "0    0.969401  \n",
            "==================================================\n",
            "38 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "블라인드가 내려져 있어 안은 어두웠다. 순경이 전등 스위치를 찾아내어 당겼다. 그러나 전구의 촉수가 낮아 안은 여전히 어두웠다. 나는 가게 안을 빙 둘러보았다. 지저분하고 좁은 곳으로 몇 권의 싸구려 잡지가 흩어져 있고 어제 신문에는 하루치 먼지가 쌓여 있었다. 계산대 뒤에는 천장까지 선반이 매어져 파이프 담배며 궐련 봉지가 놓여 있었다. 박하가 든 과자와 사탕병도 있었다. 흔해빠진 구멍가게로 다른 데에도 몇천 군데나 있는 그런 곳이었다. 순경은 느릿한 햄프셔 사투리로 상황을 설명했다. “거기 계산대 뒤에 웅크린 채 쓰러져 있었지요. 할머니는 자신이 습격당하는 것을 모르고 있었다고 의사 선생님이 말씀하셨습니다. 아마 선반으로 막 손을 내민 순간이었는지도 모르지요. ” “손에는 아무것도 없었소?” “없었습니다. 다만 곁에 <플레이어즈>꾸러미가 하나 떨어져 있었지요. ” 포아로는 고개를 끄덕였다. 그의 눈은 그 좁은 가게를 탐색하듯 둘러보았다. 아무것도 없다. “그런데 철도 안내서는 어디에?” “여기입니다. ” 순경은 계산대 위를 가리켰다. “바로 앤도버 있는 데가 펼쳐진 채 뒤집혀져 있었습니다.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/134       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/133       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/132       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/131       \n",
            "Negative tokens: ['안은' '가게' '계산대' '흔해빠진' '계산대' '모르고' '선반으로' '다만' '가게를' '계산대']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 132/133       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 131/132       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 130/131       \n",
            "Peak count: 7\n",
            "Frame tokens: 안을 둘러보았다. 흔해빠진 순경은 ” 둘러보았다. 있었습니다. \n",
            "\n",
            "Similarity : 0.3651038417381125\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.4270899295806885 Generator / grammar loss:-0.18229222297668457   similarity loss:-0.13891567289829254\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "어두웠다. 찾아내어 그러나 안을 빙 둘러보았다. 싸구려 있고 있었다. 흔해빠진 순경은 햄프셔 선반으로 ” 다만 가게를 둘러보았다. “그런데 순경은 계산대 가리켰다.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio   intro     body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.161634  0.5552  0.41831  0.486468  0.003123  0.466136   \n",
            "\n",
            "    grammar  \n",
            "0  0.971172  \n",
            "Current result ==================================================\n",
            "Sample count: 38\n",
            "     method  comp rate     intro      body  conclusion  isthmus  simlirality  \\\n",
            "0  SAM+WGAN   0.175837  0.519095  0.522424    0.537322  0.00446     0.526228   \n",
            "\n",
            "   grammarity  \n",
            "0    0.969448  \n",
            "==================================================\n",
            "39 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "런던 행 기차를 보고 있었던 것 같습니다. 그렇다면 그는 앤도버 사람이 아닙니다. 그러나 물론 철도 안내서는 살인과 관계없는 다른 사람이 잃어버리고 간 거라고 생각할 수도 있습니다. ” 내가 물어 보았다. “지문은?” 순경은 머리를 저었다. “곧바로 모두 조사해 보았지만 없었지요. ” 포아로가 물었다. “계산대에도?” “굉장히 많았습니다. 모두 함께 뒤섞여 뒤죽박죽되어 있었지요. ” “그 속에 애셔의 지문은?” “아직 알 수 없습니다. ” 포아로는 고개를 끄덕이고 나서 죽은 사람이 가게 안에서 살고 있었느냐고 물었다. “그렇습니다. 안쪽 문을 지나면 그곳으로 들어가게 됩니다. 함께 가드렸으면 좋겠습니다만, 저는 여기 있지 않으면 안 돼서……. ” 포아로는 문을 열고 들어갔다. 나도 그 뒤를 따라갔다. 가게 안은 부엌 딸린 조그만 거실로 되어 있었다. 그곳은 깨끗하게 정리되어 있었지만 음침한 느낌이 들었으며 가구도 거의 없었다. 벽난로 위에 사진이 몇 장 있었다. 내가 다가가서 들여다보자 포아로도 옆으로 왔다.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/127       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/126       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/125       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/124       \n",
            "Negative tokens: ['그러나' '다른' '”' '”' '내가']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 125/126       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 124/125       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 123/124       \n",
            "Peak count: 7\n",
            "Frame tokens: ” 보았다. ” 물었다. ” “그렇습니다. 왔다. \n",
            "\n",
            "Similarity : 0.4435005445789578\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.6929128170013428 Generator / grammar loss:-0.20594274997711182   similarity loss:-0.13366052508354187\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "런던 기차를 보고 있었던 살인과 관계없는 거라고 ” 보았다. “곧바로 ” 포아로가 물었다. ” 속에 안에서 살고 “그렇습니다. 들어가게 됩니다. 왔다.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.163107  0.592689  0.470296  0.533044  0.002497  0.513599   \n",
            "\n",
            "    grammar  \n",
            "0  0.978414  \n",
            "Current result ==================================================\n",
            "Sample count: 39\n",
            "     method  comp rate     intro      body  conclusion  isthmus  simlirality  \\\n",
            "0  SAM+WGAN    0.17551  0.520982  0.521088    0.537212  0.00441     0.525904   \n",
            "\n",
            "   grammarity  \n",
            "0    0.969678  \n",
            "==================================================\n",
            "40 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "사진은 모두 세 장이었다. 한 장은 오늘 오후에 만난 아가씨 메리 드로워의 싸구려 사진이었다. 그녀는 가장 좋은 옷을 입고 얼굴에 부자연스러운 미소를 떠올리고 있었다. 포즈를 취한 이런 사진은 표정을 엉망으로 만들기 때문에 스냅 사진 쪽이 훨씬 좋다. 두 번째 것은 더 고급스러운 것으로, 꽤 나이든 머리가 희끗희끗한 부인을 기교적으로 흐릿하게 찍은 사진이었다. 털목도리를 두르고 있었다. 나는 아마도 미스 로즈일 거라고 생각했다. 즉 애셔 부인에게 장사를 시작할 수 있도록 돈을 물려준 사람이다. 세 번째 사진은 아주 오래된 것으로 누렇게 빛이 바래 있었다. 얼마쯤 구식으로 보이는 것으로 팔짱낀 젊은 남녀가 찍혀있었다. 남자는 단춧구멍에 꽃을 꽂고 있으며, 전체적으로 고풍스러움이 느껴지는 딱딱한 사진이었다. 포아로가 말했다. “아마도 결혼 기념사진인 모양이군. 보게, 헤이스팅즈. 그녀는 아름다웠을 거라고 내가 말했잖나. ” 그 말대로였다. 시대에 뒤떨어진 머리 모양과 기묘한 옷 때문에 좀 이상해 보이긴 했지만 이목구비가 또렷하고 반듯한 아가씨의 아름다움은 의심할 바가 없었다. 나는 옆에 있는 다른 한 인물을 자세히 보았는데, 이 군인 같은 모습의 말쑥한 젊은이가 그 초라한 애셔였다고는 도저히 생각되지 않았다. 나는 그 곁눈질을 하는 주정꾼 노인과 피로에 지친 얼굴의 죽은 노파를 생각해 내고 세월의 무자비함에 몸을 떨었다. 그 거실로부터 2층의 두 방으로 층계가 이어져 있었다.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/180       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/179       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/178       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/177       \n",
            "Negative tokens: ['미소를' '나이든' '기교적으로' '로즈일' '오래된' '구식으로' '고풍스러움이' '기념사진인' '시대에' '애셔였다고는'\n",
            " '노파를']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 178/179       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 177/178       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 176/177       \n",
            "Peak count: 10\n",
            "Frame tokens: 그녀는 것으로, 털목도리를 미스 포아로가 그녀는 머리 했지만 아가씨의 있었다. \n",
            "\n",
            "Similarity : 0.28803418625150023\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.450047016143799 Generator / grammar loss:-0.15789952874183655   similarity loss:-0.11211127042770386\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "사진은 모두 세 장이었다. 장은 오후에 만난 메리 사진이었다. 그녀는 쪽이 좋다. 고급스러운 나이든 기교적으로 얼마쯤 단춧구멍에 내가 그 옷 아름다움은 보았는데, 나는 그 얼굴의 내고 무자비함에 이어져 있었다. \n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro     body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.163435  0.703184  0.35389  0.480912  0.020838  0.461855   \n",
            "\n",
            "   grammar  \n",
            "0   0.9854  \n",
            "Current result ==================================================\n",
            "Sample count: 40\n",
            "     method  comp rate     intro      body  conclusion   isthmus  simlirality  \\\n",
            "0  SAM+WGAN   0.175208  0.525537  0.516908    0.535804  0.004821     0.524303   \n",
            "\n",
            "   grammarity  \n",
            "0    0.970071  \n",
            "==================================================\n",
            "41 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "하나는 빈방으로 가구도 없고, 다른 하나는 죽은 노파의 침실이었다. 경찰이 조사한 뒤여서 그 흔적이 그대로 있었다. 침대에는 털이 빠진 낡은 담요가 두 장 있었다. 한 서랍에는 알뜰히 기워진 속옷 몇 벌, 또 한 서랍에는 요리책 종류, ≪녹색의 오아시스≫라는 제목의 표지가 달린 책, 번쩍거리는 싸구려 새 양말 한 컬레?그것은 번쩍거리는 싸구려였다?사기 그릇 장식 한 쌍?드레스덴 도자기로 된 깨어진 양치기며 파랑과 노랑점이 있는 개?나무못에 걸린 검은 레인코트와 털 자켓. 이러한 것들이 죽은 애셔 부인이 이 세상에 남긴 재산이었다. 무언가 개인적인 메모 같은 게 있었다 해도 경찰이 가져가 버렸을 것이다. 포아로가 중얼거렸다. “가엾게도. 자, 헤이스팅즈, 여기에는 이제 아무것도 없네. ” 다른 길로 나서자 그는 잠시 망설이더니 길을 건넜다. 바로 애셔 부인의 가게 맞은편에 야채 가게가 있었다. 안에 있는 물건보다 밖에 내놓은 물건이 더 많은 그런 종류의 가게였다. 포아로는 낮은 소리로 내게 몇 마디 일러두고 혼자 가게에 들어갔다. 나는 잠시 뒤 따라 들어갔다. 그는 막 상추를 사고 있는 중이었다. 나는 딸기를 1파운드 샀다. 포아로는 물건을 싸주는 뚱뚱한 아주머니와 큰소리로 이야기하고 있었다. “그 살인 사건이 일어난 곳이 바로 댁 맞은편이었군요. 이런 끔찍한 일이 있나. 얼마나 놀랐겠습니까!” 그 뚱뚱한 여자는 살인 사건 이야기에는 이제 질린 것 같았다.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/182       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/181       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/180       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/179       \n",
            "Negative tokens: ['없고,' '노파의' '뒤여서' '빠진' '한' '몇' '싸구려' '컬레?그것은' '싸구려였다?사기' '된' '애셔' '남긴'\n",
            " '망설이더니' '애셔' '내놓은' '“그' '질린']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 180/181       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 179/180       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 178/179       \n",
            "Peak count: 10\n",
            "Frame tokens: 빈방으로 “가엾게도. 없네. 잠시 포아로는 혼자 잠시 포아로는 맞은편이었군요. 같았다. \n",
            "\n",
            "Similarity : 0.35117239819280077\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.6093180179595947 Generator / grammar loss:-0.20423713326454163   similarity loss:-0.14130766689777374\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "빈방으로 번쩍거리는 양말 털 “가엾게도. 헤이스팅즈, 아무것도 없네. ” 그는 잠시 그런 포아로는 일러두고 혼자 나는 잠시 막 포아로는 뚱뚱한 살인 곳이 바로 맞은편이었군요. 얼마나 여자는 살인 사건 이야기에는 같았다.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var   total  \\\n",
            "0  SAM+WGAN    0.171348  0.459792  0.417501  0.322304  0.003306  0.3974   \n",
            "\n",
            "    grammar  \n",
            "0  0.980317  \n",
            "Current result ==================================================\n",
            "Sample count: 41\n",
            "     method  comp rate     intro      body  conclusion   isthmus  simlirality  \\\n",
            "0  SAM+WGAN   0.175114  0.523934  0.514483    0.530597  0.004784     0.521207   \n",
            "\n",
            "   grammarity  \n",
            "0    0.970321  \n",
            "==================================================\n",
            "42 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "그날은 그녀에게 있어 너무 길었던 모양이다. “이 법석거리는 구경꾼들을 어떻게 좀 할 수 없을까요? 대체 무엇을 그렇게 보는 것일까요?” 포아로가 말했다. “어젯밤에는 꽤 달랐을 테지요?아주머니는 범인이 가게로 들어가는 걸 보시지 못했습니까? 키가 큰 훌륭한 남자로 수염이 있었다지요? 러시아인이라든가 뭐 그렇다는 이야기던데요?” 여자가 날카롭게 돌아보았다. “뭐라고요? 러시아인이 했다고요?” “경찰이 체포했다던데요. ” “정말이에요?” 여자는 흥분해서 입이 가벼워졌다. “외국 사람인가요?” “그렇습니다. 나는 틀림없이 아주머니가 어젯밤 그 남자를 본 줄 알았지요. ” “아니, 그럴 기회가 없었어요. 그래요, 저녁 무렵의 한창 바쁜 때여서 일을 끝내고 돌아가는 사람들이 많이 비나가니까요. 키가 크고 수염이 난 훌륭한 남자라니……아니에요. 그런 사람이 이 언저리에 있었다고는 생각되지 않는데요. ” 그래서 내가 대사를 받았다. 나는 포아로에게 말했다. “실례지만, 당신이 잘못 들은 게 아닙니까? 키가 작고 얼굴빛이 검은 남자라고 나는 들었습니다만.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/119       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/118       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/117       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/116       \n",
            "Negative tokens: ['무엇을' '“어젯밤에는' '있었다지요?' '“뭐라고요?' '어젯밤' '”' '들은' '아닙니까?']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 117/118       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 116/117       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 115/116       \n",
            "Peak count: 7\n",
            "Frame tokens: 모양이다. “어젯밤에는 못했습니까? ” 비나가니까요. 않는데요. 들었습니다만. \n",
            "\n",
            "Similarity : 0.43839375681584547\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.445701837539673 Generator / grammar loss:-0.2131340652704239   similarity loss:-0.16780325770378113\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            " 그날은 길었던 모양이다. 말했다. “어젯밤에는 못했습니까? ” 나는 한창 비나가니까요. 난 이 언저리에 있었다고는 않는데요. 그래서 게 키가 들었습니다만. \n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro     body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.164486  0.631802  0.41652  0.600917  0.009034  0.514896   \n",
            "\n",
            "    grammar  \n",
            "0  0.991067  \n",
            "Current result ==================================================\n",
            "Sample count: 42\n",
            "     method  comp rate     intro      body  conclusion   isthmus  simlirality  \\\n",
            "0  SAM+WGAN   0.174861  0.526502  0.512151    0.532271  0.004885     0.521057   \n",
            "\n",
            "   grammarity  \n",
            "0    0.970815  \n",
            "==================================================\n",
            "43 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "” 그리하여 이 뚱뚱한 여자에다 여윈 남편과 쇳소리 내는 심부름꾼 아이까지 합쳐 재미있는 토론이 시작되었다. 키 작은 검은 얼굴의 남자가 네 사람이나 목격된 이야기가 나오고, 쇳소리 내는 심부름꾼 아이는 키가 큰 훌륭한 남자를 보았지만 그에게는 수염이 없었다고 유감스러운 듯 덧붙였다. 겨우 쇼핑이 끝나 우리는 거짓말을 한 채 그대로 가게를 나왔다. 나는 얼마쯤 비난을 섞어 물었다. “대체 그건 무슨 연극이었나, 포아로?” “나는 다만 낯선 사람이 저쪽 가게로 들어갔는지 어떤지 듣고 싶었던 것뿐일세. ” “그럼, 그렇게 물어보면 되잖나, 그런 엉터리 같은 소리 하지 말고. ” “아니, 자네가 말하는 것처럼 그냥 물어 보아서는 아무 대답도 얻을 수 없다네. 자네는 자신도 영국 사람이면서, 그냥 물어보는 질문에 반발하는 게 영국 사람의 기질이라는 걸 모르고 있는 모양이군. 그것은 반드시 의심하는 마음을 불러일으켜 결과는 완강한 침묵으로 끝난다네. 이 사람들에게 뭘 물어보게나, 그들은 조가비처럼 입을 다물어 버리지. 그렇지만 이상하고 터무니없는 어떤 말을 한 가지 꺼내 거기서 자네가 반대되는 말이라도 해보이면, 금방 이야기가 풀려나온다네. 그런 방법으로 우리는 문제의 시각이 바쁜 때였다는 것, 그래서 누구나 자기 일 말고는 신경 쓸 수 없으며 많은 사람이 길을 지나가고 있었던 때임을 알게 된 거야. 우리의 살인범은 좋은 시간을 택했다는 말이 되네, 헤이스팅즈. ” 그는 말을 끊었다. 그리고는 엄격하게 나무라는 듯한 말투로 덧붙였다. “자네는 상식이라는 걸 갖고 있지 않는 것 같군, 헤이스팅즈. 무엇이든 사라고 했더니 하필이면 딸기를 고르다니! 보게, 벌써 포장지에서 물이 배어 나와 그 좋은 옷을 버리게 하고 있잖나. ” 정말 그의 말대로였으므로 나는 좀 당황했다. 나는 급히 한 아이에게 딸기를 줘버렸다.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/230       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/229       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/228       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/227       \n",
            "Negative tokens: ['심부름꾼' '남자가' '쇳소리' '겨우' '거짓말을' '비난을' '낯선' '엉터리' '모르고' '의심하는' '터무니없는'\n",
            " '문제의' '바쁜' '자기' '없으며' '시간을' '않는' '배어' '버리게']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 228/229       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 227/228       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 226/227       \n",
            "Peak count: 12\n",
            "Frame tokens: 것뿐일세. 물어 없다네. 질문에 버리지. 말이라도 신경 끊었다. 말투로 보게, 당황했다. 줘버렸다. \n",
            "\n",
            "Similarity : 0.4313699919429057\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.369115114212036 Generator / grammar loss:-0.1922210156917572   similarity loss:-0.15488165616989136\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "그리하여 얼굴의 남자가 남자를 보았지만 그에게는 겨우 끝나 그대로 그건 사람이 싶었던 것뿐일세. 엉터리 물어 아무 없다네. 질문에 결과는 완강한 침묵으로 끝난다네. 버리지. 자네가 말이라도 그래서 신경 끊었다. 말투로 덧붙였다. 것 보게, ” 말대로였으므로 당황했다. 줘버렸다.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio    intro      body    ending       var    total  \\\n",
            "0  SAM+WGAN    0.170893  0.46432  0.574313  0.478096  0.002394  0.52345   \n",
            "\n",
            "   grammar  \n",
            "0  0.95642  \n",
            "Current result ==================================================\n",
            "Sample count: 43\n",
            "     method  comp rate     intro      body  conclusion   isthmus  simlirality  \\\n",
            "0  SAM+WGAN   0.174769  0.525056  0.513596    0.531012  0.004827     0.521113   \n",
            "\n",
            "   grammarity  \n",
            "0     0.97048  \n",
            "==================================================\n",
            "44 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "그 아이는 깜짝 놀라 좀 경계하는 빛이 되었다. 포아로도 상추를 주자 아이는 완전히 당황한 모양이었다. 포아로는 설교를 계속했다. “허름한 야채 가게에서는 딸기 같은걸 사면 안돼. 딸기란 막 따온 게 아니면 물이 배어 나오지. 바나나, 사과, 양배추, 이런 것들이라면 그래도 좀 낫지만, 딸기는 안 되네. ” 나는 변명하듯 말했다. “막 들어서자 생각이 났으니 어쩌나. ” 포아로는 엄숙하게 대답했다. “그건 자네 상상력이 모자라기 때문일세,” 그는 보도에서 걸음을 멈췄다. 애셔 부인 가게 오른쪽에 있는 집 딸린 가게는 비어 있었다. 창에 <세놓음>이라고 씌어 있었다. 반대쪽 옆집에는 때낀 모슬린 커튼이 내려져 있었다. 포아로는 그 집 쪽으로 걸어갔는데 벨이 없어서 노커를 힘차게 몇 번이나 두드렸다. 한참 있다가 코를 훌쩍거리는 지저분한 아이가 문을 열었다. 포아로가 말했다. “안녕, 어머니 계시니?” “네?” 아이는 불쾌하고 의심스럽게 우리를 보았다. 포아로가 말했다. “네 어머니 말이야. ” 아이는 이 말을 알아듣는 데 5분의 1분쯤 걸렸다.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/133       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/132       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/131       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/130       \n",
            "Negative tokens: ['놀라' '좀' '”' '때문일세,”' '애셔' '포아로는' '벨이' '어머니' '데']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 131/132       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 130/131       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 129/130       \n",
            "Peak count: 7\n",
            "Frame tokens: 깜짝 모양이었다. 말했다. ” 말했다. 포아로가 걸렸다. \n",
            "\n",
            "Similarity : 0.3769874857083003\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.6381523609161377 Generator / grammar loss:-0.2027723491191864   similarity loss:-0.13664871454238892\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "깜짝 좀 아이는 모양이었다. 되네. ” 말했다. 났으니 ” 대답했다. “그건 보도에서 씌어 있었다. 옆집에는 지저분한 포아로가 말했다. 포아로가 1분쯤 걸렸다.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.166667  0.365385  0.413243  0.639963  0.014343  0.471688   \n",
            "\n",
            "    grammar  \n",
            "0  0.989467  \n",
            "Current result ==================================================\n",
            "Sample count: 44\n",
            "     method  comp rate     intro      body  conclusion   isthmus  simlirality  \\\n",
            "0  SAM+WGAN   0.174585  0.521427  0.511316    0.533488  0.005043      0.51999   \n",
            "\n",
            "   grammarity  \n",
            "0    0.970911  \n",
            "==================================================\n",
            "45 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "이윽고 아이는 층계 쪽을 향해 소리쳤다. “엄마, 손님. ” 그리고는 어두컴컴한 안쪽으로 들어가 버렸다. 딱딱한 얼굴을 한 여자가 난간 너머로 내려다보고 나서 층계를 내려왔다. “시간 낭비예요. ” 여자가 말을 시작했으나, 포아로가 가로막았다. 그는 모자를 벗고 정중하게 인사했다. “안녕하십니까, 아주머니. 저는 <이브닝 프리커>의 기자인데 살해된 이웃집의 애셔 부인에 대해 기사가 될 만한 것을 얻으러 왔습니다. 사례금으로 5파운드 드리지요. ” 화난 목소리를 억누르고 여자는 머리를 쓰다듬고 치마를 잡아당기며 층계를 내려왔다. “자, 안으로 들어오세요. 이쪽으로. 어서 앉으세요. ” 그 조그만 방은 커다란 모조 자코비언 식 가구로 어수선하여 우리는 가까스로 안으로 들어가 딱딱한 긴 의자에 앉았다. 여자는 이야기하기 시작했다. “죄송해요. 조금 전에 그런 실례되는 말을 드려서요. 그렇지만 우리가 얼마나 성가신 꼴을 당하고 있는지 도저히 모르실 거예요. 아무튼 여러 사람들이 진공청소기니 양말이니 향로 주머니니 뭐니 온갖 잡동사니들을 팔러 온답니다.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/125       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/124       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/123       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/122       \n",
            "Negative tokens: ['“엄마,' '들어가' '”' '“자,' '자코비언' '여자는' '실례되는' '아무튼']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 123/124       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 122/123       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 121/122       \n",
            "Peak count: 7\n",
            "Frame tokens: “엄마, 낭비예요. 아주머니. “자, 들어오세요. “죄송해요. 온답니다. \n",
            "\n",
            "Similarity : 0.5045193179926102\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.4838762283325195 Generator / grammar loss:-0.20933447778224945   similarity loss:-0.15996812283992767\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "층계 “엄마, 그리고는 얼굴을 내려다보고 층계를 낭비예요. ” 아주머니. 애셔 5파운드 쓰다듬고 내려왔다. “자, 들어오세요. 어서 조그만 방은 “죄송해요. 전에 온답니다.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.179439  0.529841  0.562182  0.491128  0.000844  0.534397   \n",
            "\n",
            "    grammar  \n",
            "0  0.955781  \n",
            "Current result ==================================================\n",
            "Sample count: 45\n",
            "     method  comp rate     intro      body  conclusion  isthmus  simlirality  \\\n",
            "0  SAM+WGAN   0.174693  0.521614  0.512446    0.532546  0.00495      0.52031   \n",
            "\n",
            "   grammarity  \n",
            "0    0.970575  \n",
            "==================================================\n",
            "46 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "그들은 정말 말솜씨가 좋고 점잖게 보이지요. 이름도 한 번 들으면 금방 외워서 이쪽은 파울러 부인이고, 저쪽은 누구라느니 하며 말예요. ” 재치있게 그 이름을 잡아서 포아로가 말했다. “갑작스러운 이야기입니다만, 파울러 부인, 우리가 부탁드린 일을 들어주시겠습니까?” “글쎄요. ” 그러나 이미 5파운드가 파울러 부인의 눈앞에 유혹하듯 어른거리고 있다. “애셔 부인은 알고 있지만, 글로 쓰는 일이고 보면. ” 포아로는 얼른 안심시키듯 그녀 쪽에서는 아무것도 하지 않아도 되며, 그녀로부터 사실 이야기를 들은 다음 기사는 자기 쪽에서 쓴다고 이야기해 주었다. 이에 용기를 얻어 파울러 부인은 자진해서 기억이며 억측이며 소문 따위를 이것저것 이야기해 주었다. 애셔 부인은 사람들을 멀리하며 살았다. 이웃과 어울리는 일이 거의 없었고, 그 가엾은 d자에게는 여러 가지 근심거리가 있었다. 그것은 누구나 모두 잘 알고 있는 일이었다. 프란츠 애셔는 벌써 형무소에 처넣어야 마땅할 그런 남자였다. 그러나 애셔 부인이 그를 무서워하고 있었던 건 아니다. 그녀가 화를 내면 굉장했다. 그리고 언제나 솜씨 있게 잘 응수해 왔다. 하지만 그런 일이 일어나다니……. 즉 일이 되어갈 데까지 가버린 것이다. 파울러 부인은 몇 번이고 되풀이 그녀에게 이야기했었다. “그 남자는 언젠가 당신에게 무서운 짓을 할 거예요. 내 말을 잘 기억해 둬요.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/169       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/168       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/167       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/166       \n",
            "Negative tokens: ['재치있게' '이야기입니다만,' '얼른' '사실' '자기' '이에' '그녀가' '부인은' '잘']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 167/168       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 166/167       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 165/166       \n",
            "Peak count: 9\n",
            "Frame tokens: 말솜씨가 금방 부인은 주었다. 잘 있는 응수해 일어나다니……. 둬요. \n",
            "\n",
            "Similarity : 0.47425714093623694\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.2098069190979004 Generator / grammar loss:-0.19593197107315063   similarity loss:-0.17487381398677826\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "말솜씨가 금방 그 부인은 안심시키듯 사실 따위를 이것저것 주었다. 살았다. 그 d자에게는 잘 있는 일이었다. 아니다. 그녀가 굉장했다. 응수해 왔다. 일어나다니……. 즉 일이 부인은 그녀에게 짓을 둬요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.164964  0.616693  0.475977  0.628307  0.004793  0.549819   \n",
            "\n",
            "    grammar  \n",
            "0  0.976641  \n",
            "Current result ==================================================\n",
            "Sample count: 46\n",
            "     method  comp rate     intro      body  conclusion   isthmus  simlirality  \\\n",
            "0  SAM+WGAN   0.174481  0.523681  0.511653    0.534628  0.004947     0.520951   \n",
            "\n",
            "   grammarity  \n",
            "0    0.970707  \n",
            "==================================================\n",
            "47 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "” 마침내 그 남자는 일을 저지르고 말았다. 그리고 그녀, 파울러 부인은 바로 이웃에 살면서 아무 소리도 못 들은 것이다. 잠시 사이를 두고 나서 포아로가 물었다. 애셔 부인은 어떤 이상한 편지?이를테면 개인적인 서명이 없는?예를 들어 ABC라는 서명이 든 편지를 받은 일이 없는가?파울러 부인은 유감스러운 듯 없다고 대답했다. “당신이 이야기하시는 그런 일은 저도 알고 있어요. 익명 편지라는 거지요. 큰소리로 말하기가 뭣할 정도로 창피스러운 게 가득 씌어 있는……네, 물론 프란츠 애셔가 그런 것을 썼는지 어떤지 저는 몰라요. 물론 썼다고 해도 애셔 부인이 제게 말했을 리 없고요. 뭐라고요? 철도 안내, ABC 철도 안내서라고요? 아니오, 그런 건 못 보았어요. 그리고 만일 애셔 부인에게 그런 게 보내져 왔다면 저한테 꼭 말해 줬을 거예요. 이번 사건을 들었을 때 전 하마터면 쓰러질 뻔했어요. 딸 에디가 알려 줬지요. ‘엄마, 옆 가게에 순경들이 많이 와 있어. ’라고 말예요. 정말 놀랐어요. 그 말을 듣고 전 말했지요. ‘저 아주머니는 그 집에 혼자 사는 게 아니었어.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/144       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/143       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/142       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/141       \n",
            "Negative tokens: ['애셔' '없는?예를' '받은' '“당신이' '익명' '뭐라고요?' '이번' '‘저' '혼자']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 142/143       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 141/142       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 140/141       \n",
            "Peak count: 8\n",
            "Frame tokens: 말았다. 것이다. 애셔 몰라요. 그리고 놀랐어요. ‘저 아니었어. \n",
            "\n",
            "Similarity : 0.49907813827162095\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.382920026779175 Generator / grammar loss:-0.20916222035884857   similarity loss:-0.1703917682170868\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "그 남자는 말았다. 애셔 “당신이 알고 있는……네, 것을 몰라요. 리 안내, 그리고 그런 사건을 ’라고 놀랐어요. 그 ‘저 아주머니는 집에 혼자 사는 게 아니었어.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var    total  \\\n",
            "0  SAM+WGAN    0.165455  0.578978  0.454916  0.549987  0.002808  0.50825   \n",
            "\n",
            "    grammar  \n",
            "0  0.993001  \n",
            "Current result ==================================================\n",
            "Sample count: 47\n",
            "     method  comp rate     intro      body  conclusion   isthmus  simlirality  \\\n",
            "0  SAM+WGAN   0.174289  0.524857  0.510446    0.534955  0.004901     0.520681   \n",
            "\n",
            "   grammarity  \n",
            "0    0.971181  \n",
            "==================================================\n",
            "48 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "그 조카딸이라도 함께 있었더라면 좋았을걸. 주정꾼 남자란 정말 허기진 늑대나 다름없으니까. 그 아주머니 남편은 짐승과 다를 바 없어. 나는 그 아주머니한테 몇 번이나 말했었는데, 결국 내 말대로 되어 버렸구나!그 남자는 언젠가 심한 짓을 할 거라고 말했는데. ’ 그 남자는 진짜로 해치운 거예요. 남자란 술을 마시면 무슨 짓을 할지 모르니까요. 이 살인이 그걸 말해 주고 있잖아요. ” 그녀는 숨을 헐떡이며 이야기를 끝냈다. 포아로가 물었다. “그 애셔라는 남자가 가게로 들어가는 것은 아무도 못 본 셈이군요?” 파울러 부인은 경멸하는 듯 콧방귀를 뀌며 말했다. “그야 아무도 못 보도록 들어가는 게 당연하지요. “ 그러나 그녀는 애셔가 어떻게 남의 눈에 띄지 않고 들어갈 수 있었는지에 대해선 설명해 주지 못했다. 그 집에는 뒷문이 없다고 그녀는 말했다. 또 애셔가 이 가까이에 잘 알려져 있다는 데에도 동의했다. “그렇지만 그는 교수형에 처해지기 싫으니까 용케 숨어 들어간 거예요. ” 포아로는 얼마동안 이야기를 이끌어 나가다가 파울러 부인이 알고 있는 이야기를 몇 번이나 되풀이하는 것을 깨닫자 그 면담을 끝내고 약속한 돈을 주었다. 길을 나서자 나는 말했다. “5파운드는 너무 비싼데, 포아로. ” “그렇지, 그것만으로는.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/161       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/160       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/159       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/158       \n",
            "Negative tokens: ['주정꾼' '결국' '해치운' '그녀는' '못' '셈이군요?”' '“그야' '애셔가' '얼마동안' '나가다가' '약속한']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 159/160       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 158/159       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 157/158       \n",
            "Peak count: 9\n",
            "Frame tokens: 주정꾼 정말 다름없으니까. 없어. 모르니까요. 끝냈다. 그녀는 않고 그것만으로는. \n",
            "\n",
            "Similarity : 0.4211492793566485\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.6330721378326416 Generator / grammar loss:-0.20739278197288513   similarity loss:-0.14183422923088074\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "그 주정꾼 정말 다름없으니까. 없어. 번이나 내 그 거예요. 남자란 술을 마시면 모르니까요. 이 숨을 이야기를 끝냈다. 물었다. 그녀는 않고 있었는지에 설명해 잘 동의했다. 나는 너무 그것만으로는.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending      var     total  \\\n",
            "0  SAM+WGAN    0.173776  0.449665  0.535618  0.503903  0.00126  0.508913   \n",
            "\n",
            "    grammar  \n",
            "0  0.973036  \n",
            "Current result ==================================================\n",
            "Sample count: 48\n",
            "     method  comp rate     intro     body  conclusion   isthmus  simlirality  \\\n",
            "0  SAM+WGAN   0.174278  0.523291  0.51097    0.534308  0.004825     0.520436   \n",
            "\n",
            "   grammarity  \n",
            "0     0.97122  \n",
            "==================================================\n",
            "49 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "‘ “자네는 그녀가 이야기한 이상의 것을 알고 있다고 생각하나?” “우리는 지금 무엇을 물어야 좋을지 모르는 기묘한 위치에 놓여 있네. 우리는 어둠 속에서 숨바꼭질하고 있는 어린이들과도 같은 걸세. 우리는 손을 내밀어 찾고 있지. 파울러 부인은 자기가 알고 있다고 여기는 일들을 우리에게 말해줬네. 더욱이 꽤 억측을 해가면서. 그러나 언젠가 그 진술이 쓸모 있게 될 걸세. 5파운드를 투자한 건 결국 그 언젠가를 위해서라네. ” 나는 요점을 잘 잡을 수가 없었다. 그리고 마침 그때 우리는 글렌 형사와 마주쳤다. < 두 증인 > 글렌 형사는 좀 핼쑥해져 있는 듯 했다. 그는 오후 내내 담배 가게에 들어간 사람들 리스트를 만들고 있었던 모양이다. 포아로가 물었다. “결국은 눈에 띈 사람이 아무도 없다는 거로군요?” “아니, 보기는 본 모양입니다. 흘끔거리는 것 같은 느낌의 키가 큰 남자 셋, 시커먼 수염의 키 작은 남자 넷, 턱수염이 있는 사람 둘, 뚱뚱한 사람 셋, 모두 낯선 사람들로, 증언을 믿는다면 다 어딘지 수상쩍은 데가 있는 이들뿐입니다. 권총을 든 복면한 갱 한 무리가 범행을 저지르는 걸 보았다는 사람이 없는 게 이상할 정도입니다. ” 포아로는 동정적인 미소를 지었다. “애셔라는 사나이를 본 사람은 없던가요?” “없습니다. 이것도 그에게 유리한 점입니다. 저는 지금 막 서장님에게, 이것을 런던 경찰국에서 맡아야 할 일이라고 이야기하고 오는 참입니다. 이건 지방적인 범죄가 아닙니다.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/189       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/188       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/187       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/186       \n",
            "Negative tokens: ['모르는' '억측을' '언젠가를' '좀' '듯' '흘끔거리는' '수상쩍은' '“애셔라는']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 187/188       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 186/187       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 185/186       \n",
            "Peak count: 10\n",
            "Frame tokens: 있지. 그러나 걸세. 그리고 있는 포아로가 믿는다면 이들뿐입니다. “없습니다. 아닙니다. \n",
            "\n",
            "Similarity : 0.41135330821713934\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.6032652854919434 Generator / grammar loss:-0.16658322513103485   similarity loss:-0.10432028025388718\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            " 그녀가 이야기한 “우리는 좋을지 우리는 속에서 내밀어 찾고 있지. 파울러 부인은 여기는 일들을 말해줬네. 그러나 언젠가 쓸모 걸세. 잘 것 “없습니다. 저는 서장님에게, 런던 맡아야 참입니다. 이건 아닙니다. \n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body   ending       var     total  \\\n",
            "0  SAM+WGAN    0.161866  0.548167  0.468529  0.44896  0.001841  0.478586   \n",
            "\n",
            "    grammar  \n",
            "0  0.987883  \n",
            "Current result ==================================================\n",
            "Sample count: 49\n",
            "     method  comp rate     intro      body  conclusion   isthmus  simlirality  \\\n",
            "0  SAM+WGAN   0.174025  0.523799  0.510104    0.532566  0.004764     0.519582   \n",
            "\n",
            "   grammarity  \n",
            "0     0.97156  \n",
            "==================================================\n",
            "50 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "” 포아로는 신중하게 말했다. “나도 그렇게 생각하오. ” “포아로 씨, 싫은 사건입니다. 참으로 싫은 사건입니다. 저는 아무래도 마음에 들지 않습니다. ” 우리는 런던으로 돌아가기 전에 두 사람을 더 만났다. 하나는 제임즈 패트리지라는 인물이었다. 패트리지 씨는 애셔 부인이 살아 있는 동안 맨 마지막으로 만난 사람이었다. 그는 5시 30분에 그녀 가게에서 물건을 샀던 것이다. 페트리지 씨는 몸집 작은 빈약한 남자로 은행원이었다. 코안경은 걸친 무뚝뚝하고 빼빼 마른 느낌의 사나이였으나 말씨는 또박또박했다. 그는 자기에게 잘 어울리는 깨끗한 작은 집에 살고 있었다. 내 친구가 내민 명함을 보며 그는 말했다. “네, 포아로 씨. 글렌 형사에게서 들으셨습니까? 무슨 도움이 될까요, 포아로 씨?” “패트리지 씨, 당신은 살아있는 애셔 부인을 맨 마지막으로 만난 분이시니까요. ” 패트리지 씨는 두 손을 마주대고 미심쩍은 수표라도 들여다보듯 포아로를 보았다. “그것이 토론의 여지가 있는 점입니다, 포아로 씨. 제 다음에도 더 많은 손님이 애셔 부인한테서 물건을 샀을지 모르니 말입니다. ” “그렇더라도 지금으로선 아직 신고해 온 사람이 없습니다.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/143       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/142       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/141       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/140       \n",
            "Negative tokens: ['”' '씨,' '전에' '내' '수표라도' '포아로를']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 141/142       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 140/141       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 139/140       \n",
            "Peak count: 8\n",
            "Frame tokens: 신중하게 참으로 씨는 페트리지 그는 씨. 씨. 없습니다. \n",
            "\n",
            "Similarity : 0.40710856216577507\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.588862419128418 Generator / grammar loss:-0.17765600979328156   similarity loss:-0.11697377264499664\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "” 신중하게 생각하오. 싫은 사건입니다. 참으로 우리는 돌아가기 만났다. 맨 것이다. “패트리지 두 씨. 애셔 물건을 샀을지 모르니 “그렇더라도 지금으로선 신고해 사람이 없습니다. \n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro     body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.172355  0.781302  0.47915  0.472058  0.020775  0.537453   \n",
            "\n",
            "    grammar  \n",
            "0  0.983295  \n",
            "Current result ==================================================\n",
            "Sample count: 50\n",
            "     method  comp rate     intro      body  conclusion   isthmus  simlirality  \\\n",
            "0  SAM+WGAN   0.173992  0.528949  0.509485    0.531356  0.005085     0.519939   \n",
            "\n",
            "   grammarity  \n",
            "0    0.971795  \n",
            "==================================================\n",
            "51 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "” 패트리지 씨는 헛기침을 했다. “그들은 시민의 의무에 대한 관념을 갖고 있지 않으니까요, 포아로 씨. ” 그는 부엉이처럼 코안경 너머로 우리를 보았다. 포아로가 중얼거렸다. “정말 그렇습니다. 당신은 자진해서 경찰에 신고하셨습니까?” “그럼요, 저는 이 무서운 사건 이야기를 듣자 곧 제 진술이 도움이 될지도 모른다고 생각했습니다. 그래서 바로 신고했지요. ” 포아로는 엄숙하게 말했다. “정말 훌륭한 마음씨입니다. 저에게도 그 이야기를 되풀이 들려주실 수 있으시겠지요?” “알겠습니다. 저는 집으로 돌아오는 길이었는데, 정각 5시 30분에……. ” “실례입니다만, 어째서 그토록 정확하게 시간을 알고 계십니까?” 패트리지 씨는 방해를 받아 기분이 좀 상한 모양이었다. “교회 시계가 울렸습니다. 저는 제 시계를 보고 1분 늦는 것을 알았지요. 그때가 바로 애셔 부인 가게로 들어가기 직전이었습니다. ” “거기서 자주 물건을 사셨습니까?” “네, 자주 샀습니다. 집으로 돌아오는 길목이니까요. 1주일에 한두 번씩 저는 <존 코튼>을 순한 것으로 2온스씩 사고 있습니다. ” “애셔 부인을 알고 계셨습니까? 그녀의 가정에 대해서라든지 과거에 대해?” “전혀 모릅니다.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/138       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/137       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/136       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/135       \n",
            "Negative tokens: ['“그들은' '저는' '저에게도' '”' '시간을' '그때가' '번씩']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 136/137       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 135/136       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 134/135       \n",
            "Peak count: 7\n",
            "Frame tokens: 중얼거렸다. 신고했지요. 울렸습니다. 직전이었습니다. 샀습니다. ” 모릅니다. \n",
            "\n",
            "Similarity : 0.4762319230508373\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.502392530441284 Generator / grammar loss:-0.1911451816558838   similarity loss:-0.13980732858181\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "” 포아로가 중얼거렸다. 그렇습니다. “그럼요, 듣자 제 모른다고 신고했지요. 저에게도 “알겠습니다. 정각 어째서 좀 “교회 시계가 울렸습니다. 직전이었습니다. 샀습니다. ” 모릅니다.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.172241  0.521886  0.647314  0.495495  0.004386  0.576683   \n",
            "\n",
            "    grammar  \n",
            "0  0.979872  \n",
            "Current result ==================================================\n",
            "Sample count: 51\n",
            "     method  comp rate    intro      body  conclusion   isthmus  simlirality  \\\n",
            "0  SAM+WGAN   0.173957  0.52881  0.512188    0.530653  0.005071     0.521052   \n",
            "\n",
            "   grammarity  \n",
            "0    0.971953  \n",
            "==================================================\n",
            "52 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "사는 물건이나 또는 날씨에 대해 몇 마디 나눈 것 말고는 이야기한 일이 없습니다. ” “그녀의 생명을 위협하는 말을 자주 했었던 주정꾼 남편에 대해 알고 계셨습니까?” “아니오, 그 사람에 대해서는 아무것도 모릅니다. ” “그러나 당신도 얼굴은 알고 계셨겠지요. 어제 여느 때와 다른 어떤 기색은 없었습니까?흥분해 있었다던가, 화를 내고 있었다던가?” 패트리지 씨는 생각해 보더니 대답했다. “내가 아느 한에서는 여느 때와 다른 점이 전혀 없었습니다. ” 포아로는 일어섰다. “패트리지 씨, 질문에 대답해 주셔서 고맙습니다. 그런데 댁은 혹시 ABC가 없는지요? 런던으로 가는 시간표를 좀 보고 싶어서요. ” 그가 말한 선반 위에는 ABC와 함께 브래드쇼, 주식연감, 케리의 인명록 그리고 현대 인명록 및 지방 신사록 등이 있었다. 포아로는 ABC를 들고 기차시간을 살펴보는 시늉을 한 다음 패트리지 씨에게 고맙다는 인사를 하고 나왔다. 또 다른 한 사람은 앨버트 리딜로, 이 또한 색다른 사람이었다. 앨버트 리딜 씨는 철도 인부였다. 그의 신경질적인 아내가 접시 씻는 소리며, 그 집 개가 으르렁대는 소리며, 리딜 씨 자신의 노골적인 적의 등과 더불어 이야기가 진행되었다. 그는 넓적한 얼굴에 의심 많은 눈을 한 크고 우둥퉁한 거인으로, 고기든 파이를 아주 진한 차와 함께 집어삼키고 있었다. 그는 찻잔 가장자리께로부터 화난 듯한 얼굴로 우리를 노려보고 있었다. 그는 으르렁거렸다. “필요한 말은 다 한 줄로 아는데, 대체 나와 무슨 관계가 있다는거요? 나는 경찰에 다 말해줬소.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/195       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/194       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/193       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/192       \n",
            "Negative tokens: ['나눈' '이야기한' '주정꾼' '씨는' '씨,' '시간표를' '브래드쇼,' '인명록' '신사록' '앨버트' '그의' '씨'\n",
            " '“필요한' '아는데,' '나는']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 193/194       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 192/193       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 191/192       \n",
            "Peak count: 10\n",
            "Frame tokens: 했었던 계셨겠지요. 화를 대답했다. 일어섰다. 앨버트 진행되었다. 으르렁거렸다. 다 말해줬소. \n",
            "\n",
            "Similarity : 0.4473613274369119\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.4882073402404785 Generator / grammar loss:-0.1436653733253479   similarity loss:-0.09383872896432877\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "다른 화를 대답했다. 없었습니다. ” 포아로는 일어섰다. 질문에 고맙습니다. 런던으로 보고 위에는 ABC를 한 사람은 앨버트 인부였다. 진행되었다. 눈을 차와 집어삼키고 그는 으르렁거렸다. “필요한 다 나와 경찰에 다 말해줬소. \n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.165375  0.314666  0.530127  0.629918  0.017307  0.516972   \n",
            "\n",
            "    grammar  \n",
            "0  0.871154  \n",
            "Current result ==================================================\n",
            "Sample count: 52\n",
            "     method  comp rate     intro      body  conclusion   isthmus  simlirality  \\\n",
            "0  SAM+WGAN   0.173792  0.524692  0.512533    0.532562  0.005306     0.520973   \n",
            "\n",
            "   grammarity  \n",
            "0    0.970015  \n",
            "==================================================\n",
            "53 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "그런데 이번엔 또 외국놈 따위에게 다시 한 번 말하지 않으면 안 된다는 거요?” 포아로는 재빨리 내 쪽으로 흥미가 끌리는 듯한 눈짓을 보내고 나서 입을 열었다. “정말이지 안 되셨습니다. 그렇지만 할 수 없잖습니까? 어쨌든 살인 사건이니까요. 아주 신중하게 하지 않으면 안 되지요. ” 앨버트의 아내가 신경질적으로 말했다. “이분들이 듣고 싶어하시는 것을 모조리 이야기하는 게 좋아요. ” 거인이 소리쳤다. “잠자코 있어. ” 포아로가 솜씨 좋게 끼어들었다. “당신은 자진해서 경찰에 가신 게 아니잖습니까. ” “어째서 그런 짓을 해야 되는 거요? 그런 건 내 일이 아니잖소. ” 포아로는 아무렇지도 않게 말했다. “생각할 나름이지요. 살인이 일어났고 경찰은 가게에 왔던 사람을 알고 싶어했습니다. 저는 당신이 자진해서 신고하시는 편이 뭐랄까, 자연스럽다고 생각되는데요. ” “나한테는 일이 있소. 스스로 자진해서 가지 않았다니, 그렇게 말하면 곤란한데. ” “하지만 당신이 애셔 부인 가게로 들어가는 것을 본 사람이 있습니다.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/128       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/127       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/126       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/125       \n",
            "Negative tokens: ['거요?”' '없잖습니까?' '”' '스스로' '것을']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 126/127       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 125/126       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 124/125       \n",
            "Peak count: 7\n",
            "Frame tokens: 않으면 안 되지요. 끼어들었다. 나름이지요. ” 있습니다. \n",
            "\n",
            "Similarity : 0.47863085740565825\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.3712470531463623 Generator / grammar loss:-0.18148425221443176   similarity loss:-0.14392413198947906\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "그런데 번 내 안 되지요. 신경질적으로 모조리 게 소리쳤다. “잠자코 ” 포아로가 끼어들었다. 가신 건 내 아니잖소. ” “생각할 나름이지요. \n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro     body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.154143  0.544115  0.55261  0.412526  0.004112  0.508886   \n",
            "\n",
            "    grammar  \n",
            "0  0.988241  \n",
            "Current result ==================================================\n",
            "Sample count: 53\n",
            "     method  comp rate     intro      body  conclusion   isthmus  simlirality  \\\n",
            "0  SAM+WGAN   0.173422  0.525058  0.513289    0.530297  0.005284     0.520745   \n",
            "\n",
            "   grammarity  \n",
            "0    0.970359  \n",
            "==================================================\n",
            "54 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "그래서 경찰은 당신을 만나러 오지 않으면 안 되었던 것입니다. 그런데 경찰은 당신 이야기에 만족했습니까?” 앨버트는 사납게 되물었다. “어째서 만족하지 않겠소?” 포아로는 다만 어깨를 으쓱했을 뿐이었다. “대체 뭘 냄새 맡으려는 거요. 당신은. 나한테서 뭘 끄집어낼 수 있을 리 없잖소. 그 노파를 죽인 게 누군지 모두들 알고 있어. 그 남편이잖소?” “그렇지만 그날 밤 그는 그곳에 있지 않았고, 당신은 있었지요. ‘ “나한테 죄를 뒤집어씌우려는 거요, 당신? 잘됐어, 이거 잘해 봐야겠군. 대체 내가 그런 짓을 해야 될 이유가 어디 있소? 그 늙은이의 피로 얼룩진 담배를 한 갑 훔치려고? 내가 남들이 말하는 피에 굶주린 살인광이란 말이오? 이 내가?” 그는 위협하듯 의자에서 일어섰다. 그의 아내가 양 같은 소리를 질렀다. “버트, 버트, 그런 말을 해선 안 돼요. 버트, 그런 말을 하면 모두들……. ” 포아로가 말했다. “좀 침착하십시오. 저는 그저 당신이 그 가게에 가셨었다는 이야기를 듣고 싶었던 것뿐입니다.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/131       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/130       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/129       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/128       \n",
            "Negative tokens: ['“대체' '누군지' '그' '당신?' '있소?' '내가' '버트,' '싶었던']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 129/130       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 128/129       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 127/128       \n",
            "Peak count: 7\n",
            "Frame tokens: “어째서 당신은. 없잖소. 대체 이 “버트, 것뿐입니다. \n",
            "\n",
            "Similarity : 0.33850391566573057\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.295426845550537 Generator / grammar loss:-0.20319503545761108   similarity loss:-0.17343461513519287\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "그래서 당신을 오지 사납게 “어째서 뭘 맡으려는 거요. 당신은. 나한테서 없잖소. 게 있어. 당신? 대체 살인광이란 말이오? 이 “버트, 그저 것뿐입니다.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN     0.16699  0.425009  0.593759  0.482319  0.004909  0.526577   \n",
            "\n",
            "    grammar  \n",
            "0  0.990252  \n",
            "Current result ==================================================\n",
            "Sample count: 54\n",
            "     method  comp rate     intro      body  conclusion   isthmus  simlirality  \\\n",
            "0  SAM+WGAN   0.173302  0.523206  0.514779    0.529409  0.005277     0.520853   \n",
            "\n",
            "   grammarity  \n",
            "0    0.970727  \n",
            "==================================================\n",
            "55 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "그런데 그걸 거부하면 저에게는 어쩐지, 뭐라고 하나, 좀 이상한 기분이 드는군요. ” “내가 거부한다고 누가 말했소?” 리딜은 다시 의자에 앉았다. “이야기해 주겠소. ‘ “가게에 들어가셨던 게 6시였지요?” “그렇소. 사실은 1. 2분 지나 있었소. 골든 프레이크를 한 갑 사려고. 내가 문을 밀자……. ” “그러니까, 즉 가게 문이 닫혀 있었다는 거로군요?” “그렇소. 나는 벌써 가게를 닫았나 하고 생각했소. 그런데 그게 아니었소. 안으로 들어가니 아무도 없었소. 그래서 계산대를 쾅 두드리고는 잠시 기다려 보았소. 그래도 아무도 나오지 않길래 나는 밖으로 나왔소. ” “계산대 뒤에 쓰러져 있는 시체는 못 보셨군요?” “못 보았소. 다른 사람도 못 봤을 거요, 찾기라도 하지 않았다면. ” “철도 안내서는 있었습니까?” “있었소, 책장이 펼쳐져서 말이오. 그래서 나는 생각했소. 이 할머니, 너무 급하게 나가느라 문잠그는 걸 잊었나 보다고. ” “그래서 당신은 철도 안내서를 건드리거나 움직여 보셨군요?” “당치도 않소, 누가 그런 짓을 하겠소.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/130       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/129       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/128       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/127       \n",
            "Negative tokens: ['않길래' '“못' '잊었나']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 128/129       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 127/128       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 126/127       \n",
            "Peak count: 7\n",
            "Frame tokens: 밀자……. 생각했소. 없었소. 보았소. 않았다면. 생각했소. 하겠소. \n",
            "\n",
            "Similarity : 0.45211308684540485\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.4809763431549072 Generator / grammar loss:-0.1923356056213379   similarity loss:-0.14327718317508698\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "좀 누가 말했소?” “가게에 한 문을 밀자……. 생각했소. 들어가니 아무도 없었소. 보았소. 나왔소. “철도 있었습니까?” 생각했소. 문잠그는 잊었나 보다고. “당치도 하겠소.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.183865  0.492968  0.553699  0.598854  0.001882  0.555099   \n",
            "\n",
            "    grammar  \n",
            "0  0.980737  \n",
            "Current result ==================================================\n",
            "Sample count: 55\n",
            "     method  comp rate     intro      body  conclusion   isthmus  simlirality  \\\n",
            "0  SAM+WGAN   0.173494  0.522656  0.515487    0.530671  0.005215     0.521476   \n",
            "\n",
            "   grammarity  \n",
            "0    0.970909  \n",
            "==================================================\n",
            "56 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "지금 말한 일밖에 하지 않았소. ” “당신이 거기 들어가기 전에 누가 나오는 건 못 보셨습니까?” “못 보았소. 내가 말하고 싶은 건, 어째서 나에게 누명을 씌우려고……. ” 포아로는 일어섰다. “아무도 그러지 않습니다. 아직 지금 단계에서는. 그럼, 안녕히 계십시오. ” 그는 멍하니 입을 벌린 채 있는 사나이를 뒤에 남겨 두고 나왔다. 나는 그 뒤를 따랐다. 길로 나오자 그는 시계를 보았다. “빨리 가면 7시 2분 기차를 탈 수 있겠군. 자, 서둘러 가세. ‘ < 두 번째 편지 > 나는 열심히 물었다. “그래서?” 우리는 우리 말고는 아무도 없는 1등 차칸에 앉아 있었다. 기차는 급행으로 막 앤도버를 떠난 참이었다. 포아로가 말했다. “범죄는 빨강 머리에 왼쪽 눈이 사팔뜨기인 중키의 사나이에 의해 저질러졌네. 그 사나이는 오른쪽 다리를 조금 절고, 왼쪽 어때 밑에 점이 있지. ” 나는 소리쳤다. “포아로!” 한순간 나는 정말로 믿어 버렸던 것이다.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/128       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/127       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/126       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/125       \n",
            "Negative tokens: ['”' '내가' '건,' '”' '”' '“빨리' '“그래서?”' '막' '“포아로!”']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 126/127       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 125/126       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 124/125       \n",
            "Peak count: 7\n",
            "Frame tokens: ” 단계에서는. 나는 서둘러 말했다. 소리쳤다. 것이다. \n",
            "\n",
            "Similarity : 0.4536520907703009\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.3924455642700195 Generator / grammar loss:-0.18341046571731567   similarity loss:-0.14365026354789734\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "지금 말한 일밖에 하지 거기 “못 보았소. 나에게 씌우려고……. 나는 보았다. 서둘러 포아로가 말했다. 머리에 눈이 의해 조금 왼쪽 밑에 소리쳤다.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.170478  0.696886  0.534392  0.480712  0.008446  0.550787   \n",
            "\n",
            "    grammar  \n",
            "0  0.980763  \n",
            "Current result ==================================================\n",
            "Sample count: 56\n",
            "     method  comp rate     intro      body  conclusion   isthmus  simlirality  \\\n",
            "0  SAM+WGAN   0.173441  0.525767  0.515824    0.529779  0.005273     0.521999   \n",
            "\n",
            "   grammarity  \n",
            "0    0.971085  \n",
            "==================================================\n",
            "57 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "그러나 곧 이 친구의 장난기 어린 눈빛이 사실을 가르쳐 주었다. 나는 되풀이했다. 이번에는 나무라듯이 “포아로!” “자네는 어떻게 하자는 건가? 자네는 나에게 충성스러운 개같이 헌신적인 눈길을 보내면서 셜록 홈즈 같은 해결을 바라고 있네. 그런데 진상은 말일세. 살인범이 어떤 사니이며, 어디에 살고, 어떻게 하면 잡을 수 있는지 나는 도무지 알 수 없네. ” 나는 중얼거렸다. “녀석이 무슨 단서라도 남겨 줬더라면. ‘ 그렇지, 단서. 언제나 자네 마음을 끄는 건 그 단서라는 걸세. 유감스럽게도 그 사나이는 담배를 피워 담뱃재를 남겨 둬 주지도 않았고, 야릇한 모양의 징을 박은 신 자국도 남겨 주지 않았네. 그렇지, 그는 그리 친절하지 않았어. 그러나 적어도 철도 안내서가 있잖나. 그 ABC야말로 자네의 단서가 아니겠나!“ “그가 실수해서 그것을 남겨 뒀다고 생각하나?” “물론 그렇지는 않네. 일부러 두고 간 걸세. 지문 상태를 보면 알 수 있지. ” “지문이 없었잖나?” “바로 그걸세. 어제는 어떤 밤이었나? 더운 6월의 밤이었지. 이런 밤에 장갑을 끼고 다니는 사나이가 있을까?\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/141       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/140       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/139       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/138       \n",
            "Negative tokens: ['자네는' '보내면서' '알' '단서라도' '야릇한' '자국도']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 139/140       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 138/139       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 137/138       \n",
            "Peak count: 8\n",
            "Frame tokens: 되풀이했다. 말일세. 중얼거렸다. 걸세. 일부러 걸세. 없었잖나?” 있을까? \n",
            "\n",
            "Similarity : 0.47020314778208205\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.080526113510132 Generator / grammar loss:-0.14316314458847046   similarity loss:-0.1351061761379242\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "사실을 되풀이했다. 어떻게 자네는 눈길을 바라고 말일세. 어떤 잡을 중얼거렸다. 무슨 남겨 자네 마음을 끄는 그 걸세. 주지 ABC야말로 아니겠나!“ 일부러 걸세. 있지. 없었잖나?”\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.183784  0.513605  0.533124  0.400972  0.003392  0.489575   \n",
            "\n",
            "    grammar  \n",
            "0  0.866827  \n",
            "Current result ==================================================\n",
            "Sample count: 57\n",
            "     method  comp rate     intro      body  conclusion  isthmus  simlirality  \\\n",
            "0  SAM+WGAN   0.173622  0.525554  0.516128    0.527519  0.00524      0.52143   \n",
            "\n",
            "   grammarity  \n",
            "0    0.969256  \n",
            "==================================================\n",
            "58 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "그런 사나이는 곧 눈에 띄지. 그러니까 ABC에 지문이 없었다면 주의깊게 닦아 낸 게 틀림없네. 죄없는 남자라면 지문을 남겨 두겠지만, 죄가 있는 자는 남기지 않네. 그러므로 우리의 살인범은 그것을 일부러 남겨두고 간 걸세. 그러나 그 때문에 이것이 또 한 단서가 되지. ABC는 누군가가 사서 갖다 두었다……이런 가능성이 있는 셈일세. ” “그 방법으로 무엇을 알 수 있나?” “사실을 말하면, 헤이스팅즈. 나는 그리 희망을 가지고 있지 않네. 이 사나이, 이 미지의 X라는 사나이는 확실히 자기 능력에 자부심을 갖고 있네. 그는 뒤를 밟힐 그런 따위의 표시를 남겨 두지 않아. ” “그렇다면 ABC는 전혀 희망이 없는가?” “자네가 말하는 뜻에서는. ” “다른 뜻에서라면 있다는 건가?” 포아로는 곧바로 대답하지 않았다. 이윽고 그는 천천히 말했다. “그 답은 <있다>일세. 우리는 지금 미지의 인물과 마주하고 있네. 상대는 어둠 속에 있고, 언제까지나 어둠 속에 있으려 하지. 그러나 일의 성질로 보아 그는 자기에게 빛을 비추지 않고는 견디지 못할 걸세. 어떤 뜻에서는 이미 많은 것을 알고 있지. 나에게는 그의 모습이 흐릿하게 형태를 갖추어 오는 게 보인다네. 올바른 활자체를 달필로 쓸 수 있는 사나이?그것을 부당하게 느끼며 싸워 온 사나이가 내 눈에 보이네.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/169       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/168       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/167       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/166       \n",
            "Negative tokens: ['없었다면' '남자라면' '두겠지만,' '그러므로' '일부러' '그러나' '자기' '그는' '답은' '미지의' '그러나' '견디지'\n",
            " '그의']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 167/168       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 166/167       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 165/166       \n",
            "Peak count: 9\n",
            "Frame tokens: 곧 띄지. 되지. 있는 “사실을 이 않았다. 어떤 보이네. \n",
            "\n",
            "Similarity : 0.44337037015951364\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.3895671367645264 Generator / grammar loss:-0.17044749855995178   similarity loss:-0.13098657131195068\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "그런 사나이는 곧 눈에 띄지. 지문이 없었다면 낸 게 틀림없네. 죄없는 자는 남기지 않네. 살인범은 그것을 걸세. 또 되지. 않네. 사나이, 어떤 오는 올바른 달필로 보이네. \n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro     body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.149847  0.776146  0.49707  0.510894  0.016492  0.557033   \n",
            "\n",
            "    grammar  \n",
            "0  0.983684  \n",
            "Current result ==================================================\n",
            "Sample count: 58\n",
            "     method  comp rate     intro      body  conclusion   isthmus  simlirality  \\\n",
            "0  SAM+WGAN   0.173212  0.529874  0.515799    0.527233  0.005434     0.522044   \n",
            "\n",
            "   grammarity  \n",
            "0    0.969505  \n",
            "==================================================\n",
            "59 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "자신을 주장하고 남의 관심을 끌고 싶은 마음속 충동이 점점 강해지고, 사건이며 사물이 그것을 부숴 버려 한층 더 비굴한 감정을 쌓아 올려 간 것이 내 눈에는 보이네. 그리하여 내부의 성냥이 이 화약을 실은 열차에 불을 붙이게 된 걸세. ‘ 나는 반대했다. 그런 것은 모두 억측에 지나지 않잖나. 실제로는 아무 쓸모도 없어. “ “자네는 성냥 끄트러기라든가 담뱃재라든가 징 박은 구두 쪽이 마음에 드는가 보군. 그러나 적어도 우리는 스스로 실제적인 질문을 해보지 않으면 안 되네. 어째서 ABC인가? 어째서 애셔 부인인가? 어째서 앤도버인가?” “그 여자의 과거 생활은 아주 단순해 보이네. ” 나는 생각에 잠겼다. “그 두 남자와의 면담은 실망이었어. 그들은 우리가 이미 알고 있는 것 이상의 일은 아무것도 말하지 못했잖아. ” “사실을 말하면 나는 그들에게 큰 기대를 걸고 있지 않았네. 그러나 살인 후보자로서의 두 사람의 가능성을 무시할 수도 없었지. ‘ “자네는 정말로……. ” “적어도 범인이 앤도버 또는 그 언저리에 살고 있을 가능성은 있는 걸세. 그것이 어째서 앤도버인가 하는 우리들의 질문에 대한 가능한 대답이 되네. 게다가 그날 그 시간 가게에 있었던 것으로 알려진 사나이가 둘이나 있는 걸세. 그 어느 쪽이 범인일지도 모르잖나.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/168       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/167       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/166       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/165       \n",
            "Negative tokens: ['비굴한' '그리하여' '그러나' '스스로' '않으면' '애셔' '과거' '”' '생각에' '“자네는' '앤도버' '앤도버인가'\n",
            " '사나이가']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 166/167       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 165/166       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 164/165       \n",
            "Peak count: 9\n",
            "Frame tokens: 그런 지나지 “ ” 않았네. 수도 걸세. 그 모르잖나. \n",
            "\n",
            "Similarity : 0.373817312549104\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.3572068214416504 Generator / grammar loss:-0.17544713616371155   similarity loss:-0.13933919370174408\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "더 감정을 올려 보이네. 그런 지나지 “ 부인인가? “그 여자의 실망이었어. 우리가 말하지 ” 나는 큰 걸고 있지 않았네. 수도 정말로……. “적어도 범인이 살고 있을 걸세. 사나이가\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending      var     total  \\\n",
            "0  SAM+WGAN    0.159375  0.494473  0.535363  0.494593  0.00037  0.514954   \n",
            "\n",
            "    grammar  \n",
            "0  0.931043  \n",
            "Current result ==================================================\n",
            "Sample count: 59\n",
            "     method  comp rate     intro      body  conclusion   isthmus  simlirality  \\\n",
            "0  SAM+WGAN   0.172978  0.529274  0.516131    0.526679  0.005348     0.521924   \n",
            "\n",
            "   grammarity  \n",
            "0    0.968853  \n",
            "==================================================\n",
            "60 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "그리고 그 가운데 어느 쪽인가가 범인이 아님을 알리는 표시는 아직 아무것도 나타나지 않았으니 말일세. ‘ 나는 인정했다. “그 꼴사나운 짐승 같은 리딜일지도 모르지. ” “그런데 나는 리딜은 풀어줘도 좋다고 생각하고 있네. 그는 신경질적이고 큰소리를 치며 분명 초조해 있었어. ” “그러나 그것은 확실히……. ” “그 ABC 편지를 쓰는 그런 자와는 정반대의 성격일세. 자신감과 자부심이 우리가 찾고 있는 특징이지. ” “누군가 자신의 중대성을 알리고 싶어하는 사람이란 말인가?” “아마도 그럴 걸세. 그러나 어떤 종류의 사람들은 신경질적이고 겸손한 속에 오히려 크나큰 허영심과 자기만족을 숨기고 있기도 하지. ” “그 몸집 작은 패트리지 씨는 어떤가?” “그 사나이 쪽이 그런 타입에 가까워. 그 이상은 말할 수 없지만. 그는 마치 그 편지를 쓴 자가 할 것 같은 행동을 취하고 있었지. 바로 경찰에 갔고, 자기를 돋보이려 했으며, 자기 위치를 즐기고 있었거든. ” “정말로 그렇게 생각하나?” “아니, 헤이스팅즈. 내 개인적으로는 범인이 앤도버 밖에서 왔다고 생각하지만 어떤 수사도 소홀히 할 수 없네. 그리고 나는 언제나 <그>라고 말하고 있지만, 여성이 관계해 있을 가능성도 빼놓을 수 없네. ” “설마!” “물론 공격 수법으로 보아선 남자일세. 그러나 익명 편지란 남자보다 오히려 여자에 의해 잘 씌어지는 법이지. 이 사실을 머리에 넣어두지 않으면 안 되네.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/179       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/178       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/177       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/176       \n",
            "Negative tokens: ['그는' '싶어하는' '오히려' '자기만족을' '타입에' '개인적으로는' '생각하지만' '그리고' '<그>라고' '오히려'\n",
            " '씌어지는' '않으면']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 177/178       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 176/177       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 175/176       \n",
            "Peak count: 10\n",
            "Frame tokens: ” ” 걸세. 하지. 그는 것 했으며, 있었거든. 남자일세. 되네. \n",
            "\n",
            "Similarity : 0.42221730140770286\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.4664671421051025 Generator / grammar loss:-0.19652460515499115   similarity loss:-0.14900332689285278\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "아직 ‘ ” 그는 ” “그러나 그것은 그런 우리가 있는 걸세. 속에 있기도 하지. ” “정말로 생각하나?” 내 범인이 생각하지만 수사도 없네. 그리고 빼놓을 수 없네. “설마!” 남자일세. 법이지. 되네.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN     0.16079  0.587637  0.473116  0.436341  0.004151  0.484988   \n",
            "\n",
            "    grammar  \n",
            "0  0.993423  \n",
            "Current result ==================================================\n",
            "Sample count: 60\n",
            "     method  comp rate     intro      body  conclusion   isthmus  simlirality  \\\n",
            "0  SAM+WGAN   0.172774  0.530247  0.515414    0.525174  0.005328     0.521308   \n",
            "\n",
            "   grammarity  \n",
            "0    0.969262  \n",
            "==================================================\n",
            "61 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "” 나는 잠시 입을 다물고 있다가 말했다. “이번엔 뭘 하면 되나?” “오, 정력가 헤이스팅즈여. ” 포아로는 나에게 미소를 보냈다. “아니, 정말 뭘 하지?” “아무것도. ” “아무것도?” 내 목소리에는 뚜렷한 실망이 나타나 있었다. “내가 마술사인가, 마법사인가? 내게 뭘 시키고 싶은가?” 마음속으로 사태를 잘 생각해 보고 나서 나는 대답하기 힘들다는 것을 알았다. 그러나 나는 뭔가 하지 않으면 안 된다. 발밑에 풀이 나게 해선 안 된다는 확신을 가지고 있었다. 나는 말했다. “ABC도 있고, 편지지도 있고, 봉투도 있고……. ” “그 점에서는 물론 여러 가지 수배가 되어 있네. 경찰은 그런 종류의 수사를 하는 데 자유스러운 여러 가지 수단을 갖고 있지. 그런 점에서 무엇이 발견된다면 그들이 찾아내 줄 테니 걱정할 것 없네. ” 그래서 나 또한 만족하는 수밖에 없었다. 그뒤 며칠동안 이상하게도 포아로는 사건에 대한 토론을 피하는 듯했다. 내가 그 문제를 꺼내려 하면 못 참겠는지 손을 흔들며 말머리를 돌려 버렸다. 나는 그 까닭을 깊이 생각해 보기를 은근히 두려워하고 있었다. 애셔 부인 살해에 대해서는 포아로도 자신의 패배를 인정하고 있었다. ABC가 그에게 도전했고, 그리고 이겼다.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/158       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/157       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/156       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/155       \n",
            "Negative tokens: ['하면' '나에게' '하지?”' '내게' '대답하기' '그러나' '않으면' '그런' '수밖에' '하면' '생각해' '도전했고,']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 156/157       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 155/156       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 154/155       \n",
            "Peak count: 8\n",
            "Frame tokens: 잠시 말했다. 줄 ” 듯했다. 못 있었다. 이겼다. \n",
            "\n",
            "Similarity : 0.45429422364397454\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.352195978164673 Generator / grammar loss:-0.16251496970653534   similarity loss:-0.12692438066005707\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "” 잠시 말했다. “이번엔 하면 되나?” 헤이스팅즈여. 포아로는 정말 뭘 “아무것도. “내가 말했다. 있고……. 그들이 내가 못 말머리를 버렸다. 까닭을 깊이 두려워하고 있었다. 이겼다.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.168831  0.775396  0.452075  0.586753  0.017585  0.557143   \n",
            "\n",
            "    grammar  \n",
            "0  0.962373  \n",
            "Current result ==================================================\n",
            "Sample count: 61\n",
            "     method  comp rate     intro      body  conclusion   isthmus  simlirality  \\\n",
            "0  SAM+WGAN    0.17271  0.534266  0.514376    0.526183  0.005529     0.521896   \n",
            "\n",
            "   grammarity  \n",
            "0    0.969149  \n",
            "==================================================\n",
            "62 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "잇따른 성공에 익숙해 있던 내 친구는 자기 실패에 민감했다. 그런 만큼 그는 이 문제에 대한 토론을 참을 수 없었던 것이다. 그것은 분명 위대한 남자의 왜소함을 나타내는 일임에 틀림없지만, 아무리 냉정한 사람일지라도 성공했을 때 흥분되는 것은 흔히 있는 일이다. 포아로의 경우는 그 흥분이 몇 해나 계속 되고 있었다. 포아로의 경우는 그 흥분이 몇 해나 계속 되고 있었다. 그 결과 지금에야 겨우 눈을 뜨게 되었다 해도 그리 이상할 것은 없으리라. 나는 친구의 약점을 존중하여 사건에 대해 그 이상 이야기하는 것을 삼갔다. 심문 보고는 신문에서 읽었다. 그것은 무척 간단한 것으로, ABC 편지에 대해서도 아무 언급이 없었다. 배심원 평결은 한 사람 또는 몇 사람의 알 수 없는 인물에 의한 살인으로 되어 있었다. 이 사건은 신문의 여러 기사들 속에서 그리 주의를 끌지 못했다. 이야깃거리가 될 듯한 데도, 구경거리가 될 듯한 데도 없었다. 뒷골목의 노파 살해 따윈 더 스릴 있는 화제 때문에 곧 흐지부지되어 버리는 것이다. 사실을 말하면, 사건은 내 머리 속에서도 사라져 가고 있었다. 그것은 포아로가 실패했다고 생각하는 게 싫었기 때문이라고도 할 수 있다. 그런데 7월 25일이 되어 사건은 갑자기 되살아났다. 나는 주말에 요크셔에 가 있었기 때문에 이틀쯤 포아로를 만나지 못했다. 월요일 오후에 돌아왔는데, 그 편지는 6시 우편으로 배달되었다. 나는 문제의 봉투를 뜯어 펼쳐 보았을 때 포아로가 갑자기 날카롭게 숨을 들이 쉬었던 것을 기억하고 있다. “왔네.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/202       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/201       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/200       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/199       \n",
            "Negative tokens: ['있던' '참을' '없었던' '틀림없지만,' '되고' '지금에야' '심문' '한' '몇' '이야깃거리가' '곧' '생각하는'\n",
            " '있었기' '갑자기']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 200/201       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 199/200       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 198/199       \n",
            "Peak count: 11\n",
            "Frame tokens: 익숙해 그런 흥분되는 흥분이 흥분이 없으리라. 그것은 못했다. 듯한 사실을 “왔네. \n",
            "\n",
            "Similarity : 0.44664290381411553\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.3889386653900146 Generator / grammar loss:-0.19312599301338196   similarity loss:-0.1537303924560547\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            " 익숙해 그런 그는 이 참을 틀림없지만, 사람일지라도 흥분되는 흥분이 흥분이 되었다 이상할 것은 없으리라. 것을 삼갔다. 심문 그것은 무척 ABC 편지에 한 없는 살인으로 되어 이 주의를 못했다. 될 것을 “왔네. \n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.157274  0.591591  0.475449  0.446702  0.003923  0.490053   \n",
            "\n",
            "    grammar  \n",
            "0  0.958307  \n",
            "Current result ==================================================\n",
            "Sample count: 62\n",
            "     method  comp rate    intro      body  conclusion   isthmus  simlirality  \\\n",
            "0  SAM+WGAN   0.172461  0.53519  0.513748    0.524901  0.005503     0.521382   \n",
            "\n",
            "   grammarity  \n",
            "0    0.968974  \n",
            "==================================================\n",
            "63 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "” 그가 말했다. 나는 그를 쳐다보았으나 잘 알 수가 없었다. “뭐가 왔다는 건가?” “ABC 사건의 제2장일세. ” 나는 잠시 멍해진 채 그를 보고 있엇다. 사건은 완전히 내 기억에서 떨어져 나가 있었던 것이다. “읽어보게. ” 포아로는 나에게 편지를 건네주었다. 전과 마찬가지로 좋은 편지지에 활자체로 씌어 있었다. 친애하는 포아로여, 대체 어떻게 된 건가? 첫 번째 게임은 내 승리다. 앤도버 사건은 실로 잘 되었잖은가? 그러나 재미는 이제 시작이다. 이번에는 벡스힐 바닷가로 주의를 돌리도록. 날짜는 오는 25일. 이 얼마나 유쾌한 일인가! 이만. ABC 나는 소리쳤다. “이런, 포아로! 이 미치광이는 또 다른 범죄를 저지르려는 게 아닌가?” “물론이지, 헤이스팅즈. 자네는 어떻게 생각하고 있었나?\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/98       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/97       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/96       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/95       \n",
            "Negative tokens: ['“뭐가' '”' '앤도버' '그러나' '이' '“이런,']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 96/97       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 95/96       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 94/95       \n",
            "Peak count: 5\n",
            "Frame tokens: 말했다. “뭐가 “읽어보게. “이런, 있었나? \n",
            "\n",
            "Similarity : 0.5197851191550267\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.0957515239715576 Generator / grammar loss:-0.14704933762550354   similarity loss:-0.13746686279773712\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            " 말했다. 수가 “뭐가 건가?” 제2장일세. 그를 내 “읽어보게. 실로 바닷가로 25일. “이런, 이 있었나?\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN     0.15404  0.678211  0.541072  0.553937  0.003824  0.572359   \n",
            "\n",
            "    grammar  \n",
            "0  0.942218  \n",
            "Current result ==================================================\n",
            "Sample count: 63\n",
            "     method  comp rate     intro      body  conclusion   isthmus  simlirality  \\\n",
            "0  SAM+WGAN   0.172168  0.537461  0.514181    0.525362  0.005476     0.522192   \n",
            "\n",
            "   grammarity  \n",
            "0     0.96855  \n",
            "==================================================\n",
            "64 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "앤도버 사건 하나로 끝날 줄 여겼나? 자네는 내가 말한 걸 기억하고 있겠지. <무서운 시작이다>라고. ” “무서운 일이군. ” “그렇네, 무서운 일일세. ” “우리는 살인광을 상대하고 있어. ” “바로 그렇네. ” 그의 냉정함은 어떤 극적인 태도보다도 인상적이었다. 나는 편지를 돌려주며 몸을 떨었다. 다음날 아침, 담당자들의 회의가 열렸다. 서섹스 주 경찰서장, 범죄 수사과장, 앤도버의 글렌 형사, 서섹스 경찰의 카터 경감, 재프 경감과 크롬이라는 이름의 젊은 형사, 그리고 저명한 정신과의 솜프슨 박사가 한 자리에 모였다. 편지의 소인은 햄스티드로 되어 있었지만, 포아로의 의견으로 이것은 그리 중요시되지 않았다. 사건은 충분히 검토되었다. 솜프슨 박사는 인상 좋은 중년 신사로, 그 풍부한 학식에도 불구하고 직업상의 전문용어를 피해 아주 평범한 말을 쓰도록 마음 쓰고 있었다. 범죄 수사과장이 말했다. “이 두 편지가 같은 필적임은 틀림없습니다. 둘 다 한 인물에 의해 씌어진 겁니다. 그리고 그 인물이 앤도버 살인 사건에 관련해 있는 것도 확실합니다. ” “과연 그렇습니다. 우리는 지금 또다른 명백한 두 번째의 계획적 살인 예고를 받고 있습니다.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/147       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/146       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/145       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/144       \n",
            "Negative tokens: ['서섹스' '사건은' '그' '불구하고' '예고를']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 145/146       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 144/145       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 143/144       \n",
            "Peak count: 8\n",
            "Frame tokens: <무서운 일이군. 무서운 범죄 겁니다. 확실합니다. “과연 있습니다. \n",
            "\n",
            "Similarity : 0.5045972926817466\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.4556665420532227 Generator / grammar loss:-0.19831813871860504   similarity loss:-0.1519375592470169\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            " 앤도버 <무서운 일이군. 무서운 일일세. 인상적이었다. 서섹스 주 앤도버의 이름의 한 모였다. 그리고 그 앤도버 살인 사건에 관련해 것도 확실합니다. “과연 살인 있습니다.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.164129  0.631892  0.518835  0.592333  0.002194  0.563496   \n",
            "\n",
            "    grammar  \n",
            "0  0.990562  \n",
            "Current result ==================================================\n",
            "Sample count: 64\n",
            "     method  comp rate     intro      body  conclusion   isthmus  simlirality  \\\n",
            "0  SAM+WGAN   0.172043  0.538936  0.514254    0.526409  0.005425     0.522837   \n",
            "\n",
            "   grammarity  \n",
            "0    0.968894  \n",
            "==================================================\n",
            "65 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "그 살인은 오는 25일 벡스힐로 예정되어 있습니다. 어떤 수단을 취하면 좋겠습니까?” 서섹스 주 경찰서장이 자기 경감 쪽을 보았다. “카터, 어떻게 해야 할까?” 카터 경감은 무겁게 고개를 저었다. “어렵군요, 예정된 피해자에 대한 최소한의 단서도 없습니다. 정직하고 공정하게 말해서 과연 우리가 어떤 수단을 취할 수 있겠습니까?” 포아로가 나섰다. “힌트가 있습니다. ” 모두의 얼굴이 그에게로 돌려졌다. “예정된 피해자의 이름은 B로 시작된다고 여겨집니다. ” 수사과장이 의심스러운 듯 말했다. “그것은 다만 생각일 따름이지요. ” 솜프슨 박사가 생각에 잠겨 말했다. “알파벡 콤플렉스군요. ” “나는 단지 가능성으로 말하고 있는 겁니다. 그 이상은 아니지요. 이 생각은 지난달에 살해된 그 불운한 여자의 가게 문에 애셔라는 글자가 씌어져 있는 것을 보았을 때 떠오른 겁니다. 벡스힐이라고 장소를 정한 편지를 보고 피해자도 알파벳순으로 정해지리라는 게 하나의 가능성으로 떠올랐지요. ” “그것은 확실히 가능성이 있습니다. 그러나 동시에 애셔라는 이름은 우연의 일치였는지도 모릅니다. 이번 피해자의 이름이 무엇이든 또 가게를 가진 노파일지도 모르지요. 알겠습니까?\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/139       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/138       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/137       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/136       \n",
            "Negative tokens: ['어떤' '예정된' '있겠습니까?”' '“힌트가' '“예정된' '가능성으로' '그러나' '애셔라는']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 137/138       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 136/137       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 135/136       \n",
            "Peak count: 8\n",
            "Frame tokens: 어떤 우리가 ” 말했다. 생각일 겁니다. 모릅니다. 알겠습니까? \n",
            "\n",
            "Similarity : 0.463486519064498\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.495910882949829 Generator / grammar loss:-0.21984577178955078   similarity loss:-0.1691991537809372\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "그 어떤 쪽을 정직하고 우리가 돌려졌다. ” 말했다. “그것은 생각일 ” 박사가 “알파벡 “나는 그 이상은 떠오른 겁니다. 장소를 정해지리라는 우연의 모릅니다. 이름이 알겠습니까?\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.167785  0.272601  0.513776  0.465137  0.010845  0.450949   \n",
            "\n",
            "    grammar  \n",
            "0  0.970015  \n",
            "Current result ==================================================\n",
            "Sample count: 65\n",
            "     method  comp rate     intro      body  conclusion   isthmus  simlirality  \\\n",
            "0  SAM+WGAN   0.171977  0.534839  0.514247    0.525466  0.005508     0.521731   \n",
            "\n",
            "   grammarity  \n",
            "0    0.968911  \n",
            "==================================================\n",
            "66 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "우리는 한 미치광이를 상대하고 있습니다. 상대는 동기에 대한 실마리를 아무것도 나타내 보이고 있지 않습니다. ” 카터 경감이 의심스러운 듯 물었다. “미치광이에게도 동기가 있을까요?” “물론 있습니다. 편집광의 특징 가운데 하나는 아주 논리적이라는 겁니다. 그는 자신이 목사, 의사 도는 담배 가게 노파라도 좋은데, 이들을 죽이게끔 신에 의해 정해져 있다고 믿지요. 그 배후에는 하나같이 어떤 완전하고도 타당한 이유가 있는 법입니다. 그러니 우리는 알파벳 같은 것에 정신을 팔면 안 됩니다. 앤도버 다음이 벡스힐인 것은 아마 우연의 일치에 지나지 않을 겁니다. ” “우리는 적어도 그 경계만은 할 수 있는 셈이네, 카터. 특히 조그만 가게의 B로 시작되는 이름에 주의하여, 혼자서 경영하는 조그만 담배 가게라든가 신문 가게를 지키게. 그 밖에는 달리 우리가 할 수 있는 일이 없어. 낯선 사람을 특히 주의해야 할 것은 물론이지만. ” 카터 경감은 신음 소리를 냈다. “학교의 방학이 시작되었는데 말입니까? 이번 주일에는 그곳으로 굉장한 인파가 몰릴 겁니다. ” 경찰서장이 날카롭게 말했다. “우리는 할 수 있는 건 다 해야만 되네. ” 이번에는 글렌 형사가 말했다. “애셔 사건에 관계있는 사람은 제가 지키지요.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/158       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/157       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/156       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/155       \n",
            "Negative tokens: ['편집광의' '이들을' '앤도버' '우연의' '셈이네,' '주의하여,' '그' '특히' '이번' '해야만']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 156/157       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 155/156       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 154/155       \n",
            "Peak count: 8\n",
            "Frame tokens: 있습니다. “미치광이에게도 겁니다. 믿지요. 법입니다. “우리는 “애셔 지키지요. \n",
            "\n",
            "Similarity : 0.41739711039546346\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.5273256301879883 Generator / grammar loss:-0.16648544371128082   similarity loss:-0.11247728019952774\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "상대하고 실마리를 나타내 물었다. 의사 좋은데, 정해져 믿지요. 그 타당한 이유가 있는 법입니다. 그러니 알파벳 것에 팔면 됩니다. 담배 카터 “우리는 할 “애셔 지키지요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.154341  0.332685  0.434441  0.357114  0.001881  0.390892   \n",
            "\n",
            "    grammar  \n",
            "0  0.984078  \n",
            "Current result ==================================================\n",
            "Sample count: 66\n",
            "     method  comp rate     intro      body  conclusion   isthmus  simlirality  \\\n",
            "0  SAM+WGAN    0.17171  0.531776  0.513038    0.522915  0.005453     0.519748   \n",
            "\n",
            "   grammarity  \n",
            "0    0.969141  \n",
            "==================================================\n",
            "67 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "패트리지와 리딜 두 증인과 물론 애셔도. 그들이 앤도버를 떠나면 미행시키겠습니다. ” 그리고 나서 두세 가지 제안과 얼마쯤 산만한 대화가 오간 뒤 회의는 끝났다. 나는 강을 따라 걸으며 말했다. “포아로, 이 범죄를 예방할 수 있을까?” 그는 야윈 얼굴을 내 쪽으로 돌렸다. “한 사람의 광기에 대해, 이렇게 사람 들끊는 정상적인 거리에서? 나는 걱정일세, 헤이스팅즈. 아주 걱정이네. 살인광 잭의 그 오래 계속된 성공을 기억하고 있겠지!” “무서운 일이군. ” “헤이스팅즈, 광기란 무서운 거라네. 나는 걱정일세. 아주 걱정이야. ” < 벡스힐 바닷가 살인 > 나는 지금도 7월 25일 아침, 잠에서 깨어난 무렵의 일을 기억하고 있다. 그것은 아마 7시 30분쯤이었다고 생각된다. 포아로가 침대 옆에 서서 가만히 내 어깨를 흔들고 있었다. 그의 얼굴을 한 번 보자 나는 곧 반쯤 잠든 상태에서 눈을 떴다. 나는 얼른 일어나면서 물었다. “무슨 일인가?” 그는 아주 간단하게 대답했지만, 그의 짧은 말 속에는 풍부한 감동이 담겨 있었다. “일어났네. ” 나는 소리쳤다.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/139       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/138       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/137       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/136       \n",
            "Negative tokens: ['산만한' '걱정일세,' '무렵의' '얼른' '대답했지만,']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 137/138       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 136/137       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 135/136       \n",
            "Peak count: 8\n",
            "Frame tokens: 그들이 미행시키겠습니다. 걱정이네. “무서운 걱정일세. 일어나면서 “일어났네. 소리쳤다. \n",
            "\n",
            "Similarity : 0.5651068921688067\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.468736410140991 Generator / grammar loss:-0.2224803864955902   similarity loss:-0.17471908032894135\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "두 물론 그들이 떠나면 미행시키겠습니다. 두세 헤이스팅즈. 걱정이네. 잭의 “무서운 광기란 걱정일세. 나는 아침, 기억하고 서서 곧 얼른 일어나면서 물었다. 일인가?” 대답했지만, “일어났네. 소리쳤다.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN    0.208487  0.477422  0.670586  0.649873  0.007498  0.625739   \n",
            "\n",
            "    grammar  \n",
            "0  0.982723  \n",
            "Current result ==================================================\n",
            "Sample count: 67\n",
            "     method  comp rate     intro      body  conclusion   isthmus  simlirality  \\\n",
            "0  SAM+WGAN   0.172259  0.530964  0.515389     0.52481  0.005484      0.52133   \n",
            "\n",
            "   grammarity  \n",
            "0    0.969343  \n",
            "==================================================\n",
            "68 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "“뭐라고? 하지만 오늘은 25일이잖나. ” “어젯밤. 아니, 오늘 아침 일찍 일어났네. ” 내가 침대에서 튀어 일어나 재빨리 옷을 입자 그는 지금 막 전화로 들은 이야기를 간간히 들려주었다. “젊은 여자의 시체가 벡스힐 바닷가에서 발견됐네. 그녀는 일리저버스 버너드(Barnard)라는 이름의 카페 여급사로 밝혀졌네. 이 아가씨는 최근 갓 지은 조그만 방갈로에서 부모와 함께 살고 있었지. 검시 결과에 의하면 12시에서 새벽 1시 사이에 살해된 모양일세. ” 나는 면도를 하며 물었다. “그러나 이것이 그 범죄라는 건 확실한가?” “벡스힐 행 기차 시간표가 있는 데가 펼쳐진 ABC 철도 안내서가 시체 밑에서 나왔네. ” 나는 손이 떨렸다. “무서운 이야기로군. ” “조심하게, 헤이스팅즈. 내 방에서 또 하나의 사건이 일어나면 참을 수 없으니까. ” 나는 얼마쯤 맥이 풀려 턱의 피를 닦았다. 그리고 물었다. “우리들의 전투 계획은?” “이제 곧 경찰차가 우리를 데리러 오게 되어 있네. 자네 커피는 이리로 가져오도록 시켰네. 출발을 늦출 수 없으니까.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/133       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/132       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/131       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/130       \n",
            "Negative tokens: ['막' '이' '최근' '일어나면' '“이제']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 131/132       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 130/131       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 129/130       \n",
            "Peak count: 7\n",
            "Frame tokens: ” 일어났네. 이 “그러나 헤이스팅즈. 물었다. 없으니까. \n",
            "\n",
            "Similarity : 0.3866438649937426\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.6891236305236816 Generator / grammar loss:-0.20159755647182465   similarity loss:-0.12974561750888824\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "25일이잖나. ” 아침 일어났네. ” 여급사로 밝혀졌네. 이 아가씨는 모양일세. 물었다. “그러나 건 기차 이야기로군. 헤이스팅즈. 그리고 물었다. 곧 오게 없으니까.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var    total  \\\n",
            "0  SAM+WGAN    0.174157  0.777859  0.487127  0.435648  0.022698  0.52983   \n",
            "\n",
            "    grammar  \n",
            "0  0.983995  \n",
            "Current result ==================================================\n",
            "Sample count: 68\n",
            "     method  comp rate     intro      body  conclusion   isthmus  simlirality  \\\n",
            "0  SAM+WGAN   0.172287  0.534595  0.514973    0.523499  0.005737     0.521455   \n",
            "\n",
            "   grammarity  \n",
            "0    0.969559  \n",
            "==================================================\n",
            "69 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "” 20분 뒤 우리는 속력 빠른 경찰차를 타고 템즈 강을 건너 런던을 벗어났다. 경찰차에는 크롬 형사가 함께 타고 있었다. 지난번 회의에 참석했었던 이 사건 담당 형사였다. 크롬 형사는 재프 경감과는 다른 타입의 경관이었다. 훨씬 젊고 말수가 적은 남자였다. 교양과 지식을 지녔으나, 내 기호로 말하면 얼마쯤 자기만족에 빠져있는 듯했다. 그는 최근에 있었던 일련의 어린이 살해 사건으로, 지금 브로드무어에 들어가 있는 범인을 끈질기게 추적해 이름을 떨친 참이었다. 그는 분명 이번 사건을 맡는 데 알맞은 인물이었으나, 그것을 그 자신이 지나치게 의식하고 있는 듯 생각되었다. 포아로를 대하는 그의 태도에는 좀 잘난 체하는 데가 있고, 얼마쯤 자의식적인 공립학교 식 방법으로 젊은 사람이 연장자를 대하는 것같이 그에게 복종하고 있었다. 그가 말했다. “저는 솜프슨 박사와 많은 이야기를 했습니다. 그분은 연속 살인 사건에 아주 흥미를 갖고 계시지요. 그것은 특수하게 비틀린 심성의 산물입니다. 물론 비전문가로서는 그가 의학적 견지에 대해 보이는 세부적인 점은 이해할 수 없지요. ” 그는 헛기침을 했다. “사실 저의 지난번 사건으로 말하면, 그 기사를 읽으셨는지 모르겠습니다만, 머스윌 힐 여학교 학생 메이벌 호머 사건 말입니다. 그 캐퍼라는 사나이는 무서운 녀석이었습니다. 그 범죄를 그의 짓이라고 밝혀내기까지 참으로 힘이 들었습니다. 아무튼 세 사람째였으니 말입니다. 아주 멀쩡해 보였지요.\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/178       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/177       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/176       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/175       \n",
            "Negative tokens: ['형사가' '교양과' '그는' '범인을' '인물이었으나,' '잘난' '자의식적인' '것같이' '많은' '그분은' '흥미를'\n",
            " '“사실' '사건으로' '그' '밝혀내기까지']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 176/177       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 175/176       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 174/175       \n",
            "Peak count: 9\n",
            "Frame tokens: 경관이었다. 남자였다. 자기만족에 참이었다. 자신이 있었다. 산물입니다. 그 보였지요. \n",
            "\n",
            "Similarity : 0.43295154619372567\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:2.579594135284424 Generator / grammar loss:-0.18990348279476166   similarity loss:-0.1302345246076584\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "경관이었다. 젊고 적은 남자였다. 자기만족에 추적해 떨친 참이었다. 인물이었으나, 자신이 있는 그의 식 있었다. 솜프슨 산물입니다. 저의 힐 학생 호머 캐퍼라는 그 참으로 아무튼 말입니다. 멀쩡해 보였지요.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending     var     total  \\\n",
            "0  SAM+WGAN    0.159059  0.384698  0.541563  0.634145  0.0106  0.537965   \n",
            "\n",
            "    grammar  \n",
            "0  0.977274  \n",
            "Current result ==================================================\n",
            "Sample count: 69\n",
            "     method  comp rate     intro      body  conclusion   isthmus  simlirality  \\\n",
            "0  SAM+WGAN   0.172095  0.532423  0.515359    0.525102  0.005808     0.521695   \n",
            "\n",
            "   grammarity  \n",
            "0    0.969671  \n",
            "==================================================\n",
            "70 / 70\n",
            "==================================================\n",
            "------------------------------------------------------------------\n",
            "하지만 여러 가지 테스트라는 게 있잖습니까. 아시겠지요, 유도심문이라는 것을. 물론 아주 새로운 것이어서 전에는 별로 문제되지 않았던 겁니다. 한 번 잡아들이면 이미 문제없습니다!이쪽이 알고 있다는 걸 알게 되면 상대방은 그만 손을 들지요. 상대는 완전히 이쪽이 하는 대로 따라옵니다. ” 포아로가 말했다. “우리 때에도 그런 일은 흔히 있었지요. ” 크롬 형사는 그를 돌아보고 대화를 계속하는 것처럼 입속으로 말했다. “아, 그렇습니까?” 잠시 침묵이 이어졌다. 뉴크로스 역을 지났을 즈음 크롬이 말했다. “이 사건에 대해 무언가 들어주고 싶은 게 있으시면 말씀하십시오. ” “그럼, 죽은 아가씨에 대해 이야기해 주겠소?” “그녀는 23살로 카페 <진저 캣>의 여급사로 일하고 있었습니다. ” “아니, 그런 점이 아니라, 이를테면 그녀는 아름다웠다든가……. ” 크롬 형사는 당할 수 없다는 투로 말했다. “그런 일에 대해서는 전혀 들은 게 없습니다. ” 그의 몸짓은 이렇게 말하고 있었다. 이거 정말, 외국인이란 모두 이렇다니까! 포아로의 눈에 재미있어 하는 빛이 슬며시 떠올랐다. “그런 사실이 당신에게는 중요하게 보이지 않소?\n",
            "------------------------------------------------------------------\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0] 1/140       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/139       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/138       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/137       \n",
            "Negative tokens: ['하는' '”' '“그런' '”' '“그런']\n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 138/139       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 137/138       \n",
            "Frame token scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 136/137       \n",
            "Peak count: 8\n",
            "Frame tokens: 한 말했다. “아, “이 ” 있었다. 포아로의 않소? \n",
            "\n",
            "Similarity : 0.4661321572977345\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, beta:1.9548474550247192 Generator / grammar loss:-0.13163864612579346   similarity loss:-0.1361546516418457\n",
            "--------------------------------------------------\n",
            "gold summary:\n",
            "\n",
            "--------------------------------------------------\n",
            "sam_wgan summary:\n",
            "테스트라는 게 한 알게 되면 상대방은 손을 완전히 따라옵니다. ” 말했다. 있었지요. “아, “이 대해 대해 아름다웠다든가……. 당할 수 없습니다. 정말, 포아로의 눈에 떠올랐다.\n",
            "--------------------------------------------------\n",
            "     method  comp ratio     intro      body    ending       var     total  \\\n",
            "0  SAM+WGAN     0.17301  0.492511  0.531212  0.578031  0.001223  0.537518   \n",
            "\n",
            "    grammar  \n",
            "0  0.970171  \n",
            "Current result ==================================================\n",
            "Sample count: 70\n",
            "     method  comp rate     intro      body  conclusion   isthmus  simlirality  \\\n",
            "0  SAM+WGAN   0.172108  0.531853  0.515585    0.525859  0.005742     0.521921   \n",
            "\n",
            "   grammarity  \n",
            "0    0.969678  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>method</th>\n",
              "      <th>comp rate</th>\n",
              "      <th>intro</th>\n",
              "      <th>body</th>\n",
              "      <th>conclusion</th>\n",
              "      <th>isthmus</th>\n",
              "      <th>simlirality</th>\n",
              "      <th>grammarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SAM+WGAN</td>\n",
              "      <td>0.172108</td>\n",
              "      <td>0.531853</td>\n",
              "      <td>0.515585</td>\n",
              "      <td>0.525859</td>\n",
              "      <td>0.005742</td>\n",
              "      <td>0.521921</td>\n",
              "      <td>0.969678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     method  comp rate     intro      body  conclusion   isthmus  simlirality  \\\n",
              "0  SAM+WGAN   0.172108  0.531853  0.515585    0.525859  0.005742     0.521921   \n",
              "\n",
              "   grammarity  \n",
              "0    0.969678  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9Rgq4SHvqOD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}