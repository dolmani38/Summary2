{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMkDw38IjpSdc8n4CDZaCTO",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0340ab796cd44bf3a87e90e067e795d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c32b2b99d6f54c1ebc8181f81e6460c8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ea9b5bb23e5449229a51f279455bef05",
              "IPY_MODEL_6e9d1fbd1dd54801b066c1af65c48c4d",
              "IPY_MODEL_20d1a76279b94f5d9eefd795171495d7"
            ]
          }
        },
        "c32b2b99d6f54c1ebc8181f81e6460c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ea9b5bb23e5449229a51f279455bef05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b23428589509409ea72ceb48b2bd52fa",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_610b9fe7151249368d36421b4c557fbc"
          }
        },
        "6e9d1fbd1dd54801b066c1af65c48c4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a2b908a235bc4ca688d4d1dd0539fa8f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 344259,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 344259,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_903d000a6fb64c35943c151f314aefa0"
          }
        },
        "20d1a76279b94f5d9eefd795171495d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1f53a74d9270471c8be3fa1d021476cb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 344k/344k [00:00&lt;00:00, 1.38MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_67599893a8d447f78ae8576f265b3d3d"
          }
        },
        "b23428589509409ea72ceb48b2bd52fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "610b9fe7151249368d36421b4c557fbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a2b908a235bc4ca688d4d1dd0539fa8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "903d000a6fb64c35943c151f314aefa0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1f53a74d9270471c8be3fa1d021476cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "67599893a8d447f78ae8576f265b3d3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bb0697f86df247a68ee9d253f522822d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b96a5b0e971745d0800016caaaed0e04",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_759213c2699d492aa50589eb9f494983",
              "IPY_MODEL_ce298454187143c7bc7a5633a8baf4a5",
              "IPY_MODEL_d826fdd40de342c3b22a273649445471"
            ]
          }
        },
        "b96a5b0e971745d0800016caaaed0e04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "759213c2699d492aa50589eb9f494983": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ce68aa6e70e84f10b4de859f45787daf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a53b6afdb15148cda29e4d5ba428f8d2"
          }
        },
        "ce298454187143c7bc7a5633a8baf4a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c6feb8f994154176bfbb5d616f4a1b4a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 80,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 80,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8000f3719f1742b4b8b4e0385cd9e78a"
          }
        },
        "d826fdd40de342c3b22a273649445471": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_817620cb9c9e4fb9b66fd31326dce827",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 80.0/80.0 [00:00&lt;00:00, 3.21kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_490ee69e61ad4db19be904835207f28e"
          }
        },
        "ce68aa6e70e84f10b4de859f45787daf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a53b6afdb15148cda29e4d5ba428f8d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c6feb8f994154176bfbb5d616f4a1b4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8000f3719f1742b4b8b4e0385cd9e78a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "817620cb9c9e4fb9b66fd31326dce827": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "490ee69e61ad4db19be904835207f28e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "71b013dd0b6b498db2828cbd8b004bf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5540254fd6f847ffbbd92c8c6b332bde",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d77fb501b03642b9ba02d4e36041c630",
              "IPY_MODEL_4139ac3d3a164c20a1df8bd45513125c",
              "IPY_MODEL_b0cd1144a0ad4dafa4b3ca5e185dcac1"
            ]
          }
        },
        "5540254fd6f847ffbbd92c8c6b332bde": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d77fb501b03642b9ba02d4e36041c630": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_759843dd9c0d41299964360ade71a81f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_683df7599027436796046e97fa2a3401"
          }
        },
        "4139ac3d3a164c20a1df8bd45513125c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b72def4524e04f64a90d5549842d38cc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 725,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 725,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cd46a8a3314d40faa534dac2f1d365dc"
          }
        },
        "b0cd1144a0ad4dafa4b3ca5e185dcac1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_83a1dfb60de04456a8aefde764a47adc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 725/725 [00:00&lt;00:00, 31.8kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e19be3228a204ce5948e05f7c17970fd"
          }
        },
        "759843dd9c0d41299964360ade71a81f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "683df7599027436796046e97fa2a3401": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b72def4524e04f64a90d5549842d38cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cd46a8a3314d40faa534dac2f1d365dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "83a1dfb60de04456a8aefde764a47adc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e19be3228a204ce5948e05f7c17970fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c4267915b6404b8fb3e56c31bd9711fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_950ef53b2968454b8dfbedeb1112da6c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_81ab4ec33baf425f84fd341bd14087ad",
              "IPY_MODEL_7f7cdf5cda774887bd4c86d2fbecb65d",
              "IPY_MODEL_125a15c68f6a4a32a6661d2aa8b0310c"
            ]
          }
        },
        "950ef53b2968454b8dfbedeb1112da6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "81ab4ec33baf425f84fd341bd14087ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_aaa7a515147e4e76be3303fc8c304f4c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_272e8cd0cae1495abb76d4dd9a3a5f15"
          }
        },
        "7f7cdf5cda774887bd4c86d2fbecb65d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e4f72dcfa3644688a645b2fecc939626",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 475782997,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 475782997,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a64bc891b8614356bb63d01a25b0af08"
          }
        },
        "125a15c68f6a4a32a6661d2aa8b0310c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0c3be9f669124a7cbd1e1359edbc9f28",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 476M/476M [00:08&lt;00:00, 48.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0c2e39e7a6ba4423bdae9f1b28485bc3"
          }
        },
        "aaa7a515147e4e76be3303fc8c304f4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "272e8cd0cae1495abb76d4dd9a3a5f15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e4f72dcfa3644688a645b2fecc939626": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a64bc891b8614356bb63d01a25b0af08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0c3be9f669124a7cbd1e1359edbc9f28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0c2e39e7a6ba4423bdae9f1b28485bc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dolmani38/Summary2/blob/main/sentence_complete_0913.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdbEdzqr9ziR"
      },
      "source": [
        "# 불완전 문장(일부 토큰이 빠진)을 완성형 문장으로 교정하는 Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGdhwDQh9vDQ",
        "outputId": "6f721bdb-42d3-4fb7-e6f6-2ad9ae38d4e8"
      },
      "source": [
        "if True:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "id2bSKAD-R-I",
        "outputId": "29f4de61-41ac-4dcd-d7eb-875cb4cac5eb"
      },
      "source": [
        "!pip3 install transformers\n",
        "!pip3 install sentence-transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.10.2-py3-none-any.whl (2.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8 MB 9.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 66.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting huggingface-hub>=0.0.12\n",
            "  Downloading huggingface_hub-0.0.16-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 7.7 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 80.0 MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 69.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: tokenizers, sacremoses, pyyaml, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.0.16 pyyaml-5.4.1 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.10.2\n",
            "Collecting sentence-transformers\n",
            "  Downloading sentence-transformers-2.0.0.tar.gz (85 kB)\n",
            "\u001b[K     |████████████████████████████████| 85 kB 3.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.10.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.62.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.9.0+cu102)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.10.0+cu102)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.2.5)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 17.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.0.16)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers) (3.7.4.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (21.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (5.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.12)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.0.45)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.10.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (4.6.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2019.12.20)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2021.5.30)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.0.1)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers) (7.1.2)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.0.0-py3-none-any.whl size=126710 sha256=ca1b64067dce9942aa6052e57b6a176dba54dca2d272b67e197a87c3ef5819e1\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/c1/0f/faafd427f705c4b012274ba60d9a91d75830306811e1355293\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: sentencepiece, sentence-transformers\n",
            "Successfully installed sentence-transformers-2.0.0 sentencepiece-0.1.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qpqhqts_-VLx",
        "outputId": "e73eab77-599d-4738-f120-9884f6cf1fb8"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# set seeds for reproducability\n",
        "from numpy.random import seed\n",
        "#seed(1)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string, os \n",
        "\n",
        "import urllib.request\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYMCJtNd-Xvg",
        "outputId": "62ae5f2f-c5f6-472b-9e7a-890f46c175ab"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-xyCNNS-bJx"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDtXh1PW-B2n"
      },
      "source": [
        "## data 준비"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVQb1Dsk-NRg"
      },
      "source": [
        "import json  \n",
        "import zipfile  \n",
        "\n",
        "data_1 = None  \n",
        "data = None  \n",
        "with zipfile.ZipFile(\"/content/drive/MyDrive/Colab Notebooks/summary/data/사설잡지_2.train_original.json.zip\", \"r\") as z:\n",
        "    with z.open('train_original.json') as f:  \n",
        "        data = f.read()  \n",
        "        data_1 = json.loads(data.decode(\"utf-8\"))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q17bbZS8-nwk"
      },
      "source": [
        "data_2 = None  \n",
        "data = None  \n",
        "with zipfile.ZipFile(\"/content/drive/MyDrive/Colab Notebooks/summary/data/신문기사_2.train_original.json.zip\", \"r\") as z:\n",
        "    with z.open('train_original.json') as f:  \n",
        "        data = f.read()  \n",
        "        data_2 = json.loads(data.decode(\"utf-8\"))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "3sH_A9Lv-wHO",
        "outputId": "47621f4c-c01d-4e94-854d-e372fcdcb90b"
      },
      "source": [
        "' '.join(data_2[1]['article_original'])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'서산시의회(의장 임재관) 가충순·이수의 의원이 (사)한국지역신문협회에서 수여하는 우수의정대상을 받았다. 가충순 의원과 이수의 의원은 16일 팔봉면 폰타나 리조트에서 열린 한국지역신문협회 하계 워크샵에서 지역사회 발전을 위해 활발한 의정활동을 펼친 공로를 인정받아 우수의정대상을 수상했다. 지난해 6월 제7회 전국동시지방선거를 통해 등원한 두 의원은 산업건설위원회에서 열정적인 의정활동을 펼치고 있다. 가충순 의원은 5분발언, 행정사무감사, 시정질문을 통해 자동차 연비테스트 연구시설 유치, 천수만 염해피해 재발 방지, 서산시 대표 농산물 육성 등 지역의 크고 작은 문제를 개선하기 위해 노력하고 있다. 이수의 의원은 지난 행정사무감사에서 대산공단 기업 임원을 참고인으로 출석시켜 지역인재채용 및 관내업체·자재 활용을 확대할 것을 제안하며 기존 행정사무감사의 틀을 깨는 등 다양한 의정활동을 펼쳐나가고 있다. 가충순 의원은 \"시의원이라면 마땅히 해야할 일을 한 것 뿐인데 상까지 주시니 몸 둘 바를 모르겠다\"며 \"항상 초심을 잊지 않고 지역 발전을 위해 최선을 다하겠다\"고 소감을 밝혔다. 이수의 의원은 \"믿고 뽑아주신 주민들을 위해 당연히 해야할 일을 했을 뿐인데 상까지 받게 돼 영광\"이라며 \"시민들이 자부심을 느낄 수 있는 지역사회를 만들어 나가기 위해 앞으로도 최선을 다 하겠다\"고 말했다.'"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6lDYyhM-2K1"
      },
      "source": [
        "sentences = []\n",
        "for i in range(len(data_2)):\n",
        "    for txt in data_2[i]['article_original']:\n",
        "        #if len(txt) < 50:\n",
        "        sentences.append(txt)\n",
        "for i in range(len(data_1)):\n",
        "    for txt in data_1[i]['article_original']:\n",
        "        #if len(txt) < 50:\n",
        "        sentences.append(txt)        "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRv4jTXh_HsP",
        "outputId": "ef20daca-0132-46fb-88d9-befaf1cbf9de"
      },
      "source": [
        "len(sentences)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4407160"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZwbiFZsFEEA"
      },
      "source": [
        "## 문법 Scoring 모델"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meEhlpD0FMmK"
      },
      "source": [
        "from transformers import BertTokenizer, BertTokenizerFast,AutoTokenizer, BertForSequenceClassification, AdamW, BertConfig, get_linear_schedule_with_warmup\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset, random_split\n",
        "\n",
        "import time\n",
        "import random\n",
        "import datetime\n",
        "\n",
        "# 간단한 전처리\n",
        "def clean_text(txt):\n",
        "    txt = txt.replace('\\n',' ')\n",
        "    txt = txt.replace('\\r',' ')    \n",
        "    txt = txt.replace('=','')\n",
        "    txt = txt.replace('\\\"','')   \n",
        "    txt = txt.replace('\\'','')\n",
        "    #txt = txt.replace(',','')\n",
        "    txt = txt.replace('..','')\n",
        "    txt = txt.replace('...','')\n",
        "    txt = txt.replace(' .','.')\n",
        "    txt = txt.replace('.','. ')\n",
        "    txt = txt.replace('  ',' ')\n",
        "    txt = txt.replace('  ',' ')    \n",
        "    txt = txt.replace('  ',' ')   \n",
        "    txt = txt.replace('  ',' ')           \n",
        "    txt = txt.replace('  ',' ')\n",
        "    txt = txt.replace('  ',' ')    \n",
        "    txt = txt.replace('  ',' ')   \n",
        "    txt = txt.replace('  ',' ')             \n",
        "    return txt.strip()\n",
        "\n",
        "def shuffling(txt):\n",
        "    txt_list = txt.split(' ')\n",
        "    random.shuffle(txt_list)\n",
        "    return ' '.join(txt_list)\n",
        "\n",
        "def collect_training_dataset_for_grammar_discriminator(sentences_dataset):\n",
        "\n",
        "    sentences = []\n",
        "    labels = []\n",
        "\n",
        "    for txtss in sentences_dataset:\n",
        "        txtss = clean_text(txtss)\n",
        "        txts = txtss.strip().split('.')\n",
        "        for txt in txts:  \n",
        "            txt = txt.strip()\n",
        "            if len(txt) > 10:\n",
        "                #ko_grammar_dataset.append([txt,1])\n",
        "                txt = txt.replace('.','')\n",
        "                tf = random.choice([True,False])\n",
        "                # 정상 또는 비정상 둘중에 하나만 데이터셋에 추가\n",
        "                if (tf):\n",
        "                    sentences.append(txt) # '.'의 위치를 보고 True, False를 판단 하기 땜에...\n",
        "                    labels.append(1)\n",
        "                else:\n",
        "                    sentences.append(shuffling(txt))\n",
        "                    labels.append(0)\n",
        "\n",
        "    return sentences,labels\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
        "\n",
        "class Grammar_Discriminator:\n",
        "\n",
        "\n",
        "    def __init__(self, pretraoned_kobert_model_name='kykim/bert-kor-base', input_dir=None):\n",
        "\n",
        "        if input_dir is None:\n",
        "            self.tokenizer = BertTokenizerFast.from_pretrained(pretraoned_kobert_model_name)\n",
        "            self.discriminator = BertForSequenceClassification.from_pretrained(\n",
        "                                    pretraoned_kobert_model_name, # Use the 12-layer BERT model, with an uncased vocab.\n",
        "                                    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                                                    # You can increase this for multi-class tasks.   \n",
        "                                    output_attentions = False, # Whether the model returns attentions weights.\n",
        "                                    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        "                                )            \n",
        "        else:\n",
        "            self.__load_model(input_dir)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def set_dataset(self, sentences,labels):\n",
        "        # Print the original sentence.\n",
        "        print(' Original: ', sentences[0])\n",
        "\n",
        "        # Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "        input_ids = []\n",
        "        attention_masks = []\n",
        "\n",
        "        # For every sentence...\n",
        "        for sent in sentences:\n",
        "            # `encode_plus` will:\n",
        "            #   (1) Tokenize the sentence.\n",
        "            #   (2) Prepend the `[CLS]` token to the start.\n",
        "            #   (3) Append the `[SEP]` token to the end.\n",
        "            #   (4) Map tokens to their IDs.\n",
        "            #   (5) Pad or truncate the sentence to `max_length`\n",
        "            #   (6) Create attention masks for [PAD] tokens.\n",
        "            encoded_dict = self.tokenizer.encode_plus(\n",
        "                                sent,                      # Sentence to encode.\n",
        "                                add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                                max_length = 64,           # Pad & truncate all sentences.\n",
        "                                pad_to_max_length = True,\n",
        "                                return_attention_mask = True,   # Construct attn. masks.\n",
        "                                return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                                truncation = True,\n",
        "                        )\n",
        "            \n",
        "            # Add the encoded sentence to the list.    \n",
        "            input_ids.append(encoded_dict['input_ids'])\n",
        "            \n",
        "            # And its attention mask (simply differentiates padding from non-padding).\n",
        "            attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "        # Convert the lists into tensors.\n",
        "        input_ids = torch.cat(input_ids, dim=0)\n",
        "        attention_masks = torch.cat(attention_masks, dim=0)\n",
        "        labels = torch.tensor(labels)\n",
        "\n",
        "        # Print sentence 0, now as a list of IDs.\n",
        "        print('Original: ', sentences[0])\n",
        "        print('Token IDs:', input_ids[0])\n",
        "\n",
        "        # Training & Validation Split\n",
        "        # Divide up our training set to use 90% for training and 10% for validation.\n",
        "\n",
        "        # Combine the training inputs into a TensorDataset.\n",
        "        dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "        # Create a 90-10 train-validation split.\n",
        "\n",
        "        # Calculate the number of samples to include in each set.\n",
        "        train_size = int(0.9 * len(dataset))\n",
        "        val_size = len(dataset) - train_size\n",
        "\n",
        "        # Divide the dataset by randomly selecting samples.\n",
        "        train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "        print('{:>5,} training samples'.format(train_size))\n",
        "        print('{:>5,} validation samples'.format(val_size))\n",
        "\n",
        "        # The DataLoader needs to know our batch size for training, so we specify it \n",
        "        # here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "        # size of 16 or 32.\n",
        "        self.batch_size = 32\n",
        "\n",
        "        # Create the DataLoaders for our training and validation sets.\n",
        "        # We'll take training samples in random order. \n",
        "        self.train_dataloader = DataLoader(\n",
        "                    train_dataset,  # The training samples.\n",
        "                    sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "                    batch_size = self.batch_size # Trains with this batch size.\n",
        "                )\n",
        "\n",
        "        # For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "        self.validation_dataloader = DataLoader(\n",
        "                    val_dataset, # The validation samples.\n",
        "                    sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "                    batch_size = self.batch_size # Evaluate with this batch size.\n",
        "                )        \n",
        "\n",
        "\n",
        "\n",
        "    def train(self,epochs=4):\n",
        "        # Tell pytorch to run this model on the GPU.\n",
        "        self.discriminator.cuda()\n",
        "\n",
        "        # Get all of the model's parameters as a list of tuples.\n",
        "        params = list(self.discriminator.named_parameters())\n",
        "\n",
        "        print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "        print('==== Embedding Layer ====\\n')\n",
        "\n",
        "        for p in params[0:5]:\n",
        "            print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "        print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "        for p in params[5:21]:\n",
        "            print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "        print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "        for p in params[-4:]:\n",
        "            print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))  \n",
        "\n",
        "        # Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "        # I believe the 'W' stands for 'Weight Decay fix\"\n",
        "        self.optimizer = AdamW(self.discriminator.parameters(),\n",
        "                        lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                        eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                        )\n",
        "\n",
        "        # Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "        # We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "        # training data.\n",
        "        #epochs = 2\n",
        "\n",
        "        # Total number of training steps is [number of batches] x [number of epochs]. \n",
        "        # (Note that this is not the same as the number of training samples).\n",
        "        total_steps = len(self.train_dataloader) * epochs\n",
        "\n",
        "        # Create the learning rate scheduler.\n",
        "        scheduler = get_linear_schedule_with_warmup(self.optimizer, \n",
        "                                                    num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                                    num_training_steps = total_steps)\n",
        "            \n",
        "        # This training code is based on the `run_glue.py` script here:\n",
        "        # https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "        # Set the seed value all over the place to make this reproducible.\n",
        "        seed_val = 42\n",
        "\n",
        "        random.seed(seed_val)\n",
        "        np.random.seed(seed_val)\n",
        "        torch.manual_seed(seed_val)\n",
        "        torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "        # We'll store a number of quantities such as training and validation loss, \n",
        "        # validation accuracy, and timings.\n",
        "        training_stats = []\n",
        "\n",
        "        # Measure the total training time for the whole run.\n",
        "        total_t0 = time.time()\n",
        "\n",
        "        # For each epoch...\n",
        "        for epoch_i in range(0, epochs):\n",
        "            \n",
        "            # ========================================\n",
        "            #               Training\n",
        "            # ========================================\n",
        "            \n",
        "            # Perform one full pass over the training set.\n",
        "\n",
        "            print(\"\")\n",
        "            print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "            print('Training...')\n",
        "\n",
        "            # Measure how long the training epoch takes.\n",
        "            t0 = time.time()\n",
        "\n",
        "            # Reset the total loss for this epoch.\n",
        "            total_train_loss = 0\n",
        "\n",
        "            # Put the model into training mode. Don't be mislead--the call to \n",
        "            # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "            # `dropout` and `batchnorm` layers behave differently during training\n",
        "            # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "            self.discriminator.train()\n",
        "\n",
        "            # For each batch of training data...\n",
        "            for step, batch in enumerate(self.train_dataloader):\n",
        "\n",
        "                # Progress update every 40 batches.\n",
        "                if step % 40 == 0 and not step == 0:\n",
        "                    # Calculate elapsed time in minutes.\n",
        "                    elapsed = format_time(time.time() - t0)\n",
        "                    \n",
        "                    # Report progress.\n",
        "                    print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(self.train_dataloader), elapsed))\n",
        "\n",
        "                # Unpack this training batch from our dataloader. \n",
        "                #\n",
        "                # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "                # `to` method.\n",
        "                #\n",
        "                # `batch` contains three pytorch tensors:\n",
        "                #   [0]: input ids \n",
        "                #   [1]: attention masks\n",
        "                #   [2]: labels \n",
        "                b_input_ids = batch[0].to(device)\n",
        "                b_input_mask = batch[1].to(device)\n",
        "                b_labels = batch[2].to(device)\n",
        "\n",
        "                # Always clear any previously calculated gradients before performing a\n",
        "                # backward pass. PyTorch doesn't do this automatically because \n",
        "                # accumulating the gradients is \"convenient while training RNNs\". \n",
        "                # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "                self.discriminator.zero_grad()        \n",
        "\n",
        "                # Perform a forward pass (evaluate the model on this training batch).\n",
        "                # The documentation for this `model` function is here: \n",
        "                # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "                # It returns different numbers of parameters depending on what arguments\n",
        "                # arge given and what flags are set. For our useage here, it returns\n",
        "                # the loss (because we provided labels) and the \"logits\"--the model\n",
        "                # outputs prior to activation.\n",
        "                outputs = self.discriminator(b_input_ids, \n",
        "                                    token_type_ids=None, \n",
        "                                    attention_mask=b_input_mask, \n",
        "                                    labels=b_labels)\n",
        "                loss, logits = outputs.loss, outputs.logits\n",
        "                # Accumulate the training loss over all of the batches so that we can\n",
        "                # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "                # single value; the `.item()` function just returns the Python value \n",
        "                # from the tensor.\n",
        "                total_train_loss += loss.item()\n",
        "\n",
        "                # Perform a backward pass to calculate the gradients.\n",
        "                loss.backward()\n",
        "\n",
        "                # Clip the norm of the gradients to 1.0.\n",
        "                # This is to help prevent the \"exploding gradients\" problem.\n",
        "                torch.nn.utils.clip_grad_norm_(self.discriminator.parameters(), 1.0)\n",
        "\n",
        "                # Update parameters and take a step using the computed gradient.\n",
        "                # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "                # modified based on their gradients, the learning rate, etc.\n",
        "                self.optimizer.step()\n",
        "\n",
        "                # Update the learning rate.\n",
        "                scheduler.step()\n",
        "\n",
        "            # Calculate the average loss over all of the batches.\n",
        "            avg_train_loss = total_train_loss / len(self.train_dataloader)            \n",
        "            \n",
        "            # Measure how long this epoch took.\n",
        "            training_time = format_time(time.time() - t0)\n",
        "\n",
        "            print(\"\")\n",
        "            print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "            print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "                \n",
        "            # ========================================\n",
        "            #               Validation\n",
        "            # ========================================\n",
        "            # After the completion of each training epoch, measure our performance on\n",
        "            # our validation set.\n",
        "\n",
        "            print(\"\")\n",
        "            print(\"Running Validation...\")\n",
        "\n",
        "            t0 = time.time()\n",
        "\n",
        "            # Put the model in evaluation mode--the dropout layers behave differently\n",
        "            # during evaluation.\n",
        "            self.discriminator.eval()\n",
        "\n",
        "            # Tracking variables \n",
        "            total_eval_accuracy = 0\n",
        "            total_eval_loss = 0\n",
        "            nb_eval_steps = 0\n",
        "\n",
        "            # Evaluate data for one epoch\n",
        "            for batch in self.validation_dataloader:\n",
        "                \n",
        "                # Unpack this training batch from our dataloader. \n",
        "                #\n",
        "                # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "                # the `to` method.\n",
        "                #\n",
        "                # `batch` contains three pytorch tensors:\n",
        "                #   [0]: input ids \n",
        "                #   [1]: attention masks\n",
        "                #   [2]: labels \n",
        "                b_input_ids = batch[0].to(device)\n",
        "                b_input_mask = batch[1].to(device)\n",
        "                b_labels = batch[2].to(device)\n",
        "                \n",
        "                # Tell pytorch not to bother with constructing the compute graph during\n",
        "                # the forward pass, since this is only needed for backprop (training).\n",
        "                with torch.no_grad():        \n",
        "\n",
        "                    # Forward pass, calculate logit predictions.\n",
        "                    # token_type_ids is the same as the \"segment ids\", which \n",
        "                    # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "                    # The documentation for this `model` function is here: \n",
        "                    # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "                    # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "                    # values prior to applying an activation function like the softmax.\n",
        "                    outputs = self.discriminator(b_input_ids, \n",
        "                                        token_type_ids=None, \n",
        "                                        attention_mask=b_input_mask,\n",
        "                                        labels=b_labels)\n",
        "                loss, logits = outputs.loss, outputs.logits\n",
        "                # Accumulate the validation loss.\n",
        "                total_eval_loss += loss.item()\n",
        "\n",
        "                # Move logits and labels to CPU\n",
        "                logits = logits.detach().cpu().numpy()\n",
        "                label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "                # Calculate the accuracy for this batch of test sentences, and\n",
        "                # accumulate it over all batches.\n",
        "                total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "                \n",
        "\n",
        "            # Report the final accuracy for this validation run.\n",
        "            avg_val_accuracy = total_eval_accuracy / len(self.validation_dataloader)\n",
        "            print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "            # Calculate the average loss over all of the batches.\n",
        "            avg_val_loss = total_eval_loss / len(self.validation_dataloader)\n",
        "            \n",
        "            # Measure how long the validation run took.\n",
        "            validation_time = format_time(time.time() - t0)\n",
        "            \n",
        "            print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "            print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "            # Record all statistics from this epoch.\n",
        "            training_stats.append(\n",
        "                {\n",
        "                    'epoch': epoch_i + 1,\n",
        "                    'Training Loss': avg_train_loss,\n",
        "                    'Valid. Loss': avg_val_loss,\n",
        "                    'Valid. Accur.': avg_val_accuracy,\n",
        "                    'Training Time': training_time,\n",
        "                    'Validation Time': validation_time\n",
        "                }\n",
        "            )\n",
        "\n",
        "        print(\"\")\n",
        "        print(\"Training complete!\")\n",
        "\n",
        "        print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n",
        "            \n",
        "\n",
        "        return training_stats\n",
        "\n",
        "    def save_model(self, output_dir = './model_save/'):\n",
        "        # Create output directory if needed\n",
        "        if not os.path.exists(output_dir):\n",
        "            os.makedirs(output_dir)\n",
        "\n",
        "        print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "        # Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "        # They can then be reloaded using `from_pretrained()`\n",
        "        model_to_save = self.discriminator.module if hasattr(self.discriminator, 'module') else self.discriminator  # Take care of distributed/parallel training\n",
        "        model_to_save.save_pretrained(output_dir)\n",
        "        self.tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "        # Good practice: save your training arguments together with the trained model\n",
        "        # torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n",
        "\n",
        "    def __load_model(self, input_dir = './drive/MyDrive/Colab Notebooks/summary/en_grammar_check_model'):\n",
        "        print('Loading BERT tokenizer...')\n",
        "        self.tokenizer = BertTokenizerFast.from_pretrained(input_dir)\n",
        "        self.discriminator = BertForSequenceClassification.from_pretrained(input_dir)\n",
        "\n",
        "    def transfer_learning(self, sentences, train_for = True):\n",
        "        \n",
        "        input_ids = []\n",
        "        attention_masks = []\n",
        "\n",
        "        # For every sentence...\n",
        "        for sent in sentences:\n",
        "            # `encode_plus` will:\n",
        "            #   (1) Tokenize the sentence.\n",
        "            #   (2) Prepend the `[CLS]` token to the start.\n",
        "            #   (3) Append the `[SEP]` token to the end.\n",
        "            #   (4) Map tokens to their IDs.\n",
        "            #   (5) Pad or truncate the sentence to `max_length`\n",
        "            #   (6) Create attention masks for [PAD] tokens.\n",
        "            encoded_dict = self.tokenizer.encode_plus(\n",
        "                                sent,                      # Sentence to encode.\n",
        "                                add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                                max_length = 64,           # Pad & truncate all sentences.\n",
        "                                pad_to_max_length = True,\n",
        "                                return_attention_mask = True,   # Construct attn. masks.\n",
        "                                return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                                truncation = True,\n",
        "                        )\n",
        "            # Add the encoded sentence to the list.    \n",
        "            input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "            # And its attention mask (simply differentiates padding from non-padding).\n",
        "            attention_masks.append(encoded_dict['attention_mask'])\n",
        "        \n",
        "        if train_for:\n",
        "            b_labels = torch.ones(len(sentences),dtype=torch.long).to(device)\n",
        "        else:\n",
        "            b_labels = torch.zeros(len(sentences),dtype=torch.long).to(device)\n",
        "        #print(b_labels)\n",
        "        # Convert the lists into tensors.\n",
        "        input_ids = torch.cat(input_ids, dim=0).to(device)\n",
        "        attention_masks = torch.cat(attention_masks, dim=0).to(device)    \n",
        "        #if str(discriminator1.device) == 'cpu':\n",
        "        #    pass\n",
        "        #else:\n",
        "        #    input_ids = input_ids.to(device)\n",
        "        #    attention_masks = attention_masks.to(device)        \n",
        "\n",
        "        outputs = self.discriminator(input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=attention_masks, \n",
        "                                labels=b_labels)\n",
        "\n",
        "        #print(outputs)\n",
        "        #return torch.sigmoid(outputs[0][:,1])\n",
        "        #return outputs[0][:,1]\n",
        "        return outputs['loss'], outputs['logits']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "Vwyq26SOFV_N",
        "outputId": "62e07ae5-5fbb-4c0f-ae3e-5ba4f69234aa"
      },
      "source": [
        "grammer_checker = Grammar_Discriminator(input_dir = '/content/drive/MyDrive/Colab Notebooks/summary/ko_grammar_model3')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-a071bff8b332>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgrammer_checker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGrammar_Discriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/Colab Notebooks/summary/ko_grammar_model3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-65fcb41cfa81>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, pretraoned_kobert_model_name, input_dir)\u001b[0m\n\u001b[1;32m     88\u001b[0m                                 )            \n\u001b[1;32m     89\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-65fcb41cfa81>\u001b[0m in \u001b[0;36m__load_model\u001b[0;34m(self, input_dir)\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loading BERT tokenizer...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertTokenizerFast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscriminator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertForSequenceClassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransfer_learning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_for\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   1285\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstate_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1286\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1287\u001b[0;31m                     \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolved_archive_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1288\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1289\u001b[0m                     raise OSError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    605\u001b[0m                     \u001b[0mopened_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_position\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m    880\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnpicklerWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_loaded_sparse_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m    855\u001b[0m         \u001b[0mdata_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m             \u001b[0mload_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_maybe_decode_ascii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload_tensor\u001b[0;34m(data_type, size, key, location)\u001b[0m\n\u001b[1;32m    843\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_storage_from_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    846\u001b[0m         \u001b[0mloaded_storages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lS9l3MLLOu2i"
      },
      "source": [
        "## dataset 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1ncRdZgApww",
        "outputId": "49085971-dcab-4174-d1dc-642bae2bc085"
      },
      "source": [
        "sentences[0:100]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['지난해 고령화와 유례가 드문 겨울 한파 등 영향으로 우리나라 사망자 수가 통계 작성 이후 가장 많았다.',\n",
              " '폐렴과 치매의 일종인 알츠하이머병은 지난해 사망원인 순위 3위와 9위로 전년보다 각각 한 단계, 두 단계 상승하는 등 노인성 질병에 의한 사망률이 급증하는 추세다.',\n",
              " '‘연령표준화 사망률’(표준인구 10만 명당 사망자 수)은 울산·충북·부산 순으로 높게 나타났다.',\n",
              " '■작년 사망자 29만 8820명, 역대 최다',\n",
              " \"24일 통계청이 발표한 '2018년 사망원인통계'를 보면 지난해 총 사망자 수는 전년 대비 4.7%(1만 3286명) 증가한 29만 8820명으로 관련 통계를 작성한 1983년 이후 가장 많았으며, 5년 연속 증가세를 보였다.\",\n",
              " '통계청은 인구 구조의 고령화와 지난해 1~2월 유례가 드문 한파 등을 그 원인으로 꼽았다.',\n",
              " '지난해 조사망률(인구 10만 명당 사망자 수) 역시 582.5명으로 전년보다 4.5%(25.1명) 증가해 5년 연속 늘었다.',\n",
              " '특히 80세 이상의 사망자가 전체 사망자의 절반에 가까운 46.3%로, 10년 전보다 14.3%포인트(P)나 증가했다.',\n",
              " '■폐렴·알츠하이머병 사망률 순위 ‘껑충’',\n",
              " '사망원인별로 보면 지난해 암(악성신생물)에 의한 사망률(이하 인구 10만 명당 사망자 수)은 154.3명으로 전년보다 0.2% 증가했다.',\n",
              " '1983년 관련 통계를 집계한 이래 줄곧 암이 사망원인 1위로 집계됐다.',\n",
              " '특히 폐렴(4위→3위)과 치매의 일종인 알츠하이머병(11위→9위)에 의한 사망률 순위 상승이 두드러졌다.',\n",
              " '폐렴 사망률은 2004년 10위에서 꾸준히 순위가 상승하고 있고, 알츠하이머병 사망률 역시 통계 작성 이래 10대 사인에 처음 포함됐다.',\n",
              " '지난해 알츠하이머병에 의한 사망률은 12.0명으로 전년(9.8명) 대비 22.5% 증가했다.',\n",
              " '알츠하이머병 사망률은 10년 전(3.8명)과 비교하면 무려 214.2% 증가했다.',\n",
              " '폐렴 사망률은 45.4명으로 전년(37.8명) 대비 20.0% 증가했다.',\n",
              " '알코올 관련 사망률은 9.6명으로 전년보다 2.0% 늘었다.',\n",
              " '■자살률 5년 만에 증가…\"베르테르 효과 영향\"',\n",
              " '지난해 자살에 의한 사망자는 1만 3670명으로 전년보다 9.7%(1207명) 증가했다.',\n",
              " '자살률은 26.6명으로 전년보다 2.3명(9.5%) 증가했다.',\n",
              " '자살률은 2013년 28.5명, 2014년 27.3명, 2015년 26.5명, 2016년 25.6명, 2017년 24.3명 등 4년 연속 줄어들다가 5년 만에 증가세로 돌아섰다.',\n",
              " '자살은 10∼30대까지 사망원인 순위 1위를 차지했고, 40∼50대에서도 2위를 기록했다.',\n",
              " '김진 통계청 인구동향과장은 \"자살에는 베르테르 효과, 즉 유명인 자살이 영향을 준다.',\n",
              " '2011년 이후 유명인 자살이 줄면서 자살이 줄었는데 지난해에는 유명인 자살이 있어 영향을 줬다\"고 설명했다.',\n",
              " '지역 간 연령구조 차이를 표준화한 사망률(표준인구 10만 명당 사망자 수)을 보면 울산(355.3명), 충북(352.6명), 부산(350.8명)이 높았고, 서울(283.3명)과 경기(306.8명)가 낮았다.',\n",
              " '사인별로 연령표준화 사망률이 높은 지역을 보면 암은 경남(101.5명), 심장 질환은 경남(44.6명), 뇌혈관 질환은 울산(30.6명), 폐렴은 경북(30.3명), 운수사고는 전남(14.4명), 고의적 자해(자살)는 충남(29.8명)이었다.',\n",
              " '서산시의회(의장 임재관) 가충순·이수의 의원이 (사)한국지역신문협회에서 수여하는 우수의정대상을 받았다.',\n",
              " '가충순 의원과 이수의 의원은 16일 팔봉면 폰타나 리조트에서 열린 한국지역신문협회 하계 워크샵에서 지역사회 발전을 위해 활발한 의정활동을 펼친 공로를 인정받아 우수의정대상을 수상했다.',\n",
              " '지난해 6월 제7회 전국동시지방선거를 통해 등원한 두 의원은 산업건설위원회에서 열정적인 의정활동을 펼치고 있다.',\n",
              " '가충순 의원은 5분발언, 행정사무감사, 시정질문을 통해 자동차 연비테스트 연구시설 유치, 천수만 염해피해 재발 방지, 서산시 대표 농산물 육성 등 지역의 크고 작은 문제를 개선하기 위해 노력하고 있다.',\n",
              " '이수의 의원은 지난 행정사무감사에서 대산공단 기업 임원을 참고인으로 출석시켜 지역인재채용 및 관내업체·자재 활용을 확대할 것을 제안하며 기존 행정사무감사의 틀을 깨는 등 다양한 의정활동을 펼쳐나가고 있다.',\n",
              " '가충순 의원은 \"시의원이라면 마땅히 해야할 일을 한 것 뿐인데 상까지 주시니 몸 둘 바를 모르겠다\"며 \"항상 초심을 잊지 않고 지역 발전을 위해 최선을 다하겠다\"고 소감을 밝혔다.',\n",
              " '이수의 의원은 \"믿고 뽑아주신 주민들을 위해 당연히 해야할 일을 했을 뿐인데 상까지 받게 돼 영광\"이라며 \"시민들이 자부심을 느낄 수 있는 지역사회를 만들어 나가기 위해 앞으로도 최선을 다 하겠다\"고 말했다.',\n",
              " '지난 2004년 시작해 조선대 학생들의 대표적인 행사로 자리매김한 ‘조선대 국토대장정’이 지난 5일 해단식을 끝으로 일정을 마감했다.',\n",
              " '조선대는 지난 5일 오후 서석홀 4층 대호전기홀에서 ‘2019학년도 조선대학교 제16기 국토대장정’ 해단식을 열었다.',\n",
              " '국토대장정은 매년 여름방학에 조선대 학생들이 직접 우리 국토를 걸으면서 애국심을 느끼고, 단체생활을 통해 협동심과 리더십, 공동체 의식을 함양할 수 있도록 지원하는 행사다.',\n",
              " '해마다 학생들에게 큰 호응을 받아 왔다.',\n",
              " '올해 국토대장정은 16번째 행사로 ‘조선대의 새로운 비상을 꿈꾸다’를 슬로건으로 진행됐다.',\n",
              " '지난달 24일 출정식을 갖고 25일 새벽에 출발한 52명의 대원들은 총 10박 11일간 제주도 일대 총 321㎞를 행군했다.',\n",
              " '이는 지난해보다 더 늘어난 행군 기록이다.',\n",
              " '대원들은 목포항을 거쳐 배편으로 제주도로 이동해 관음사 야영지로 이동했다.',\n",
              " '대원들은 다음날인 지난달 26일 제주 애월읍의 곽지해수욕장, 지난달 27일 서귀포 하모해수욕장, 지난달 28일 서귀포 체육공원을 향해 걸었다.',\n",
              " '이어 지난달 29일 서귀포 표선해수욕장을 거쳐 지난달 30일 서귀포 섭지코지와 성산일출봉을 여행했다.',\n",
              " '이달 1일에는 한라산 백록담을 등반했다.',\n",
              " '그 다음날에는 제주 함덕해수욕장에 도착해 시간을 보냈다.',\n",
              " '이후 3일 휴식시간을 거져 4일 제주항에서 배를 타고 목포항에 도착했다.',\n",
              " '마침내 지난 5일 대원들은 동신대에서 모교인 조선대로 걸어서 귀교해 일정을 끝마쳤다.',\n",
              " '대원들은 대장정 기간 모든 야영지에서 쓰레기를 수거하는 등 환경정화활동을 펼치기도 했다.',\n",
              " '5일 열린 해단식에선 참가자 전원이 완주에 성공한 기념으로 국토대장정 대장을 맡은 김준연(정치외교학과 4학년) 학생 등을 포함한 조장단에게 표창장이 수여됐다.',\n",
              " '서울시는 신학기가 시작되는 다음달 4일부터 고등학교 3학년 무상급식을 실시한다고 28일 밝혔다.',\n",
              " '서울 시내 319개 고등학교 3학년 8만4700명이 대상이다.',\n",
              " '올해 고3을 시작으로 연차별로 2학년, 1학년 순으로 확대 실시한다.',\n",
              " '시는 이와 함께 의무교육 대상이었으나 사립학교라는 이유로 제외됐던 국·사립초와 국제중 37개교 2만415명에게도 무상급식을 제공한다.',\n",
              " '급식 기준단가는 공립초등학교 3628원, 국·사립초등학교 4649원, 중·고등학교는 5406원이다.',\n",
              " '공립초와 국·사립초의 단가 차이는 조리종사자의 인건비가 국·사립초 단가에는 포함되고, 공립초는 교육청 지원으로 별도 책정되기 때문이라고 시는 설명했다.',\n",
              " '시는 또 무상급식에서 제외된 고등학교 1, 2학년과 특수학교를 대상으로, 신청 학교에 한해 친환경 농산물 구매에 대한 차액금을 지원한다.',\n",
              " '올해 총 157개교에 27억7000만원을 지원한다.',\n",
              " '올해 서울시 친환경 무상급식 총 소요액은 5688억 원이다.',\n",
              " '재원 분담비율은 서울시 30%, 자치구 20%, 교육청 50%다.',\n",
              " '서울시는 \"무상급식 지원대상의 증가에 따른 재원 분담의 어려움이 있어 서울시와 타 시·도, 교육청 등과 합동으로 국가 부담을 지속해서 요청할 계획\"이라고 밝혔다.',\n",
              " '미국인 선교사가 우간다에서 의사 행세를 하며 의료 시설을 운영한 혐의로 지역 시민단체와 주민들로부터 고소당했다.',\n",
              " '원고 측은 선교사가 두 아이의 죽음과도 관련돼 있다고 주장했다.',\n",
              " \"CNN은 3일(현지시간) 우간다에서 비영리 종교단체 '서빙 히스 칠드런'(SHC)을 설립한 러네이 바흐가 허가없이 의료 시설을 운영한 혐의로 우간다 여성 인권 단체인 '여성 프로보노 이니셔티브'(WPI)로부터 고소당했다고 전했다.\",\n",
              " 'SHC에서 치료받다 사망한 아이의 부모인 주베다와 아넷도 WPI와 함께 했다.',\n",
              " 'WPI는 지난 1월 바흐와 SHC가 \"취약한 아이들을 상대로 불법적인 의료 행위를 자행했다\"며 고소장을 접수했다.',\n",
              " '바흐가 의사나 간호사 등 의료 전문가가 아님에도 의료 행위를 했다는 것이다.',\n",
              " '아픈 아이를 SHC에 맡겼던 주베다와 아넷은 바흐가 의사인줄만 알았다고 전했다.',\n",
              " \"'의료 시설'을 운영하면서 흰 가운과 청진기를 맨 모습으로 자신이 돌보는 아이들에게 의료 행위를 해서다.\",\n",
              " 'SHC에서 일했던 두 명의 직원도 바흐가 의사라고 믿고 있었다고 진술했다.',\n",
              " 'CNN은 바흐와 그의 부모님에게 연락을 했으나 직접적인 응답은 받을 수 없었다고 전했다.',\n",
              " '다만 바흐의 변호인이자 \\'국가생명자유센터\\'(NCLL)의 대표인 데이비드 깁스는 성명을 통해 \"바흐는 우간다의 의료인 옆에서 그들을 보조했을 뿐 자신이 직접 의료 행위를 수행한 적은 없다\"고 전했다.',\n",
              " '이어 \"젊은 여성(바흐)이 신의 비전 아래 설립한 SHC는 매년 수많은 생명을 구하고 있다\"면서 \"바흐는 우간다 아이들에 대한 열정으로 그들의 어머니에 대한 멘토 역할을 수행하는 과정에서 의료행위를 포함시킨 것일 뿐\"이라고 의혹을 일축했다.',\n",
              " '깁스는 바흐가 의료인처럼 행세한 것에 대해 강하게 부정했다.',\n",
              " 'WPI나 사망한 아이들의 부모가 제기한 의혹은 전혀 신빙성이 없다고 재차 강조한 것이다.',\n",
              " '그는 \"두 아이 중 한 아이는 심지어 SHC에서 케어를 받은 적이 없으며 다른 아이는 케어를 받았지만 그때 바흐는 우간다에 있지도 않았다\"고 반박했다.',\n",
              " '그러나 원고 측 증인으로 나선 또 다른 직원은 피해 아동이 단 두명에서 그치지 않는다고 주장했다.',\n",
              " 'SHC에서 8년간 운전기사로 일한 찰스 올웨니는 자신이 일주일에 최소 7명에서 10명의 아이들의 시신을 가족들에게 전달했다고 밝혔다.',\n",
              " '그는 유가족에게 작은 관과 옥수수로 만든 음식과 더불어 5만 우간다 실링(약 1만 5800원)을 전달했다고 말했다.',\n",
              " '깁슨은 이에 대해 \"말도 안되는 소리\"라면서 \"SHC는 지난 10년간 3600명의 아이들을 돌봤고 그 중 105명이 사망했다\"고 반박했다.',\n",
              " '바흐는 지난 3월 12일 재판에 출석했으며 내년 초에 다음 재판을 앞두고 있다.',\n",
              " \"음성 극동대학교 평생교육원(김동옥 원장)은 지난 12일 충북 혁신도시 맹동면에 있는 극동대 혁신도시센터에서 '내 아이를 위한 만화심리치료' 강좌를 개설했다.\",\n",
              " '사진은 김동옥 (가운데)평생교육원장과 만화심리치료 강좌 개강식에 참석한 사람들의 모습.',\n",
              " \"[음성]음성 극동대학교 평생교육원(김동옥 원장)은 지난 12일 충북 혁신도시 맹동면에 있는 극동대 혁신도시센터에서 '내 아이를 위한 만화심리치료' 강좌를 개설했다고 밝혔다.\",\n",
              " '이 강좌는 우리나라 혁신도시 중 가장 젊은 세대들이 산다는 지역적 특성을 반영해 어린 자녀가 있는 부모들을 위한 교육부터 시작한 것이다.',\n",
              " '특히, 만화심리치료는 17년간 극동대학교 만화애니메이션학과 전공 학생들의 정서를 돌보면서 느끼는 문제들을 해결하기 위한 마음에서 미술치료 박사과정을 별도로 공부한 김동옥 원장이 직접 강의를 진행함으로써 그동안 터득한 노하우를 지역주민들에게 조금이나마 돌려드리기 위한 마음으로 진행되고 있다.',\n",
              " '이날 수업에 참여한 수강생들은 \"자신만을 위한 힐링 시간이어서 너무 좋았고 부모가 변화되는 것이 우리 아이들을 건강하게 성장시키는 비결\"이라며 \"교육 강좌 개설이 거의 없는 혁신도시에 극동대 평생교육원이 더 많은 강좌를 개설해 주었으면 좋겠다\"고 말했다.',\n",
              " '한편, 이 강좌는 오는 5월 31일까지, 매주 금요일 오전 10시부터 8주간 진행된다.',\n",
              " '집배원이 또 사망했다.',\n",
              " '올해만 과로사 등 9번째다.',\n",
              " '우정사업본부 노사에 따르면 19일 아침 충남 당진우체국 소속 집배원 강 모씨가 자택에서 숨진 채 발견됐다.',\n",
              " '강씨는 49세로 특별한 병력이 없었고 올해 3월 건강검진에서도 특이 소견이 없었다.',\n",
              " '전국우정노조는 강씨의 사인을 과로사로 추정하고 있다.',\n",
              " '우정노조는 \"우정사업본부와 정부는 그동안 \\'중노동 과로로 죽어가는 집배원을 살리기 위해서는 인력을 증원해야 한다\\'는 우정노조의 정당한 요구를 묵살해왔다\"며 \"이번 강씨 사망은 예견된 인재이자 타살\"이라고 주장했다.',\n",
              " '이어 \"정부는 노사 합의사항인 \\'집배원 인력 증원\\'과 \\'완전한 주 5일제\\'가 당장 이행될 수 있도록 직접 나서야 한다\"고 덧붙였다.',\n",
              " '우정노조는 집배원의 완전한 주 5일제 및 인력 증원을 위해 24일 전 조합원 쟁의행위 찬반투표, 25일 쟁의행위 찬반투표 관련 기자회견, 30일 전 조합원 총파업 출정식을 거쳐 다음 달 9일 전면 총파업을 할 계획이다.',\n",
              " '우정사업본부는 \"안전보건 관리 추진 및 노동시간 단축노력에도 불구하고 또다시 사망사고가 발생해 송구스럽다\"면서 \"우정노조와 공동으로 사망사고조사위원회를 구성해 한 점 의혹 없도록 사고경위를 면밀하게 조사할 계획\"이라고 밝혔다.',\n",
              " \"앞서 한국노총은 전날 열린 경제사회노동위원회(경사노위) 의제개발조정위원회에서 집배원 장시간 노동과 과로사 문제와 관련해 '집배원 노동조건 개선 특별위원회' 설치를 제안했다.\",\n",
              " '한국노총은 \"집배원의 노동시간이 연간 2745시간(2017년 기준)이고 장시간·중노동에 따른 만성적 질환과 사고위험, 직무 스트레스 등에 노출돼 있다\"면서 \"특별위원회를 통해 집배원의 노동시간 단축 및 적정 인력 배치 등 근본적인 대책을 마련해야 한다\"고 강조했다.',\n",
              " '채태병 기자 1차 평가 나란히 통과… 강점 홍보하며 오늘 2차 평가 총력전 수원 “사람중심 교통체계 완성”… 성남 “판교 기업 경쟁력 강화”',\n",
              " '‘국내 1호 트램’ 도시로 거듭나기 위한 수원시와 성남시의 제2라운드 경쟁이 막을 올렸다.']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEqN-K1jIWui"
      },
      "source": [
        "sentences2 = []\n",
        "for sen in sentences:\n",
        "    if sen.find('\\\"') + sen.find('\\'') + sen.find('“') == -3:\n",
        "        sentences2.append(sen)\n",
        "    else:\n",
        "        pass"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Os52RUwBJh4I",
        "outputId": "8d14ff23-1d04-481e-bc13-606833aa9e02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(sentences2)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3370416"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXAXurU_Jm1N",
        "outputId": "1259d7ca-0b86-4f66-8ffb-5f93d6a18e43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "sentences2[200:300]"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['하지만 A 씨와 B 씨가 밀양의 한 차량에서 숨진 채 발견되면서 아동학대로 인한 것으로 굳어지고 있다.',\n",
              " '이 여아에 대한 최종 사인은 국과수 정밀부검 결과가 나오면 밝혀지게 된다.',\n",
              " '울산지역 아동학대는 매년 신고 건수가 늘고 있지만 신고 건수의 70%는 비신고의무자로 집계, 신고의무자들의 신고를 보완할 수 있는 대책 마련도 절실한 실정이다.',\n",
              " '‘아동학대범죄의 처벌 등에 관한 특례법 제 63조’에는 아동학대 신고의무자가 정당한 사유 없이 아동학대를 신고하지 않을 경우 500만 원 이하의 과태료가 부과된다.',\n",
              " '아동학대 신고의무자는 어린이집, 유치원, 학교, 종합병원, 아동복지시설 5개의 직군에서 지난해 4월부터 신고의무자가 소속된 모든 직군 총 24개로 확대됐다.',\n",
              " '이들은 아동학대가 의심되면 반드시 신고해야 한다.',\n",
              " '하지만 최근 5년간 신고 의무자의 비율은 총 신고 건수의 20%에 그치고 있다.',\n",
              " '이같은 아동학대가 이어지자 최근 아동학대 예방과 학대 아동을 보호를 위해 울산시와 구군에서 조례안을 추진하는 움직임도 활발하게 진행되고 있다.',\n",
              " '동구의회는 이날 임시회에서 아동학대 예방과 피해 아동 보호를 위한 ‘울산 동구 공동 육아 나눔터 지원에 관한 조례안’을 가결했다.',\n",
              " '울산시의회에서도 10월 임시회에 안건을 발의할 예정인데 이를 통해 아동학대 예방과 아동을 보호하는 사회 분위기를 조성한다는 계획이다.',\n",
              " '3일 한국거래소에 따르면 외국인은 지난달 28일부터까지 이달 1일까지 한 주 동안 국내 주식시장에서 약 491억원을 순매수했다.',\n",
              " '코스피 시장에서 291억원을, 코스닥 시장에서는 198억원을 각각 사들였다.',\n",
              " '전주 3800억원 이상을 순매수한 것에 비해서는 크게 감소한 규모다.',\n",
              " '외국인이 지난 주 가장 많이 사들인 종목은 삼성전자였다.',\n",
              " '외국인은 지난 주 삼성전자를 893억원 순매수했다.',\n",
              " '뒤이어 SK하이닉스를 882억원 사들였다.',\n",
              " '이밖에 삼성바이오로직스(854억원), 아모레퍼시픽(712억원), 셀트리온(677억원), 삼성전기(620억원), 삼성엔지니어링(316억원), LG화학(271억원), 카카오(216억원), 삼성SDI(215억원) 등을 사들였다.',\n",
              " '지난 주 외국인이 가장 많이 판 종목은 롯데리츠였다.',\n",
              " '외국인은 지난 주 롯데리츠를 785원 순매도했다.',\n",
              " '이어 SK를 745억원 팔아치웠다.',\n",
              " '이밖에 호텔신라(411억원), 현대제철(387억원), 한국전력(377억원), 넷마블(310억원), 동진쎄미켐(289억원), 기업은행(256억원), 삼성전자우(241억원), 케이엠더블유(205억원) 등이 외국인 순매도 상위에 올랐다.',\n",
              " '증시는 경제 지표 등에 따라 점차 상승세를 보일 것이란 전망이다.',\n",
              " '각 교육청과 사설기관별로 수능 가채점 분석 결과가 속속 발표되면서 여기저기서 수험생들의 한숨 소리가 들려오고 있다.',\n",
              " '영역별 들쭉날쭉한 난이도로 복불복 수능이 재현될 수 있다는 우려에 일찌감치 재수로 눈길을 돌리는 학생도 눈에 띈다.',\n",
              " '하지만 재수를 하더라도 희망하는 대학 진학을 보장할 수 없고, 1년이라는 시간만 허비할 수 있는 것이 사실이다.',\n",
              " '이에 수능, 내신 성적이 부족해도 영어 성적에 따라 진로 선택이 가능한 미국 대학이 새로운 대안으로 주목 받고 있다.',\n",
              " '미국입시는 대학과 전공 선택사항이 많아 지금 준비해도 원하는 진로를 선택할 수 있어 재수 없이 2020학년도를 시작할 수 있다.',\n",
              " '해외 대학 졸업 시 다양한 취업의 기회도 가질 수 있다고 관계자측은 전했다.',\n",
              " '미국 대학은 국내뿐 아니라 전세계의 다양한 글로벌 기업에서 취업의 기회를 가질 수 있으며, 수학 기간 동안 다양한 경험을 쌓을 수 있다.',\n",
              " '최근 미국의 명문대 중 하나인 위스콘신대학교가 한국학생 특별전형을 운영하는 등 유학의 문턱이 낮아지고 있다는 점도 주목할 만 하다.',\n",
              " '위스콘신대학교는 유학생들에게도 장학금 혜택을 제공해 유학이 비싸다는 편견을 깨고 있다.',\n",
              " '미국 내에서 가장 안전하고 학력 수준이 높은 지역으로 알려진 만큼 체계적인 교육 시스템을 바탕으로 수준 높은 교육을 기대할 수 있다는 점도 장점으로 꼽힌다.',\n",
              " '약 200년의 역사를 가진 미국 내 Public IVY리그로 불리는 위스콘신대학교는 미국 내에서도 명문대로 잘 알려져 있다.',\n",
              " '세계에서 가장 많은 CEO를 배출했으며, 노벨상 수상자도 23명 배출했다.',\n",
              " '위스콘신대학교는 서울 삼성동에 위치한 한국대표를 통해 한국 학생들을 모집 중이다.',\n",
              " '입학사정관과의 1:1 심층면접을 통해 입학을 결정하게 되며, 면접 시에는 한국어와 영어 중 자신 있는 언어를 선택할 수 있다.',\n",
              " '다양한 캠퍼스 중 자신의 성향과 전공을 중심으로 지원 및 합격이 가능하며 최소 $500에서 최대 $20,000의 전액 장학금을 받을 수 있다.',\n",
              " '한편, 수능 가채점 이후 학부모와 학생들의 미국유학 문의가 증가하고 있는 가운데, 오는 11월 23일(토) 오후 2시, 위스콘신대학교 한국대표에서 입학설명회가 진행된다.',\n",
              " '설명회에는 입학사정관이 직접 참가해 한국학생 특별전형 및 장학금에 대한 입학 솔루션을 제공한다.',\n",
              " '참가 신청은 홈페이지 및 전화로 접수 가능하다.',\n",
              " '노동, 부(富)와 빈곤 문제 등을 다루며 인간성 상실과 삶의 황폐화를 꼬집어왔던 황석영 작가가 젊은이들이 스스로 목숨을 끊도록 내몰고 있는 사회를 바꿔야 한다고 강조했다.',\n",
              " '최근 고령화 등으로 웰다잉에 대한 인식이 달라지고 사회적으로 점차 많은 논의도 이뤄지고 있다.',\n",
              " '하지만 팍팍한 삶의 현실로 스스로 목숨을 끊는 젊은이들이 있는 상황에서 웰다잉을 이야기하는 것이 부끄럽고 쑥스러운 일이라는게 황 작가의 생각이다.',\n",
              " '이 날 황 작가와 함께 토크콘서트에 나선 이선종 원불교 교무도 젊은이들이 삶에 대한 의지를 가지고 더 열심히 살 수 있도록 하는게 중요하다고 밝혔다.',\n",
              " '지난해 12월 출범함 웰다잉시민운동은 차홍봉 전 보건복지부 장관이 이사장을 맡고 있으며, 죽음에 대한 인식을 바꾸고 삶의 마무리를 아름답게 하기 위한 활동을 이어오고 있다.',\n",
              " '[충청투데이 이승동 기자] 세종시 구도심 지역에 태양광과 지열 등 친환경 에너지원을 활용한 에너지 자립마을이 들어선다.',\n",
              " '세종시는 최근 산업통상자원부가 주관하고 한국에너지공단이 추진하는 2020년 신재생에너지 융복합지원 사업 공모에 참여, 지원 대상에 최종 선정됐다.',\n",
              " '국비 14억 1700만원을 확보한 시는 연동·연서·전의면 일원 태양광 264개소 946㎾, 지열 33개소 577㎾를 보급할 계획이다.',\n",
              " '사업기간은 내년 1~12월이다.',\n",
              " '공공건물을 제외한 주택·건물·축사의 자부담률은 20%다.',\n",
              " '시는 지난 3월부터 사업제안서 및 참여기업 선정을 위한 모집공고를 실시, 지난 6월 컨소시엄 구성을 완료한 뒤 사업계획서를 한국에너지공단에 제출했다.',\n",
              " '이후 프레젠테이션 발표를 통한 1차 통과 후 현장평가를 거쳐 최종 사업 대상지로 선정됐다.',\n",
              " '시는 이번 공모 선정으로 구도심 지역에 친환경 에너지원(태양광·지열)을 보급, 에너지 자립마을을 조성해 구도심과 신도심 간 에너지 불균형을 해소하는 계기를 마련하겠다는 구상이다.',\n",
              " '전 세계적으로 인기를 얻고 있는 방탄소년단(BTS)를 향해 혐오 발언을 쏟아낸 호주의 한 방송사가 여론의 뭇매를 맞고 있다.',\n",
              " '이들은 프로그램에서 연예정보 소개하면서, BTS를 향한 원색적인 비난을 쏟아냈다.',\n",
              " '방송은 삽시간에 호주 내 BTS 팬들 사이에서 화제가 됐다.',\n",
              " '이들은 사회관계망서비스(SNS)에 #channel9apologize 해시태그를 붙여 사과를 요구하고 있다.',\n",
              " '채널9은 민간 방송사가 아닌 공영방송사란 점에서 더욱 비난 여론이 거세게 일고 있다.',\n",
              " '이는 전 세계 BTS 팬들에게 공유되면서 삽시간에 채널9에 대한 보이콧 운동으로까지 비화되고 있다.',\n",
              " '한편 BTS는 세계를 돌며 팬들과 만나고 있다.',\n",
              " '특히 미국 3개 도시 6회, 브라질 상파울루 2회, 영국 런던과 프랑스 파리 4회 등 12차례 공연을 열어 티켓 판매량 60만6409장을 기록했다.',\n",
              " '판매수익금은 7890만 달러(약 936억 원)로 집계됐다.',\n",
              " '제1부 균형발전선언 15주년 기념식에서는 이춘희 시장과 노무현재단 유시민 이사장의 인사말에 이어 이해찬 더불어민주당대표와 송재호 국가균형발전위원장, 김진숙 행복도시건설청장의 환영사가 이어졌다.',\n",
              " '정책 심포지엄에서는 ▶재정분권과 포용적 정부간 재정관계 개편과제 ▶국가균형발전을 위한 재정혁신 등에 대한 발제와 더불어 각 분야 전문가들이 열띤 토론을 펼쳤다.',\n",
              " '시는 이번 정책 심포지엄이 전문가와 시민이 참여하는 공론의 장으로 국가균형발전에 대한 사회적 공감대를 더욱 확산하는 계기가 될 것으로 기대하고 있다.',\n",
              " '국가균형발전 선언 기념행사는 참여정부의 지방화와 균형발전시대 개막선언일을 기념해 균형발전과 자치분권의 상징도시인 세종시에서 매년 열리고 있다.',\n",
              " '특히 지난해에는 문재인 대통령이 참석한 가운데 정부의 국가균형발전정책 방향을 선포하는 국가균형발전 비전 선포식으로 열렸다.',\n",
              " '올해는 국가균형발전 선언 15주년의 의미를 살려 행사에 참석한 주요인사와 시민들로부터 균형발전에 대한 응원메시지를 받아 세종시 균형발전 상징공원에 박석(바닥돌)으로 제작할 예정이다.',\n",
              " '최근에 남원에 이어 전주에서 차선도색 부실시공이 적발된 가운데, 이같은 불법행위는 업체들의 돈만 되면 그만이라는 안일한 안전불감증과 지자체나 공공기관들의 관리 감독 부실이 복합적으로 얽히면서 빚어진 나쁜 산물이라는 지적이 나온다.',\n",
              " '이같은 부실시공 문제가 근절이 되지 않는 가장 큰 이유는 업체 선정과정이다.',\n",
              " '차선도색 업체의 경우 대부분 차선 도색을 할 수 있는 도장 면허를 가지고 있다.',\n",
              " '하지만 이들 업체 대부분은 면허만 소지했을 뿐 차선도색에 필요한 장비도 없고 실제로 해보지 않은 경우가 다반사인 경우가 많다.',\n",
              " '상황이 이렇다보니 직접시공을 하는 조건으로 입찰을 받은 업체는 하도급 업체에 다시 재하도급을 하는 일이 벌어진다.',\n",
              " '최초 입찰을 받은 업체가 입찰금액에서 수수료를 떼어가고 재하도급을 받은 업체는 적은 금액에서 수익을 남기려다 보니 값싼 페인트나 저가 유리알 등을 사용하게 되는 악순환이 반복되고 있다.',\n",
              " '또 다른 이유는 차선 도색을 발주하고 관리감독을 시행해야 할 지방자치단체에 있다.',\n",
              " '지자체 차선도색 시공 담당자 대부분은 차선 도색과 관련된 전문지식이 부족한 실정이다.',\n",
              " '관련 매뉴얼이 있지만 여러 업무를 동시에 맡고 있어 숙지할 시간조차 부족하고 빠르면 6개월 만에 이뤄지는 순환 인사체계도 원인으로 지목되고 있다.',\n",
              " '때문에 전문지식이 없어 발주한 업체가 시공능력이 되는지도 확인이 어렵다.',\n",
              " '실제 전주시나 LH는 시공후 이를 관리하고 감시할수 있는 기본 적인 장비인 휘도측정기가 비치돼 있지 않은 실정이다.',\n",
              " '관련 지식이 없고 제대로 된 시공을 확인할 수 있는 측정장비도 없다보니 검사는 외부로 맡긴다.',\n",
              " '공사후 지자체와 LH 등은 도로교통관리공단에 의뢰해 시공 후 단 한차례만 준공검사를 실시하는데, 경찰은 시공완료 후 곧바로 이뤄지는 차선 검사에는 부실이 잘 나타나지 않는다고 설명했다.',\n",
              " '이같은 상황에서 타지역 사례를 참고할 만하다.',\n",
              " '충북 청주시의 경우 선정된 차선도색 시공업체는 테스트 시공을 실시해야한다.',\n",
              " '또 품질, 두께, 휘도, 온도, 장비 등과 관련된 교육도 받는다.',\n",
              " '전주 시내버스 완전공영제실현운동본부가 버스재정지원 정보의 공개와 도내 버스 사업자들의 부당이익 환수를 촉구했다.',\n",
              " '그러나 전북도는 이에 불복하고, 항소를 준비하고 있다.',\n",
              " '이에 전북도는 기업의 영업비밀과 업무수행의 공정성 등을 이유로 공개를 거부했다.',\n",
              " '앞서 운동본부는 전북도를 상대로 5건의 정보를 공개할 것을 청구한 바 있다.',\n",
              " '전주지법은 최근 정보공개청구 거부처분 취소 소송에 대해 원고 승소 판결을 내렸다.',\n",
              " '실제 정보공개법은 국가안보에 중대한 사안이나 개인인권 문제 등을 제외하고, 모든 공공정보를 개방하도록 규정하고 있다.',\n",
              " '아울러 전북을 제외한 타 자치단체는 버스재정지원 정보를 투명하게 공개하고 있다.',\n",
              " '이같은 시장에 최근 좋은 소식이 나와 주식 투자자들에게 주목을 받고 있다.',\n",
              " '대출 금리를 대폭 인하한 스탁론이 출시된 것이다.',\n",
              " '주가의 상승이 기대되는 종목을 발견했을 때, 부족한 투자금이 아쉬웠던 투자자들에게 좋은 소식이자 기회라고 할 수 있다.',\n",
              " '또한 오르지 않는 금리로 오랫동안 이용할 수 있어, 장기 투자자들에게는 좋은 소식이 아닐 수 없다.',\n",
              " '골드스탁론은 투자자들의 성향에 따른 다양한 상품을 보유, 최장 5년 동안 자유롭게 이용하며 마이너스 통장식으로 쓸 수 있다는 장점도 있다.',\n",
              " '최저금리 상품의 한도가 낮아 곧 마감될 예정인 것으로 알려졌다.',\n",
              " '골드스탁론에 대해 자세히 알고 싶은 투자자는 고객센터(1588-5356)로 연락하면 대출여부와 상관없이 24시간 언제든 전문상담원과 편리한 상담이 가능하다.',\n",
              " '보다 자세한 내용은 골드스탁론 홈페이지를 통해 확인 할 수 있다.',\n",
              " '매년 10월 16일부터 중국 쌍끌이(타망) 어선들이 우리 측 배타적 경제수역(EEZ)에 입역이 허가되면 제주해경은 불법조업 외국어선에 대해서 강력한 단속에 나선다.']"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hf9qdcpXVqfh"
      },
      "source": [
        "combine_matching_table = {}\n",
        "\n",
        "#combine_matching_table['있고,'] = '있'\n",
        "#combine_matching_table['있고'] = '있'\n",
        "\n",
        "#combine_matching_table['했고,'] = '했'\n",
        "#combine_matching_table['했고'] = '했'\n",
        "\n",
        "combine_matching_table['는데,'] = ''\n",
        "combine_matching_table['는데'] = ''\n",
        "\n",
        "combine_matching_table['어,'] = ''\n",
        "combine_matching_table['어'] = ''\n",
        "\n",
        "combine_matching_table['으나,'] = ''\n",
        "combine_matching_table['으나'] = ''\n",
        "\n",
        "combine_matching_table['으며,'] = ''\n",
        "combine_matching_table['으며'] = ''\n",
        "\n",
        "#combine_matching_table['았고,'] = '았'\n",
        "#combine_matching_table['았고'] = '았'\n",
        "\n",
        "combine_matching_table['지만,'] = ''\n",
        "combine_matching_table['지만'] = ''\n",
        "\n",
        "combine_matching_table['하고,'] = '한'\n",
        "#combine_matching_table['하고'] = '한'\n",
        "\n",
        "combine_matching_table['하면서,'] = '한'\n",
        "combine_matching_table['하면서'] = '한'\n",
        "\n",
        "combine_matching_table['리면,'] = '린'\n",
        "combine_matching_table['리면'] = '린'\n",
        "\n",
        "#combine_matching_table['이고,'] = '이'\n",
        "#combine_matching_table['이고'] = '이'\n",
        "\n",
        "combine_matching_table['되는데,'] = '된'\n",
        "combine_matching_table['되는데'] = '된'\n",
        "\n",
        "combine_matching_table['지자,'] = '진'\n",
        "combine_matching_table['지자'] = '진'\n",
        "\n",
        "#combine_matching_table['지만,'] = ''\n",
        "#combine_matching_table['지만'] = ''\n",
        "\n",
        "#combine_matching_table['면서도,'] = '였'\n",
        "#combine_matching_table['면서도'] = '였'\n",
        "\n",
        "combine_matching_table['면서,'] = ''\n",
        "combine_matching_table['면서'] = ''\n",
        "\n",
        "combine_matching_table['지만,'] = ''\n",
        "combine_matching_table['지만'] = ''\n",
        "\n",
        "combine_matching_table['서고,'] = '선'\n",
        "combine_matching_table['서고'] = '선'\n",
        "\n",
        "combine_matching_table['있어,'] = ''\n",
        "combine_matching_table['있어'] = ''\n",
        "\n",
        "combine_matching_table['기에,'] = ''\n",
        "combine_matching_table['기에'] = ''\n",
        "\n",
        "combine_matching_table['으나,'] = ''\n",
        "combine_matching_table['으나'] = ''\n",
        "\n",
        "combine_matching_table['하며,'] = '한'\n",
        "combine_matching_table['하며'] = '한'\n",
        "\n",
        "combine_matching_table['었던,'] = '었'\n",
        "combine_matching_table['었던'] = '었'\n",
        "\n",
        "combine_matching_table['으며,'] = ''\n",
        "combine_matching_table['으며'] = ''\n",
        "\n",
        "#combine_matching_table['되고,'] = ''\n",
        "#combine_matching_table['되고'] = ''\n",
        "\n",
        "#combine_matching_table['웠고,'] = '웠'\n",
        "#combine_matching_table['웠고'] = '웠'\n",
        "\n",
        "combine_matching_table['고,'] = ''\n",
        "combine_matching_table['고'] = ''\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66kuKtNUVppy"
      },
      "source": [
        "def combine_sentence(txt):\n",
        "    for c in combine_matching_table.keys():\n",
        "        if txt.endswith(c):\n",
        "            txt = txt.replace(c,combine_matching_table[c])\n",
        "            break\n",
        "    return txt"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "THly47izaSJW",
        "outputId": "274e99e6-5d5e-4a9e-bcf9-888c6a6e1d4d"
      },
      "source": [
        "txt = \"\"\"\n",
        "실제 정보공개법은 국가안보에 중대한 사안이나 개인인권 문제 등을 제외하고, 모든 공공정보를 개방하도록 규정하고 있다.\n",
        "\"\"\"\n",
        "sens = np.array(txt.split(' '))\n",
        "for i,sen in enumerate(sens):\n",
        "    sens[i] = combine_sentence(sen)\n",
        "\n",
        "' '.join(sens)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n실제 정보공개법은 국가안보에 중대한 사안이나 개인인권 문제 등을 제외한 모든 공공정보를 개방하도록 규정하 있다.\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-IYWKKHAldq"
      },
      "source": [
        "import random\n",
        "\n",
        "def crush_sent(txt,crush_rate=0.3):\n",
        "    sens = np.array(txt.split(' '))\n",
        "    for i,sen in enumerate(sens):\n",
        "        sens[i] = combine_sentence(sen)\n",
        "    l = len(sens)\n",
        "    r = int(l*crush_rate)\n",
        "    s = [i for i in range(l)]\n",
        "    c = random.sample(s,r)\n",
        "    t = [x for x in s if (x not in c)]\n",
        "    crushed_text = ' '.join(sens[t])\n",
        "    score = 0 #grammer_checker.transfer_learning([crushed_text])[1][0,1].item()\n",
        "    return crushed_text,score,txt"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IIFiYw3ABsl",
        "outputId": "682eab0f-60bb-41d0-8d34-76de16742c0b"
      },
      "source": [
        "crush_sent('가충순 의원과 이수의 의원은 16일 팔봉면 폰타나 리조트에서 한국지역신문협회 하계 워크샵에 참석했고 지역사회 발전을 위해 활발한 의정활동을 펼친 공로를 인정받아 우수의정대상을 수상했다.')"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('가충순 의원과 이수의 의원은 16일 팔봉면 리조트에서 한국지역신문협회 하계 워크샵에 참석했 의정활동을 펼친 인정받아 우수의정대상을 수상했다.',\n",
              " 0,\n",
              " '가충순 의원과 이수의 의원은 16일 팔봉면 폰타나 리조트에서 한국지역신문협회 하계 워크샵에 참석했고 지역사회 발전을 위해 활발한 의정활동을 펼친 공로를 인정받아 우수의정대상을 수상했다.')"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBOqlSY-aAv7"
      },
      "source": [
        "random.shuffle(sentences)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5UvR9L6FsVs",
        "outputId": "019d3d77-122f-4a63-8946-ab1648493c62"
      },
      "source": [
        "import json\n",
        "import pickle\n",
        "\n",
        "dataset = []\n",
        "\n",
        "def save_dataset():\n",
        "    with open(\"/content/drive/MyDrive/GAN_ENDE/sentence_complete_dataset.bin\", \"wb\") as fp:   #Pickling\n",
        "        pickle.dump(dataset, fp)\n",
        "\n",
        "for i,sentence in enumerate(sentences2):\n",
        "    print(f'\\r {i+1}/{len(sentences2)}', end=\"\", flush=True)\n",
        "    src,score,trg = crush_sent(sentence)\n",
        "    dataset.append((src,score,trg))\n",
        "    if i%10000 == 0:\n",
        "        save_dataset()\n",
        "\n",
        "save_dataset()\n",
        "\n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 3370416/3370416"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Q8oCSLngqMJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4243801-cca1-4a60-ae18-c819515a3201"
      },
      "source": [
        "len(dataset)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3370416"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHAT8v8_MLCL"
      },
      "source": [
        "import json\n",
        "import pickle\n",
        "if False:\n",
        "    with open(\"/content/drive/MyDrive/GAN_ENDE/sentence_complete_dataset.bin\", \"wb\") as fp:   #Pickling\n",
        "        pickle.dump(dataset, fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOAZpKj9SX8r"
      },
      "source": [
        "import json\n",
        "import pickle\n",
        "if True:\n",
        "    with open(\"/content/drive/MyDrive/GAN_ENDE/sentence_complete_dataset.bin\", \"rb\") as fp:   # Unpickling\n",
        "        dataset = pickle.load(fp)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBZT5JG2SMg3",
        "outputId": "7ccce017-3d15-4202-8241-c5b128983f2d"
      },
      "source": [
        "len(dataset)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4405001"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faaI8NH6AebB",
        "outputId": "d0701f30-a275-4190-cd4d-b3f61f9ee630"
      },
      "source": [
        "dataset[1]"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('폐렴과 일종인 지난해 사망원인 9위로 전년보다 각각 단계, 단계 상승하는 등 노인성 질병에 의한 사망률이 급증하는 추세다.',\n",
              " 0,\n",
              " '폐렴과 치매의 일종인 알츠하이머병은 지난해 사망원인 순위 3위와 9위로 전년보다 각각 한 단계, 두 단계 상승하는 등 노인성 질병에 의한 사망률이 급증하는 추세다.')"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qTVK90USnqR"
      },
      "source": [
        "# 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgWeybbqJrMj"
      },
      "source": [
        "pre_trained_kobert_model_name='kykim/bert-kor-base'\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "0340ab796cd44bf3a87e90e067e795d6",
            "c32b2b99d6f54c1ebc8181f81e6460c8",
            "ea9b5bb23e5449229a51f279455bef05",
            "6e9d1fbd1dd54801b066c1af65c48c4d",
            "20d1a76279b94f5d9eefd795171495d7",
            "b23428589509409ea72ceb48b2bd52fa",
            "610b9fe7151249368d36421b4c557fbc",
            "a2b908a235bc4ca688d4d1dd0539fa8f",
            "903d000a6fb64c35943c151f314aefa0",
            "1f53a74d9270471c8be3fa1d021476cb",
            "67599893a8d447f78ae8576f265b3d3d",
            "bb0697f86df247a68ee9d253f522822d",
            "b96a5b0e971745d0800016caaaed0e04",
            "759213c2699d492aa50589eb9f494983",
            "ce298454187143c7bc7a5633a8baf4a5",
            "d826fdd40de342c3b22a273649445471",
            "ce68aa6e70e84f10b4de859f45787daf",
            "a53b6afdb15148cda29e4d5ba428f8d2",
            "c6feb8f994154176bfbb5d616f4a1b4a",
            "8000f3719f1742b4b8b4e0385cd9e78a",
            "817620cb9c9e4fb9b66fd31326dce827",
            "490ee69e61ad4db19be904835207f28e",
            "71b013dd0b6b498db2828cbd8b004bf3",
            "5540254fd6f847ffbbd92c8c6b332bde",
            "d77fb501b03642b9ba02d4e36041c630",
            "4139ac3d3a164c20a1df8bd45513125c",
            "b0cd1144a0ad4dafa4b3ca5e185dcac1",
            "759843dd9c0d41299964360ade71a81f",
            "683df7599027436796046e97fa2a3401",
            "b72def4524e04f64a90d5549842d38cc",
            "cd46a8a3314d40faa534dac2f1d365dc",
            "83a1dfb60de04456a8aefde764a47adc",
            "e19be3228a204ce5948e05f7c17970fd"
          ]
        },
        "id": "NC6F1EakJtR-",
        "outputId": "3b462168-2180-43b2-a725-f03a0b7a24ec"
      },
      "source": [
        "from transformers import EncoderDecoderModel, BertTokenizerFast\n",
        "import torch\n",
        "\n",
        "tokenizer = BertTokenizerFast.from_pretrained(pre_trained_kobert_model_name)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0340ab796cd44bf3a87e90e067e795d6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/344k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bb0697f86df247a68ee9d253f522822d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/80.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "71b013dd0b6b498db2828cbd8b004bf3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/725 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QopjnhrJvvJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4297415e-e65d-448a-c982-d30e2ae1184b"
      },
      "source": [
        "op = tokenizer('옛날 어느 집에 귀여운 여자 아기가 태어났어요.[SEP]아기는 무럭무럭 자라서 예쁘고 마음씨 고운 소녀가 되었어요.', return_tensors=\"pt\",padding=\"max_length\", truncation=True, max_length=64)\n",
        "print(op)\n",
        "print(\"Tokens (str)      : {}\".format([tokenizer.convert_ids_to_tokens(s) for s in op['input_ids'].tolist()[0]]))\n",
        "print(\"Tokens (int)      : {}\".format(op['input_ids'].tolist()[0]))\n",
        "print(\"Tokens (attn_mask): {}\\n\".format(op['attention_mask'].tolist()[0]))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[    2, 17463, 14385, 14662, 15886, 14891, 17818, 33791, 13972,  2016,\n",
            "             3, 35244,  4215,  8669,  8035,  8669, 19206,  8044, 17364, 14125,\n",
            "          8472, 26268, 18857,  8048, 17292,  2016,     3,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
            "Tokens (str)      : ['[CLS]', '옛날', '어느', '집에', '귀여운', '여자', '아기가', '태어났', '##어요', '.', '[SEP]', '아기는', '무', '##럭', '##무', '##럭', '자라', '##서', '예쁘고', '마음', '##씨', '고운', '소녀', '##가', '되었어요', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
            "Tokens (int)      : [2, 17463, 14385, 14662, 15886, 14891, 17818, 33791, 13972, 2016, 3, 35244, 4215, 8669, 8035, 8669, 19206, 8044, 17364, 14125, 8472, 26268, 18857, 8048, 17292, 2016, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Tokens (attn_mask): [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WT0qXS3KKONG"
      },
      "source": [
        "curren_sentence_num = 0\n",
        "dataset_iterator = []"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vp0trRIbLrff"
      },
      "source": [
        "import pickle\n",
        "\n",
        "if False:\n",
        "    with open(\"/content/drive/MyDrive/GAN_ENDE/sentence_complete_tokenized_dataset.bin\", \"wb\") as fp:   #Pickling\n",
        "        pickle.dump(dataset_iterator, fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wH6iQN5b2bJ0"
      },
      "source": [
        "import pickle\n",
        "\n",
        "if True:\n",
        "    with open(\"/content/drive/MyDrive/GAN_ENDE/sentence_complete_tokenized_dataset.bin\", \"rb\") as fp:   # Unpickling\n",
        "        dataset_iterator = pickle.load(fp)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jea-GWfCopN",
        "outputId": "3030a35a-8e8e-462c-aba5-d340c4117066",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(dataset_iterator) * 32"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3300032"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_spwQAHuJ0UL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7b128d5e-db31-4c94-e48c-bb37f25dd318"
      },
      "source": [
        "\n",
        "encoder_max_length = 64\n",
        "decoder_max_length = 64\n",
        "batch_size = 32 #4 # 64, 128\n",
        "\n",
        "for cnt in range(curren_sentence_num,len(dataset),batch_size):\n",
        "    print(f'\\r {cnt+1}/{len(dataset)}', end=\"\", flush=True)\n",
        "    batch = {}\n",
        "    batch['input_ids'] = []\n",
        "    batch['attention_mask'] = []\n",
        "    batch['decoder_input_ids'] = []\n",
        "    batch['decoder_attention_mask'] = []\n",
        "    batch['labels'] = []\n",
        "\n",
        "    for i in range(cnt,cnt+batch_size):\n",
        "        (src,score,trg) = dataset[i]\n",
        "        inputs = tokenizer(src, padding=\"max_length\", truncation=True, max_length=encoder_max_length)\n",
        "        outputs = tokenizer(trg, padding=\"max_length\", truncation=True, max_length=decoder_max_length)\n",
        "        batch[\"input_ids\"].append(inputs.input_ids)\n",
        "        batch[\"attention_mask\"].append(inputs.attention_mask)\n",
        "        batch[\"decoder_input_ids\"].append(outputs.input_ids)\n",
        "        batch[\"decoder_attention_mask\"].append(outputs.attention_mask)\n",
        "        batch[\"labels\"].append(outputs.input_ids.copy())\n",
        "    \n",
        "    dataset_iterator.append(batch)\n",
        "    if cnt%100000 == 0:\n",
        "        with open(\"/content/drive/MyDrive/GAN_ENDE/sentence_complete_tokenized_dataset.bin\", \"wb\") as fp:   #Pickling\n",
        "            pickle.dump(dataset_iterator, fp)\n",
        "            print('\\n저장')\n",
        "\n",
        "with open(\"/content/drive/MyDrive/GAN_ENDE/sentence_complete_tokenized_dataset.bin\", \"wb\") as fp:   #Pickling\n",
        "    pickle.dump(dataset_iterator, fp)           "
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1/3370416\n",
            "저장\n",
            " 100001/3370416\n",
            "저장\n",
            " 200001/3370416\n",
            "저장\n",
            " 300001/3370416\n",
            "저장\n",
            " 400001/3370416\n",
            "저장\n",
            " 500001/3370416\n",
            "저장\n",
            " 600001/3370416\n",
            "저장\n",
            " 700001/3370416\n",
            "저장\n",
            " 800001/3370416\n",
            "저장\n",
            " 900001/3370416\n",
            "저장\n",
            " 1000001/3370416\n",
            "저장\n",
            " 1100001/3370416\n",
            "저장\n",
            " 1200001/3370416\n",
            "저장\n",
            " 1300001/3370416\n",
            "저장\n",
            " 1400001/3370416\n",
            "저장\n",
            " 1500001/3370416\n",
            "저장\n",
            " 1600001/3370416\n",
            "저장\n",
            " 1700001/3370416\n",
            "저장\n",
            " 1800001/3370416\n",
            "저장\n",
            " 1900001/3370416\n",
            "저장\n",
            " 2000001/3370416\n",
            "저장\n",
            " 2100001/3370416\n",
            "저장\n",
            " 2200001/3370416\n",
            "저장\n",
            " 2300001/3370416\n",
            "저장\n",
            " 2400001/3370416\n",
            "저장\n",
            " 2500001/3370416\n",
            "저장\n",
            " 2600001/3370416\n",
            "저장\n",
            " 2700001/3370416\n",
            "저장\n",
            " 2800001/3370416\n",
            "저장\n",
            " 2900001/3370416\n",
            "저장\n",
            " 3000001/3370416\n",
            "저장\n",
            " 3100001/3370416\n",
            "저장\n",
            " 3200001/3370416\n",
            "저장\n",
            " 3300001/3370416\n",
            "저장\n",
            " 3370401/3370416"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-8c72b4efc73b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcnt\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"max_length\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_max_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"max_length\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_max_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foqQQ0h9hkTQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89dd2560-32ac-490a-c291-5cb23c00d87a"
      },
      "source": [
        "len(dataset_iterator)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "105325"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRELcFHphYDV"
      },
      "source": [
        "import pickle\n",
        "\n",
        "if True:\n",
        "    with open(\"/content/drive/MyDrive/GAN_ENDE/sentence_complete_tokenized_dataset.bin\", \"wb\") as fp:   #Pickling\n",
        "        pickle.dump(dataset_iterator, fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZHsFJzOPjNR"
      },
      "source": [
        "import pickle\n",
        "\n",
        "if True:\n",
        "    with open(\"/content/drive/MyDrive/GAN_ENDE/sentence_complete_tokenized_dataset.bin\", \"rb\") as fp:   # Unpickling\n",
        "        dataset_iterator = pickle.load(fp)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ar-Q8mB2J5g3"
      },
      "source": [
        "### 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFaE-hk7QxyW"
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oWfnAXdQyQ-"
      },
      "source": [
        "def generate_summary(text):\n",
        "    # cut off at BERT max length 512\n",
        "    sens = nltk.sent_tokenize(text)\n",
        "    assert(len(sens) == 2)\n",
        "    inputs = tokenizer(sens[0].strip()+'[SEP]'+sens[1].strip(), padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n",
        "    input_ids = inputs.input_ids.to(device)\n",
        "    attention_mask = inputs.attention_mask.to(device)\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    outputs = model.generate(input_ids, attention_mask=attention_mask).cpu().detach().numpy()[0]\n",
        "    o=[]\n",
        "    for token in outputs:\n",
        "        if token == tokenizer.pad_token_id:\n",
        "            break\n",
        "        o.append(token)\n",
        "    output_str = tokenizer.batch_decode([o], skip_special_tokens=True)[0]\n",
        "\n",
        "    return output_str"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDauosgHRhT_"
      },
      "source": [
        "def generate_summary2(text):\n",
        "    inputs = tokenizer(text, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n",
        "    input_ids = inputs.input_ids.to(device)\n",
        "    attention_mask = inputs.attention_mask.to(device)\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    outputs = model.generate(input_ids, attention_mask=attention_mask).cpu().detach().numpy()[0]\n",
        "    o=[]\n",
        "    for token in outputs:\n",
        "        if token == tokenizer.pad_token_id:\n",
        "            break\n",
        "        o.append(token)\n",
        "    output_str = tokenizer.batch_decode([o], skip_special_tokens=True)[0]\n",
        "\n",
        "    return output_str"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YW5tbQ0GIylS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228,
          "referenced_widgets": [
            "c4267915b6404b8fb3e56c31bd9711fa",
            "950ef53b2968454b8dfbedeb1112da6c",
            "81ab4ec33baf425f84fd341bd14087ad",
            "7f7cdf5cda774887bd4c86d2fbecb65d",
            "125a15c68f6a4a32a6661d2aa8b0310c",
            "aaa7a515147e4e76be3303fc8c304f4c",
            "272e8cd0cae1495abb76d4dd9a3a5f15",
            "e4f72dcfa3644688a645b2fecc939626",
            "a64bc891b8614356bb63d01a25b0af08",
            "0c3be9f669124a7cbd1e1359edbc9f28",
            "0c2e39e7a6ba4423bdae9f1b28485bc3"
          ]
        },
        "outputId": "3a1a1dad-10fa-46f6-ac91-46e5a66f490f"
      },
      "source": [
        "from transformers import EncoderDecoderModel, BertTokenizerFast\n",
        "\n",
        "try:\n",
        "    del model\n",
        "    print('delete model')\n",
        "except Exception as ex:\n",
        "    pass\n",
        "\n",
        "use_pretrained_model = False\n",
        "\n",
        "if use_pretrained_model:\n",
        "    model = EncoderDecoderModel.from_pretrained(\"/content/drive/MyDrive/GAN_ENDE/sentence_complete_model\")\n",
        "    print('Load from pre-trained model...')\n",
        "else:\n",
        "    model = EncoderDecoderModel.from_encoder_decoder_pretrained(pre_trained_kobert_model_name, pre_trained_kobert_model_name) # initialize Bert2Bert from pre-trained checkpoints\n",
        "    print('Initialize with ',pre_trained_kobert_model_name)\n",
        "\n",
        "model.config.decoder_start_token_id = tokenizer.cls_token_id\n",
        "model.config.eos_token_id = tokenizer.sep_token_id\n",
        "model.config.pad_token_id = tokenizer.pad_token_id\n",
        "model.config.vocab_size = model.config.encoder.vocab_size\n",
        "\n",
        "model.config.max_length = 142\n",
        "model.config.min_length = 56\n",
        "model.config.no_repeat_ngram_size = 3\n",
        "model.config.early_stopping = True\n",
        "model.config.length_penalty = 2.0\n",
        "model.config.num_beams = 4\n",
        "\n",
        "N_EPOCHS = 1"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c4267915b6404b8fb3e56c31bd9711fa",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/476M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertLMHeadModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertLMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertLMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertLMHeadModel were not initialized from the model checkpoint at kykim/bert-kor-base and are newly initialized: ['bert.encoder.layer.8.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.6.crossattention.self.query.weight', 'bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.1.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.7.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.self.value.weight', 'bert.encoder.layer.5.crossattention.self.query.weight', 'bert.encoder.layer.2.crossattention.output.dense.bias', 'bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.9.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.2.crossattention.output.dense.weight', 'bert.encoder.layer.5.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.9.crossattention.self.key.weight', 'bert.encoder.layer.5.crossattention.self.value.weight', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.3.crossattention.self.key.bias', 'bert.encoder.layer.8.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.8.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.self.key.bias', 'bert.encoder.layer.10.crossattention.output.dense.bias', 'bert.encoder.layer.3.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.5.crossattention.self.value.bias', 'bert.encoder.layer.11.crossattention.self.key.weight', 'bert.encoder.layer.9.crossattention.self.key.bias', 'bert.encoder.layer.10.crossattention.output.dense.weight', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.6.crossattention.output.dense.weight', 'bert.encoder.layer.11.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.9.crossattention.self.query.weight', 'bert.encoder.layer.7.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.self.value.bias', 'bert.encoder.layer.3.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.10.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.self.value.bias', 'bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.11.crossattention.self.query.weight', 'bert.encoder.layer.10.crossattention.self.key.bias', 'bert.encoder.layer.5.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.9.crossattention.self.value.bias', 'bert.encoder.layer.4.crossattention.self.key.weight', 'bert.encoder.layer.11.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.7.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.self.query.weight', 'bert.encoder.layer.5.crossattention.self.key.bias', 'bert.encoder.layer.5.crossattention.output.dense.bias', 'bert.encoder.layer.8.crossattention.self.value.bias', 'bert.encoder.layer.11.crossattention.self.value.bias', 'bert.encoder.layer.3.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.5.crossattention.self.key.weight', 'bert.encoder.layer.11.crossattention.output.dense.bias', 'bert.encoder.layer.10.crossattention.self.query.bias', 'bert.encoder.layer.11.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.9.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.self.query.bias', 'bert.encoder.layer.1.crossattention.self.key.weight', 'bert.encoder.layer.1.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.self.query.weight', 'bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.9.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.self.key.bias', 'bert.encoder.layer.1.crossattention.self.value.bias', 'bert.encoder.layer.6.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.self.query.bias', 'bert.encoder.layer.3.crossattention.self.query.bias', 'bert.encoder.layer.7.crossattention.self.value.weight', 'bert.encoder.layer.6.crossattention.self.query.bias', 'bert.encoder.layer.6.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.self.key.weight', 'bert.encoder.layer.7.crossattention.self.query.bias', 'bert.encoder.layer.7.crossattention.output.dense.bias', 'bert.encoder.layer.3.crossattention.self.query.weight', 'bert.encoder.layer.9.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.7.crossattention.self.query.weight', 'bert.encoder.layer.11.crossattention.self.key.bias', 'bert.encoder.layer.8.crossattention.output.dense.bias', 'bert.encoder.layer.4.crossattention.output.dense.weight', 'bert.encoder.layer.10.crossattention.self.value.weight', 'bert.encoder.layer.8.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.7.crossattention.self.value.bias', 'bert.encoder.layer.3.crossattention.self.value.weight', 'bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.output.dense.bias', 'bert.encoder.layer.9.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.self.key.bias', 'bert.encoder.layer.11.crossattention.output.dense.weight', 'bert.encoder.layer.2.crossattention.self.value.weight', 'bert.encoder.layer.6.crossattention.self.value.weight', 'bert.encoder.layer.9.crossattention.self.query.bias', 'bert.encoder.layer.3.crossattention.self.value.bias', 'bert.encoder.layer.4.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.output.dense.weight', 'bert.encoder.layer.6.crossattention.self.key.weight', 'bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.6.crossattention.output.dense.bias', 'bert.encoder.layer.5.crossattention.output.dense.weight', 'bert.encoder.layer.5.crossattention.self.query.bias', 'bert.encoder.layer.4.crossattention.self.value.weight', 'bert.encoder.layer.3.crossattention.output.dense.weight', 'bert.encoder.layer.4.crossattention.self.key.bias', 'bert.encoder.layer.7.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.11.crossattention.self.value.weight', 'bert.encoder.layer.8.crossattention.self.query.bias', 'bert.encoder.layer.3.crossattention.output.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialize with  kykim/bert-kor-base\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJn82eSXhuNz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e0519d4-2987-4d92-8c75-916565d3db93"
      },
      "source": [
        "print('\\tTarget text:',generate_summary2('옛날 귀여운 아기가 마음씨 소녀가 되었 어머니는 돌아가셨다.')) "
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTarget text: ##가가가 가 가 가 다 다 다 아 아 아 어 어 어 아 아 다 다 어 어 다 다다다다어어어 어 어어 어어어다다 다 다어어려어어난난난어어칭칭칭다다칭칭어어구어어닝닝닝칭칭난난칭칭닝닝다다닝닝응응응칭칭응응닝닝난난닝닝어어응응어어여여어어워칭칭잉칭칭구어칭응칭닝어칭닝칭닝응칭응닝칭응어닝칭어칭어닝응닝응어칭칭을칭칭ing칭칭칭을\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqWYHgr5QqrZ"
      },
      "source": [
        "from transformers import BertTokenizer, AutoTokenizer, BertForSequenceClassification, AdamW, BertConfig, get_linear_schedule_with_warmup\n",
        "\n",
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n",
        "        \n",
        "criterion = nn.CrossEntropyLoss(ignore_index = tokenizer.pad_token_id)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41pica0wQnEa"
      },
      "source": [
        "def train2(model, iterator, optimizer, criterion, scheduler,clip):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    optimizer.zero_grad()\n",
        "    #for i, batch in enumerate(iterator):\n",
        "    for i in range(0,len(iterator)):\n",
        "        batch = iterator[i]\n",
        "        print(f'\\r batch {i+1}/{len(iterator)}', end=\"\", flush=True)\n",
        "\n",
        "        input_ids = torch.tensor(batch[\"input_ids\"]).to(device)\n",
        "        attention_mask = torch.tensor(batch[\"attention_mask\"]).to(device)\n",
        "        decoder_input_ids= torch.tensor(batch[\"decoder_input_ids\"]).to(device)\n",
        "        decoder_attention_mask= torch.tensor(batch[\"decoder_attention_mask\"]).to(device)\n",
        "        labels= torch.tensor(batch[\"labels\"]).to(device)\n",
        "\n",
        "            \n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask,\n",
        "                        decoder_input_ids=decoder_input_ids, \n",
        "                        decoder_attention_mask=decoder_attention_mask,\n",
        "                        labels=labels)\n",
        "\n",
        "        loss = outputs.loss #* b_rewards\n",
        "        loss.backward()\n",
        "        ##print('loss',loss)\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "\n",
        "        scheduler.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        ##print('epoch_loss',epoch_loss)\n",
        "\n",
        "        if i%1000 == 0:\n",
        "            print('\\tTarget text:',generate_summary2('옛날 귀여운 아기가 마음씨 소녀가 되었 어머니는 돌아가셨다.'))      \n",
        "            model.save_pretrained(\"/content/drive/MyDrive/GAN_ENDE/sentence_complete_model\")\n",
        "            model.train()\n",
        "            \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAO-U5mKQs3V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "428b4167-4838-4258-e0b7-65148d6233bb"
      },
      "source": [
        "import time\n",
        "import random\n",
        "import datetime\n",
        "import math\n",
        "\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "model.to(device)\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(dataset_iterator) * N_EPOCHS\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    train_loss = train2(model, dataset_iterator, optimizer, criterion, scheduler,CLIP)\n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    #if valid_loss < best_valid_loss:\n",
        "    #    best_valid_loss = valid_loss\n",
        "    #    torch.save(model.state_dict(), 'tut6-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "\n",
        "    doc_end_time = time.time()\n",
        "    model.save_pretrained(\"/content/drive/MyDrive/GAN_ENDE/sentence_complete_model\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " batch 1/103126\tTarget text: ##가가가 가 가 가 다 다 다 아 다 다 어 어 어 다 다다 다 다 와 어 어어 어 어 아 어어어어 어 아 아 어 아어어 아 어 어 흐어 어 흐 어어 흐어어 흐 어 어 [어어허어어려어어난어어 [ [ [ 어 [ [어 어 [ 어 어 응어어응어어에어어닝닝어 어어닝어어아어어여어어와어어칭어어창어어해어어잉어어구어어규어어타어어차어어나타어어어를어어워어어저어어제어어\n",
            " batch 1001/103126\tTarget text: 아기 아기 아기 시절의 모습이 고스란히 담긴 엽서가 완성됐다.\n",
            " batch 2001/103126\tTarget text: 옛날 귀여운 아기 아기가 마음씨 좋은 마음씨 소녀 소녀가 되었고, 어머니는 어머니 어머니가 돌아가신 후 돌아가셨다고 한다.\n",
            " batch 3001/103126\tTarget text: 옛날 귀여운 아기가 마음에 들었던 것은 마음씨 소녀 소녀가 되었고, 어머니는 돌아가셨다는 전설이 있다. 고했다 옛날에는 어머니는 어머니가 돌아가셨다고 한다. 옛날 어머니가 돌아가신 것이다 옛날 어머니는 돌아가신 적었다. 할머니가 돌아가셨다.\n",
            " batch 4001/103126\tTarget text: 옛날 귀여운 아기가 어린 아기 소녀가 마음씨 소녀가 되었고 어머니는 돌아가셨는데 어머니는 돌아가셨다고 한다. 할머니의 어머니가 돌아가셨다는 이야기는 돌아가신 후 어머니가 돌아가신 것으로 전해졌다. 고산산 어머니는 지금은 돌아가셨다. 돌아가신 어머니가 돌아가셨다\n",
            " batch 5001/103126\tTarget text: 옛날 어린 시절 귀여운 아기가 마음씨 좋은 소녀가 되었으나 어머니는 돌아가셨다가 지금은 돌아가셨다.\n",
            " batch 6001/103126\tTarget text: 옛날 어린 시절 귀여운 아기가 마음씨 소녀가 되었고 어머니는 돌아가셨다고 한다.\n",
            " batch 7001/103126\tTarget text: 옛날 어린 시절 귀여운 아기가 마음씨 좋은 소녀가 되었고 어머니는 돌아가셨다가 지금은 돌아가셨다는 후문이다.\n",
            " batch 8001/103126\tTarget text: 옛날 귀여운 아기 아기가 마음씨 좋은 소녀가 되었고, 어머니는 돌아가셨다는 어머니는 안타깝게도 돌아가셨다.\n",
            " batch 9001/103126\tTarget text: 옛날 귀여운 아기 아기가 마음씨 소녀가 되었고, 어머니는 돌아가시고 어머니는 일찍 돌아가셨다고 전해진다. 고 전해진다 ) 고 어머니는 돌아가셨다. 옛날 어린 시절이 지나고 지금은 돌아가셨다 ( 사진 ) 고 한다 ( 사진 오른쪽 오른쪽 ) 고 회상한다 ( 사진 왼쪽 )\n",
            " batch 10001/103126\tTarget text: 옛날 귀여운 아기가 마음씨 좋은 소녀가 되었고, 어머니는 돌아가시고 어머니는 세상을 떠나셨다가 세상을 떠났다.\n",
            " batch 11001/103126\tTarget text: 옛날 귀여운 아기가 마음씨 좋은 소녀가 되었고, 어머니는 돌아가시고, 어머니는 일찍 돌아가셨다 ( ) 고 한다 ). 고 어머니는 안타깝게 돌아가셨다 ) 고 했다 ( (. -. ( - 0 ( - )\n",
            " batch 12001/103126\tTarget text: 옛날 귀여운 아기 아기가 마음씨 좋은 소녀가 되었고, 어머니는 돌아가시고 어머니는 안타깝게 돌아가시고 어머니가 돌아가셨다 ( ) 는 슬픈 사연이 있었다.\n",
            " batch 13001/103126\tTarget text: 옛날 귀여운 아기가 마음씨 좋은 소녀가 되었고, 어머니는 돌아가셨다가 지금은 세상을 떠나시고.. ( ) ( 오른쪽 ) ( 왼쪽 ) - / / / - b ) / b ( ) / b / b b\n",
            " batch 14001/103126\tTarget text: 옛날 귀여운 아기가 어린 아기로 마음씨 소녀가 되었고 어머니는 돌아가셨다. 고 어머니는 돌아가시고 돌아가시고 말았다. ( 사진 오른쪽 두번째 ) 고 ( 오른쪽 ).\n",
            " batch 15001/103126\tTarget text: 옛날 귀여운 아기가 귀여운 마음씨 소녀가 되었지만 어머니는 돌아가시고 어머니는 돌아가셨다가 세상을 떠나셨다. 고 고 ( ) 이 되었다.\n",
            " batch 16001/103126\tTarget text: 옛날 귀여운 아기가 태어나 마음씨 좋은 소녀가 되었고, 어머니는 돌아가셨다가 어머니는 돌아가시고 세상을 떠났다가 세상을 뜨셨다. 옛날이다. 고 말했다.. 고 ( ) 고 불렀다 ( / / / / ).\n",
            " batch 17001/103126\tTarget text: 옛날 귀여운 아기가 마음씨 소녀가 되었고, 어머니는 돌아가셨다가 돌아가셨다.....\n",
            " batch 18001/103126\tTarget text: 옛날 귀여운 아기가 마음씨 좋은 소녀가 되었으나 어머니는 돌아가셨다는 후문이다. 고 말했다.\n",
            " batch 19001/103126\tTarget text: 옛날 귀여운 아기가 귀여운 아기처럼 마음씨 좋은 소녀가 되었고 어머니는 돌아가셨다가 지금은 돌아가셨다.\n",
            " batch 20001/103126\tTarget text: 옛날 어린 아기가 귀여운 아기가 되어 마음씨 소녀가 되었고 어머니는 돌아가시고 돌아가셨다가 지금은 안타깝게 돌아가시고....\n",
            " batch 21001/103126\tTarget text: 옛날 귀여운 아기가 마음씨 좋은 소녀가 되었고, 어머니는 돌아가셨다는 어머니 말씀에 어머니는 돌아가시고 돌아가셨다셨다.. 고 말씀하신 말씀... 고 고 ( ( ), 어머니 어머니 - 어머니 - 흐 - 흐 흐 / 흐 흐 흐 -\n",
            " batch 22001/103126\tTarget text: 옛날 귀여운 아기가 어린 아기처럼 마음씨 소녀가 되었고 어머니는 돌아가셨다가 지금은 안타깝게 돌아가셨다. 고 말씀하신다. 고 고 ( ), 고귀한 고귀 ( ) 고 ( ( / / ) 고 ( ).\n",
            " batch 23001/103126\tTarget text: 옛날 귀여운 아기가 어린 아기처럼 마음씨 소녀가 되었고 어머니는 돌아가셨다는 전설이 있다.\n",
            " batch 24001/103126\tTarget text: 옛날 귀여운 아기가 귀여운 아기처럼 마음씨 소녀가 되었고, 어머니는 돌아가셨다가 지금은 돌아가셨다. 고 말했다.\n",
            " batch 25001/103126\tTarget text: 옛날 귀여운 아기가 태어나 마음씨 좋은 소녀가 되었고, 어머니는 돌아가셨다. ( ) 고 어머니는 안타깝게 돌아가셨다 고 말씀하신다.. 고 말했다.. 고 고 (? / / ~ / ).\n",
            " batch 26001/103126\tTarget text: 옛날 귀여운 아기가 어린 아기처럼 마음씨 소녀가 되었고, 어머니는 돌아가셨다는 사연이 전해지고 있다 ( ) ).\n",
            " batch 27001/103126\tTarget text: 옛날 귀여운 아기가 마음씨 고운 소녀가 되었고, 어머니는 돌아가셨다는데 어머니는 돌아가시고셨다가 돌아가셨다가셨다. 고 한다..\n",
            " batch 28001/103126\tTarget text: 옛날 귀여운 아기가 마음씨 고운 소녀가 되었고, 어머니는 돌아가셨다는데 어머니는 돌아가시고 돌아가셨다 ( 사진 오른쪽 ). / ( 왼쪽 ) ) ( 오른쪽 ) / / / ( 왼쪽줄 )...\n",
            " batch 29001/103126\tTarget text: 옛날 귀여운 아기가 태어나 마음씨 소녀가 되었고, 어머니는 돌아가셨다는 소식을 듣고 어머니는 안타깝게 돌아가셨다. 고 합니다..\n",
            " batch 30001/103126\tTarget text: 옛날 귀여운 아기가 마음씨 착한 소녀가 되었고, 어머니는 돌아가셨다. 고 어머니는 돌아가시다셨다.. 고 말씀하신 것 같다. 고 고 말했다. 옛날의 그 그머니가 돌아가셨다 ( / / ). 고 말했다 ).\n",
            " batch 31001/103126\tTarget text: 옛날 귀여운 아기가 마음씨 착한 소녀가 되었고, 어머니는 돌아가셨다고 전해져왔다. 옛날에는 돌아가셨다 고 했다. 할머니 ( ) 가 되었다 고 회상했다 (? ~ / / - ).\n",
            " batch 32001/103126\tTarget text: 옛날 귀여운 아기가 마음에 들어 마음씨 소녀가 되었고, 어머니는 돌아가셨다. 옛날에는 할아버지가 돌아가셨다 고 했다.. ( ) 고 말했다. 고 ( ( ) 고 한다. ( -..\n",
            " batch 33001/103126\tTarget text: 옛날 귀여운 아기가 마음씨 고운 소녀가 되었고, 어머니는 돌아가셨다는 이야기를 들려주었다고 전해진다.\n",
            " batch 34001/103126\tTarget text: 옛날 귀여운 아기가 마음씨 착한 소녀가 되었고, 어머니는 돌아가셨다는 이야기를 들려주셨다고 전해지고. ( ) / / ~... ( ( ) / / / ) / ( / )\n",
            " batch 35001/103126\tTarget text: 옛날 귀여운 아기가 마음씨 착한 소녀가 되었으며, 어머니는 돌아가셨다... ( ) (?., / ~? ) ( ) - - ) ).\n",
            " batch 36001/103126\tTarget text: 옛날 귀여운 아기가 마음씨 착한 소녀가 되었고, 어머니는 돌아가셨다. 고 어머니께 말씀드립니다 고 말했다. ( ), 어머니는 어머니 ( ) 가 돌아가셨다 고 한다... ) 고 어머니 (? ).\n",
            " batch 37001/103126\tTarget text: 옛날 귀여운 아기가 마음씨 고운 소녀가 되었고, 어머니는 돌아가셨다가 지금은 돌아가셨다. ( / ) ~ - - = - - d - ) - - dd d - d\n",
            " batch 38001/103126\tTarget text: 옛날 귀여운 아기가 되어 마음씨 착한 소녀가 되었고, 어머니는 돌아가셨다는 후문이다 ). ( / ) (? ~ - -!\n",
            " batch 39001/103126\tTarget text: 옛날 귀여운 아기가 태어나 마음씨 소녀가 되었고, 어머니는 돌아가셨다는 이야기를 듣고 어머니께 모시고셨다...\n",
            " batch 40001/103126\tTarget text: 옛날 귀여운 아기가 태어나 마음씨 고운 소녀가 되었고, 어머니는 돌아가셨다. ( ) - - / / ~! =. ) ]\n",
            " batch 41001/103126\tTarget text: 옛날 귀여운 아기가 마음씨 좋은 소녀가 되었고, 어머니는 돌아가셨다는 후문이다...\n",
            " batch 42001/103126\tTarget text: 옛날 귀여운 아기가 마음에 들어 마음씨 소녀가 되었고, 어머니는 돌아가셨다가 지금은 돌아가셨다.. ( /. ~ - ) 고 하시던 어머니 ( ) 는 돌아가셨다 (?? ).\n",
            " batch 43001/103126\tTarget text: 옛날 귀여운 아기가 마음씨 좋은 소녀가 되었고, 어머니는 결국 돌아가셨다가 지금은 쓸쓸하게 돌아가셨다. 옛날이다 고 말했다 고 했다 고 고 말했다 ( / ~ - ) 고 고 했다. 고 고 고.\n",
            " batch 44001/103126\tTarget text: 옛날 귀여운 아기가 어린 시절 마음씨 소녀가 되었고, 어머니는 돌아가셨다가 지금은 돌아가셨다. 고 말했다. 고 ( ) 고 했다. 고 고 ( ( ) 고 ) 고 ( - - ), 고 (? ).\n",
            " batch 45001/103126\tTarget text: 옛날 귀여운 아기가 태어나 마음씨 좋은 소녀가 되었고, 어머니는 돌아가셨다. 고 말했다. 고 ( ) 고 말했다 고 고 ( ( ) 고 (? ) 고 ( ) (? ) 는 고 ( - ) 라고 말했다.\n",
            " batch 46001/103126\tTarget text: 옛날 귀여운 아기가 마음씨 좋은 소녀가 되었고, 그 어머니는 돌아가셨다가 지금은 돌아가셨다. 옛날에 돌아가셨다 고 말했다 고 고명했다 고 는 말했다. 고 고씨는 말했다 라고 말했다. 이튿날에는 어머니는 어머니가 돌아가셨다 ( 고.\n",
            " batch 47001/103126\tTarget text: 옛날 귀여운 아기가 마음씨 좋은 소녀가 되었고, 어머니는 돌아가셨다가 지금은 돌아가셨다 고 말했다 고 했다. 고 ( ) 고 말했다 (? / / - - ] ). 고 - - - ]. 고.\n",
            " batch 48001/103126\tTarget text: 옛날 귀여운 아기가 되어 마음씨 따뜻한 소녀가 되었고, 어머니는 홀어 돌아가셨다가 지금은 돌아가셨다. 옛날이다 고 말했다 고 하시던 어머니는 돌아가셨다 ( / / ) 고 하셨다. 고 고 말했다. 고 는 어머니는 어머니 ( ).\n",
            " batch 49001/103126\tTarget text: 옛날 귀여운 아기가 어느새 마음씨 소녀가 되었고, 어머니는 돌아가셨다가 지금은 병으로 돌아가셨다는 것 - 사진 - 사진 > - - - - - - > ( / ) - ( / / / )\n",
            " batch 50001/103126\tTarget text: 옛날 귀여운 아기가 어느새 마음씨 소녀가 되었고, 어머니는 일찍 돌아가셨다는 후문이다 는 후문 ( ) 이 되었다 고 한다... - - = - - ] - - - > > > -\n",
            " batch 51001/103126\tTarget text: 옛날 귀여운 아기가 마음씨 어린 소녀가 되었고, 어머니는 돌아가셨다. 고 어머니는 어머니에게 돌아가셨다 ( ) 고 말했다. 고 고 말했다 (. / ~ - + ). 고 는 어머니 ( ) 는.\n",
            " batch 52001/103126\tTarget text: 옛날 귀여운 아기가 되어 마음씨 좋은 소녀가 되었고, 어머니는 돌아가셨다는 후문이다. 옛날은 이렇게셨다..... 그 시절 어머니는 돌아가셨고, 어머니는 안타깝고 쓸쓸하게 돌아가셨다 ( / - ).\n",
            " batch 53001/103126\tTarget text: 옛날 귀여운 아기가 마음씨 착한 소녀가 되었고, 어머니는 갑자기 돌아가셨다. 고 어머니는 돌아가셨다 ( ) 고 말했다. 고 고규 (... 고 고 ( ) 했다 고 는 어머니 (? ) 고.\n",
            " batch 54001/103126\tTarget text: 옛날 귀여운 아기가 태어나면 마음씨 소녀가 되었고, 어머니는 돌아가셨다가 어머니가 돌아가셨다... ( / ) (?? ), 어머니는 어머니 ( ) 로 돌아가셨다 (. )..\n",
            " batch 55001/103126\tTarget text: 옛날 귀여운 아기가 태어나자 마음씨 좋은 소녀가 되었고, 어머니는 돌아가셨다가 지금은 돌아가셨다. 옛날이다 고 말했다 고 했다 고 는 말했다. 고 ( ) 고 ( ( ) 라고도 했다. 고 고 (,\n",
            " batch 56001/103126\tTarget text: 옛날 귀여운 아기가 태어나자 마음씨 좋은 소녀가 되었고, 어머니는 돌아가셨다가 지금은 병치병으로 돌아가셨다. 고인이셨다 고 ( ) 고했다. 고 ( ( ) 하시던 어머니는 돌아가셨고, 아버지는 돌아가셨다 (? ).\n",
            " batch 57001/103126\tTarget text: 옛날 귀여운 아기가 어느새 마음씨 좋은 소녀가 되었고, 어머니는 병든 병으로 돌아가셨다. 고인은 안타깝게 돌아가셨다 고 말했다. 고 ( ) 고혼 ( ) 고혼 (. /...\n",
            " batch 58001/103126\tTarget text: 옛날 귀여운 아기가 어느새 마음씨 좋은 소녀가 되었고, 어머니는 돌아가셨다가 돌아가셨다. 고 말했다.. ( /. ) ( - ) - - - ( ( - ) - ( ).\n",
            " batch 59001/103126\tTarget text: 옛날 귀여운 아기가 마음씨 좋은 소녀가 되었고, 어머니는 돌아가셨다는 후문이 전해진다. 옛날 어린 시절...\n",
            " batch 60001/103126\tTarget text: 옛날 귀여운 아기가 태어나 마음씨 좋은 소녀가 되었고, 어머니는 돌아가셨다가 돌아가셨다는 후문이다. 어렸을 때 어머니는 귀여운 아이가셨다 고 말했다 고 한다 고 하시더라 고 하셨다 고 는 어머니는 어머니는 예쁜 아기가셨다. 고 고 고 ( )\n",
            " batch 61001/103126\tTarget text: 옛날 귀여운 아기가 태어나 마음씨 좋은 소녀가 되었고, 어머니는 돌아가셨다... / / / ( ) - + =. / ( ) / / / = / ) /\n",
            " batch 62001/103126\tTarget text: 옛날 귀여운 아기가 되어 마음씨 좋은 소녀가 되었고, 어머니는 돌아가셨다는 후문이다. 옛날에는 돌아가셨다 고 말했다.. ( / / / / = ) 고 말했다 고 했다.. 고 ( )\n",
            " batch 63001/103126\tTarget text: 옛날 귀여운 아기가 마음씨 좋은 소녀가 되었고, 어머니는 돌아가셨다는 후문이 전해진다. 옛날에는 그렇게 하셨다.. ( / / = / / (. + -... ).\n",
            " batch 63776/103126"
          ]
        }
      ]
    }
  ]
}