{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "korean_frame_token_0_1.0_gamma_10.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dolmani38/Summary2/blob/main/multi-discriminator%20GAN%200911.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkQCxNatSIOk"
      },
      "source": [
        "# Multi-Discriminator GAN\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZjIW9VwyjDf"
      },
      "source": [
        "ABSTRACT\n",
        "\n",
        "----\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K87VNBbeRLFF"
      },
      "source": [
        "#4. Implementation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQZeBAf8NxAR"
      },
      "source": [
        "## 4.1 기본 설정..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAdXzWGuKSBT",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a01600d-af49-4cb4-8256-560946b7bb59"
      },
      "source": [
        "if True:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "newO0mBXKVnE",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "099f4a8d-1a78-4357-d163-7a67f0c37a6a"
      },
      "source": [
        "#!pip install keybert\n",
        "!pip3 install transformers\n",
        "!pip3 install sentence-transformers\n",
        "\n",
        "#!pip install sentence-transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.10.2-py3-none-any.whl (2.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8 MB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Collecting huggingface-hub>=0.0.12\n",
            "  Downloading huggingface_hub-0.0.16-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 5.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 35.5 MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 17.7 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 42.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Installing collected packages: tokenizers, sacremoses, pyyaml, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.0.16 pyyaml-5.4.1 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.10.2\n",
            "Collecting sentence-transformers\n",
            "  Downloading sentence-transformers-2.0.0.tar.gz (85 kB)\n",
            "\u001b[K     |████████████████████████████████| 85 kB 2.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.10.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.62.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.9.0+cu102)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.10.0+cu102)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.2.5)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 25.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.0.16)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers) (3.7.4.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.0.45)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (21.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (4.6.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.10.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (5.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2021.5.30)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers) (7.1.2)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.0.0-py3-none-any.whl size=126710 sha256=e541ae2c6c7a8dd99c1fd7b6aa5736cfc8ab9a7821b9da19f2e57ec241523403\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/c1/0f/faafd427f705c4b012274ba60d9a91d75830306811e1355293\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: sentencepiece, sentence-transformers\n",
            "Successfully installed sentence-transformers-2.0.0 sentencepiece-0.1.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmIxp0FnKXif",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78d4f6a2-eca1-4275-e08c-4bd95e222a46"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# set seeds for reproducability\n",
        "from numpy.random import seed\n",
        "#seed(1)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string, os \n",
        "\n",
        "import urllib.request\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3J0n_lhKcgm",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5965e5ab-a997-4d74-db5a-4c5ba347211d"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ue_4ZfdRKfdX",
        "trusted": true
      },
      "source": [
        "# Print iterations progress\n",
        "class ProgressBar:\n",
        "\n",
        "    def __init__(self,total=20, prefix = '', suffix = '', decimals = 1, length = 20, fill = '|', printEnd = \"\\r\"):\n",
        "        self.total = total\n",
        "        self.prefix = prefix\n",
        "        self.suffix = suffix\n",
        "        self.decimals = decimals\n",
        "        self.length = length\n",
        "        self.fill = fill\n",
        "        self.printEnd = printEnd\n",
        "        self.ite = 0\n",
        "        self.back_filledLength = 0\n",
        "\n",
        "    def printProgress(self,iteration, text):\n",
        "        self.ite += iteration\n",
        "        percent = (\"{0:.\" + str(self.decimals) + \"f}\").format(100 * (self.ite / float(self.total)))\n",
        "        filledLength = int(self.length * self.ite // self.total)\n",
        "        bar = self.fill * filledLength + '.' * (self.length - filledLength)\n",
        "        if filledLength > self.back_filledLength or percent == 100:\n",
        "            print(f'\\r{self.prefix} |{bar}| {percent}% {self.suffix}  {text}', end=\"\", flush=True)\n",
        "            # Print New Line on Complete\n",
        "            if self.ite == self.total: \n",
        "                print()\n",
        "        self.back_filledLength = filledLength    "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNHI0G6JKc5h",
        "trusted": true
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Zsv-LVkKmfL"
      },
      "source": [
        "##4.2 Grammar Discriminator Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VQdGLciKc_y",
        "trusted": true
      },
      "source": [
        "from transformers import BertTokenizer, BertTokenizerFast,AutoTokenizer, BertForSequenceClassification, AdamW, BertConfig, get_linear_schedule_with_warmup\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset, random_split\n",
        "\n",
        "import time\n",
        "import random\n",
        "import datetime\n",
        "import pickle\n",
        "\n",
        "# 간단한 전처리\n",
        "def clean_text(txt):\n",
        "    txt = txt.replace('\\n',' ')\n",
        "    txt = txt.replace('\\r',' ')    \n",
        "    txt = txt.replace('=','')\n",
        "    txt = txt.replace('\\\"','')   \n",
        "    txt = txt.replace('\\'','')\n",
        "    #txt = txt.replace(',','')\n",
        "    txt = txt.replace('..','')\n",
        "    txt = txt.replace('...','')\n",
        "    txt = txt.replace(' .','.')\n",
        "    txt = txt.replace('.','. ')\n",
        "    txt = txt.replace('  ',' ')\n",
        "    txt = txt.replace('  ',' ')    \n",
        "    txt = txt.replace('  ',' ')   \n",
        "    txt = txt.replace('  ',' ')           \n",
        "    txt = txt.replace('  ',' ')\n",
        "    txt = txt.replace('  ',' ')    \n",
        "    txt = txt.replace('  ',' ')   \n",
        "    txt = txt.replace('  ',' ')             \n",
        "    return txt.strip()\n",
        "\n",
        "def shuffling(txt):\n",
        "    txt_list = txt.split(' ')\n",
        "    random.shuffle(txt_list)\n",
        "    return ' '.join(txt_list)\n",
        "\n",
        "def collect_training_dataset_for_grammar_discriminator(sentences_dataset):\n",
        "\n",
        "    sentences = []\n",
        "    labels = []\n",
        "\n",
        "    for txtss in sentences_dataset:\n",
        "        txtss = clean_text(txtss)\n",
        "        txts = txtss.strip().split('.')\n",
        "        for txt in txts:  \n",
        "            txt = txt.strip()\n",
        "            if len(txt) > 10:\n",
        "                #ko_grammar_dataset.append([txt,1])\n",
        "                txt = txt.replace('.','')\n",
        "                tf = random.choice([True,False])\n",
        "                # 정상 또는 비정상 둘중에 하나만 데이터셋에 추가\n",
        "                if (tf):\n",
        "                    sentences.append(txt) # '.'의 위치를 보고 True, False를 판단 하기 땜에...\n",
        "                    labels.append(1)\n",
        "                else:\n",
        "                    sentences.append(shuffling(txt))\n",
        "                    labels.append(0)\n",
        "\n",
        "    return sentences,labels\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
        "\n",
        "class Grammar_Discriminator:\n",
        "\n",
        "\n",
        "    def __init__(self, pretraoned_kobert_model_name='kykim/bert-kor-base', input_dir=None):\n",
        "\n",
        "        if input_dir is None:\n",
        "            self.tokenizer = BertTokenizerFast.from_pretrained(pretraoned_kobert_model_name)\n",
        "            self.discriminator = BertForSequenceClassification.from_pretrained(\n",
        "                                    pretraoned_kobert_model_name, # Use the 12-layer BERT model, with an uncased vocab.\n",
        "                                    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                                                    # You can increase this for multi-class tasks.   \n",
        "                                    output_attentions = False, # Whether the model returns attentions weights.\n",
        "                                    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        "                                )            \n",
        "        else:\n",
        "            self.__load_model(input_dir)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def set_dataset(self, sentences,labels):\n",
        "        # Print the original sentence.\n",
        "        print(' Original: ', sentences[0])\n",
        "\n",
        "        # Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "        input_ids = []\n",
        "        attention_masks = []\n",
        "\n",
        "        # For every sentence...\n",
        "        for i, sent in enumerate(sentences):\n",
        "            print(f'\\r Tokenize {i+1}/{len(sentences)}', end=\"\", flush=True)            \n",
        "            # `encode_plus` will:\n",
        "            #   (1) Tokenize the sentence.\n",
        "            #   (2) Prepend the `[CLS]` token to the start.\n",
        "            #   (3) Append the `[SEP]` token to the end.\n",
        "            #   (4) Map tokens to their IDs.\n",
        "            #   (5) Pad or truncate the sentence to `max_length`\n",
        "            #   (6) Create attention masks for [PAD] tokens.\n",
        "            encoded_dict = self.tokenizer.encode_plus(\n",
        "                                sent,                      # Sentence to encode.\n",
        "                                add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                                max_length = 64,           # Pad & truncate all sentences.\n",
        "                                pad_to_max_length = True,\n",
        "                                return_attention_mask = True,   # Construct attn. masks.\n",
        "                                return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                                truncation = True,\n",
        "                        )\n",
        "            \n",
        "            # Add the encoded sentence to the list.    \n",
        "            input_ids.append(encoded_dict['input_ids'])\n",
        "            \n",
        "            # And its attention mask (simply differentiates padding from non-padding).\n",
        "            attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "        # Convert the lists into tensors.\n",
        "        input_ids = torch.cat(input_ids, dim=0)\n",
        "        attention_masks = torch.cat(attention_masks, dim=0)\n",
        "        labels = torch.tensor(labels)\n",
        "\n",
        "        # Print sentence 0, now as a list of IDs.\n",
        "        print('Original: ', sentences[0])\n",
        "        print('Token IDs:', input_ids[0])\n",
        "\n",
        "        # Training & Validation Split\n",
        "        # Divide up our training set to use 90% for training and 10% for validation.\n",
        "\n",
        "        # Combine the training inputs into a TensorDataset.\n",
        "        dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "        # Create a 90-10 train-validation split.\n",
        "\n",
        "        # Calculate the number of samples to include in each set.\n",
        "        train_size = int(0.9 * len(dataset))\n",
        "        val_size = len(dataset) - train_size\n",
        "\n",
        "        # Divide the dataset by randomly selecting samples.\n",
        "        train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "        print('{:>5,} training samples'.format(train_size))\n",
        "        print('{:>5,} validation samples'.format(val_size))\n",
        "\n",
        "        # The DataLoader needs to know our batch size for training, so we specify it \n",
        "        # here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "        # size of 16 or 32.\n",
        "        self.batch_size = 32\n",
        "\n",
        "        # Create the DataLoaders for our training and validation sets.\n",
        "        # We'll take training samples in random order. \n",
        "        self.train_dataloader = DataLoader(\n",
        "                    train_dataset,  # The training samples.\n",
        "                    sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "                    batch_size = self.batch_size # Trains with this batch size.\n",
        "                )\n",
        "\n",
        "        # For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "        self.validation_dataloader = DataLoader(\n",
        "                    val_dataset, # The validation samples.\n",
        "                    sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "                    batch_size = self.batch_size # Evaluate with this batch size.\n",
        "                )        \n",
        "\n",
        "\n",
        "    def train(self,epochs=4):\n",
        "        # Tell pytorch to run this model on the GPU.\n",
        "        self.discriminator.cuda()\n",
        "\n",
        "        # Get all of the model's parameters as a list of tuples.\n",
        "        params = list(self.discriminator.named_parameters())\n",
        "\n",
        "        print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "        print('==== Embedding Layer ====\\n')\n",
        "\n",
        "        for p in params[0:5]:\n",
        "            print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "        print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "        for p in params[5:21]:\n",
        "            print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "        print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "        for p in params[-4:]:\n",
        "            print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))  \n",
        "\n",
        "        # Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "        # I believe the 'W' stands for 'Weight Decay fix\"\n",
        "        self.optimizer = AdamW(self.discriminator.parameters(),\n",
        "                        lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                        eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                        )\n",
        "\n",
        "        # Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "        # We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "        # training data.\n",
        "        #epochs = 2\n",
        "\n",
        "        # Total number of training steps is [number of batches] x [number of epochs]. \n",
        "        # (Note that this is not the same as the number of training samples).\n",
        "        total_steps = len(self.train_dataloader) * epochs\n",
        "\n",
        "        # Create the learning rate scheduler.\n",
        "        scheduler = get_linear_schedule_with_warmup(self.optimizer, \n",
        "                                                    num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                                    num_training_steps = total_steps)\n",
        "            \n",
        "        # This training code is based on the `run_glue.py` script here:\n",
        "        # https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "        # Set the seed value all over the place to make this reproducible.\n",
        "        seed_val = 42\n",
        "\n",
        "        random.seed(seed_val)\n",
        "        np.random.seed(seed_val)\n",
        "        torch.manual_seed(seed_val)\n",
        "        torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "        # We'll store a number of quantities such as training and validation loss, \n",
        "        # validation accuracy, and timings.\n",
        "        training_stats = []\n",
        "\n",
        "        # Measure the total training time for the whole run.\n",
        "        total_t0 = time.time()\n",
        "\n",
        "        # For each epoch...\n",
        "        for epoch_i in range(0, epochs):\n",
        "            \n",
        "            # ========================================\n",
        "            #               Training\n",
        "            # ========================================\n",
        "            \n",
        "            # Perform one full pass over the training set.\n",
        "\n",
        "            print(\"\")\n",
        "            print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "            print('Training...')\n",
        "\n",
        "            # Measure how long the training epoch takes.\n",
        "            t0 = time.time()\n",
        "\n",
        "            # Reset the total loss for this epoch.\n",
        "            total_train_loss = 0\n",
        "\n",
        "            # Put the model into training mode. Don't be mislead--the call to \n",
        "            # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "            # `dropout` and `batchnorm` layers behave differently during training\n",
        "            # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "            self.discriminator.train()\n",
        "\n",
        "            # For each batch of training data...\n",
        "            for step, batch in enumerate(self.train_dataloader):\n",
        "\n",
        "                # Progress update every 40 batches.\n",
        "                if step % 40 == 0 and not step == 0:\n",
        "                    # Calculate elapsed time in minutes.\n",
        "                    elapsed = format_time(time.time() - t0)\n",
        "                    \n",
        "                    # Report progress.\n",
        "                    print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(self.train_dataloader), elapsed))\n",
        "\n",
        "                # Unpack this training batch from our dataloader. \n",
        "                #\n",
        "                # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "                # `to` method.\n",
        "                #\n",
        "                # `batch` contains three pytorch tensors:\n",
        "                #   [0]: input ids \n",
        "                #   [1]: attention masks\n",
        "                #   [2]: labels \n",
        "                b_input_ids = batch[0].to(device)\n",
        "                b_input_mask = batch[1].to(device)\n",
        "                b_labels = batch[2].to(device)\n",
        "\n",
        "                # Always clear any previously calculated gradients before performing a\n",
        "                # backward pass. PyTorch doesn't do this automatically because \n",
        "                # accumulating the gradients is \"convenient while training RNNs\". \n",
        "                # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "                self.discriminator.zero_grad()        \n",
        "\n",
        "                # Perform a forward pass (evaluate the model on this training batch).\n",
        "                # The documentation for this `model` function is here: \n",
        "                # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "                # It returns different numbers of parameters depending on what arguments\n",
        "                # arge given and what flags are set. For our useage here, it returns\n",
        "                # the loss (because we provided labels) and the \"logits\"--the model\n",
        "                # outputs prior to activation.\n",
        "                outputs = self.discriminator(b_input_ids, \n",
        "                                    token_type_ids=None, \n",
        "                                    attention_mask=b_input_mask, \n",
        "                                    labels=b_labels)\n",
        "                loss, logits = outputs.loss, outputs.logits\n",
        "                # Accumulate the training loss over all of the batches so that we can\n",
        "                # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "                # single value; the `.item()` function just returns the Python value \n",
        "                # from the tensor.\n",
        "                total_train_loss += loss.item()\n",
        "\n",
        "                # Perform a backward pass to calculate the gradients.\n",
        "                loss.backward()\n",
        "\n",
        "                # Clip the norm of the gradients to 1.0.\n",
        "                # This is to help prevent the \"exploding gradients\" problem.\n",
        "                torch.nn.utils.clip_grad_norm_(self.discriminator.parameters(), 1.0)\n",
        "\n",
        "                # Update parameters and take a step using the computed gradient.\n",
        "                # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "                # modified based on their gradients, the learning rate, etc.\n",
        "                self.optimizer.step()\n",
        "\n",
        "                # Update the learning rate.\n",
        "                scheduler.step()\n",
        "\n",
        "            # Calculate the average loss over all of the batches.\n",
        "            avg_train_loss = total_train_loss / len(self.train_dataloader)            \n",
        "            \n",
        "            # Measure how long this epoch took.\n",
        "            training_time = format_time(time.time() - t0)\n",
        "\n",
        "            print(\"\")\n",
        "            print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "            print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "                \n",
        "            # ========================================\n",
        "            #               Validation\n",
        "            # ========================================\n",
        "            # After the completion of each training epoch, measure our performance on\n",
        "            # our validation set.\n",
        "\n",
        "            print(\"\")\n",
        "            print(\"Running Validation...\")\n",
        "\n",
        "            t0 = time.time()\n",
        "\n",
        "            # Put the model in evaluation mode--the dropout layers behave differently\n",
        "            # during evaluation.\n",
        "            self.discriminator.eval()\n",
        "\n",
        "            # Tracking variables \n",
        "            total_eval_accuracy = 0\n",
        "            total_eval_loss = 0\n",
        "            nb_eval_steps = 0\n",
        "\n",
        "            # Evaluate data for one epoch\n",
        "            for batch in self.validation_dataloader:\n",
        "                \n",
        "                # Unpack this training batch from our dataloader. \n",
        "                #\n",
        "                # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "                # the `to` method.\n",
        "                #\n",
        "                # `batch` contains three pytorch tensors:\n",
        "                #   [0]: input ids \n",
        "                #   [1]: attention masks\n",
        "                #   [2]: labels \n",
        "                b_input_ids = batch[0].to(device)\n",
        "                b_input_mask = batch[1].to(device)\n",
        "                b_labels = batch[2].to(device)\n",
        "                \n",
        "                # Tell pytorch not to bother with constructing the compute graph during\n",
        "                # the forward pass, since this is only needed for backprop (training).\n",
        "                with torch.no_grad():        \n",
        "\n",
        "                    # Forward pass, calculate logit predictions.\n",
        "                    # token_type_ids is the same as the \"segment ids\", which \n",
        "                    # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "                    # The documentation for this `model` function is here: \n",
        "                    # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "                    # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "                    # values prior to applying an activation function like the softmax.\n",
        "                    outputs = self.discriminator(b_input_ids, \n",
        "                                        token_type_ids=None, \n",
        "                                        attention_mask=b_input_mask,\n",
        "                                        labels=b_labels)\n",
        "                loss, logits = outputs.loss, outputs.logits\n",
        "                # Accumulate the validation loss.\n",
        "                total_eval_loss += loss.item()\n",
        "\n",
        "                # Move logits and labels to CPU\n",
        "                logits = logits.detach().cpu().numpy()\n",
        "                label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "                # Calculate the accuracy for this batch of test sentences, and\n",
        "                # accumulate it over all batches.\n",
        "                total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "                \n",
        "\n",
        "            # Report the final accuracy for this validation run.\n",
        "            avg_val_accuracy = total_eval_accuracy / len(self.validation_dataloader)\n",
        "            print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "            # Calculate the average loss over all of the batches.\n",
        "            avg_val_loss = total_eval_loss / len(self.validation_dataloader)\n",
        "            \n",
        "            # Measure how long the validation run took.\n",
        "            validation_time = format_time(time.time() - t0)\n",
        "            \n",
        "            print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "            print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "            # Record all statistics from this epoch.\n",
        "            training_stats.append(\n",
        "                {\n",
        "                    'epoch': epoch_i + 1,\n",
        "                    'Training Loss': avg_train_loss,\n",
        "                    'Valid. Loss': avg_val_loss,\n",
        "                    'Valid. Accur.': avg_val_accuracy,\n",
        "                    'Training Time': training_time,\n",
        "                    'Validation Time': validation_time\n",
        "                }\n",
        "            )\n",
        "\n",
        "        print(\"\")\n",
        "        print(\"Training complete!\")\n",
        "\n",
        "        print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n",
        "            \n",
        "\n",
        "        return training_stats\n",
        "\n",
        "    def save_model(self, output_dir = './model_save/'):\n",
        "        # Create output directory if needed\n",
        "        if not os.path.exists(output_dir):\n",
        "            os.makedirs(output_dir)\n",
        "\n",
        "        print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "        # Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "        # They can then be reloaded using `from_pretrained()`\n",
        "        model_to_save = self.discriminator.module if hasattr(self.discriminator, 'module') else self.discriminator  # Take care of distributed/parallel training\n",
        "        model_to_save.save_pretrained(output_dir)\n",
        "        self.tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "        # Good practice: save your training arguments together with the trained model\n",
        "        # torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n",
        "\n",
        "    def __load_model(self, input_dir = './drive/MyDrive/Colab Notebooks/summary/en_grammar_check_model'):\n",
        "        print('Loading BERT tokenizer...')\n",
        "        self.tokenizer = BertTokenizerFast.from_pretrained(input_dir)\n",
        "        self.discriminator = BertForSequenceClassification.from_pretrained(input_dir)\n",
        "\n",
        "    def transfer_learning(self, sentences, train_for = True):\n",
        "        \n",
        "        input_ids = []\n",
        "        attention_masks = []\n",
        "\n",
        "        # For every sentence...\n",
        "        for sent in sentences:\n",
        "            # `encode_plus` will:\n",
        "            #   (1) Tokenize the sentence.\n",
        "            #   (2) Prepend the `[CLS]` token to the start.\n",
        "            #   (3) Append the `[SEP]` token to the end.\n",
        "            #   (4) Map tokens to their IDs.\n",
        "            #   (5) Pad or truncate the sentence to `max_length`\n",
        "            #   (6) Create attention masks for [PAD] tokens.\n",
        "            encoded_dict = self.tokenizer.encode_plus(\n",
        "                                sent,                      # Sentence to encode.\n",
        "                                add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                                max_length = 64,           # Pad & truncate all sentences.\n",
        "                                pad_to_max_length = True,\n",
        "                                return_attention_mask = True,   # Construct attn. masks.\n",
        "                                return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                                truncation = True,\n",
        "                        )\n",
        "            # Add the encoded sentence to the list.    \n",
        "            input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "            # And its attention mask (simply differentiates padding from non-padding).\n",
        "            attention_masks.append(encoded_dict['attention_mask'])\n",
        "        \n",
        "        if train_for:\n",
        "            b_labels = torch.ones(len(sentences),dtype=torch.long).to(device)\n",
        "        else:\n",
        "            b_labels = torch.zeros(len(sentences),dtype=torch.long).to(device)\n",
        "        #print(b_labels)\n",
        "        # Convert the lists into tensors.\n",
        "        input_ids = torch.cat(input_ids, dim=0).to(device)\n",
        "        attention_masks = torch.cat(attention_masks, dim=0).to(device)    \n",
        "        #if str(discriminator1.device) == 'cpu':\n",
        "        #    pass\n",
        "        #else:\n",
        "        #    input_ids = input_ids.to(device)\n",
        "        #    attention_masks = attention_masks.to(device)        \n",
        "\n",
        "        outputs = self.discriminator(input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=attention_masks, \n",
        "                                labels=b_labels)\n",
        "\n",
        "        #print(outputs)\n",
        "        #return torch.sigmoid(outputs[0][:,1])\n",
        "        #return outputs[0][:,1]\n",
        "        return outputs['loss'], outputs['logits']\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nk93tR2Nuk8t"
      },
      "source": [
        "# 문법 discriminator의 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "4czGliqpPCj4",
        "outputId": "a8f5ac3d-b6bf-46e1-d343-f08fe1a9c266"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/summary/korean_news_corpus.csv')\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>contents</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>문 대통령 변창흠 국토장관 사의표명 사실상 수용</td>\n",
              "      <td>정만호 국민소통수석이 12일 오후 청와대 춘추관 대브리핑룸에서 변창흠 국토부 장관 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>계급장 수여하는 문 대통령</td>\n",
              "      <td>(아산뉴스1) 이광호 기자 문재인 대통령이 12일 오후 충남 아산시 경찰대학에서 열...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>계급장 수여하는 문 대통령</td>\n",
              "      <td>(아산뉴스1) 이광호 기자 문재인 대통령이 12일 오후 충남 아산시 경찰대학에서 열...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>수상자 메달 걸어주는 문 대통령</td>\n",
              "      <td>(아산뉴스1) 이광호 기자 문재인 대통령이 12일 오후 충남 아산시 경찰대학에서 열...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>정몽구 서울아산병원에 50억 쾌척</td>\n",
              "      <td>인재 양성·소외 계층 지원 등 계획 “부친 질병·가난 악순환 끊기 원해 국내 최고 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140559</th>\n",
              "      <td>[건축과도시] 북한산을 캔버스 삼아. 미술관 또 하나의 작품이 되다</td>\n",
              "      <td>&lt;은평구 진관동 사비나 미술관&gt; 서울시 은평구 진관동에 자리잡은 사비나미술관. 삼각...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140560</th>\n",
              "      <td>조선후기 문인 김조순 별장 그린 옥호정도 첫 공개</td>\n",
              "      <td>국립중앙박물관 서화실 개편해 32점 새롭게 전시 옥호정도[국립중앙박물관 제공연합뉴스...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140561</th>\n",
              "      <td>안성 청룡사 대웅전에서 목재 곡자 발견</td>\n",
              "      <td>문화재청(청장 정재숙)의 국고보조와 기술지도로 안성시에서 시행하고 있는 안성 청룡사...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140562</th>\n",
              "      <td>156년전 ㄱ자 곡자 찾았다 안성 청룡사 기둥 밑에서</td>\n",
              "      <td>안성 청룡사 대웅전에서 발견된 곡자 【서울뉴시스】 이수지 기자 안성 청룡사 대웅전에...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140563</th>\n",
              "      <td>[김중기의 필름통] 새 영화 도굴 나인스 게이트 앙상블</td>\n",
              "      <td>영화 도굴 스틸컷 ◆도굴 감독: 박정배 출연: 이제훈 조우진 신혜선 도굴을 소재로 ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>140564 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        title                                           contents\n",
              "0                  문 대통령 변창흠 국토장관 사의표명 사실상 수용  정만호 국민소통수석이 12일 오후 청와대 춘추관 대브리핑룸에서 변창흠 국토부 장관 ...\n",
              "1                              계급장 수여하는 문 대통령  (아산뉴스1) 이광호 기자 문재인 대통령이 12일 오후 충남 아산시 경찰대학에서 열...\n",
              "2                              계급장 수여하는 문 대통령  (아산뉴스1) 이광호 기자 문재인 대통령이 12일 오후 충남 아산시 경찰대학에서 열...\n",
              "3                           수상자 메달 걸어주는 문 대통령  (아산뉴스1) 이광호 기자 문재인 대통령이 12일 오후 충남 아산시 경찰대학에서 열...\n",
              "4                          정몽구 서울아산병원에 50억 쾌척  인재 양성·소외 계층 지원 등 계획 “부친 질병·가난 악순환 끊기 원해 국내 최고 ...\n",
              "...                                       ...                                                ...\n",
              "140559  [건축과도시] 북한산을 캔버스 삼아. 미술관 또 하나의 작품이 되다  <은평구 진관동 사비나 미술관> 서울시 은평구 진관동에 자리잡은 사비나미술관. 삼각...\n",
              "140560            조선후기 문인 김조순 별장 그린 옥호정도 첫 공개  국립중앙박물관 서화실 개편해 32점 새롭게 전시 옥호정도[국립중앙박물관 제공연합뉴스...\n",
              "140561                  안성 청룡사 대웅전에서 목재 곡자 발견  문화재청(청장 정재숙)의 국고보조와 기술지도로 안성시에서 시행하고 있는 안성 청룡사...\n",
              "140562          156년전 ㄱ자 곡자 찾았다 안성 청룡사 기둥 밑에서  안성 청룡사 대웅전에서 발견된 곡자 【서울뉴시스】 이수지 기자 안성 청룡사 대웅전에...\n",
              "140563         [김중기의 필름통] 새 영화 도굴 나인스 게이트 앙상블  영화 도굴 스틸컷 ◆도굴 감독: 박정배 출연: 이제훈 조우진 신혜선 도굴을 소재로 ...\n",
              "\n",
              "[140564 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrcixShxPldd",
        "outputId": "687693d0-ee4e-40b5-bc8b-cb2179ecd29a"
      },
      "source": [
        "import re\n",
        "import sys\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "# 간단한 전처리\n",
        "def clean_text(txt):\n",
        "    txt = txt.replace('\\n',' ')\n",
        "    txt = txt.replace('\\r',' ')    \n",
        "    txt = txt.replace('=','')\n",
        "    txt = txt.replace('\\\"','')   \n",
        "    txt = txt.replace('\\'','')\n",
        "    txt = txt.replace('”','')\n",
        "    txt = txt.replace('“','')\n",
        "    txt = txt.replace('’','')\n",
        "    #txt = txt.replace(',','')\n",
        "    txt = txt.replace('..','')\n",
        "    txt = txt.replace('...','')\n",
        "    #txt = txt.replace('.','. ')\n",
        "    txt = txt.replace('.','. ')\n",
        "    txt = txt.replace('  ',' ')\n",
        "    txt = txt.replace('  ',' ')    \n",
        "    txt = txt.replace('  ',' ')   \n",
        "    txt = txt.replace('  ',' ')           \n",
        "    txt = txt.replace('  ',' ')\n",
        "    txt = txt.replace('  ',' ')    \n",
        "    txt = txt.replace('  ',' ')   \n",
        "    txt = txt.replace('  ',' ')             \n",
        "    return txt.strip()\n",
        "    \n",
        "# 검사...\n",
        "pattens = [\"[34569][0-9]{3}[\\;.\\;-\\; ][0-9]{4}[\\;.\\;-\\; ][0-9]{4}[\\;.\\;-\\; ][0-9]{4}\",\n",
        "           \"[0-9]{2,3}[\\:\\s\\;.\\;,\\;-;)][0-9]{3,4}[\\:\\s\\;.\\;,\\;-][0-9]{4}\",\n",
        "           \"[0-9]{1}[0-9]{1}[\\W]?[0-1]{1}[0-9]{1}[\\W]?[0-3]{1}[\\W]?[0-9]{1}[\\W]?[1-4]{1}[\\W]?[0-9]{1}[\\W]?[0-9]{1}[\\W]?[0-9]{1}[\\W]?[0-9]{1}[\\W]?[0-9]{1}[\\W]?[0-9]{1}\",\n",
        "           \"[0-9]{2}[\\:\\s\\;.\\;,\\;-][0-9]{2}[\\:\\s\\;.\\;,\\;-][0-9]{6}|[0-9]{3}[\\:\\s\\;.\\;,\\;-]([0-9]{5,6}[\\:\\s\\;.\\;,\\;-][0-9]{3}|[0-9]{6}[\\:\\s\\;.\\;,\\;-][0-9]{5}|[0-9]{2,3}[\\:\\s\\;.\\;,\\;-][0-9]{6}|[0-9]{2}[\\:\\s\\;.\\;,\\;-][0-9]{7}|[0-9]{2}[\\:\\s\\;.\\;,\\;-][0-9]{4,6}[\\:\\s\\;.\\;,\\;-][0-9]|[0-9]{5}[\\:\\s\\;.\\;,\\;-][0-9]{3}[\\:\\s\\;.\\;,\\;-][0-9]{2}|[0-9]{2}[\\:\\s\\;.\\;,\\;-][0-9]{5}[\\:\\s\\;.\\;,\\;-][0-9]{3}|[0-9]{4}[\\:\\s\\;.\\;,\\;-][0-9]{4}[\\:\\s\\;.\\;,\\;-][0-9]{3}|[0-9]{6}[\\:\\s\\;.\\;,\\;-][0-9]{2}[\\:\\s\\;.\\;,\\;-][0-9]{3}|[0-9]{2}[\\:\\s\\;.\\;,\\;-][0-9]{2}[\\:\\s\\;.\\;,\\;-][0-9]{7})|[0-9]{4}[\\:\\s\\;.\\;,\\;-]([0-9]{3}[\\:\\s\\;.\\;,\\;-][0-9]{6}|[0-9]{2}[\\:\\s\\;.\\;,\\;-][0-9]{6}[\\:\\s\\;.\\;,\\;-][0-9])|[0-9]{5}[\\:\\s\\;.\\;,\\;-][0-9]{2}[\\:\\s\\;.\\;,\\;-][0-9]{6}|[0-9]{6}[\\:\\s\\;.\\;,\\;-][0-9]{2}[\\:\\s\\;.\\;,\\;-][0-9]{5,6}\"\n",
        "           ]\n",
        "\n",
        "filters = []\n",
        "for p in pattens:\n",
        "    filters.append(re.compile(p))\n",
        "\n",
        "sentences = []\n",
        "df = df.dropna(axis=0)\n",
        "cnt = df['contents'].count()\n",
        "#print('Total row count:',cnt)\n",
        "i=0\n",
        "for raw_text in df['contents']:\n",
        "    i=i+1\n",
        "    try:\n",
        "        if i%100 == 0:\n",
        "            percent = (\"{0:.2f}\").format(100 * (i / float(cnt)))\n",
        "            print(f'\\r {percent}% {i}/{str(cnt)}', end=\"\", flush=True)\n",
        "\n",
        "        docs = nltk.sent_tokenize(clean_text(raw_text))\n",
        "        for txt in docs:\n",
        "            if txt.find('▶') > -1 or txt.find('@') > -1 or txt.find('ⓒ') > -1: \n",
        "                pass\n",
        "            else:\n",
        "                txt = txt.strip()\n",
        "                if any(chr.isdigit() for chr in txt) :\n",
        "                    pass\n",
        "                else:\n",
        "                    sentences.append(txt)\n",
        "    except KeyboardInterrupt as ki:\n",
        "        raise ki        \n",
        "    except:\n",
        "        pass #print(\"Unexpected error:\", sys.exc_info()[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            " 99.97% 140500/140536"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSLis2L1PnTl"
      },
      "source": [
        "import re\n",
        "import sys\n",
        "import io\n",
        "\n",
        "#텍스트 정제(전처리)\n",
        "def cleanText(readData):\n",
        "    #텍스트에 포함되어 있는 특수 문자 제거\n",
        "    text = re.sub('[-=+,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》◆◇●🎧○▲\\t―△━▷]', '', readData)\n",
        "    return text.lower()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSzNUTbsPtHE"
      },
      "source": [
        "\n",
        "c_sentences = []\n",
        "for sentence in sentences:\n",
        "    s = cleanText(sentence)\n",
        "    c = len(s.split())\n",
        "    if c >= 3 and c < 10 and s.find('재배포') < 0 and s.find('기자') < 0  and s.find('유투브') < 0 and s.find('www') < 0 and s.find('com') < 0 and s.find('접속하기') < 0 and s.find('http') < 0 and s.find('뉴스') < 0 and s.find('일보') < 0 :\n",
        "        if s.endswith(('다','요')):\n",
        "            c_sentences.append(s.strip())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PiUf-3LiPv8i",
        "outputId": "51dfc37c-c9ba-41b7-9825-30ea1fb78574"
      },
      "source": [
        "len(c_sentences)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "868830"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_zXMQugPyaP"
      },
      "source": [
        "import json  \n",
        "import zipfile  \n",
        "\n",
        "data_1 = None  \n",
        "data = None  \n",
        "with zipfile.ZipFile(\"/content/drive/MyDrive/Colab Notebooks/summary/data/사설잡지_2.train_original.json.zip\", \"r\") as z:\n",
        "    with z.open('train_original.json') as f:  \n",
        "        data = f.read()  \n",
        "        data_1 = json.loads(data.decode(\"utf-8\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNT2C7ohP68c"
      },
      "source": [
        "data_2 = None  \n",
        "data = None  \n",
        "with zipfile.ZipFile(\"/content/drive/MyDrive/Colab Notebooks/summary/data/신문기사_2.train_original.json.zip\", \"r\") as z:\n",
        "    with z.open('train_original.json') as f:  \n",
        "        data = f.read()  \n",
        "        data_2 = json.loads(data.decode(\"utf-8\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAAJ4d1jQAr-"
      },
      "source": [
        "\n",
        "for i in range(len(data_2)):\n",
        "    for txt in data_2[i]['article_original']:\n",
        "        c_sentences.append(txt)\n",
        "for i in range(len(data_1)):\n",
        "    for txt in data_1[i]['article_original']:\n",
        "        c_sentences.append(txt)    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWDa9NfeQF_g",
        "outputId": "318ba623-098f-4f2f-e516-701616802742"
      },
      "source": [
        "len(c_sentences)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5275990"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6D39wqgqQRNH"
      },
      "source": [
        "random.shuffle(c_sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TI2jEHtbD6e-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdp_eqBjQoag",
        "outputId": "7e223787-0fce-405f-8e39-8bc3b7bc16e8"
      },
      "source": [
        "ko_sentences_dataset = c_sentences\n",
        "\n",
        "use_pretrained_model = True\n",
        "\n",
        "if use_pretrained_model:\n",
        "    #g_discriminator = Grammar_Discriminator(input_dir = '/content/drive/MyDrive/Colab Notebooks/summary/model_save')\n",
        "    g_discriminator = Grammar_Discriminator(input_dir = '/content/drive/MyDrive/Colab Notebooks/summary/ko_grammar_model4')\n",
        "else:\n",
        "    sentences,labels = collect_training_dataset_for_grammar_discriminator(ko_sentences_dataset[:1000000])\n",
        "    print(len(sentences))\n",
        "    g_discriminator = Grammar_Discriminator()\n",
        "    g_discriminator.set_dataset(sentences,labels)\n",
        "    g_discriminator.train(epochs=1)\n",
        "    g_discriminator.save_model(output_dir='/content/drive/MyDrive/Colab Notebooks/summary/ko_grammar_model4')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_1s5vH4Fwq3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "413dce6e-67f5-419b-9968-5fb6ceae55a0"
      },
      "source": [
        "if True:\n",
        "    sentences,labels = collect_training_dataset_for_grammar_discriminator(ko_sentences_dataset[:1000000])\n",
        "    print(len(sentences))\n",
        "    #g_discriminator = Grammar_Discriminator()\n",
        "    g_discriminator.set_dataset(sentences,labels)\n",
        "    g_discriminator.train(epochs=1) \n",
        "    g_discriminator.save_model(output_dir='/content/drive/MyDrive/Colab Notebooks/summary/ko_grammar_model4')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1049374\n",
            " Original:  신숙은 박재혁에 대해 다음과 같이 증언하고 있다\n",
            " Tokenize 1049374/1049374Original:  신숙은 박재혁에 대해 다음과 같이 증언하고 있다\n",
            "Token IDs: tensor([    2,  5226,  8579,  8078,  4346,  8559,  9096,  8008, 14368, 18108,\n",
            "        14192, 33738, 13973, 13984,     3,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0])\n",
            "944,436 training samples\n",
            "104,938 validation samples\n",
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (42000, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (2, 768)\n",
            "classifier.bias                                                 (2,)\n",
            "\n",
            "======== Epoch 1 / 1 ========\n",
            "Training...\n",
            "  Batch    40  of  29,514.    Elapsed: 0:00:16.\n",
            "  Batch    80  of  29,514.    Elapsed: 0:00:33.\n",
            "  Batch   120  of  29,514.    Elapsed: 0:00:49.\n",
            "  Batch   160  of  29,514.    Elapsed: 0:01:06.\n",
            "  Batch   200  of  29,514.    Elapsed: 0:01:22.\n",
            "  Batch   240  of  29,514.    Elapsed: 0:01:38.\n",
            "  Batch   280  of  29,514.    Elapsed: 0:01:56.\n",
            "  Batch   320  of  29,514.    Elapsed: 0:02:14.\n",
            "  Batch   360  of  29,514.    Elapsed: 0:02:30.\n",
            "  Batch   400  of  29,514.    Elapsed: 0:02:47.\n",
            "  Batch   440  of  29,514.    Elapsed: 0:03:05.\n",
            "  Batch   480  of  29,514.    Elapsed: 0:03:22.\n",
            "  Batch   520  of  29,514.    Elapsed: 0:03:40.\n",
            "  Batch   560  of  29,514.    Elapsed: 0:03:57.\n",
            "  Batch   600  of  29,514.    Elapsed: 0:04:13.\n",
            "  Batch   640  of  29,514.    Elapsed: 0:04:31.\n",
            "  Batch   680  of  29,514.    Elapsed: 0:04:48.\n",
            "  Batch   720  of  29,514.    Elapsed: 0:05:05.\n",
            "  Batch   760  of  29,514.    Elapsed: 0:05:22.\n",
            "  Batch   800  of  29,514.    Elapsed: 0:05:39.\n",
            "  Batch   840  of  29,514.    Elapsed: 0:05:57.\n",
            "  Batch   880  of  29,514.    Elapsed: 0:06:14.\n",
            "  Batch   920  of  29,514.    Elapsed: 0:06:30.\n",
            "  Batch   960  of  29,514.    Elapsed: 0:06:48.\n",
            "  Batch 1,000  of  29,514.    Elapsed: 0:07:05.\n",
            "  Batch 1,040  of  29,514.    Elapsed: 0:07:23.\n",
            "  Batch 1,080  of  29,514.    Elapsed: 0:07:41.\n",
            "  Batch 1,120  of  29,514.    Elapsed: 0:08:00.\n",
            "  Batch 1,160  of  29,514.    Elapsed: 0:08:17.\n",
            "  Batch 1,200  of  29,514.    Elapsed: 0:08:35.\n",
            "  Batch 1,240  of  29,514.    Elapsed: 0:08:53.\n",
            "  Batch 1,280  of  29,514.    Elapsed: 0:09:10.\n",
            "  Batch 1,320  of  29,514.    Elapsed: 0:09:27.\n",
            "  Batch 1,360  of  29,514.    Elapsed: 0:09:45.\n",
            "  Batch 1,400  of  29,514.    Elapsed: 0:10:03.\n",
            "  Batch 1,440  of  29,514.    Elapsed: 0:10:21.\n",
            "  Batch 1,480  of  29,514.    Elapsed: 0:10:39.\n",
            "  Batch 1,520  of  29,514.    Elapsed: 0:10:58.\n",
            "  Batch 1,560  of  29,514.    Elapsed: 0:11:14.\n",
            "  Batch 1,600  of  29,514.    Elapsed: 0:11:32.\n",
            "  Batch 1,640  of  29,514.    Elapsed: 0:11:49.\n",
            "  Batch 1,680  of  29,514.    Elapsed: 0:14:15.\n",
            "  Batch 1,720  of  29,514.    Elapsed: 0:16:00.\n",
            "  Batch 1,760  of  29,514.    Elapsed: 0:16:14.\n",
            "  Batch 1,800  of  29,514.    Elapsed: 0:16:29.\n",
            "  Batch 1,840  of  29,514.    Elapsed: 0:16:43.\n",
            "  Batch 1,880  of  29,514.    Elapsed: 0:16:57.\n",
            "  Batch 1,920  of  29,514.    Elapsed: 0:17:11.\n",
            "  Batch 1,960  of  29,514.    Elapsed: 0:17:25.\n",
            "  Batch 2,000  of  29,514.    Elapsed: 0:17:39.\n",
            "  Batch 2,040  of  29,514.    Elapsed: 0:17:54.\n",
            "  Batch 2,080  of  29,514.    Elapsed: 0:18:08.\n",
            "  Batch 2,120  of  29,514.    Elapsed: 0:18:22.\n",
            "  Batch 2,160  of  29,514.    Elapsed: 0:18:36.\n",
            "  Batch 2,200  of  29,514.    Elapsed: 0:18:50.\n",
            "  Batch 2,240  of  29,514.    Elapsed: 0:19:04.\n",
            "  Batch 2,280  of  29,514.    Elapsed: 0:19:18.\n",
            "  Batch 2,320  of  29,514.    Elapsed: 0:19:33.\n",
            "  Batch 2,360  of  29,514.    Elapsed: 0:19:47.\n",
            "  Batch 2,400  of  29,514.    Elapsed: 0:20:01.\n",
            "  Batch 2,440  of  29,514.    Elapsed: 0:20:15.\n",
            "  Batch 2,480  of  29,514.    Elapsed: 0:20:29.\n",
            "  Batch 2,520  of  29,514.    Elapsed: 0:20:43.\n",
            "  Batch 2,560  of  29,514.    Elapsed: 0:20:58.\n",
            "  Batch 2,600  of  29,514.    Elapsed: 0:21:12.\n",
            "  Batch 2,640  of  29,514.    Elapsed: 0:21:26.\n",
            "  Batch 2,680  of  29,514.    Elapsed: 0:21:40.\n",
            "  Batch 2,720  of  29,514.    Elapsed: 0:21:54.\n",
            "  Batch 2,760  of  29,514.    Elapsed: 0:22:08.\n",
            "  Batch 2,800  of  29,514.    Elapsed: 0:22:23.\n",
            "  Batch 2,840  of  29,514.    Elapsed: 0:22:37.\n",
            "  Batch 2,880  of  29,514.    Elapsed: 0:22:51.\n",
            "  Batch 2,920  of  29,514.    Elapsed: 0:23:05.\n",
            "  Batch 2,960  of  29,514.    Elapsed: 0:23:19.\n",
            "  Batch 3,000  of  29,514.    Elapsed: 0:23:33.\n",
            "  Batch 3,040  of  29,514.    Elapsed: 0:23:47.\n",
            "  Batch 3,080  of  29,514.    Elapsed: 0:24:02.\n",
            "  Batch 3,120  of  29,514.    Elapsed: 0:24:16.\n",
            "  Batch 3,160  of  29,514.    Elapsed: 0:24:30.\n",
            "  Batch 3,200  of  29,514.    Elapsed: 0:24:44.\n",
            "  Batch 3,240  of  29,514.    Elapsed: 0:24:58.\n",
            "  Batch 3,280  of  29,514.    Elapsed: 0:25:13.\n",
            "  Batch 3,320  of  29,514.    Elapsed: 0:25:27.\n",
            "  Batch 3,360  of  29,514.    Elapsed: 0:25:41.\n",
            "  Batch 3,400  of  29,514.    Elapsed: 0:25:55.\n",
            "  Batch 3,440  of  29,514.    Elapsed: 0:26:09.\n",
            "  Batch 3,480  of  29,514.    Elapsed: 0:26:23.\n",
            "  Batch 3,520  of  29,514.    Elapsed: 0:26:37.\n",
            "  Batch 3,560  of  29,514.    Elapsed: 0:26:52.\n",
            "  Batch 3,600  of  29,514.    Elapsed: 0:27:06.\n",
            "  Batch 3,640  of  29,514.    Elapsed: 0:27:20.\n",
            "  Batch 3,680  of  29,514.    Elapsed: 0:27:34.\n",
            "  Batch 3,720  of  29,514.    Elapsed: 0:27:48.\n",
            "  Batch 3,760  of  29,514.    Elapsed: 0:28:02.\n",
            "  Batch 3,800  of  29,514.    Elapsed: 0:28:17.\n",
            "  Batch 3,840  of  29,514.    Elapsed: 0:28:31.\n",
            "  Batch 3,880  of  29,514.    Elapsed: 0:28:45.\n",
            "  Batch 3,920  of  29,514.    Elapsed: 0:28:59.\n",
            "  Batch 3,960  of  29,514.    Elapsed: 0:29:13.\n",
            "  Batch 4,000  of  29,514.    Elapsed: 0:29:27.\n",
            "  Batch 4,040  of  29,514.    Elapsed: 0:29:42.\n",
            "  Batch 4,080  of  29,514.    Elapsed: 0:29:56.\n",
            "  Batch 4,120  of  29,514.    Elapsed: 0:30:10.\n",
            "  Batch 4,160  of  29,514.    Elapsed: 0:30:24.\n",
            "  Batch 4,200  of  29,514.    Elapsed: 0:30:38.\n",
            "  Batch 4,240  of  29,514.    Elapsed: 0:30:52.\n",
            "  Batch 4,280  of  29,514.    Elapsed: 0:31:07.\n",
            "  Batch 4,320  of  29,514.    Elapsed: 0:31:21.\n",
            "  Batch 4,360  of  29,514.    Elapsed: 0:31:35.\n",
            "  Batch 4,400  of  29,514.    Elapsed: 0:31:49.\n",
            "  Batch 4,440  of  29,514.    Elapsed: 0:32:03.\n",
            "  Batch 4,480  of  29,514.    Elapsed: 0:32:18.\n",
            "  Batch 4,520  of  29,514.    Elapsed: 0:32:32.\n",
            "  Batch 4,560  of  29,514.    Elapsed: 0:32:46.\n",
            "  Batch 4,600  of  29,514.    Elapsed: 0:33:00.\n",
            "  Batch 4,640  of  29,514.    Elapsed: 0:33:14.\n",
            "  Batch 4,680  of  29,514.    Elapsed: 0:33:28.\n",
            "  Batch 4,720  of  29,514.    Elapsed: 0:33:42.\n",
            "  Batch 4,760  of  29,514.    Elapsed: 0:33:57.\n",
            "  Batch 4,800  of  29,514.    Elapsed: 0:34:11.\n",
            "  Batch 4,840  of  29,514.    Elapsed: 0:34:25.\n",
            "  Batch 4,880  of  29,514.    Elapsed: 0:34:39.\n",
            "  Batch 4,920  of  29,514.    Elapsed: 0:34:53.\n",
            "  Batch 4,960  of  29,514.    Elapsed: 0:35:07.\n",
            "  Batch 5,000  of  29,514.    Elapsed: 0:35:22.\n",
            "  Batch 5,040  of  29,514.    Elapsed: 0:35:36.\n",
            "  Batch 5,080  of  29,514.    Elapsed: 0:35:50.\n",
            "  Batch 5,120  of  29,514.    Elapsed: 0:36:04.\n",
            "  Batch 5,160  of  29,514.    Elapsed: 0:36:18.\n",
            "  Batch 5,200  of  29,514.    Elapsed: 0:36:32.\n",
            "  Batch 5,240  of  29,514.    Elapsed: 0:36:47.\n",
            "  Batch 5,280  of  29,514.    Elapsed: 0:37:01.\n",
            "  Batch 5,320  of  29,514.    Elapsed: 0:37:15.\n",
            "  Batch 5,360  of  29,514.    Elapsed: 0:37:29.\n",
            "  Batch 5,400  of  29,514.    Elapsed: 0:37:43.\n",
            "  Batch 5,440  of  29,514.    Elapsed: 0:37:57.\n",
            "  Batch 5,480  of  29,514.    Elapsed: 0:38:12.\n",
            "  Batch 5,520  of  29,514.    Elapsed: 0:38:26.\n",
            "  Batch 5,560  of  29,514.    Elapsed: 0:38:40.\n",
            "  Batch 5,600  of  29,514.    Elapsed: 0:38:54.\n",
            "  Batch 5,640  of  29,514.    Elapsed: 0:39:08.\n",
            "  Batch 5,680  of  29,514.    Elapsed: 0:39:22.\n",
            "  Batch 5,720  of  29,514.    Elapsed: 0:39:36.\n",
            "  Batch 5,760  of  29,514.    Elapsed: 0:39:51.\n",
            "  Batch 5,800  of  29,514.    Elapsed: 0:40:05.\n",
            "  Batch 5,840  of  29,514.    Elapsed: 0:40:19.\n",
            "  Batch 5,880  of  29,514.    Elapsed: 0:40:33.\n",
            "  Batch 5,920  of  29,514.    Elapsed: 0:40:47.\n",
            "  Batch 5,960  of  29,514.    Elapsed: 0:41:01.\n",
            "  Batch 6,000  of  29,514.    Elapsed: 0:41:16.\n",
            "  Batch 6,040  of  29,514.    Elapsed: 0:41:30.\n",
            "  Batch 6,080  of  29,514.    Elapsed: 0:41:44.\n",
            "  Batch 6,120  of  29,514.    Elapsed: 0:41:58.\n",
            "  Batch 6,160  of  29,514.    Elapsed: 0:42:12.\n",
            "  Batch 6,200  of  29,514.    Elapsed: 0:42:26.\n",
            "  Batch 6,240  of  29,514.    Elapsed: 0:42:41.\n",
            "  Batch 6,280  of  29,514.    Elapsed: 0:42:55.\n",
            "  Batch 6,320  of  29,514.    Elapsed: 0:43:09.\n",
            "  Batch 6,360  of  29,514.    Elapsed: 0:43:23.\n",
            "  Batch 6,400  of  29,514.    Elapsed: 0:43:37.\n",
            "  Batch 6,440  of  29,514.    Elapsed: 0:43:51.\n",
            "  Batch 6,480  of  29,514.    Elapsed: 0:44:05.\n",
            "  Batch 6,520  of  29,514.    Elapsed: 0:44:20.\n",
            "  Batch 6,560  of  29,514.    Elapsed: 0:44:34.\n",
            "  Batch 6,600  of  29,514.    Elapsed: 0:44:48.\n",
            "  Batch 6,640  of  29,514.    Elapsed: 0:45:02.\n",
            "  Batch 6,680  of  29,514.    Elapsed: 0:45:16.\n",
            "  Batch 6,720  of  29,514.    Elapsed: 0:45:30.\n",
            "  Batch 6,760  of  29,514.    Elapsed: 0:45:45.\n",
            "  Batch 6,800  of  29,514.    Elapsed: 0:45:59.\n",
            "  Batch 6,840  of  29,514.    Elapsed: 0:46:13.\n",
            "  Batch 6,880  of  29,514.    Elapsed: 0:46:27.\n",
            "  Batch 6,920  of  29,514.    Elapsed: 0:46:41.\n",
            "  Batch 6,960  of  29,514.    Elapsed: 0:46:55.\n",
            "  Batch 7,000  of  29,514.    Elapsed: 0:47:10.\n",
            "  Batch 7,040  of  29,514.    Elapsed: 0:47:24.\n",
            "  Batch 7,080  of  29,514.    Elapsed: 0:47:38.\n",
            "  Batch 7,120  of  29,514.    Elapsed: 0:47:52.\n",
            "  Batch 7,160  of  29,514.    Elapsed: 0:48:06.\n",
            "  Batch 7,200  of  29,514.    Elapsed: 0:48:20.\n",
            "  Batch 7,240  of  29,514.    Elapsed: 0:48:35.\n",
            "  Batch 7,280  of  29,514.    Elapsed: 0:48:49.\n",
            "  Batch 7,320  of  29,514.    Elapsed: 0:49:03.\n",
            "  Batch 7,360  of  29,514.    Elapsed: 0:49:17.\n",
            "  Batch 7,400  of  29,514.    Elapsed: 0:49:31.\n",
            "  Batch 7,440  of  29,514.    Elapsed: 0:49:45.\n",
            "  Batch 7,480  of  29,514.    Elapsed: 0:50:00.\n",
            "  Batch 7,520  of  29,514.    Elapsed: 0:50:14.\n",
            "  Batch 7,560  of  29,514.    Elapsed: 0:50:28.\n",
            "  Batch 7,600  of  29,514.    Elapsed: 0:50:42.\n",
            "  Batch 7,640  of  29,514.    Elapsed: 0:50:56.\n",
            "  Batch 7,680  of  29,514.    Elapsed: 0:51:10.\n",
            "  Batch 7,720  of  29,514.    Elapsed: 0:51:25.\n",
            "  Batch 7,760  of  29,514.    Elapsed: 0:51:39.\n",
            "  Batch 7,800  of  29,514.    Elapsed: 0:51:53.\n",
            "  Batch 7,840  of  29,514.    Elapsed: 0:52:07.\n",
            "  Batch 7,880  of  29,514.    Elapsed: 0:52:21.\n",
            "  Batch 7,920  of  29,514.    Elapsed: 0:52:35.\n",
            "  Batch 7,960  of  29,514.    Elapsed: 0:52:49.\n",
            "  Batch 8,000  of  29,514.    Elapsed: 0:53:04.\n",
            "  Batch 8,040  of  29,514.    Elapsed: 0:53:18.\n",
            "  Batch 8,080  of  29,514.    Elapsed: 0:53:32.\n",
            "  Batch 8,120  of  29,514.    Elapsed: 0:53:46.\n",
            "  Batch 8,160  of  29,514.    Elapsed: 0:54:00.\n",
            "  Batch 8,200  of  29,514.    Elapsed: 0:54:14.\n",
            "  Batch 8,240  of  29,514.    Elapsed: 0:54:28.\n",
            "  Batch 8,280  of  29,514.    Elapsed: 0:54:43.\n",
            "  Batch 8,320  of  29,514.    Elapsed: 0:54:57.\n",
            "  Batch 8,360  of  29,514.    Elapsed: 0:55:11.\n",
            "  Batch 8,400  of  29,514.    Elapsed: 0:55:25.\n",
            "  Batch 8,440  of  29,514.    Elapsed: 0:55:39.\n",
            "  Batch 8,480  of  29,514.    Elapsed: 0:55:53.\n",
            "  Batch 8,520  of  29,514.    Elapsed: 0:56:07.\n",
            "  Batch 8,560  of  29,514.    Elapsed: 0:56:21.\n",
            "  Batch 8,600  of  29,514.    Elapsed: 0:56:36.\n",
            "  Batch 8,640  of  29,514.    Elapsed: 0:56:50.\n",
            "  Batch 8,680  of  29,514.    Elapsed: 0:57:04.\n",
            "  Batch 8,720  of  29,514.    Elapsed: 0:57:18.\n",
            "  Batch 8,760  of  29,514.    Elapsed: 0:57:32.\n",
            "  Batch 8,800  of  29,514.    Elapsed: 0:57:46.\n",
            "  Batch 8,840  of  29,514.    Elapsed: 0:58:00.\n",
            "  Batch 8,880  of  29,514.    Elapsed: 0:58:14.\n",
            "  Batch 8,920  of  29,514.    Elapsed: 0:58:29.\n",
            "  Batch 8,960  of  29,514.    Elapsed: 0:58:43.\n",
            "  Batch 9,000  of  29,514.    Elapsed: 0:58:57.\n",
            "  Batch 9,040  of  29,514.    Elapsed: 0:59:11.\n",
            "  Batch 9,080  of  29,514.    Elapsed: 0:59:25.\n",
            "  Batch 9,120  of  29,514.    Elapsed: 0:59:39.\n",
            "  Batch 9,160  of  29,514.    Elapsed: 0:59:53.\n",
            "  Batch 9,200  of  29,514.    Elapsed: 1:00:08.\n",
            "  Batch 9,240  of  29,514.    Elapsed: 1:00:22.\n",
            "  Batch 9,280  of  29,514.    Elapsed: 1:00:36.\n",
            "  Batch 9,320  of  29,514.    Elapsed: 1:00:50.\n",
            "  Batch 9,360  of  29,514.    Elapsed: 1:01:04.\n",
            "  Batch 9,400  of  29,514.    Elapsed: 1:01:18.\n",
            "  Batch 9,440  of  29,514.    Elapsed: 1:01:32.\n",
            "  Batch 9,480  of  29,514.    Elapsed: 1:01:46.\n",
            "  Batch 9,520  of  29,514.    Elapsed: 1:02:01.\n",
            "  Batch 9,560  of  29,514.    Elapsed: 1:02:15.\n",
            "  Batch 9,600  of  29,514.    Elapsed: 1:02:29.\n",
            "  Batch 9,640  of  29,514.    Elapsed: 1:02:43.\n",
            "  Batch 9,680  of  29,514.    Elapsed: 1:02:57.\n",
            "  Batch 9,720  of  29,514.    Elapsed: 1:03:11.\n",
            "  Batch 9,760  of  29,514.    Elapsed: 1:03:25.\n",
            "  Batch 9,800  of  29,514.    Elapsed: 1:03:40.\n",
            "  Batch 9,840  of  29,514.    Elapsed: 1:03:54.\n",
            "  Batch 9,880  of  29,514.    Elapsed: 1:04:08.\n",
            "  Batch 9,920  of  29,514.    Elapsed: 1:04:22.\n",
            "  Batch 9,960  of  29,514.    Elapsed: 1:04:36.\n",
            "  Batch 10,000  of  29,514.    Elapsed: 1:04:50.\n",
            "  Batch 10,040  of  29,514.    Elapsed: 1:05:04.\n",
            "  Batch 10,080  of  29,514.    Elapsed: 1:05:19.\n",
            "  Batch 10,120  of  29,514.    Elapsed: 1:05:33.\n",
            "  Batch 10,160  of  29,514.    Elapsed: 1:05:47.\n",
            "  Batch 10,200  of  29,514.    Elapsed: 1:06:01.\n",
            "  Batch 10,240  of  29,514.    Elapsed: 1:06:15.\n",
            "  Batch 10,280  of  29,514.    Elapsed: 1:06:29.\n",
            "  Batch 10,320  of  29,514.    Elapsed: 1:06:43.\n",
            "  Batch 10,360  of  29,514.    Elapsed: 1:06:58.\n",
            "  Batch 10,400  of  29,514.    Elapsed: 1:07:12.\n",
            "  Batch 10,440  of  29,514.    Elapsed: 1:07:26.\n",
            "  Batch 10,480  of  29,514.    Elapsed: 1:07:40.\n",
            "  Batch 10,520  of  29,514.    Elapsed: 1:07:54.\n",
            "  Batch 10,560  of  29,514.    Elapsed: 1:08:08.\n",
            "  Batch 10,600  of  29,514.    Elapsed: 1:08:22.\n",
            "  Batch 10,640  of  29,514.    Elapsed: 1:08:36.\n",
            "  Batch 10,680  of  29,514.    Elapsed: 1:08:51.\n",
            "  Batch 10,720  of  29,514.    Elapsed: 1:09:05.\n",
            "  Batch 10,760  of  29,514.    Elapsed: 1:09:19.\n",
            "  Batch 10,800  of  29,514.    Elapsed: 1:09:33.\n",
            "  Batch 10,840  of  29,514.    Elapsed: 1:09:47.\n",
            "  Batch 10,880  of  29,514.    Elapsed: 1:10:01.\n",
            "  Batch 10,920  of  29,514.    Elapsed: 1:10:15.\n",
            "  Batch 10,960  of  29,514.    Elapsed: 1:10:30.\n",
            "  Batch 11,000  of  29,514.    Elapsed: 1:10:44.\n",
            "  Batch 11,040  of  29,514.    Elapsed: 1:10:58.\n",
            "  Batch 11,080  of  29,514.    Elapsed: 1:11:12.\n",
            "  Batch 11,120  of  29,514.    Elapsed: 1:11:26.\n",
            "  Batch 11,160  of  29,514.    Elapsed: 1:11:40.\n",
            "  Batch 11,200  of  29,514.    Elapsed: 1:11:54.\n",
            "  Batch 11,240  of  29,514.    Elapsed: 1:12:09.\n",
            "  Batch 11,280  of  29,514.    Elapsed: 1:12:23.\n",
            "  Batch 11,320  of  29,514.    Elapsed: 1:12:37.\n",
            "  Batch 11,360  of  29,514.    Elapsed: 1:12:51.\n",
            "  Batch 11,400  of  29,514.    Elapsed: 1:13:05.\n",
            "  Batch 11,440  of  29,514.    Elapsed: 1:13:19.\n",
            "  Batch 11,480  of  29,514.    Elapsed: 1:13:33.\n",
            "  Batch 11,520  of  29,514.    Elapsed: 1:13:48.\n",
            "  Batch 11,560  of  29,514.    Elapsed: 1:14:02.\n",
            "  Batch 11,600  of  29,514.    Elapsed: 1:14:16.\n",
            "  Batch 11,640  of  29,514.    Elapsed: 1:14:30.\n",
            "  Batch 11,680  of  29,514.    Elapsed: 1:14:44.\n",
            "  Batch 11,720  of  29,514.    Elapsed: 1:14:58.\n",
            "  Batch 11,760  of  29,514.    Elapsed: 1:15:12.\n",
            "  Batch 11,800  of  29,514.    Elapsed: 1:15:27.\n",
            "  Batch 11,840  of  29,514.    Elapsed: 1:15:41.\n",
            "  Batch 11,880  of  29,514.    Elapsed: 1:15:55.\n",
            "  Batch 11,920  of  29,514.    Elapsed: 1:16:09.\n",
            "  Batch 11,960  of  29,514.    Elapsed: 1:16:23.\n",
            "  Batch 12,000  of  29,514.    Elapsed: 1:16:37.\n",
            "  Batch 12,040  of  29,514.    Elapsed: 1:16:52.\n",
            "  Batch 12,080  of  29,514.    Elapsed: 1:17:06.\n",
            "  Batch 12,120  of  29,514.    Elapsed: 1:17:20.\n",
            "  Batch 12,160  of  29,514.    Elapsed: 1:17:34.\n",
            "  Batch 12,200  of  29,514.    Elapsed: 1:17:48.\n",
            "  Batch 12,240  of  29,514.    Elapsed: 1:18:02.\n",
            "  Batch 12,280  of  29,514.    Elapsed: 1:18:16.\n",
            "  Batch 12,320  of  29,514.    Elapsed: 1:18:30.\n",
            "  Batch 12,360  of  29,514.    Elapsed: 1:18:45.\n",
            "  Batch 12,400  of  29,514.    Elapsed: 1:18:59.\n",
            "  Batch 12,440  of  29,514.    Elapsed: 1:19:13.\n",
            "  Batch 12,480  of  29,514.    Elapsed: 1:19:27.\n",
            "  Batch 12,520  of  29,514.    Elapsed: 1:19:41.\n",
            "  Batch 12,560  of  29,514.    Elapsed: 1:19:55.\n",
            "  Batch 12,600  of  29,514.    Elapsed: 1:20:09.\n",
            "  Batch 12,640  of  29,514.    Elapsed: 1:20:24.\n",
            "  Batch 12,680  of  29,514.    Elapsed: 1:20:38.\n",
            "  Batch 12,720  of  29,514.    Elapsed: 1:20:52.\n",
            "  Batch 12,760  of  29,514.    Elapsed: 1:21:06.\n",
            "  Batch 12,800  of  29,514.    Elapsed: 1:21:20.\n",
            "  Batch 12,840  of  29,514.    Elapsed: 1:21:34.\n",
            "  Batch 12,880  of  29,514.    Elapsed: 1:21:48.\n",
            "  Batch 12,920  of  29,514.    Elapsed: 1:22:02.\n",
            "  Batch 12,960  of  29,514.    Elapsed: 1:22:17.\n",
            "  Batch 13,000  of  29,514.    Elapsed: 1:22:31.\n",
            "  Batch 13,040  of  29,514.    Elapsed: 1:22:45.\n",
            "  Batch 13,080  of  29,514.    Elapsed: 1:22:59.\n",
            "  Batch 13,120  of  29,514.    Elapsed: 1:23:13.\n",
            "  Batch 13,160  of  29,514.    Elapsed: 1:23:27.\n",
            "  Batch 13,200  of  29,514.    Elapsed: 1:23:41.\n",
            "  Batch 13,240  of  29,514.    Elapsed: 1:23:56.\n",
            "  Batch 13,280  of  29,514.    Elapsed: 1:24:10.\n",
            "  Batch 13,320  of  29,514.    Elapsed: 1:24:24.\n",
            "  Batch 13,360  of  29,514.    Elapsed: 1:24:38.\n",
            "  Batch 13,400  of  29,514.    Elapsed: 1:24:52.\n",
            "  Batch 13,440  of  29,514.    Elapsed: 1:25:06.\n",
            "  Batch 13,480  of  29,514.    Elapsed: 1:25:21.\n",
            "  Batch 13,520  of  29,514.    Elapsed: 1:25:35.\n",
            "  Batch 13,560  of  29,514.    Elapsed: 1:25:49.\n",
            "  Batch 13,600  of  29,514.    Elapsed: 1:26:03.\n",
            "  Batch 13,640  of  29,514.    Elapsed: 1:26:17.\n",
            "  Batch 13,680  of  29,514.    Elapsed: 1:26:31.\n",
            "  Batch 13,720  of  29,514.    Elapsed: 1:26:45.\n",
            "  Batch 13,760  of  29,514.    Elapsed: 1:27:00.\n",
            "  Batch 13,800  of  29,514.    Elapsed: 1:27:14.\n",
            "  Batch 13,840  of  29,514.    Elapsed: 1:27:28.\n",
            "  Batch 13,880  of  29,514.    Elapsed: 1:27:42.\n",
            "  Batch 13,920  of  29,514.    Elapsed: 1:27:56.\n",
            "  Batch 13,960  of  29,514.    Elapsed: 1:28:10.\n",
            "  Batch 14,000  of  29,514.    Elapsed: 1:28:24.\n",
            "  Batch 14,040  of  29,514.    Elapsed: 1:28:39.\n",
            "  Batch 14,080  of  29,514.    Elapsed: 1:28:53.\n",
            "  Batch 14,120  of  29,514.    Elapsed: 1:29:07.\n",
            "  Batch 14,160  of  29,514.    Elapsed: 1:29:21.\n",
            "  Batch 14,200  of  29,514.    Elapsed: 1:29:35.\n",
            "  Batch 14,240  of  29,514.    Elapsed: 1:29:49.\n",
            "  Batch 14,280  of  29,514.    Elapsed: 1:30:04.\n",
            "  Batch 14,320  of  29,514.    Elapsed: 1:30:18.\n",
            "  Batch 14,360  of  29,514.    Elapsed: 1:30:32.\n",
            "  Batch 14,400  of  29,514.    Elapsed: 1:30:46.\n",
            "  Batch 14,440  of  29,514.    Elapsed: 1:31:00.\n",
            "  Batch 14,480  of  29,514.    Elapsed: 1:31:14.\n",
            "  Batch 14,520  of  29,514.    Elapsed: 1:31:28.\n",
            "  Batch 14,560  of  29,514.    Elapsed: 1:31:43.\n",
            "  Batch 14,600  of  29,514.    Elapsed: 1:31:57.\n",
            "  Batch 14,640  of  29,514.    Elapsed: 1:32:11.\n",
            "  Batch 14,680  of  29,514.    Elapsed: 1:32:25.\n",
            "  Batch 14,720  of  29,514.    Elapsed: 1:32:39.\n",
            "  Batch 14,760  of  29,514.    Elapsed: 1:32:53.\n",
            "  Batch 14,800  of  29,514.    Elapsed: 1:33:08.\n",
            "  Batch 14,840  of  29,514.    Elapsed: 1:33:22.\n",
            "  Batch 14,880  of  29,514.    Elapsed: 1:33:36.\n",
            "  Batch 14,920  of  29,514.    Elapsed: 1:33:50.\n",
            "  Batch 14,960  of  29,514.    Elapsed: 1:34:04.\n",
            "  Batch 15,000  of  29,514.    Elapsed: 1:34:18.\n",
            "  Batch 15,040  of  29,514.    Elapsed: 1:34:33.\n",
            "  Batch 15,080  of  29,514.    Elapsed: 1:34:47.\n",
            "  Batch 15,120  of  29,514.    Elapsed: 1:35:01.\n",
            "  Batch 15,160  of  29,514.    Elapsed: 1:35:15.\n",
            "  Batch 15,200  of  29,514.    Elapsed: 1:35:29.\n",
            "  Batch 15,240  of  29,514.    Elapsed: 1:35:43.\n",
            "  Batch 15,280  of  29,514.    Elapsed: 1:35:57.\n",
            "  Batch 15,320  of  29,514.    Elapsed: 1:36:12.\n",
            "  Batch 15,360  of  29,514.    Elapsed: 1:36:26.\n",
            "  Batch 15,400  of  29,514.    Elapsed: 1:36:40.\n",
            "  Batch 15,440  of  29,514.    Elapsed: 1:36:54.\n",
            "  Batch 15,480  of  29,514.    Elapsed: 1:37:08.\n",
            "  Batch 15,520  of  29,514.    Elapsed: 1:37:22.\n",
            "  Batch 15,560  of  29,514.    Elapsed: 1:37:37.\n",
            "  Batch 15,600  of  29,514.    Elapsed: 1:37:51.\n",
            "  Batch 15,640  of  29,514.    Elapsed: 1:38:05.\n",
            "  Batch 15,680  of  29,514.    Elapsed: 1:38:19.\n",
            "  Batch 15,720  of  29,514.    Elapsed: 1:38:33.\n",
            "  Batch 15,760  of  29,514.    Elapsed: 1:38:47.\n",
            "  Batch 15,800  of  29,514.    Elapsed: 1:39:02.\n",
            "  Batch 15,840  of  29,514.    Elapsed: 1:39:16.\n",
            "  Batch 15,880  of  29,514.    Elapsed: 1:39:30.\n",
            "  Batch 15,920  of  29,514.    Elapsed: 1:39:44.\n",
            "  Batch 15,960  of  29,514.    Elapsed: 1:39:58.\n",
            "  Batch 16,000  of  29,514.    Elapsed: 1:40:12.\n",
            "  Batch 16,040  of  29,514.    Elapsed: 1:40:26.\n",
            "  Batch 16,080  of  29,514.    Elapsed: 1:40:41.\n",
            "  Batch 16,120  of  29,514.    Elapsed: 1:40:55.\n",
            "  Batch 16,160  of  29,514.    Elapsed: 1:41:09.\n",
            "  Batch 16,200  of  29,514.    Elapsed: 1:41:23.\n",
            "  Batch 16,240  of  29,514.    Elapsed: 1:41:37.\n",
            "  Batch 16,280  of  29,514.    Elapsed: 1:41:51.\n",
            "  Batch 16,320  of  29,514.    Elapsed: 1:42:05.\n",
            "  Batch 16,360  of  29,514.    Elapsed: 1:42:20.\n",
            "  Batch 16,400  of  29,514.    Elapsed: 1:42:34.\n",
            "  Batch 16,440  of  29,514.    Elapsed: 1:42:48.\n",
            "  Batch 16,480  of  29,514.    Elapsed: 1:43:02.\n",
            "  Batch 16,520  of  29,514.    Elapsed: 1:43:16.\n",
            "  Batch 16,560  of  29,514.    Elapsed: 1:43:30.\n",
            "  Batch 16,600  of  29,514.    Elapsed: 1:43:44.\n",
            "  Batch 16,640  of  29,514.    Elapsed: 1:43:59.\n",
            "  Batch 16,680  of  29,514.    Elapsed: 1:44:13.\n",
            "  Batch 16,720  of  29,514.    Elapsed: 1:44:27.\n",
            "  Batch 16,760  of  29,514.    Elapsed: 1:44:41.\n",
            "  Batch 16,800  of  29,514.    Elapsed: 1:44:55.\n",
            "  Batch 16,840  of  29,514.    Elapsed: 1:45:09.\n",
            "  Batch 16,880  of  29,514.    Elapsed: 1:45:23.\n",
            "  Batch 16,920  of  29,514.    Elapsed: 1:45:38.\n",
            "  Batch 16,960  of  29,514.    Elapsed: 1:45:52.\n",
            "  Batch 17,000  of  29,514.    Elapsed: 1:46:06.\n",
            "  Batch 17,040  of  29,514.    Elapsed: 1:46:20.\n",
            "  Batch 17,080  of  29,514.    Elapsed: 1:46:34.\n",
            "  Batch 17,120  of  29,514.    Elapsed: 1:46:48.\n",
            "  Batch 17,160  of  29,514.    Elapsed: 1:47:03.\n",
            "  Batch 17,200  of  29,514.    Elapsed: 1:47:17.\n",
            "  Batch 17,240  of  29,514.    Elapsed: 1:47:31.\n",
            "  Batch 17,280  of  29,514.    Elapsed: 1:47:45.\n",
            "  Batch 17,320  of  29,514.    Elapsed: 1:47:59.\n",
            "  Batch 17,360  of  29,514.    Elapsed: 1:48:13.\n",
            "  Batch 17,400  of  29,514.    Elapsed: 1:48:27.\n",
            "  Batch 17,440  of  29,514.    Elapsed: 1:48:42.\n",
            "  Batch 17,480  of  29,514.    Elapsed: 1:48:56.\n",
            "  Batch 17,520  of  29,514.    Elapsed: 1:49:10.\n",
            "  Batch 17,560  of  29,514.    Elapsed: 1:49:24.\n",
            "  Batch 17,600  of  29,514.    Elapsed: 1:49:38.\n",
            "  Batch 17,640  of  29,514.    Elapsed: 1:49:52.\n",
            "  Batch 17,680  of  29,514.    Elapsed: 1:50:06.\n",
            "  Batch 17,720  of  29,514.    Elapsed: 1:50:21.\n",
            "  Batch 17,760  of  29,514.    Elapsed: 1:50:35.\n",
            "  Batch 17,800  of  29,514.    Elapsed: 1:50:49.\n",
            "  Batch 17,840  of  29,514.    Elapsed: 1:51:03.\n",
            "  Batch 17,880  of  29,514.    Elapsed: 1:51:17.\n",
            "  Batch 17,920  of  29,514.    Elapsed: 1:51:31.\n",
            "  Batch 17,960  of  29,514.    Elapsed: 1:51:45.\n",
            "  Batch 18,000  of  29,514.    Elapsed: 1:52:00.\n",
            "  Batch 18,040  of  29,514.    Elapsed: 1:52:14.\n",
            "  Batch 18,080  of  29,514.    Elapsed: 1:52:28.\n",
            "  Batch 18,120  of  29,514.    Elapsed: 1:52:42.\n",
            "  Batch 18,160  of  29,514.    Elapsed: 1:52:56.\n",
            "  Batch 18,200  of  29,514.    Elapsed: 1:53:10.\n",
            "  Batch 18,240  of  29,514.    Elapsed: 1:53:24.\n",
            "  Batch 18,280  of  29,514.    Elapsed: 1:53:39.\n",
            "  Batch 18,320  of  29,514.    Elapsed: 1:53:53.\n",
            "  Batch 18,360  of  29,514.    Elapsed: 1:54:07.\n",
            "  Batch 18,400  of  29,514.    Elapsed: 1:54:21.\n",
            "  Batch 18,440  of  29,514.    Elapsed: 1:54:35.\n",
            "  Batch 18,480  of  29,514.    Elapsed: 1:54:49.\n",
            "  Batch 18,520  of  29,514.    Elapsed: 1:55:03.\n",
            "  Batch 18,560  of  29,514.    Elapsed: 1:55:17.\n",
            "  Batch 18,600  of  29,514.    Elapsed: 1:55:32.\n",
            "  Batch 18,640  of  29,514.    Elapsed: 1:55:46.\n",
            "  Batch 18,680  of  29,514.    Elapsed: 1:56:00.\n",
            "  Batch 18,720  of  29,514.    Elapsed: 1:56:14.\n",
            "  Batch 18,760  of  29,514.    Elapsed: 1:56:28.\n",
            "  Batch 18,800  of  29,514.    Elapsed: 1:56:42.\n",
            "  Batch 18,840  of  29,514.    Elapsed: 1:56:57.\n",
            "  Batch 18,880  of  29,514.    Elapsed: 1:57:11.\n",
            "  Batch 18,920  of  29,514.    Elapsed: 1:57:25.\n",
            "  Batch 18,960  of  29,514.    Elapsed: 1:57:39.\n",
            "  Batch 19,000  of  29,514.    Elapsed: 1:57:53.\n",
            "  Batch 19,040  of  29,514.    Elapsed: 1:58:07.\n",
            "  Batch 19,080  of  29,514.    Elapsed: 1:58:21.\n",
            "  Batch 19,120  of  29,514.    Elapsed: 1:58:35.\n",
            "  Batch 19,160  of  29,514.    Elapsed: 1:58:50.\n",
            "  Batch 19,200  of  29,514.    Elapsed: 1:59:04.\n",
            "  Batch 19,240  of  29,514.    Elapsed: 1:59:18.\n",
            "  Batch 19,280  of  29,514.    Elapsed: 1:59:32.\n",
            "  Batch 19,320  of  29,514.    Elapsed: 1:59:46.\n",
            "  Batch 19,360  of  29,514.    Elapsed: 2:00:00.\n",
            "  Batch 19,400  of  29,514.    Elapsed: 2:00:14.\n",
            "  Batch 19,440  of  29,514.    Elapsed: 2:00:29.\n",
            "  Batch 19,480  of  29,514.    Elapsed: 2:00:43.\n",
            "  Batch 19,520  of  29,514.    Elapsed: 2:00:57.\n",
            "  Batch 19,560  of  29,514.    Elapsed: 2:01:11.\n",
            "  Batch 19,600  of  29,514.    Elapsed: 2:01:25.\n",
            "  Batch 19,640  of  29,514.    Elapsed: 2:01:39.\n",
            "  Batch 19,680  of  29,514.    Elapsed: 2:01:53.\n",
            "  Batch 19,720  of  29,514.    Elapsed: 2:02:08.\n",
            "  Batch 19,760  of  29,514.    Elapsed: 2:02:22.\n",
            "  Batch 19,800  of  29,514.    Elapsed: 2:02:36.\n",
            "  Batch 19,840  of  29,514.    Elapsed: 2:02:50.\n",
            "  Batch 19,880  of  29,514.    Elapsed: 2:03:04.\n",
            "  Batch 19,920  of  29,514.    Elapsed: 2:03:18.\n",
            "  Batch 19,960  of  29,514.    Elapsed: 2:03:33.\n",
            "  Batch 20,000  of  29,514.    Elapsed: 2:03:47.\n",
            "  Batch 20,040  of  29,514.    Elapsed: 2:04:01.\n",
            "  Batch 20,080  of  29,514.    Elapsed: 2:04:15.\n",
            "  Batch 20,120  of  29,514.    Elapsed: 2:04:29.\n",
            "  Batch 20,160  of  29,514.    Elapsed: 2:04:43.\n",
            "  Batch 20,200  of  29,514.    Elapsed: 2:04:57.\n",
            "  Batch 20,240  of  29,514.    Elapsed: 2:05:12.\n",
            "  Batch 20,280  of  29,514.    Elapsed: 2:05:26.\n",
            "  Batch 20,320  of  29,514.    Elapsed: 2:05:40.\n",
            "  Batch 20,360  of  29,514.    Elapsed: 2:05:54.\n",
            "  Batch 20,400  of  29,514.    Elapsed: 2:06:08.\n",
            "  Batch 20,440  of  29,514.    Elapsed: 2:06:22.\n",
            "  Batch 20,480  of  29,514.    Elapsed: 2:06:37.\n",
            "  Batch 20,520  of  29,514.    Elapsed: 2:06:51.\n",
            "  Batch 20,560  of  29,514.    Elapsed: 2:07:05.\n",
            "  Batch 20,600  of  29,514.    Elapsed: 2:07:19.\n",
            "  Batch 20,640  of  29,514.    Elapsed: 2:07:33.\n",
            "  Batch 20,680  of  29,514.    Elapsed: 2:07:47.\n",
            "  Batch 20,720  of  29,514.    Elapsed: 2:08:01.\n",
            "  Batch 20,760  of  29,514.    Elapsed: 2:08:16.\n",
            "  Batch 20,800  of  29,514.    Elapsed: 2:08:30.\n",
            "  Batch 20,840  of  29,514.    Elapsed: 2:08:44.\n",
            "  Batch 20,880  of  29,514.    Elapsed: 2:08:58.\n",
            "  Batch 20,920  of  29,514.    Elapsed: 2:09:12.\n",
            "  Batch 20,960  of  29,514.    Elapsed: 2:09:26.\n",
            "  Batch 21,000  of  29,514.    Elapsed: 2:09:40.\n",
            "  Batch 21,040  of  29,514.    Elapsed: 2:09:55.\n",
            "  Batch 21,080  of  29,514.    Elapsed: 2:10:09.\n",
            "  Batch 21,120  of  29,514.    Elapsed: 2:10:23.\n",
            "  Batch 21,160  of  29,514.    Elapsed: 2:10:37.\n",
            "  Batch 21,200  of  29,514.    Elapsed: 2:10:51.\n",
            "  Batch 21,240  of  29,514.    Elapsed: 2:11:05.\n",
            "  Batch 21,280  of  29,514.    Elapsed: 2:11:19.\n",
            "  Batch 21,320  of  29,514.    Elapsed: 2:11:34.\n",
            "  Batch 21,360  of  29,514.    Elapsed: 2:11:48.\n",
            "  Batch 21,400  of  29,514.    Elapsed: 2:12:02.\n",
            "  Batch 21,440  of  29,514.    Elapsed: 2:12:16.\n",
            "  Batch 21,480  of  29,514.    Elapsed: 2:12:30.\n",
            "  Batch 21,520  of  29,514.    Elapsed: 2:12:44.\n",
            "  Batch 21,560  of  29,514.    Elapsed: 2:12:58.\n",
            "  Batch 21,600  of  29,514.    Elapsed: 2:13:13.\n",
            "  Batch 21,640  of  29,514.    Elapsed: 2:13:27.\n",
            "  Batch 21,680  of  29,514.    Elapsed: 2:13:41.\n",
            "  Batch 21,720  of  29,514.    Elapsed: 2:13:55.\n",
            "  Batch 21,760  of  29,514.    Elapsed: 2:14:09.\n",
            "  Batch 21,800  of  29,514.    Elapsed: 2:14:23.\n",
            "  Batch 21,840  of  29,514.    Elapsed: 2:14:37.\n",
            "  Batch 21,880  of  29,514.    Elapsed: 2:14:52.\n",
            "  Batch 21,920  of  29,514.    Elapsed: 2:15:06.\n",
            "  Batch 21,960  of  29,514.    Elapsed: 2:15:20.\n",
            "  Batch 22,000  of  29,514.    Elapsed: 2:15:34.\n",
            "  Batch 22,040  of  29,514.    Elapsed: 2:15:48.\n",
            "  Batch 22,080  of  29,514.    Elapsed: 2:16:02.\n",
            "  Batch 22,120  of  29,514.    Elapsed: 2:16:16.\n",
            "  Batch 22,160  of  29,514.    Elapsed: 2:16:31.\n",
            "  Batch 22,200  of  29,514.    Elapsed: 2:16:45.\n",
            "  Batch 22,240  of  29,514.    Elapsed: 2:16:59.\n",
            "  Batch 22,280  of  29,514.    Elapsed: 2:17:13.\n",
            "  Batch 22,320  of  29,514.    Elapsed: 2:17:27.\n",
            "  Batch 22,360  of  29,514.    Elapsed: 2:17:41.\n",
            "  Batch 22,400  of  29,514.    Elapsed: 2:17:55.\n",
            "  Batch 22,440  of  29,514.    Elapsed: 2:18:10.\n",
            "  Batch 22,480  of  29,514.    Elapsed: 2:18:24.\n",
            "  Batch 22,520  of  29,514.    Elapsed: 2:18:38.\n",
            "  Batch 22,560  of  29,514.    Elapsed: 2:18:52.\n",
            "  Batch 22,600  of  29,514.    Elapsed: 2:19:06.\n",
            "  Batch 22,640  of  29,514.    Elapsed: 2:19:20.\n",
            "  Batch 22,680  of  29,514.    Elapsed: 2:19:34.\n",
            "  Batch 22,720  of  29,514.    Elapsed: 2:19:48.\n",
            "  Batch 22,760  of  29,514.    Elapsed: 2:20:03.\n",
            "  Batch 22,800  of  29,514.    Elapsed: 2:20:17.\n",
            "  Batch 22,840  of  29,514.    Elapsed: 2:20:31.\n",
            "  Batch 22,880  of  29,514.    Elapsed: 2:20:45.\n",
            "  Batch 22,920  of  29,514.    Elapsed: 2:20:59.\n",
            "  Batch 22,960  of  29,514.    Elapsed: 2:21:13.\n",
            "  Batch 23,000  of  29,514.    Elapsed: 2:21:27.\n",
            "  Batch 23,040  of  29,514.    Elapsed: 2:21:42.\n",
            "  Batch 23,080  of  29,514.    Elapsed: 2:21:56.\n",
            "  Batch 23,120  of  29,514.    Elapsed: 2:22:10.\n",
            "  Batch 23,160  of  29,514.    Elapsed: 2:22:24.\n",
            "  Batch 23,200  of  29,514.    Elapsed: 2:22:38.\n",
            "  Batch 23,240  of  29,514.    Elapsed: 2:22:52.\n",
            "  Batch 23,280  of  29,514.    Elapsed: 2:23:06.\n",
            "  Batch 23,320  of  29,514.    Elapsed: 2:23:21.\n",
            "  Batch 23,360  of  29,514.    Elapsed: 2:23:35.\n",
            "  Batch 23,400  of  29,514.    Elapsed: 2:23:49.\n",
            "  Batch 23,440  of  29,514.    Elapsed: 2:24:03.\n",
            "  Batch 23,480  of  29,514.    Elapsed: 2:24:17.\n",
            "  Batch 23,520  of  29,514.    Elapsed: 2:24:31.\n",
            "  Batch 23,560  of  29,514.    Elapsed: 2:24:45.\n",
            "  Batch 23,600  of  29,514.    Elapsed: 2:25:00.\n",
            "  Batch 23,640  of  29,514.    Elapsed: 2:25:14.\n",
            "  Batch 23,680  of  29,514.    Elapsed: 2:25:28.\n",
            "  Batch 23,720  of  29,514.    Elapsed: 2:25:42.\n",
            "  Batch 23,760  of  29,514.    Elapsed: 2:25:56.\n",
            "  Batch 23,800  of  29,514.    Elapsed: 2:26:10.\n",
            "  Batch 23,840  of  29,514.    Elapsed: 2:26:24.\n",
            "  Batch 23,880  of  29,514.    Elapsed: 2:26:39.\n",
            "  Batch 23,920  of  29,514.    Elapsed: 2:26:53.\n",
            "  Batch 23,960  of  29,514.    Elapsed: 2:27:07.\n",
            "  Batch 24,000  of  29,514.    Elapsed: 2:27:21.\n",
            "  Batch 24,040  of  29,514.    Elapsed: 2:27:35.\n",
            "  Batch 24,080  of  29,514.    Elapsed: 2:27:49.\n",
            "  Batch 24,120  of  29,514.    Elapsed: 2:28:04.\n",
            "  Batch 24,160  of  29,514.    Elapsed: 2:28:18.\n",
            "  Batch 24,200  of  29,514.    Elapsed: 2:28:32.\n",
            "  Batch 24,240  of  29,514.    Elapsed: 2:28:46.\n",
            "  Batch 24,280  of  29,514.    Elapsed: 2:29:00.\n",
            "  Batch 24,320  of  29,514.    Elapsed: 2:29:14.\n",
            "  Batch 24,360  of  29,514.    Elapsed: 2:29:28.\n",
            "  Batch 24,400  of  29,514.    Elapsed: 2:29:43.\n",
            "  Batch 24,440  of  29,514.    Elapsed: 2:29:57.\n",
            "  Batch 24,480  of  29,514.    Elapsed: 2:30:11.\n",
            "  Batch 24,520  of  29,514.    Elapsed: 2:30:25.\n",
            "  Batch 24,560  of  29,514.    Elapsed: 2:30:39.\n",
            "  Batch 24,600  of  29,514.    Elapsed: 2:30:53.\n",
            "  Batch 24,640  of  29,514.    Elapsed: 2:31:07.\n",
            "  Batch 24,680  of  29,514.    Elapsed: 2:31:22.\n",
            "  Batch 24,720  of  29,514.    Elapsed: 2:31:36.\n",
            "  Batch 24,760  of  29,514.    Elapsed: 2:31:50.\n",
            "  Batch 24,800  of  29,514.    Elapsed: 2:32:04.\n",
            "  Batch 24,840  of  29,514.    Elapsed: 2:32:18.\n",
            "  Batch 24,880  of  29,514.    Elapsed: 2:32:32.\n",
            "  Batch 24,920  of  29,514.    Elapsed: 2:32:46.\n",
            "  Batch 24,960  of  29,514.    Elapsed: 2:33:01.\n",
            "  Batch 25,000  of  29,514.    Elapsed: 2:33:15.\n",
            "  Batch 25,040  of  29,514.    Elapsed: 2:33:29.\n",
            "  Batch 25,080  of  29,514.    Elapsed: 2:33:43.\n",
            "  Batch 25,120  of  29,514.    Elapsed: 2:33:57.\n",
            "  Batch 25,160  of  29,514.    Elapsed: 2:34:11.\n",
            "  Batch 25,200  of  29,514.    Elapsed: 2:34:26.\n",
            "  Batch 25,240  of  29,514.    Elapsed: 2:34:40.\n",
            "  Batch 25,280  of  29,514.    Elapsed: 2:34:54.\n",
            "  Batch 25,320  of  29,514.    Elapsed: 2:35:08.\n",
            "  Batch 25,360  of  29,514.    Elapsed: 2:35:22.\n",
            "  Batch 25,400  of  29,514.    Elapsed: 2:35:36.\n",
            "  Batch 25,440  of  29,514.    Elapsed: 2:35:50.\n",
            "  Batch 25,480  of  29,514.    Elapsed: 2:36:05.\n",
            "  Batch 25,520  of  29,514.    Elapsed: 2:36:19.\n",
            "  Batch 25,560  of  29,514.    Elapsed: 2:36:33.\n",
            "  Batch 25,600  of  29,514.    Elapsed: 2:36:47.\n",
            "  Batch 25,640  of  29,514.    Elapsed: 2:37:01.\n",
            "  Batch 25,680  of  29,514.    Elapsed: 2:37:15.\n",
            "  Batch 25,720  of  29,514.    Elapsed: 2:37:29.\n",
            "  Batch 25,760  of  29,514.    Elapsed: 2:37:44.\n",
            "  Batch 25,800  of  29,514.    Elapsed: 2:37:58.\n",
            "  Batch 25,840  of  29,514.    Elapsed: 2:38:12.\n",
            "  Batch 25,880  of  29,514.    Elapsed: 2:38:26.\n",
            "  Batch 25,920  of  29,514.    Elapsed: 2:38:40.\n",
            "  Batch 25,960  of  29,514.    Elapsed: 2:38:54.\n",
            "  Batch 26,000  of  29,514.    Elapsed: 2:39:09.\n",
            "  Batch 26,040  of  29,514.    Elapsed: 2:39:23.\n",
            "  Batch 26,080  of  29,514.    Elapsed: 2:39:37.\n",
            "  Batch 26,120  of  29,514.    Elapsed: 2:39:51.\n",
            "  Batch 26,160  of  29,514.    Elapsed: 2:40:05.\n",
            "  Batch 26,200  of  29,514.    Elapsed: 2:40:19.\n",
            "  Batch 26,240  of  29,514.    Elapsed: 2:40:33.\n",
            "  Batch 26,280  of  29,514.    Elapsed: 2:40:48.\n",
            "  Batch 26,320  of  29,514.    Elapsed: 2:41:02.\n",
            "  Batch 26,360  of  29,514.    Elapsed: 2:41:16.\n",
            "  Batch 26,400  of  29,514.    Elapsed: 2:41:30.\n",
            "  Batch 26,440  of  29,514.    Elapsed: 2:41:44.\n",
            "  Batch 26,480  of  29,514.    Elapsed: 2:41:58.\n",
            "  Batch 26,520  of  29,514.    Elapsed: 2:42:13.\n",
            "  Batch 26,560  of  29,514.    Elapsed: 2:42:27.\n",
            "  Batch 26,600  of  29,514.    Elapsed: 2:42:41.\n",
            "  Batch 26,640  of  29,514.    Elapsed: 2:42:55.\n",
            "  Batch 26,680  of  29,514.    Elapsed: 2:43:09.\n",
            "  Batch 26,720  of  29,514.    Elapsed: 2:43:23.\n",
            "  Batch 26,760  of  29,514.    Elapsed: 2:43:37.\n",
            "  Batch 26,800  of  29,514.    Elapsed: 2:43:52.\n",
            "  Batch 26,840  of  29,514.    Elapsed: 2:44:06.\n",
            "  Batch 26,880  of  29,514.    Elapsed: 2:44:20.\n",
            "  Batch 26,920  of  29,514.    Elapsed: 2:44:34.\n",
            "  Batch 26,960  of  29,514.    Elapsed: 2:44:48.\n",
            "  Batch 27,000  of  29,514.    Elapsed: 2:45:02.\n",
            "  Batch 27,040  of  29,514.    Elapsed: 2:45:16.\n",
            "  Batch 27,080  of  29,514.    Elapsed: 2:45:31.\n",
            "  Batch 27,120  of  29,514.    Elapsed: 2:45:45.\n",
            "  Batch 27,160  of  29,514.    Elapsed: 2:45:59.\n",
            "  Batch 27,200  of  29,514.    Elapsed: 2:46:13.\n",
            "  Batch 27,240  of  29,514.    Elapsed: 2:46:27.\n",
            "  Batch 27,280  of  29,514.    Elapsed: 2:46:41.\n",
            "  Batch 27,320  of  29,514.    Elapsed: 2:46:55.\n",
            "  Batch 27,360  of  29,514.    Elapsed: 2:47:10.\n",
            "  Batch 27,400  of  29,514.    Elapsed: 2:47:24.\n",
            "  Batch 27,440  of  29,514.    Elapsed: 2:47:38.\n",
            "  Batch 27,480  of  29,514.    Elapsed: 2:47:52.\n",
            "  Batch 27,520  of  29,514.    Elapsed: 2:48:06.\n",
            "  Batch 27,560  of  29,514.    Elapsed: 2:48:20.\n",
            "  Batch 27,600  of  29,514.    Elapsed: 2:48:35.\n",
            "  Batch 27,640  of  29,514.    Elapsed: 2:48:49.\n",
            "  Batch 27,680  of  29,514.    Elapsed: 2:49:03.\n",
            "  Batch 27,720  of  29,514.    Elapsed: 2:49:17.\n",
            "  Batch 27,760  of  29,514.    Elapsed: 2:49:31.\n",
            "  Batch 27,800  of  29,514.    Elapsed: 2:49:45.\n",
            "  Batch 27,840  of  29,514.    Elapsed: 2:49:59.\n",
            "  Batch 27,880  of  29,514.    Elapsed: 2:50:13.\n",
            "  Batch 27,920  of  29,514.    Elapsed: 2:50:28.\n",
            "  Batch 27,960  of  29,514.    Elapsed: 2:50:42.\n",
            "  Batch 28,000  of  29,514.    Elapsed: 2:50:56.\n",
            "  Batch 28,040  of  29,514.    Elapsed: 2:51:10.\n",
            "  Batch 28,080  of  29,514.    Elapsed: 2:51:24.\n",
            "  Batch 28,120  of  29,514.    Elapsed: 2:51:38.\n",
            "  Batch 28,160  of  29,514.    Elapsed: 2:51:53.\n",
            "  Batch 28,200  of  29,514.    Elapsed: 2:52:07.\n",
            "  Batch 28,240  of  29,514.    Elapsed: 2:52:21.\n",
            "  Batch 28,280  of  29,514.    Elapsed: 2:52:35.\n",
            "  Batch 28,320  of  29,514.    Elapsed: 2:52:49.\n",
            "  Batch 28,360  of  29,514.    Elapsed: 2:53:03.\n",
            "  Batch 28,400  of  29,514.    Elapsed: 2:53:18.\n",
            "  Batch 28,440  of  29,514.    Elapsed: 2:53:32.\n",
            "  Batch 28,480  of  29,514.    Elapsed: 2:53:46.\n",
            "  Batch 28,520  of  29,514.    Elapsed: 2:54:00.\n",
            "  Batch 28,560  of  29,514.    Elapsed: 2:54:14.\n",
            "  Batch 28,600  of  29,514.    Elapsed: 2:54:28.\n",
            "  Batch 28,640  of  29,514.    Elapsed: 2:54:42.\n",
            "  Batch 28,680  of  29,514.    Elapsed: 2:54:57.\n",
            "  Batch 28,720  of  29,514.    Elapsed: 2:55:11.\n",
            "  Batch 28,760  of  29,514.    Elapsed: 2:55:25.\n",
            "  Batch 28,800  of  29,514.    Elapsed: 2:55:39.\n",
            "  Batch 28,840  of  29,514.    Elapsed: 2:55:53.\n",
            "  Batch 28,880  of  29,514.    Elapsed: 2:56:07.\n",
            "  Batch 28,920  of  29,514.    Elapsed: 2:56:21.\n",
            "  Batch 28,960  of  29,514.    Elapsed: 2:56:35.\n",
            "  Batch 29,000  of  29,514.    Elapsed: 2:56:50.\n",
            "  Batch 29,040  of  29,514.    Elapsed: 2:57:04.\n",
            "  Batch 29,080  of  29,514.    Elapsed: 2:57:18.\n",
            "  Batch 29,120  of  29,514.    Elapsed: 2:57:32.\n",
            "  Batch 29,160  of  29,514.    Elapsed: 2:57:46.\n",
            "  Batch 29,200  of  29,514.    Elapsed: 2:58:00.\n",
            "  Batch 29,240  of  29,514.    Elapsed: 2:58:14.\n",
            "  Batch 29,280  of  29,514.    Elapsed: 2:58:29.\n",
            "  Batch 29,320  of  29,514.    Elapsed: 2:58:43.\n",
            "  Batch 29,360  of  29,514.    Elapsed: 2:58:57.\n",
            "  Batch 29,400  of  29,514.    Elapsed: 2:59:11.\n",
            "  Batch 29,440  of  29,514.    Elapsed: 2:59:25.\n",
            "  Batch 29,480  of  29,514.    Elapsed: 2:59:39.\n",
            "\n",
            "  Average training loss: 0.03\n",
            "  Training epcoh took: 2:59:51\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "  Validation Loss: 0.03\n",
            "  Validation took: 0:06:30\n",
            "\n",
            "Training complete!\n",
            "Total training took 3:06:21 (h:mm:ss)\n",
            "Saving model to /content/drive/MyDrive/Colab Notebooks/summary/ko_grammar_model4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4zeEb0NR2QH"
      },
      "source": [
        "# 문법 discriminator 활용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7Zf2oRMMXmH",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97fdac4e-68ea-400c-d9fc-593fdf092c12"
      },
      "source": [
        "g_discriminator = Grammar_Discriminator(input_dir = '/content/drive/MyDrive/Colab Notebooks/summary/ko_grammar_model4')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEXRsgqlXkpf",
        "outputId": "a27effec-af4f-40eb-dd5b-5b0d439942f4"
      },
      "source": [
        "txt = ['최근 날씨가 포근해지면서 산을 찾는 사람들도 늘고 있는데요','서비스를 음원 플랫폼 스포티파이가 국내  론칭한다']\n",
        "g_discriminator.discriminator.to(device)\n",
        "g_discriminator.transfer_learning(txt)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(4.3705, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " tensor([[-4.8017,  5.1989],\n",
              "         [ 4.3898, -4.3509]], device='cuda:0', grad_fn=<AddmmBackward>))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d96kaCAHKuUc"
      },
      "source": [
        "##4.3 Static similarity discriminator class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZDpXe7XKxeg",
        "trusted": true
      },
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import BertTokenizer\n",
        "from scipy.signal import find_peaks\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.misc import electrocardiogram\n",
        "import scipy\n",
        "\n",
        "\n",
        "class Similarity_Discriminator:\n",
        "    '''\n",
        "    _instance = None\n",
        "    _embedder = None\n",
        "    def __new__(cls,pre_trained_model_name='stsb-roberta-large'):\n",
        "        if cls._instance is None:\n",
        "            print('Creating Similarity_Discriminator object')\n",
        "            cls._instance = super(Similarity_Discriminator, cls).__new__(cls)\n",
        "            # Put any initialization here.\n",
        "            cls._embedder = SentenceTransformer(pre_trained_model_name)\n",
        "        return cls._instance\n",
        "\n",
        "    '''\n",
        "\n",
        "    def __init__(self,pre_trained_model_name='xlm-r-large-en-ko-nli-ststb'): #'roberta-large-nli-stsb-mean-tokens'):\n",
        "        print('Creating Similarity_Discriminator object')\n",
        "        # Put any initialization here.\n",
        "        self._embedder = SentenceTransformer(pre_trained_model_name,device=device)  \n",
        "        #self.cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
        "\n",
        "    def encode(self,texts):\n",
        "        return self._embedder.encode(texts,show_progress_bar=False)\n",
        "\n",
        "    def similarity(self, query_text, org_text_emb):\n",
        "        queries = nltk.sent_tokenize(query_text)\n",
        "        query_embeddings = self._embedder.encode(queries,show_progress_bar=False)\n",
        "        #query_embeddings = self._embedder.encode(queries,show_progress_bar=False)\n",
        "        #print(queries)\n",
        "        #print(org_text_emb)\n",
        "        \n",
        "        if len(query_embeddings) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        cos_scores = scipy.spatial.distance.cdist(query_embeddings, org_text_emb, \"cosine\")\n",
        "        similarity_score = 1.0 - np.min(np.max(cos_scores,axis=1))\n",
        "        '''\n",
        "        for query, query_embedding in zip(queries, query_embeddings):\n",
        "            distances = scipy.spatial.distance.cdist([query_embedding], [org_text_emb], \"cosine\")[0]\n",
        "            results = zip(range(len(distances)), distances)\n",
        "            for idx, distance in results:\n",
        "                scores.append(1-distance)\n",
        "        '''\n",
        "        return similarity_score  \n",
        " "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sQZ36GuMumP"
      },
      "source": [
        "###4.3.1 한국어 문장 유사도 pre-trained model 적용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9Miao14Muww",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "787d31b2-df1b-476a-f55f-cfda23f6ba66"
      },
      "source": [
        "#del s_discriminator\n",
        "\n",
        "s_discriminator = Similarity_Discriminator()\n",
        "#s_discriminator = Similarity_Discriminator()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating Similarity_Discriminator object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xnk9GsQ0K1t1"
      },
      "source": [
        "# 4.4 Document source class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhvXMrSO-CiD"
      },
      "source": [
        "## 두 문장을 합치는 rule 변환기... --> 이거... ML로 나중에 바꿔야..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_W1Wqq26MjQ"
      },
      "source": [
        "\n",
        "combine_matching_table = {}\n",
        "\n",
        "combine_matching_table['어요.'] = '고'\n",
        "combine_matching_table['지요.'] = '고'\n",
        "combine_matching_table['답니다.'] = '고'\n",
        "combine_matching_table['보거라.'] = '봐,'\n",
        "combine_matching_table['간단다.'] = '가니,'\n",
        "combine_matching_table['돼.'] = '되,'\n",
        "combine_matching_table['해.'] = '하며,'\n",
        "combine_matching_table['다.'] = '고'\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giRiIsfR6DV6"
      },
      "source": [
        "def combine_sentence(txt):\n",
        "    for c in combine_matching_table.keys():\n",
        "        if txt.endswith(c):\n",
        "            txt = txt.replace(c,combine_matching_table[c])\n",
        "    return txt"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwhMHwwefy-N"
      },
      "source": [
        "\n",
        "conjunction_table = ['그러던','그래서','그러나','그런데','그리고','그랬더니','그러니까','하지만','그래서']"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnBm6RCvNIWG"
      },
      "source": [
        "## 4.4.2 source class 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsJKbtc2K4xN",
        "trusted": true
      },
      "source": [
        "\n",
        "\n",
        "class Source:\n",
        "\n",
        "    def __init__(self,full_text,org_text,delete_ending = False):\n",
        "        self.full_text = full_text\n",
        "        self.org_text = org_text\n",
        "        self.delete_ending = delete_ending\n",
        "\n",
        "    def __crean_text(self, txt):\n",
        "        txt = txt.replace('\\n',' ')\n",
        "        txt = txt.replace('\\r',' ')    \n",
        "        txt = txt.replace('=','')\n",
        "        txt = txt.replace('\\\"','')   \n",
        "        txt = txt.replace('\\'','')\n",
        "        txt = txt.replace(',','')\n",
        "        txt = txt.replace('..','')\n",
        "        txt = txt.replace('...','')\n",
        "        txt = txt.replace(' .','.')\n",
        "        txt = txt.replace('.','. ')\n",
        "        txt = txt.replace('  ',' ')\n",
        "        txt = txt.replace('  ',' ')    \n",
        "        txt = txt.replace('  ',' ')   \n",
        "        txt = txt.replace('  ',' ')           \n",
        "        txt = txt.replace('  ',' ')\n",
        "        txt = txt.replace('  ',' ')    \n",
        "        txt = txt.replace('  ',' ')   \n",
        "        txt = txt.replace('  ',' ')           \n",
        "        return txt.strip()\n",
        "\n",
        "    def set_key_rate(self,s_discriminator):\n",
        "        self.full_text = self.__crean_text(self.full_text.strip())\n",
        "        self.org_text = self.__crean_text(self.org_text.strip())\n",
        "        print('-'*50)\n",
        "        print(self.org_text)\n",
        "        print('-'*50)\n",
        "        self.org_sentences = np.array(nltk.sent_tokenize(self.org_text))\n",
        "        for i,sents in enumerate(self.org_sentences):\n",
        "            '''\n",
        "            for cj in conjunction_table: \n",
        "                if sents.startswith(cj):\n",
        "                    self.org_sentences[i] = sents[len(cj):].strip()\n",
        "            '''\n",
        "            if self.delete_ending:\n",
        "                if i < len(self.org_sentences)-1: #중간 문장의 '~다.'를 삭제한다.\n",
        "                    #w = self.org_sentences[i].split(' ')\n",
        "                    #self.org_sentences[i] = ' '.join(w[0:len(w)-1])\n",
        "                    w = self.org_sentences[i]\n",
        "                    self.org_sentences[i] = w[0:len(w)-2]\n",
        "        '''\n",
        "        self.org_text = (' '.join(self.org_sentences)).strip()\n",
        "        print(self.org_text)\n",
        "        self.org_text = sentence_correct(self.org_text)\n",
        "        print(self.org_text)\n",
        "        '''\n",
        "\n",
        "        self.full_sentences = np.array(nltk.sent_tokenize(self.full_text))\n",
        "        \n",
        "        #self.org_term_set = (' ' + self.org_text + ' ').split(' ')\n",
        "        self.org_term_set = (' '.join(self.org_sentences)).strip().split(' ')\n",
        "        self.org_source_length = len(self.org_term_set)\n",
        "        self.term_table = {}\n",
        "        self.seps = []\n",
        "        self.bias_table = {}\n",
        "        #morp_table = {}\n",
        "\n",
        "        for index, word in enumerate(self.org_term_set):\n",
        "            self.term_table[index] = word\n",
        "            attention = cosine_similarity(self.full_text,word)\n",
        "            '''\n",
        "            if attention > 0.2:\n",
        "                self.bias_table[index] = 0.0\n",
        "            else:\n",
        "                self.bias_table[index] = attention #-cosine_similarity(self.full_text,word)\n",
        "            '''\n",
        "            if attention > 0.0:\n",
        "                self.bias_table[index] = 1.0\n",
        "            else:\n",
        "                self.bias_table[index] = -1.0 #attention #-cosine_similarity(self.full_text,word)\n",
        "\n",
        "            if self.delete_ending:\n",
        "                pass\n",
        "            else:\n",
        "                if word.endswith(('.','?')):\n",
        "                    self.seps.append(index)\n",
        "                    if self.org_source_length - 1 == index:\n",
        "                        pass\n",
        "                    else:\n",
        "                        self.term_table[index] = combine_sentence(word)\n",
        "\n",
        "        \n",
        "        #for i,w in enumerate(self.term_table.values()):\n",
        "        #    print(i,w,self.bias_table[i])\n",
        "        \n",
        "        #print(self.term_table)\n",
        "        #print('------------------------------------------------------------------')\n",
        "\n",
        "        self.s_discriminator = s_discriminator\n",
        "        # 원문의 embedding...\n",
        "        self.org_text_emb = self.s_discriminator.encode(self.org_sentences)\n",
        "        self.full_text_emb = self.s_discriminator.encode(self.full_sentences)\n",
        "        #top_n = int(len(self.term_table) * comp_rate)\n",
        "        #print('top_n',top_n)\n",
        "        #self.story_peaks = [i+1 for i in range(top_n)]\n",
        "\n",
        "    def get_org_sample(self, num):\n",
        "        return self.org_sentences[np.random.choice(len(self.org_sentences), num)]\n",
        "\n",
        "    def get_source_embedded_code(self):\n",
        "        return self.org_text_emb\n",
        "\n",
        "    def get_random_text(self,rate=0.5):\n",
        "        cnt = int(len(self.term_table) * rate)\n",
        "        a = list(self.term_table.keys())\n",
        "        b = np.random.choice(a, cnt)\n",
        "        c = [fruit for fruit in a if fruit not in b]\n",
        "        txt = []\n",
        "        for i in c:\n",
        "            txt.append(self.term_table[i])\n",
        "        return ' '.join(txt).strip(), hash(tuple(b))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnEyzqVQYxdR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbc2252b-b652-41af-e9b5-8fcfb04c9e48"
      },
      "source": [
        "a = torch.tensor([[1,1,1],[2,2,2]])\n",
        "b = torch.tensor([[1,1,1],[2,2,2]])\n",
        "torch.add(a,b)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2, 2, 2],\n",
              "        [4, 4, 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af5b1VF7poE2"
      },
      "source": [
        "## N-Gram Similarity Comparison\n",
        "\n",
        "https://gist.github.com/gaulinmp/da5825de975ed0ea6a24186434c24fe4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAfA5fHxBoGW",
        "outputId": "ba0bb554-0cb5-45f8-f706-51d789765b66"
      },
      "source": [
        "# Get Tuple algorithms \n",
        "import re\n",
        "import math\n",
        "import numpy as np\n",
        "from itertools import chain\n",
        "from collections import Counter\n",
        "import nltk\n",
        "from nltk.util import ngrams # This is the ngram magic.\n",
        "from textblob import TextBlob\n",
        "\n",
        "NGRAM = 4\n",
        "\n",
        "re_sent_ends_naive = re.compile(r'[.\\n]')\n",
        "re_stripper_alpha = re.compile('[^a-zA-Z]+')\n",
        "re_stripper_naive = re.compile('[^a-zA-Z\\.\\n]')\n",
        "\n",
        "splitter_naive = lambda x: re_sent_ends_naive.split(re_stripper_naive.sub(' ', x))\n",
        "\n",
        "sent_detector = nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "\n",
        "def get_tuples_nosentences(txt):\n",
        "    \"\"\"Get tuples that ignores all punctuation (including sentences).\"\"\"\n",
        "    if not txt: return None\n",
        "    #ng = ngrams(re_stripper_alpha.sub(' ', txt).split(), NGRAM)\n",
        "    ng = ngrams(txt, NGRAM)\n",
        "    return list(ng)\n",
        "\n",
        "def get_tuples_manual_sentences(txt):\n",
        "    \"\"\"Naive get tuples that uses periods or newlines to denote sentences.\"\"\"\n",
        "    if not txt: return None\n",
        "    sentences = (x.split() for x in splitter_naive(txt) if x)\n",
        "    ng = (ngrams(x, NGRAM) for x in sentences if len(x) >= NGRAM)\n",
        "    return list(chain(*ng))\n",
        "\n",
        "def get_tuples_nltk_punkt_sentences(txt):\n",
        "    \"\"\"Get tuples that doesn't use textblob.\"\"\"\n",
        "    if not txt: return None\n",
        "    sentences = (re_stripper_alpha.split(x) for x in sent_detector.tokenize(txt) if x)\n",
        "    # Need to filter X because of empty 'words' from punctuation split\n",
        "    ng = (ngrams(filter(None, x), NGRAM) for x in sentences if len(x) >= NGRAM)\n",
        "    return list(chain(*ng))\n",
        "\n",
        "def get_tuples_textblob_sentences(txt):\n",
        "    \"\"\"New get_tuples that does use textblob.\"\"\"\n",
        "    if not txt: return None\n",
        "    tb = TextBlob(txt)\n",
        "    ng = (ngrams(x.words, NGRAM) for x in tb.sentences if len(x.words) > NGRAM)\n",
        "    return [item for sublist in ng for item in sublist]\n",
        "\n",
        "def jaccard_distance(a, b):\n",
        "    \"\"\"Calculate the jaccard distance between sets A and B\"\"\"\n",
        "    a = set(a)\n",
        "    b = set(b)\n",
        "    return 1.0 * len(a&b)/len(a|b)\n",
        "\n",
        "def cosine_similarity_ngrams(a, b):\n",
        "    vec1 = Counter(a)\n",
        "    vec2 = Counter(b)\n",
        "    \n",
        "    intersection = set(vec1.keys()) & set(vec2.keys())\n",
        "    numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
        "\n",
        "    sum1 = sum([vec1[x]**2 for x in vec1.keys()])\n",
        "    sum2 = sum([vec2[x]**2 for x in vec2.keys()])\n",
        "    denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
        "\n",
        "    if not denominator:\n",
        "        return 0.0\n",
        "    return float(numerator) / denominator\n",
        "\n",
        "\n",
        "def test():\n",
        "    paragraph = \"\"\"It was the best of times, it was the worst of times.\n",
        "               It was the age of wisdom? It was the age of foolishness!\n",
        "               I first met Dr. Frankenstein in Munich; his monster was, presumably, at home.\"\"\"\n",
        "    print(paragraph)\n",
        "    _ = get_tuples_nosentences(paragraph);print(\"Number of N-grams (no sentences):\", len(_));_\n",
        "\n",
        "    _ = get_tuples_manual_sentences(paragraph);print(\"Number of N-grams (naive sentences):\", len(_));_\n",
        "\n",
        "    _ = get_tuples_nltk_punkt_sentences(paragraph);print(\"Number of N-grams (nltk sentences):\", len(_));_\n",
        "\n",
        "    _ = get_tuples_textblob_sentences(paragraph);print(\"Number of N-grams (TextBlob sentences):\", len(_));_\n",
        "\n",
        "    a = get_tuples_nosentences(\"It was the best of times.\")\n",
        "    b = get_tuples_nosentences(\"It was the worst of times.\")\n",
        "    print(\"Jaccard: {}   Cosine: {}\".format(jaccard_distance(a,b), cosine_similarity_ngrams(a,b)))\n",
        "\n",
        "    a = get_tuples_nosentences(\"Above is a bad example of four-gram similarity.\")\n",
        "    b = get_tuples_nosentences(\"This is a better example of four-gram similarity.\")\n",
        "    print(\"Jaccard: {}   Cosine: {}\".format(jaccard_distance(a,b), cosine_similarity_ngrams(a,b)))\n",
        "\n",
        "    a = get_tuples_nosentences(\"Jaccard Index ignores repetition repetition repetition repetition repetition.\")\n",
        "    b = get_tuples_nosentences(\"Cosine similarity weighs repetition repetition repetition repetition repetition.\")\n",
        "    print(\"Jaccard: {}   Cosine: {}\".format(jaccard_distance(a,b), cosine_similarity_ngrams(a,b)))\n",
        "test()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It was the best of times, it was the worst of times.\n",
            "               It was the age of wisdom? It was the age of foolishness!\n",
            "               I first met Dr. Frankenstein in Munich; his monster was, presumably, at home.\n",
            "Number of N-grams (no sentences): 214\n",
            "Number of N-grams (naive sentences): 25\n",
            "Number of N-grams (nltk sentences): 25\n",
            "Number of N-grams (TextBlob sentences): 25\n",
            "Jaccard: 0.6071428571428571   Cosine: 0.755742181606458\n",
            "Jaccard: 0.6071428571428571   Cosine: 0.755742181606458\n",
            "Jaccard: 0.23214285714285715   Cosine: 0.9208243668497166\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akhPuNZHBx4w"
      },
      "source": [
        "def cosine_similarity(src_txt,trg_txt):\n",
        "    try:\n",
        "        if src_txt == None or src_txt.strip() == '':\n",
        "            return 0.0\n",
        "        if trg_txt == None or trg_txt.strip() == '':\n",
        "            return 0.0\n",
        "\n",
        "        a = get_tuples_nosentences(src_txt)\n",
        "        b = get_tuples_nosentences(trg_txt)\n",
        "        return cosine_similarity_ngrams(a,b)\n",
        "    except Exception as ex:\n",
        "        #print(src_txt,trg_txt)\n",
        "        return 0.0"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VzWHWFACD5h",
        "outputId": "3cb23b40-a4b5-47b2-fe68-b0de9a50e882"
      },
      "source": [
        "'''\n",
        "그러나 0.0\n",
        "새어머니와 0.0748015715144127\n",
        "언니들은 0.03526179897416781\n",
        "성질이 0.0\n",
        "고약한 0.0\n",
        "심술쟁이들이었다. 0.03942388975758579\n",
        "그런데 0.0\n",
        "이번에는 0.03526179897416781\n",
        "아버지마저 0.024933857171470904\n",
        "돌아가셨다. 0.024933857171470904\n",
        "그러던 0.0\n",
        "어느날 0.0\n",
        "왕궁에서 0.017630899487083906\n",
        "무도회가 0.017630899487083906\n",
        "열렸다.0.0\n",
        "'''\n",
        "\n",
        "cosine_similarity('아버지가 방에 빨리 들어가신다.','아버지가 방에 들어가신다.')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7252406676228422"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "0S301yeelEvG"
      },
      "source": [
        "full_text = \"\"\"\n",
        "옛날 어느 집에 귀여운 여자 아기가 태어났다.\n",
        "신데렐라는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었다.\n",
        "그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았다.\n",
        "소녀의 아버지는 홀로 남은 소녀가 걱정되었다.\n",
        "그래서 얼마 지나서 새어머니를 맞이했다.\n",
        "새어머니는 두명의 언니들을 데리고 왔다.\n",
        "그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었다.\n",
        "새어머니는 소녀가 자기 딸들보다 예쁘고 착한게 못마땅했다.\n",
        "그런데 이번에는 아버지마저 돌아가셨다.\n",
        "소녀는 쓸고, 닦고, 하녀처럼 하루 종일 집안일을 도맡아 했다.\n",
        "집안일이 힘들어 지칠때면 난롯가에 앉아서 잠시 쉬곤 했다.\n",
        "그러던 어느날, 왕궁에서 무도회가 열렸다.\n",
        "신데렐라의 집에도 무도회 초대장이 왔다.\n",
        "새어머니는 언니들을 데리고 무도회장으로 떠났다.\n",
        "신데렐라도 무도회에 가고 싶었다.\n",
        "혼자 남은 신데렐라는 서러워 울기 시작했다.\n",
        "그때 어디선가 마법사 할머니가 나타났다.\n",
        "신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었다.\n",
        "할머니는 소녀를 무도회에 보내줄테니 호박 한개와 생쥐 두마리, 도마뱀을 가지고 오라 했다.\n",
        "마법사 할머니가 이것들을 보면서 주문을 외웠다.\n",
        "그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금마차로 변했다.\n",
        "이번에는 생쥐와 도마뱀을 건드렸다.\n",
        "그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했다.\n",
        "신데렐라의 낡은 옷은 구슬 장식이 반짝이는 예쁜 드레스로 바뀌었다.\n",
        "할머니는 신데렐라에게 반짝반짝 빛나는 유리구두를 신겨 주었다.\n",
        "그리고 밤 열두시가 되면 모든게 처음대로 돌아간다고 알려주었다.\n",
        "황금마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 된다.\n",
        "그러니까 반드시 밤 열두시가 되기 전에 돌아와야 한다.\n",
        "신데렐라는 황금마차를 타고 왕궁 무도회장으로 가서 멋진 왕자님을 만났다.\n",
        "왕자님도 아름다운 신데렐라에게 마음을 빼았겼다.\n",
        "왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고 신데렐라하고만 춤을 추었다.\n",
        "신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐다.\n",
        "어느덧 시간이 흘러 열두시가 되었다. \n",
        "벽시계의 열두시를 알리는 종소리에 신데렐라는 화들짝 놀랐다.\n",
        "신데렐라가 허둥지둥 왕궁을 빠져나가는데, 유리구두 한짝이 벗겨졌다.\n",
        "하지만 구두를 주울 시간이 없었다.\n",
        "신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리구두 한짝을 주웠다.\n",
        "왕자님은 유리구두의 주인과 결혼하기로 결심했다.\n",
        "그래서 신하들은 유리구두의 주인을 찾아 온 나라를 돌아다녔다.\n",
        "드디어 신데렐라의 집에까지 신하들이 도착했다.\n",
        "언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리구두는 너무 작았다.\n",
        "그때 신데렐라가 조용히 다가와 자기도 한번 신어보게 해달라고 부탁했다.\n",
        "유리구두는 그녀의 발에 꼭 맞았다.\n",
        "그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았다.\n",
        "\"\"\""
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UAeFBYMMxKY",
        "outputId": "510b3c22-98d2-4bea-ef04-b81c52229e28"
      },
      "source": [
        "txt = \"\"\"\n",
        "신데렐라는 신하와 결혼했습니다.\n",
        "\"\"\"\n",
        "s = Source(full_text,txt)\n",
        "s.set_key_rate(s_discriminator)\n",
        "#s_discriminator.similarity(s.org_text,s.full_text_emb)\n",
        "list(s.bias_table.values())"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            "신데렐라는 신하와 결혼했습니다.\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0, -1.0, -1.0]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XY59mdNK8ub"
      },
      "source": [
        "# 4.5 Generator class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5CLF3WcK6lp",
        "trusted": true
      },
      "source": [
        "from functools import reduce\n",
        "\n",
        "\n",
        "# custom weights initialization called on netG and netD\n",
        "\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Linear') != -1:\n",
        "        m.weight.data.normal_(0.0, 0.1)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        m.weight.data.normal_(0.0, 0.05)\n",
        "        m.bias.data.fill_(0)\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    \"\"\"\n",
        "        Simple Generator w/ MLP\n",
        "    \"\"\"\n",
        "    '''\n",
        "    def __init__(self, input_size=1024):\n",
        "        super(Generator, self).__init__()\n",
        "        self.layer = nn.Sequential(\n",
        "            nn.Linear(input_size, input_size*2),\n",
        "            nn.BatchNorm1d(input_size*2),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(input_size*2, input_size*3),\n",
        "            nn.BatchNorm1d(input_size*3),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(input_size*3, input_size*3),\n",
        "            nn.BatchNorm1d(input_size*3),\n",
        "            nn.ReLU(True),            \n",
        "            nn.Linear(input_size*3, input_size*2),\n",
        "            nn.BatchNorm1d(input_size*2),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(input_size*2, input_size),\n",
        "            #nn.BatchNorm1d(term_length*4),\n",
        "            nn.Tanh() # -1 ~ 1\n",
        "        )\n",
        "\n",
        "    \n",
        "    def __init__(self, input_size=1024):\n",
        "        super(Generator, self).__init__()\n",
        "        l1 = nn.Linear(input_size, input_size*4)\n",
        "        l1.weight.data.normal_(0.0, 0.01)\n",
        "        bn = nn.BatchNorm1d(input_size*4)\n",
        "        bn.weight.data.normal_(0.0, 0.01)\n",
        "        bn.bias.data.fill_(0)        \n",
        "        l2 = nn.Linear(input_size*4, input_size)\n",
        "        l2.weight.data.normal_(0.05, 0.01)\n",
        "        self.layer = nn.Sequential(\n",
        "            l1,\n",
        "            bn,\n",
        "            nn.ReLU(True), #nn.LeakyReLU(0.2),\n",
        "            l2,\n",
        "            #nn.BatchNorm1d(term_length*4),\n",
        "            nn.Tanh() # -1 ~ 1\n",
        "        )\n",
        "    '''\n",
        "\n",
        "    def __init__(self, input_size=1024):\n",
        "        super(Generator, self).__init__()\n",
        "        self.layer = nn.Sequential(\n",
        "            nn.Linear(input_size, input_size*4),\n",
        "            nn.BatchNorm1d(input_size*4),\n",
        "            nn.ReLU(True), #nn.LeakyReLU(0.2),\n",
        "            nn.Linear(input_size*4, input_size*2),\n",
        "            nn.BatchNorm1d(input_size*2),\n",
        "            nn.ReLU(True), #nn.LeakyReLU(0.2),            \n",
        "            nn.Linear(input_size*2, input_size),\n",
        "            #nn.BatchNorm1d(input_size),\n",
        "            #nn.ReLU(True), #nn.LeakyReLU(0.2),\n",
        "            nn.Tanh() # -1 ~ 1\n",
        "        )\n",
        "\n",
        "    def forward(self, x, bias):\n",
        "        #biased_noise = torch.randn(N,_NOISE_DIM)\n",
        "        # stroy peak에 해당하는 term에게 평균값에 해당하는 bias를 추가 한다.\n",
        "                 \n",
        "        y_ = self.layer(x)\n",
        "        y = torch.add(y_,bias)\n",
        "        #y = nn.Sigmoid()(y)\n",
        "\n",
        "        return y, y_\n"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myU75t4_4dni"
      },
      "source": [
        "# multi-discriminator에 대한 Adaptive discriminant factor 를 구하기 위한 학습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Co1MnRG8a4Vq"
      },
      "source": [
        "## 이론\n",
        "\n",
        "ref : https://realpython.com/python-ai-neural-network/\n",
        "\n",
        "colab 수식입력 : \n",
        "\n",
        "https://wikidocs.net/1679\n",
        "\n",
        "https://en.wikipedia.org/wiki/Help:Displaying_a_formula#Formatting_using_TeX\n",
        "\n",
        "Original GAN의 목적함수\n",
        "$$ \\min_{G}\\max_{D} V(D,G) = E_{x\\sim p_{data}(x)}[logD(x)] + E_{z\\sim p_{z}(z)}[log(1-D(G(z)))] $$\n",
        "\n",
        "Multi-Discriminator GAN은 discriminator가 각 목적에 의하여 여러개 (N개) 있다.\n",
        "MDGAN의 목적함수\n",
        "\n",
        "$$ \\min_{G}\\max_{D_{i\\sim N}} V(D_{i\\sim N},G) = \\sum_{i=1}^N \\{E_{x\\sim p_{data}(x)}[logD_i(x)] + E_{z\\sim p_{z}(z)}[log(1-D_i(G(z)))]\\} $$\n",
        "\n",
        "여기서\n",
        "\n",
        "$$ L(D_i,G) =  E_{x\\sim p_{data}(x)}[logD_i(x)] + E_{z\\sim p_{z}(z)}[log(1-D_i(G(z)))] $$\n",
        "\n",
        "이라하고 단순화 하면\n",
        "\n",
        "$$ \\min_{G}\\max_{D_{i\\sim N}} V(D_{i\\sim N},G) = \\sum_{i=1}^N L(D_i,G) $$\n",
        "\n",
        "와 같이 된다.\n",
        "\n",
        "문제점은 GAN의 특성상, 특정 Discriminator가 학습에 있어 지배적으로 loss 함수에 영향을 미치게 되어 각각의 Discriminator가 골고루 학습에 참여하지 못하고 의도하지 않은 결과를 만들게 된다. 이러한 문제점을 극복하기 위해 다음의 두가지 제안을 한다.\n",
        "\n",
        "1) 목적함수에 각 Loss 에 대한 표준편차 (standard-deviation) 를 반영하여 각 Discriminator에 대한 Loss가 상호 유사한 수준을 유지하면 학습이 진행되도록 한다.\n",
        "\n",
        "$$ \\min_{G}\\max_{D_{i\\sim N}} V(D_{i\\sim N},G) = \\sum_{i=1}^N L(D_i,G) + STD_{i \\sim N}(L(D_i,G))$$\n",
        "\n",
        "2) 1)의 제안에 추가하여, 각 discriminator에 의한 loss를 제어하기 위해, adaptive discriminant factor (ADF) 를 적용하고, 학습의 진행 과정에서 이를 최적화 한다. \n",
        "\n",
        "$$ \\min_{G}\\max_{D_{i\\sim N}} V(D_{i\\sim N},G) = \\sum_{i=1}^N f_iL(D_i,G) + STD_{i \\sim N}(L(D_i,G))$$\n",
        "\n",
        "여서서 \n",
        "\n",
        "fi = adaptive discriminant factor for discriminator i \n",
        "\n",
        "중요한 것은, 학습과정에서 Li을 작게 (학습의 방향)하기 위해서는 fi는 역으로 커져야 한다. 그래야, 전체 Loss function에서 비중이 증대되어 더 적극적인 학습이 이루어 지게 된다. 따라서, fi의 최적화 방향은 기존의 gradient decent와 반대 방향이 되어야 한다.\n",
        "\n",
        "$$ f_i^{t+1} = f_i^t + \\alpha \\frac{\\partial V}{\\partial f_i}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLVVmQdxLBHZ"
      },
      "source": [
        "##4.6 Summarizer class (GAN training)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0RQOPpQgUTE"
      },
      "source": [
        "# 학습기..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nd8GTS7HKz1H",
        "trusted": true
      },
      "source": [
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "from scipy.special import expit\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SAM_Summarizer:\n",
        "\n",
        "    def __init__(self,g_discriminator,s_discriminator):\n",
        "        self.g_discriminator = g_discriminator\n",
        "        #self.c_discriminator = c_discriminator\n",
        "        self.s_discriminator = s_discriminator\n",
        "        self.m = nn.Sigmoid()\n",
        "        self.with_bias = True\n",
        "\n",
        "    def ready(self,source):\n",
        "        self.source = source  \n",
        "        #self.source.analysis_frame_terms(self.s_discriminator)\n",
        "        self.generator = Generator(input_size=self.source.org_source_length)\n",
        "        self.generator.apply(weights_init)\n",
        "        return self\n",
        "\n",
        "    def summarize(self,epochs=10,batch_size=1,learning_rate=2e-4, display = False):\n",
        "        history = self.__train(epochs,batch_size,learning_rate,display)\n",
        "\n",
        "        if display and history is not None:\n",
        "            plt.figure(figsize=(12, 6))\n",
        "            plt.plot(history['gen_g_loss'],label='grammar loss')\n",
        "            plt.plot(history['gen_l_loss'],label='compression loss')\n",
        "            plt.plot(history['gen_s_loss'],label='n-gram similarity loss')\n",
        "            #plt.plot(history['gen_c_loss'],label='context similarity loss')\n",
        "            #plt.plot(history['total loss'],label='total loss')\n",
        "            plt.plot(history['losses std'],label='standard deviation of losses')\n",
        "            \n",
        "            #if 'dis_loss' in history:\n",
        "            #    plt.plot(history['dis_loss'],label='discriminator grammar loss')\n",
        "            plt.legend()\n",
        "            plt.show()\n",
        "\n",
        "        return history\n",
        "\n",
        "    # text의 생성 for torch\n",
        "    def __text_gen2(self, p_txt, gen_length):\n",
        "        gtext = []\n",
        "        sorted_noise, i = torch.sort(p_txt, descending=True)\n",
        "        order, i = torch.sort(i[:gen_length], descending=False)\n",
        "        #print(len(order))\n",
        "        #print(gen_length)\n",
        "        assert len(order) == gen_length\n",
        "        order = order.cpu().detach().numpy()\n",
        "        for k in order:\n",
        "            gtext.append((self.source.term_table[k],k))\n",
        "        return gtext\n",
        "\n",
        "    def __text_gen3(self, p_txt):\n",
        "        gtext = []\n",
        "\n",
        "        for order,p in enumerate(p_txt):\n",
        "            if p > 0.0:\n",
        "                gtext.append(self.source.term_table[order])\n",
        "        return gtext\n",
        "\n",
        "    def __text_hash(self, p_txt):\n",
        "        b = []\n",
        "        #hash(tuple(b))\n",
        "        for order,p in enumerate(p_txt):\n",
        "            if p > 0.0:\n",
        "                b.append(order)\n",
        "        return hash(tuple(b))\n",
        "\n",
        "    def __text_gen4(self, p_txt):\n",
        "        gtext = \"\"\n",
        "        indexs = []\n",
        "        for order,p in enumerate(p_txt):\n",
        "            if p > 0.0:\n",
        "                gtext += self.source.term_table[order] + ' '\n",
        "                indexs.append(order)\n",
        "        return gtext.strip(),indexs\n",
        "\n",
        "\n",
        "    def __discrete_gradient(self,weights,use_gpu=False, verbose=0):\n",
        "        fake_gen_out = torch.zeros(weights.shape).to(device)\n",
        "        fake_cos_out = torch.zeros(weights.shape).to(device)\n",
        "        fake_sim_out = torch.zeros(weights.shape).to(device)\n",
        "        fake_len_out = torch.zeros(weights.shape).to(device) \n",
        "\n",
        "        #real_text = self.source.get_org_sample(weights.shape[0])\n",
        "        fake_outs = []\n",
        "        #real_outs = []\n",
        "        apply_order = []\n",
        "        for i, noise in enumerate(weights):\n",
        "            #gtext = self.__text_gen2(noise,gen_length)\n",
        "            gtext,tk = self.__text_gen4(noise)\n",
        "            fake_outs.append(gtext)\n",
        "            apply_order.append((i,tk))\n",
        "  \n",
        "        D_z_loss, fake_gmr_out=self.g_discriminator.transfer_learning(fake_outs,train_for = False)\n",
        "\n",
        "        o_sim_out = []\n",
        "        o_cos_out = []\n",
        "        o_len_out = []\n",
        "        for fake_text in fake_outs:\n",
        "            s1 = cosine_similarity(self.source.full_text,fake_text)  \n",
        "            #s1 = self.s_discriminator.similarity(fake_text,self.source.full_text_emb)\n",
        "            #s2 = 0.5 #cosine_similarity(self.source.full_text,fake_text)  #self.s_discriminator.similarity(fake_text,self.source.full_text_emb)\n",
        "            #s = ((s1+s2)/2 - 0.5) * 2\n",
        "            #s = (s1 - 0.5) * 2\n",
        "            #print(s)\n",
        "            #print(s)\n",
        "            cs = 0.5 #(s2/2 - 0.5) * 2\n",
        "            l = 1 - len(fake_text)/len(self.source.org_text)\n",
        "            #l = ((1 - len(fake_text.split(' '))/len(self.source.org_text.split(' ')))-0.5) * 2\n",
        "            #print(l)\n",
        "            o_sim_out.append(s1)\n",
        "            o_cos_out.append(cs)\n",
        "            o_len_out.append(l)\n",
        "            #print(1 - len(fake_text.split(' '))/self.source.org_source_length)\n",
        "            #o_len_out.append(-len(fake_text.split(' '))/self.source.org_source_length)\n",
        "        \n",
        "        \n",
        "        for j, (i,tk) in enumerate(apply_order):\n",
        "\n",
        "            try:\n",
        "                '''\n",
        "                a = torch.tanh( fake_gmr_out[j,1])\n",
        "                if a > 0 :\n",
        "                    fake_gen_out[:] = -0.5\n",
        "                    fake_gen_out[i,tk] = a\n",
        "                else:\n",
        "                    fake_gen_out[:] = 0.5\n",
        "                    fake_gen_out[i,tk] = a\n",
        "                '''\n",
        "                fake_gen_out[i,tk] = torch.tanh( fake_gmr_out[j,1])\n",
        "                fake_sim_out[i,tk] = o_sim_out[j]\n",
        "                fake_cos_out[i,tk] = o_cos_out[j]\n",
        "                #fake_len_out[i,tk] = o_len_out[j]\n",
        "                fake_len_out[:] = -o_len_out[j]\n",
        "                #fake_len_out[i,tk] = 0 #torch.tensor(fake_text_len/self.source.org_source_length).to(device)\n",
        "                #fake_len_out[:] = o_len_out[j] #torch.tensor(fake_text_len/self.source.org_source_length).to(device)\n",
        "                #print(o_len_out[j])\n",
        "            except Exception as ex:\n",
        "                print(j,i,tk)\n",
        "                print(fake_gmr_out)\n",
        "                raise ex\n",
        "\n",
        "        return fake_gen_out, fake_sim_out, fake_cos_out, fake_len_out #fake_com_out, fake_sim_out #, D_z_loss, D_x_loss\n",
        "\n",
        "\n",
        "    def __train(self, epochs=10,batch_size=10,learning_rate=2e-4,display = False):\n",
        "        # In the Deepmind paper they use RMSProp however then Adam optimizer\n",
        "        # improves training time\n",
        "        #generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "        # This method returns a helper function to compute cross entropy loss\n",
        "        #cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "        # Set the seed value all over the place to make this reproducible.\n",
        "        seed_val = int(random.random()*100)\n",
        "\n",
        "        random.seed(seed_val)\n",
        "        np.random.seed(seed_val)\n",
        "        torch.manual_seed(seed_val)\n",
        "        torch.cuda.manual_seed_all(seed_val)\n",
        "        \n",
        "        criterion = nn.MSELoss()\n",
        "        #D_opt = torch.optim.Adam(D.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "        G_opt = AdamW(self.generator.parameters(),\n",
        "                        lr = 2e-3, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                        eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                        )\n",
        "        # Create the learning rate scheduler.\n",
        "        scheduler = get_linear_schedule_with_warmup(G_opt, \n",
        "                                                    num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                                    num_training_steps = epochs)\n",
        "        \n",
        "        #gen_length = len(self.source.story_peaks) + int(len(self.source.story_peaks)*self.frame_expansion_ratio)\n",
        "        pb = ProgressBar(epochs,prefix='Train...')\n",
        "        gen_gmr_loss_history = []\n",
        "        gen_len_loss_history = []\n",
        "        gen_sim_loss_history = []\n",
        "        gen_cos_loss_history = []\n",
        "        dis_loss_history = []    \n",
        "        total_loss_history = []\n",
        "        losses_std_history = []\n",
        "\n",
        "        #model 들은 cuda로 보낸다.\n",
        "        self.g_discriminator.discriminator.to(device)\n",
        "        self.g_discriminator.discriminator.eval() # 학습하지 않는다...\n",
        "        #self.c_discriminator.discriminator.to(device)\n",
        "        #self.c_discriminator.discriminator.eval() # 학습하지 않는다...\n",
        "\n",
        "        self.generator.to(device)       \n",
        "        self.generator.train()\n",
        "\n",
        "        #self.bias_w = init_bias\n",
        "        initial_bias = 0\n",
        "        G_s_loss = torch.tensor(0)\n",
        "        #G_c_loss = torch.tensor(0)\n",
        "        G_g_loss = torch.tensor(0)\n",
        "\n",
        "\n",
        "        epsilon = 1 # Epsilon-greedy algorithm in initialized at 1 meaning every step is random at the start\n",
        "        max_epsilon = 1 # You can't explore more than 100% of the time\n",
        "        min_epsilon = 0.001 # At a minimum, we'll always explore 1% of the time\n",
        "        decay = 10/epochs\n",
        "        \n",
        "\n",
        "        dfs = torch.tensor([ 1.0, 5.0, 1.0], device=device, dtype=torch.float, requires_grad=True)\n",
        "        target = torch.tensor([list(self.source.bias_table.values()) for u in range(batch_size)],dtype=torch.float).to(device)\n",
        "        #print(target)\n",
        "        #noise = torch.randn(batch_size,self.source.org_source_length).to(device) \n",
        "        for i in range(epochs):\n",
        "   \n",
        "            if True:\n",
        "                noise = torch.randn(batch_size,self.source.org_source_length).to(device) \n",
        "\n",
        "                random_number = np.random.rand()\n",
        "                # 2. Explore using the Epsilon Greedy Exploration Strategy\n",
        "                '''\n",
        "                if random_number <= epsilon:\n",
        "                    # Explore\n",
        "                    bias = torch.randn(batch_size,self.source.org_source_length).to(device) * epsilon\n",
        "                    #b = torch.tensor([list(self.source.bias_table.values()) for u in range(batch_size)]).to(device)\n",
        "                    #bias = torch.add(a,b)\n",
        "                    #noise = torch.randn(batch_size,self.source.org_source_length).to(device) \n",
        "                else:\n",
        "                    #bias = torch.tensor([list(self.source.bias_table.values()) for u in range(batch_size)]).to(device)\n",
        "                    bias = torch.zeros_like(noise).to(device)\n",
        "                '''\n",
        "                bias = torch.zeros_like(noise).to(device)\n",
        "\n",
        "\n",
        "                #if self.with_bias:\n",
        "                #    bias[:,noise.shape[1]-1] = 0.1\n",
        "                #bias[:,noise.shape[1]-1] = 0.5\n",
        "                #if i < epochs/4:\n",
        "                #bias = torch.randn(batch_size,self.source.org_source_length).to(device) / 4                 \n",
        "                #bias = torch.randn(batch_size,self.source.org_source_length).to(device) \n",
        "\n",
        "                sw, sw0 = self.generator(noise,bias)\n",
        "                #print(sw)\n",
        "                with torch.no_grad():                \n",
        "                    fake_gmr_out, fake_sim_out, fake_cos_out, fake_len_out = self.__discrete_gradient(sw)\n",
        "\n",
        "                #print(fake_len_out)\n",
        "                #print(fake_gmr_out)\n",
        "                sw2 = sw * fake_gmr_out\n",
        "                #print(sw2)\n",
        "                G_g_loss = -torch.mean(sw2)\n",
        "                #print(G_g_loss)\n",
        "                sw1 = sw * fake_sim_out\n",
        "                G_s_loss = -torch.mean(sw1)\n",
        "\n",
        "                sw4 = sw * fake_cos_out\n",
        "                G_c_loss = -torch.mean(sw4) \n",
        "\n",
        "                #sw3 = sw * fake_len_out\n",
        "                #G_l_loss = -torch.mean(sw3)\n",
        "\n",
        "                G_l_loss = criterion(sw,target) * 0.8\n",
        "\n",
        "                dsc_loss = torch.stack([G_g_loss,G_s_loss,G_l_loss])\n",
        "\n",
        "                G_loss = torch.dot(dfs,dsc_loss) #+ torch.std(dsc_loss)\n",
        "                #G_loss =  G_g_loss  + G_l_loss\n",
        "                #G_loss = G_l_loss\n",
        "\n",
        "                #print(G_loss)\n",
        "                \n",
        "                self.generator.zero_grad()\n",
        "                G_loss.backward()\n",
        "                #print('backward:')\n",
        "                G_opt.step()\n",
        "                scheduler.step()\n",
        "                '''\n",
        "                learning_rate = 0.1\n",
        "                with torch.no_grad():\n",
        "                    dfs += learning_rate * dfs.grad\n",
        "                    dfs.grad = None                    \n",
        "                    dfs[dfs < 0] = 0.1                \n",
        "                '''\n",
        "                if G_g_loss == 0:# or (i > 100 and G_g_loss > 0):\n",
        "                    return None\n",
        "\n",
        "            gen_gmr_loss_history.append(G_g_loss.cpu().detach().numpy())\n",
        "            gen_cos_loss_history.append(G_c_loss.cpu().detach().numpy())\n",
        "            gen_sim_loss_history.append(G_s_loss.cpu().detach().numpy())\n",
        "            #dis_loss_history.append(D_loss.cpu().detach().numpy())\n",
        "            gen_len_loss_history.append(G_l_loss.cpu().detach().numpy())\n",
        "\n",
        "            #pb.printProgress(+1,f'{i+1}/{epochs} epochs, beta:{dfs} Generator / grammar loss:{G_g_loss}  similarity loss:{G_s_loss}') #,   Discriminator grammar_loss:{D_loss}        ')\n",
        "            #pb.printProgress(+1,'{}/{} epochs, beta:{}, grammar loss:{:.4f}  similarity loss:{:.4f} length loss:{:.4f}'.format(i+1,epochs,dfs,G_g_loss,G_s_loss,G_l_loss)) #,   Discriminator grammar_loss:{D_loss}        ')\n",
        "            pb.printProgress(+1,'{}/{} epochs, e {:.5f} gl:{:.8f}  sl:{:.4f} ll:{:.4f}'.format(i+1,epochs,epsilon, G_g_loss,G_s_loss,G_l_loss)) #,   Discriminator grammar_loss:{D_loss}        ')\n",
        "            \n",
        "            total_loss_history.append(torch.sum(dsc_loss).item())\n",
        "            losses_std_history.append(torch.std(dsc_loss).item())\n",
        "\n",
        "            epsilon = min_epsilon + (max_epsilon - min_epsilon) * np.exp(-decay * i)\n",
        "            \n",
        "        self.generator.eval()\n",
        "        #self.g_discriminator.discriminator.eval()\n",
        "        if display:\n",
        "            plt.figure(figsize=(12, 6))\n",
        "            xs = np.arange(self.source.org_source_length)\n",
        "            plt.bar(xs+0.0,sw0[0].cpu().detach().numpy(),label='before activation weights',width=0.2)\n",
        "            plt.bar(xs+0.2,sw[0].cpu().detach().numpy(),label='after activation weights',width=0.2)\n",
        "            plt.bar(xs+0.4,bias[0].cpu().detach().numpy(),label='bias weights',width=0.2)         \n",
        "            plt.legend()        \n",
        "            plt.show()\n",
        "\n",
        "        return  {'gen_g_loss':gen_gmr_loss_history,'gen_s_loss':gen_sim_loss_history,'gen_c_loss':gen_cos_loss_history,'gen_l_loss':gen_len_loss_history,'total loss':total_loss_history,'losses std':losses_std_history} #,'dis_loss':dis_loss_history }\n",
        "\n",
        "    def get_summary(self, count):\n",
        "        #texts = []\n",
        "        self.generator.cpu()\n",
        "        self.generator.eval()\n",
        "        #gen_length = len(self.source.story_peaks) + int(len(self.source.story_peaks)*self.frame_expansion_ratio)\n",
        "        noise = torch.randn(count,self.source.org_source_length)\n",
        "        bias = torch.zeros_like(noise)\n",
        "        if self.with_bias:\n",
        "            bias[:,noise.shape[1]-1] = 1\n",
        "        with torch.no_grad():\n",
        "            sw,sw0 = self.generator(noise,bias)\n",
        "            #sw,sw0 = self.generator(noise)\n",
        "\n",
        "        max_score = 0\n",
        "        max_sim = 0\n",
        "        comp_rate = 0\n",
        "        best_text = \"\"\n",
        "\n",
        "        for p_txt in sw:\n",
        "            gtext = self.__text_gen3(p_txt)\n",
        "            text = ' '.join(gtext)\n",
        "            \n",
        "            #print('>>',text)\n",
        "            sim_score = self.s_discriminator.similarity(text,self.source.full_text_emb)\n",
        "            if sim_score > max_sim:\n",
        "                best_text = text.strip()\n",
        "                loss, out=self.g_discriminator.transfer_learning([text],train_for = False)\n",
        "                max_score = out[0,1].item()\n",
        "                comp_rate = 1 - len(best_text)/len(self.source.org_text)\n",
        "                max_sim = sim_score\n",
        "            #texts.append([text.strip(),out,sim_score])\n",
        "        return best_text, max_score, max_sim, comp_rate\n",
        "\n",
        "    def get_samples(self,count):\n",
        "        self.generator.cpu()\n",
        "        self.generator.eval()\n",
        "        noise = torch.randn(count,self.source.org_source_length)\n",
        "        bias = torch.zeros_like(noise)\n",
        "        if self.with_bias:\n",
        "            bias[:,noise.shape[1]-1] = 1\n",
        "        with torch.no_grad():\n",
        "            sw,sw0 = self.generator(noise,bias)\n",
        "        #samples = []\n",
        "        best_text = \"\"\n",
        "        best_grammar_score = 0\n",
        "        max_score = 0\n",
        "        second_best_text = \"\"\n",
        "        second_max_score = 0        \n",
        "        hash_list = []\n",
        "        for p_txt in sw:\n",
        "            gtext = self.__text_gen3(p_txt)\n",
        "            h = self.__text_hash(p_txt)\n",
        "            if h in hash_list:\n",
        "                pass\n",
        "            else:\n",
        "                hash_list.append(h)\n",
        "                text = (' '.join(gtext).strip())\n",
        "                loss, out=self.g_discriminator.transfer_learning([text],train_for = False)\n",
        "                #sim_score = self.s_discriminator.similarity(text,self.source.org_text_emb)\n",
        "\n",
        "                sim_score = cosine_similarity(self.source.org_text,text)    \n",
        "                comp_rate = 1 - len(text)/len(self.source.org_text)\n",
        "\n",
        "                #samples.append((text,out[0,1].item(),sim_score,comp_rate))\n",
        "                #score = out[0,1].item() + sim_score + comp_rate*2\n",
        "                score = out[0,1].item()/6 + sim_score * 2 + comp_rate\n",
        "                print('{:.4f},{:.4f},score:{:.4f},[{}]'.format(sim_score,comp_rate,score,text))\n",
        "                if max_score < score and (comp_rate > 0.4 and comp_rate < 0.6 ):\n",
        "                    max_score = score\n",
        "                    best_text = text\n",
        "                    best_grammar_score = out[0,1].item()\n",
        "                if max_score < score:\n",
        "                    second_max_score = score\n",
        "                    second_best_text = text\n",
        "                    best_grammar_score = out[0,1].item()\n",
        "            if max_score == 0:\n",
        "                max_score = second_max_score\n",
        "                best_text = second_best_text                           \n",
        "        #return [best_text for i in range(count)], max_score\n",
        "        \n",
        "        correct_best_text = sentence_correct(best_text)\n",
        "        loss, out=self.g_discriminator.transfer_learning([best_text],train_for = False)\n",
        "        best_grammar_score = out[0,1].item()\n",
        "        loss, out=self.g_discriminator.transfer_learning([correct_best_text],train_for = False)\n",
        "        correct_best_grammar_score = out[0,1].item()\n",
        "        if best_grammar_score < 5.0 and correct_best_grammar_score > best_grammar_score:\n",
        "            print('correct_grammar_score:{:.4f} best_grammar_score:{:.4f}'.format(correct_best_grammar_score,best_grammar_score))\n",
        "            print(best_text)\n",
        "            print(correct_best_text)\n",
        "            best_text = correct_best_text\n",
        "        \n",
        "        return best_text, max_score, best_grammar_score\n"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCdfO9iuLH6D"
      },
      "source": [
        "#5. Experiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_eAwIPLb4aj"
      },
      "source": [
        "## 비교 대상 요약 알고리즘 준비"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhcoXuPMGy09"
      },
      "source": [
        "def sam_wgan4(full_text,text, epochs=50, batch_size=100,display=False, retry = True, retry_count = 0):\n",
        "    if retry_count > 10:\n",
        "        raise Exception(\"Can't summarize the text\")\n",
        "\n",
        "    source = Source(full_text,text,delete_ending = True)\n",
        "    source.set_key_rate(s_discriminator)\n",
        "    summarizer = SAM_Summarizer(g_discriminator,s_discriminator)\n",
        "    summarizer.ready(source)\n",
        "    hist = summarizer.summarize(epochs,batch_size=2,learning_rate=5e-3,display=display)\n",
        "    if retry and hist == None and retry_count < 10:\n",
        "        print('\\n')\n",
        "        return sam_wgan4(full_text,text, epochs+10, batch_size,display=display,retry_count=retry_count+1)\n",
        "    samples, max_score, best_grammar_score = summarizer.get_samples(batch_size)\n",
        "    #print(samples)\n",
        "    \n",
        "    if retry and best_grammar_score < (2.0 - retry_count*0.1):\n",
        "        print('max score:{} grammar:{} text:{}'.format(max_score,best_grammar_score,samples))\n",
        "        return sam_wgan4(full_text,text, epochs+10, batch_size,display=display,retry_count=retry_count+1)\n",
        "    \n",
        "    return samples, max_score, best_grammar_score"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FstAHWGQ8KR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b62e799b-54f6-4c60-af89-2627c0551b9f"
      },
      "source": [
        "txt = \"\"\"\n",
        "옛날 어느 집에 귀여운 여자 아기가 태어났다.\n",
        "신데렐라는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었다.\n",
        "그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았다.\n",
        "\"\"\"\n",
        "sam_wgan4(full_text,txt,epochs=400,display= True,retry = True)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났다. 신데렐라는 무럭무럭 자라서 예쁘고 마음씨 고운 소녀가 되었다. 그러던 어느날 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았다.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   400/400 epochs, e 0.00105 gl:-0.18679540  sl:-0.0366 ll:0.0016\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.3937,0.7449,score:1.7870,[신데렐라는 무럭무럭 어머니가 병이들어 말았다.]\n",
            "correct_grammar_score:3.9236 best_grammar_score:1.5279\n",
            "신데렐라는 무럭무럭 어머니가 병이들어 말았다.\n",
            "신데렐라는 무럭무럭 자라다가 어머니가 병이들어 죽고 말았다.\n",
            "max score:1.787009387399544 grammar:1.5278992652893066 text:신데렐라는 무럭무럭 자라다가 어머니가 병이들어 죽고 말았다.\n",
            "--------------------------------------------------\n",
            "옛날 어느 집에 귀여운 여자 아기가 태어났다. 신데렐라는 무럭무럭 자라서 예쁘고 마음씨 고운 소녀가 되었다. 그러던 어느날 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았다.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   410/410 epochs, e 0.00105 gl:-0.23691951  sl:-0.0533 ll:0.1719\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4353,0.6429,score:1.8910,[집에 신데렐라는 무럭무럭 자라서 고운 어머니가 병이들어 말았다.]\n",
            "correct_grammar_score:5.1593 best_grammar_score:2.2656\n",
            "집에 신데렐라는 무럭무럭 자라서 고운 어머니가 병이들어 말았다.\n",
            "집에 도착한 신데렐라는 무럭무럭 자라서 고운 어머니가 병이들어 병에 걸리고 말았습니다.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('집에 도착한 신데렐라는 무럭무럭 자라서 고운 어머니가 병이들어 병에 걸리고 말았습니다.',\n",
              " 1.891033445438701,\n",
              " 2.2656288146972656)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yh-ixQLxlCOB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 947
        },
        "outputId": "2de9598f-838e-4dfc-ee1a-41e291b77ed4"
      },
      "source": [
        "txt = \"\"\"\n",
        "서산시의회(의장 임재관) 가충순·이수의 의원이 (사)한국지역신문협회에서 수여하는 우수의정대상을 받았다. 가충순 의원과 이수의 의원은 16일 팔봉면 폰타나 리조트에서 열린 한국지역신문협회 하계 워크샵에서 지역사회 발전을 위해 활발한 의정활동을 펼친 공로를 인정받아 우수의정대상을 수상했다.\n",
        "\"\"\"\n",
        "sam_wgan4(txt,txt,epochs=200,display= True,retry = False)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            "서산시의회(의장 임재관) 가충순·이수의 의원이 (사)한국지역신문협회에서 수여하는 우수의정대상을 받았다. 가충순 의원과 이수의 의원은 16일 팔봉면 폰타나 리조트에서 열린 한국지역신문협회 하계 워크샵에서 지역사회 발전을 위해 활발한 의정활동을 펼친 공로를 인정받아 우수의정대상을 수상했다.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   200/200 epochs, e 0.00808 gl:-0.63232970  sl:-0.4934 ll:0.5939\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7787,0.2438,score:2.3735,[서산시의회(의장 임재관) 가충순·이수의 (사)한국지역신문협회에서 수여하는 우수의정대상을 의원과 의원은 팔봉면 리조트에서 열린 한국지역신문협회 워크샵에서 지역사회 발전을 위해 의정활동을 인정받아 우수의정대상을 수상했다.]\n",
            "correct_grammar_score:5.2576 best_grammar_score:3.4337\n",
            "서산시의회(의장 임재관) 가충순·이수의 (사)한국지역신문협회에서 수여하는 우수의정대상을 의원과 의원은 팔봉면 리조트에서 열린 한국지역신문협회 워크샵에서 지역사회 발전을 위해 의정활동을 인정받아 우수의정대상을 수상했다.\n",
            "서산시의회 ( 의장 임재관 ) 가충순 이수의 의원이 ( 사 ) 한국지역신문협회에서 수여하는 우수의정대상을 수상했으며, 김 의원과 이 의원은 팔봉면 리조트에서 열린 한국지역 신문신문협회 워크샵에서 지역사회 발전을 위해 의정활동을 인정받아 우수.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('서산시의회 ( 의장 임재관 ) 가충순 이수의 의원이 ( 사 ) 한국지역신문협회에서 수여하는 우수의정대상을 수상했으며, 김 의원과 이 의원은 팔봉면 리조트에서 열린 한국지역 신문신문협회 워크샵에서 지역사회 발전을 위해 의정활동을 인정받아 우수.',\n",
              " 2.373481519343647,\n",
              " 3.433654546737671)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6v9sEryZOLa"
      },
      "source": [
        "# Sentence Corrector (EncoderDecoderModel)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUe3ZCSIz8N8"
      },
      "source": [
        "from transformers import EncoderDecoderModel, BertTokenizerFast\n",
        "import torch\n",
        "\n",
        "pre_trained_kobert_model_name='kykim/bert-kor-base'\n",
        "\n",
        "tokenizer = BertTokenizerFast.from_pretrained(pre_trained_kobert_model_name)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euuB9E5uZ1j2",
        "outputId": "4fce43f3-fb5a-427e-85f5-9d465280d3b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from transformers import EncoderDecoderModel, BertTokenizerFast\n",
        "try:\n",
        "    del model\n",
        "    print('delete model')\n",
        "except Exception as ex:\n",
        "    pass\n",
        "model = EncoderDecoderModel.from_pretrained(\"/content/drive/MyDrive/GAN_ENDE/sentence_complete_model\")"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "delete model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hr_6N_CYaKAI"
      },
      "source": [
        "def sentence_correct(text):\n",
        "    text = text.strip()\n",
        "    w = text.split(' ')\n",
        "    last_token = w[len(w)-1][:-1]\n",
        "    inputs = tokenizer(text, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n",
        "    input_ids = inputs.input_ids.to(device)\n",
        "    attention_mask = inputs.attention_mask.to(device)\n",
        "    '''\n",
        "    v = torch.sum(attention_mask[0]).item()\n",
        "    c = random.sample([i for i in range(v)],int(v/2))\n",
        "    print(c)\n",
        "    #input_ids[0][c] = 0\n",
        "    attention_mask[0][c] = 0 #random.random()\n",
        "    attention_mask[0][0] = 1\n",
        "    attention_mask[0][v-1] = 1\n",
        "    \n",
        "    print(input_ids)    \n",
        "    print(attention_mask)\n",
        "    '''\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    outputs = model.generate(input_ids, attention_mask=attention_mask).cpu().detach().numpy()[0]\n",
        "    o=[]\n",
        "    for token in outputs:\n",
        "        if token == tokenizer.pad_token_id:\n",
        "            break\n",
        "        o.append(token)\n",
        "    output_str = tokenizer.batch_decode([o], skip_special_tokens=True)[0]\n",
        "    #print('raw',output_str)\n",
        "    eos = output_str.find('.')\n",
        "    real_eos =  eos\n",
        "    if last_token.endswith('다'):\n",
        "        eos2 = output_str.find(last_token) \n",
        "        if eos2 > 0 and eos2 < eos:\n",
        "            real_eos = eos2 + len(last_token)\n",
        "    output_str = output_str[0:real_eos] + '.'\n",
        "    return output_str"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXh30j7kzwtL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "0ce0f457-6582-4504-e749-b7ef867b7121"
      },
      "source": [
        "sentence_correct('아기가 태어났고 아버지는 홀로 걱정되었 새어머니를 맞이했 새어머니와 언니들은 성질이 아주 심술쟁이들이었 이번에는 아버지마저 돌아가셨 왕궁에서 무도회가 열렸다.')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'아기가 태어났고, 아버지는 홀로 걱정되었던 새어머니를 맞이했지만, 새어가머니를 집으로 맞이했고, 그 사이 다른어머니와 언니들은 성질이 아주 심한 심술쟁이들이었고, 이번에는 아버지마저 돌아가셨기에 왕궁에서 무도회가 열렸다.'"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4Phn-X6iL246",
        "outputId": "2822003c-009a-4d91-e136-331d314a92b5"
      },
      "source": [
        "txt = '옛날 귀여운 여자 아기가 태어났 마음씨 소녀가 되었다.'\n",
        "w = txt.split(' ')\n",
        "last_token = w[len(w)-1]\n",
        "last_token[:-1]"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'되었다'"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzX2bOgzk0q_"
      },
      "source": [
        "full_text=\"\"\"\n",
        "국책연구기관인 보건사회연구원이 그제 백화점식 저출산 대책을 통폐합하고 관련 예산도 일부 삭감해야 한다는 지적을 내놨다.\n",
        "정부와 지방자치단체들이 시행 중인 저출산대책이 190 개에 이른다는 내용부터 눈길을 끈다.\n",
        "연구원은 이 가운데 상당수가 중복·유사대책이라며 90 여 개를 없앨 것을 제안했다.\n",
        "예산낭비를 줄이고 정책 효율을 높이라는 취지다.\n",
        "저출산 대책은 대표적인 '고비용·무(無)효율' 대책으로 평가받고 있다.\n",
        "최근 12 년간 122 조8000 억원의 재정을 쏟아부었지만 출산율은 세계 최저수준이다.\n",
        "출산장려금, 양육수당 같은 비용 지원 위주의 단기 처방에 급급한 탓이다.\n",
        "인구 정점(5296 만 명)에 도달하는 시기도 2031 년에서 2027 년으로 4 년 앞당겨질 판이다.\n",
        "인구 재앙 충격을 최소화하려면 재정 투입에 의존하는 기존 방식에서 벗어나 '국가 대계' 차원의 종합적인 대책이 필요하다.\n",
        "정부는 저출산 대책 구조조정의 물꼬를 트는 것을 계기로 관련 정책을 과감히 바꿔야 할 것이다.\n",
        "저출산 대책을 보다 넓은 개념의 '인구 정책'으로 전환해야 한다는 주장도 진지하게 새겨봄직 하다.\n",
        "난임 치료 지원, 국내 입양 활성화, 비혼가정 자녀 양육 지원 등 더 정교한 인구 대책을 수립해야 한다는 것이다.\n",
        "일본 등 주요 선진국처럼 고급 기술인력에 문호를 확대하는 등 이민정책도 전향적으로 바꿀 필요가 있다.\n",
        "그런 점에서 무엇보다도 대한민국을 '매력 있고, 살고 싶은 나라'로 만드는 것이 중요하다.\n",
        "개인의 자유와 창의가 보장되고, 사업하기 좋은 나라가 된다면 고급 인력의 한국 유입이 가속화될 것이다.\n",
        "생산 가능인구가 이미 줄어들기 시작했다는 점에서 저출산 대책의 구조조정 못지않게 발상 전환이 시급하다.\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_6X1JsSJLqi",
        "outputId": "e54edf95-6cfb-4a67-9042-7405554fc6bf"
      },
      "source": [
        "!pip3 install bert-extractive-summarizer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bert-extractive-summarizer\n",
            "  Downloading bert_extractive_summarizer-0.8.1-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (from bert-extractive-summarizer) (4.10.0)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (from bert-extractive-summarizer) (2.2.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from bert-extractive-summarizer) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->bert-extractive-summarizer) (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->bert-extractive-summarizer) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->bert-extractive-summarizer) (1.4.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (1.1.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (1.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (4.62.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (57.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (3.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (1.0.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (0.8.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (2.23.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (7.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (0.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (2.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (1.0.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->bert-extractive-summarizer) (4.6.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy->bert-extractive-summarizer) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy->bert-extractive-summarizer) (3.7.4.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy->bert-extractive-summarizer) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy->bert-extractive-summarizer) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy->bert-extractive-summarizer) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy->bert-extractive-summarizer) (3.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers->bert-extractive-summarizer) (3.0.12)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers->bert-extractive-summarizer) (5.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers->bert-extractive-summarizer) (21.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers->bert-extractive-summarizer) (2019.12.20)\n",
            "Requirement already satisfied: huggingface-hub>=0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers->bert-extractive-summarizer) (0.0.16)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers->bert-extractive-summarizer) (0.0.45)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers->bert-extractive-summarizer) (0.10.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers->bert-extractive-summarizer) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers->bert-extractive-summarizer) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers->bert-extractive-summarizer) (7.1.2)\n",
            "Installing collected packages: bert-extractive-summarizer\n",
            "Successfully installed bert-extractive-summarizer-0.8.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "porcPq1WJXF3"
      },
      "source": [
        "def besm(full_text,text,top_rank=2):\n",
        "\n",
        "    queries = nltk.sent_tokenize(text)\n",
        "    src_sentences = nltk.sent_tokenize(full_text)\n",
        "    query_embeddings = s_discriminator._embedder.encode(queries,show_progress_bar=False)\n",
        "    full_text_embeddings = s_discriminator._embedder.encode(src_sentences,show_progress_bar=False)\n",
        "    #print(queries)\n",
        "    #print(org_text_emb)\n",
        "    \n",
        "    if len(query_embeddings) == 0:\n",
        "        return 0.0\n",
        "\n",
        "    cos_scores = scipy.spatial.distance.cdist(query_embeddings, full_text_embeddings, \"cosine\")\n",
        "    scores = np.max(cos_scores,axis=1)\n",
        "    orderd = [(o,s) for o,s in enumerate(scores)]\n",
        "    orderd.sort(key=lambda e: e[1],reverse=True)\n",
        "    a = [orderd[i][0] for i in range(0,top_rank)]\n",
        "    a.sort()\n",
        "    summ_text = \" \".join([queries[i] for i in a])\n",
        "\n",
        "    return summ_text\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TN3dYRJ84j3Y"
      },
      "source": [
        "def besm2(full_text,text,top_rank=2):\n",
        "    scores = []\n",
        "    queries = nltk.sent_tokenize(text)\n",
        "    for sen in queries:\n",
        "        s = cosine_similarity(sen,full_text)\n",
        "        scores.append(s)\n",
        "        #print(s,sen)\n",
        "    orderd = [(o,s) for o,s in enumerate(scores)]\n",
        "    orderd.sort(key=lambda e: e[1],reverse=True)\n",
        "    a = [orderd[i][0] for i in range(0,top_rank)]\n",
        "    a.sort()\n",
        "    summ_text = \" \".join([queries[i] for i in a])\n",
        "\n",
        "    return summ_text\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "Kqc_c1jEJqRQ",
        "outputId": "403bcdf2-37d6-4997-cb45-32b5e2269274"
      },
      "source": [
        "test_text = \"\"\"\n",
        "새어머니는 소녀보다 나이가 위인 두명의 딸을 데리고 왔다.\n",
        "그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었다.\n",
        "새어머니는 소녀가 자기 딸들보다 예쁘고 착한게 못마땅했다.\n",
        "그런데 이번에는 아버지마저 돌아가셨다.\n",
        "\"\"\"\n",
        "besm2(full_text,test_text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.16738525020849007 \n",
            "새어머니는 소녀보다 나이가 위인 두명의 딸을 데리고 왔다.\n",
            "0.1211371061769273 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었다.\n",
            "0.16042481628836316 새어머니는 소녀가 자기 딸들보다 예쁘고 착한게 못마땅했다.\n",
            "0.08726850010014817 그런데 이번에는 아버지마저 돌아가셨다.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n새어머니는 소녀보다 나이가 위인 두명의 딸을 데리고 왔다. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한게 못마땅했다.'"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFJ5v8fia6VD"
      },
      "source": [
        "def summary(ft,text,steps=4,top_rank=2):\n",
        "    org_sentences = np.array(nltk.sent_tokenize(text.strip()))\n",
        "    summary_text = []\n",
        "    for i in range(0,len(org_sentences),steps):\n",
        "        txt = ''\n",
        "        cnt = 0\n",
        "        for s in range(i,i+steps):\n",
        "            if s < len(org_sentences):\n",
        "                txt +=  ' ' + org_sentences[s]\n",
        "                cnt +=1\n",
        "        #print(cnt,top_rank)\n",
        "        txt = txt.strip()\n",
        "        if cnt > top_rank:\n",
        "            txt = besm2(ft,txt,top_rank=top_rank)\n",
        "\n",
        "        t,score, grammar = sam_wgan4(ft,txt.strip(),epochs=300,display=False)\n",
        "        print('-'*50)\n",
        "        print(t,score,grammar)\n",
        "        #t = sentence_correct(t)\n",
        "        #print(t)\n",
        "        summary_text.append(t)\n",
        "\n",
        "    return ' '.join(summary_text).strip()"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SW3WKBjMbug5",
        "outputId": "ad78d7c9-1f8c-4e04-8455-3fc479a9c280"
      },
      "source": [
        "import io\n",
        "\n",
        "for try_count in range(1000):\n",
        "\n",
        "    try:\n",
        "        del model\n",
        "        print('delete model')\n",
        "    except Exception as ex:\n",
        "        pass\n",
        "    model = EncoderDecoderModel.from_pretrained(\"/content/drive/MyDrive/GAN_ENDE/sentence_complete_model\")\n",
        "\n",
        "    org_text = summary(full_text,full_text,steps=6,top_rank=2)\n",
        "    print('='*50)\n",
        "    for txt in np.array(nltk.sent_tokenize(org_text.strip())):\n",
        "        print(txt)\n",
        "    org_text = summary(full_text,org_text,steps=2,top_rank=2)\n",
        "    print('='*50 + str(try_count+1) + '='*50)\n",
        "    for txt in np.array(nltk.sent_tokenize(org_text.strip())):\n",
        "        print(txt)\n",
        "    print('\\n')\n",
        "    with io.open('/content/drive/MyDrive/GAN_ENDE/Cinderella_summary_result.txt','a',encoding='utf8') as f:\n",
        "        f.write(org_text + '\\r\\n')\n",
        "    f.close()\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "delete model\n",
            "--------------------------------------------------\n",
            "신데렐라는 무럭무럭 자라서 예쁘고 마음씨 고운 소녀가 되었다. 새어머니는 두명의 언니들을 데리고 왔다.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   300/300 epochs, e 0.00105 gl:0.26410785  sl:-0.0696 ll:0.0097\n",
            "0.4642,0.5614,score:1.3996,[신데렐라는 무럭무럭 새어머니는 언니들을 왔다.]\n",
            "correct_grammar_score:3.0224 best_grammar_score:-0.5412\n",
            "신데렐라는 무럭무럭 새어머니는 언니들을 왔다.\n",
            "신데렐라는 무럭무럭 성장하고 새어머니는 언니들을 만나러 왔다.\n",
            "max score:1.3996180742055684 grammar:-0.5411975979804993 text:신데렐라는 무럭무럭 성장하고 새어머니는 언니들을 만나러 왔다.\n",
            "--------------------------------------------------\n",
            "신데렐라는 무럭무럭 자라서 예쁘고 마음씨 고운 소녀가 되었다. 새어머니는 두명의 언니들을 데리고 왔다.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   310/310 epochs, e 0.00105 gl:0.25979835  sl:-0.0684 ll:0.0119\n",
            "0.4642,0.5614,score:1.3996,[신데렐라는 무럭무럭 새어머니는 언니들을 왔다.]\n",
            "correct_grammar_score:3.0224 best_grammar_score:-0.5412\n",
            "신데렐라는 무럭무럭 새어머니는 언니들을 왔다.\n",
            "신데렐라는 무럭무럭 성장하고 새어머니는 언니들을 만나러 왔다.\n",
            "max score:1.3996180742055684 grammar:-0.5411975979804993 text:신데렐라는 무럭무럭 성장하고 새어머니는 언니들을 만나러 왔다.\n",
            "--------------------------------------------------\n",
            "신데렐라는 무럭무럭 자라서 예쁘고 마음씨 고운 소녀가 되었다. 새어머니는 두명의 언니들을 데리고 왔다.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   320/320 epochs, e 0.00105 gl:-0.38591591  sl:-0.0996 ll:0.3808\n",
            "0.6460,0.4211,score:2.1947,[신데렐라는 무럭무럭 자라서 새어머니는 언니들을 데리고 왔다.]\n",
            "correct_grammar_score:4.1468 best_grammar_score:2.8900\n",
            "신데렐라는 무럭무럭 자라서 새어머니는 언니들을 데리고 왔다.\n",
            "신데렐라는 무럭무럭 자라서 새어머니는 언니들을 데리고 데려 왔다.\n",
            "--------------------------------------------------\n",
            "신데렐라는 무럭무럭 자라서 새어머니는 언니들을 데리고 데려 왔다. 2.1946707358766977 2.8900063037872314\n",
            "--------------------------------------------------\n",
            "새어머니는 소녀가 자기 딸들보다 예쁘고 착한게 못마땅했다. 그러던 어느날 왕궁에서 무도회가 열렸다.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   300/300 epochs, e 0.00105 gl:-0.41229075  sl:-0.0570 ll:0.0068\n",
            "0.5338,0.4545,score:1.7597,[새어머니는 딸들보다 못마땅했 왕궁에서 무도회가 열렸다.]\n",
            "correct_grammar_score:5.0943 best_grammar_score:1.4259\n",
            "새어머니는 딸들보다 못마땅했 왕궁에서 무도회가 열렸다.\n",
            "새어머니는 딸들보다 형편이 못마땅했고, 왕궁에서 열린 무도회가 자주 열렸다.\n",
            "max score:1.7597086290432056 grammar:1.42585289478302 text:새어머니는 딸들보다 형편이 못마땅했고, 왕궁에서 열린 무도회가 자주 열렸다.\n",
            "--------------------------------------------------\n",
            "새어머니는 소녀가 자기 딸들보다 예쁘고 착한게 못마땅했다. 그러던 어느날 왕궁에서 무도회가 열렸다.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   310/310 epochs, e 0.00105 gl:-0.50781858  sl:-0.0879 ll:0.3692\n",
            "0.8345,0.1818,score:2.5085,[새어머니는 소녀가 자기 딸들보다 예쁘고 착한게 못마땅했 왕궁에서 무도회가 열렸다.]\n",
            "correct_grammar_score:5.2219 best_grammar_score:3.9457\n",
            "새어머니는 소녀가 자기 딸들보다 예쁘고 착한게 못마땅했 왕궁에서 무도회가 열렸다.\n",
            "새어머니는 이 소녀가 자기 딸들보다 훨씬 예쁘고 착한게 못마땅했기에 왕궁에서 무도회가 열렸다.\n",
            "--------------------------------------------------\n",
            "새어머니는 이 소녀가 자기 딸들보다 훨씬 예쁘고 착한게 못마땅했기에 왕궁에서 무도회가 열렸다. 2.5084819497354776 3.945707082748413\n",
            "--------------------------------------------------\n",
            "혼자 남은 신데렐라는 서러워 울기 시작했다. 신데렐라가 고개를 들어보니 마법사 할머니가 빙그레 웃고 있었다.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   300/300 epochs, e 0.00105 gl:-0.47671169  sl:-0.1585 ll:0.4989\n",
            "0.6647,0.3833,score:2.2735,[남은 신데렐라는 서러워 신데렐라가 고개를 들어보니 할머니가 있었다.]\n",
            "correct_grammar_score:5.0678 best_grammar_score:3.3651\n",
            "남은 신데렐라는 서러워 신데렐라가 고개를 들어보니 할머니가 있었다.\n",
            "남은 신데렐라는 서러워 했고, 신데데가 고개를 들어보니 할머니와 할머니가 기다리고 있었다.\n",
            "--------------------------------------------------\n",
            "남은 신데렐라는 서러워 했고, 신데데가 고개를 들어보니 할머니와 할머니가 기다리고 있었다. 2.2734816298328253 3.3650851249694824\n",
            "--------------------------------------------------\n",
            "할머니는 소녀를 무도회에 보내줄테니 호박 한개와 생쥐 두마리 도마뱀을 가지고 오라 했다. 신데렐라의 낡은 옷은 구슬 장식이 반짝이는 예쁜 드레스로 바뀌었다.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   300/300 epochs, e 0.00105 gl:-0.40344617  sl:-0.0981 ll:0.2095\n",
            "0.6172,0.3908,score:1.9793,[할머니는 무도회에 보내줄테니 호박 두마리 도마뱀을 신데렐라의 장식이 반짝이는 드레스로 바뀌었다.]\n",
            "correct_grammar_score:4.5372 best_grammar_score:2.1243\n",
            "할머니는 무도회에 보내줄테니 호박 두마리 도마뱀을 신데렐라의 장식이 반짝이는 드레스로 바뀌었다.\n",
            "할머니는 무도회에 초대장을 보내줄테니 호박 두마리 도마뱀을 신데렐라의 장식장식 장식장식 장식이 반짝이는 드레스로 바뀌었다.\n",
            "--------------------------------------------------\n",
            "할머니는 무도회에 초대장을 보내줄테니 호박 두마리 도마뱀을 신데렐라의 장식장식 장식장식 장식이 반짝이는 드레스로 바뀌었다. 1.979284020510881 2.1243157386779785\n",
            "--------------------------------------------------\n",
            "할머니는 신데렐라에게 반짝반짝 빛나는 유리구두를 신겨 주었다. 신데렐라는 황금마차를 타고 왕궁 무도회장으로 가서 멋진 왕자님을 만났다.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   300/300 epochs, e 0.00105 gl:-0.45992595  sl:-0.2110 ll:0.0036\n",
            "0.7158,0.3200,score:1.9640,[할머니는 신데렐라에게 반짝반짝 유리구두를 신데렐라는 황금마차를 무도회장으로 왕자님을 만났다.]\n",
            "correct_grammar_score:5.1754 best_grammar_score:1.2741\n",
            "할머니는 신데렐라에게 반짝반짝 유리구두를 신데렐라는 황금마차를 무도회장으로 왕자님을 만났다.\n",
            "할머니는 신데렐라에게 반짝반짝 유리구두를 선물받았고, 신고데렐라는 황금마차를 타고 무도회장으로 향해 왕자님을 만났다.\n",
            "max score:1.9639865353740378 grammar:1.274074912071228 text:할머니는 신데렐라에게 반짝반짝 유리구두를 선물받았고, 신고데렐라는 황금마차를 타고 무도회장으로 향해 왕자님을 만났다.\n",
            "--------------------------------------------------\n",
            "할머니는 신데렐라에게 반짝반짝 빛나는 유리구두를 신겨 주었다. 신데렐라는 황금마차를 타고 왕궁 무도회장으로 가서 멋진 왕자님을 만났다.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   310/310 epochs, e 0.00105 gl:-0.45687255  sl:-0.2096 ll:0.0081\n",
            "0.7158,0.3200,score:1.9640,[할머니는 신데렐라에게 반짝반짝 유리구두를 신데렐라는 황금마차를 무도회장으로 왕자님을 만났다.]\n",
            "correct_grammar_score:5.1754 best_grammar_score:1.2741\n",
            "할머니는 신데렐라에게 반짝반짝 유리구두를 신데렐라는 황금마차를 무도회장으로 왕자님을 만났다.\n",
            "할머니는 신데렐라에게 반짝반짝 유리구두를 선물받았고, 신고데렐라는 황금마차를 타고 무도회장으로 향해 왕자님을 만났다.\n",
            "max score:1.9639865353740378 grammar:1.274074912071228 text:할머니는 신데렐라에게 반짝반짝 유리구두를 선물받았고, 신고데렐라는 황금마차를 타고 무도회장으로 향해 왕자님을 만났다.\n",
            "--------------------------------------------------\n",
            "할머니는 신데렐라에게 반짝반짝 빛나는 유리구두를 신겨 주었다. 신데렐라는 황금마차를 타고 왕궁 무도회장으로 가서 멋진 왕자님을 만났다.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   320/320 epochs, e 0.00105 gl:-0.46805245  sl:-0.2147 ll:0.0021\n",
            "0.7158,0.3200,score:1.9640,[할머니는 신데렐라에게 반짝반짝 유리구두를 신데렐라는 황금마차를 무도회장으로 왕자님을 만났다.]\n",
            "correct_grammar_score:5.1754 best_grammar_score:1.2741\n",
            "할머니는 신데렐라에게 반짝반짝 유리구두를 신데렐라는 황금마차를 무도회장으로 왕자님을 만났다.\n",
            "할머니는 신데렐라에게 반짝반짝 유리구두를 선물받았고, 신고데렐라는 황금마차를 타고 무도회장으로 향해 왕자님을 만났다.\n",
            "max score:1.9639865353740378 grammar:1.274074912071228 text:할머니는 신데렐라에게 반짝반짝 유리구두를 선물받았고, 신고데렐라는 황금마차를 타고 무도회장으로 향해 왕자님을 만났다.\n",
            "--------------------------------------------------\n",
            "할머니는 신데렐라에게 반짝반짝 빛나는 유리구두를 신겨 주었다. 신데렐라는 황금마차를 타고 왕궁 무도회장으로 가서 멋진 왕자님을 만났다.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   330/330 epochs, e 0.00105 gl:-0.71237689  sl:-0.2791 ll:0.5795\n",
            "0.8821,0.1467,score:2.3836,[할머니는 신데렐라에게 반짝반짝 빛나는 유리구두를 신데렐라는 황금마차를 왕궁 무도회장으로 가서 멋진 왕자님을 만났다.]\n",
            "0.8304,0.1867,score:2.2470,[할머니는 신데렐라에게 반짝반짝 빛나는 유리구두를 신데렐라는 황금마차를 왕궁 무도회장으로 멋진 왕자님을 만났다.]\n",
            "correct_grammar_score:5.2166 best_grammar_score:2.8359\n",
            "할머니는 신데렐라에게 반짝반짝 빛나는 유리구두를 신데렐라는 황금마차를 왕궁 무도회장으로 가서 멋진 왕자님을 만났다.\n",
            "할머니는 신데렐라에게 반짝반짝 빛나는 유리구두를 선물받았고, 신고신데렐라는 황금마차를 타고 왕궁 무도회장으로 가서 멋진 왕자님을 만났다.\n",
            "--------------------------------------------------\n",
            "할머니는 신데렐라에게 반짝반짝 빛나는 유리구두를 선물받았고, 신고신데렐라는 황금마차를 타고 왕궁 무도회장으로 가서 멋진 왕자님을 만났다. 2.383564102515354 2.8359313011169434\n",
            "--------------------------------------------------\n",
            "왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고 신데렐라하고만 춤을 추었다. 벽시계의 열두시를 알리는 종소리에 신데렐라는 화들짝 놀랐다.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   300/300 epochs, e 0.00105 gl:0.55069095  sl:-0.1714 ll:0.0049\n",
            "0.6875,0.3086,score:1.0441,[왕자님은 무도회장에 아가씨들은 쳐다보지도 신데렐라하고만 벽시계의 열두시를 종소리에 신데렐라는 놀랐다.]\n",
            "correct_grammar_score:5.1129 best_grammar_score:-3.8371\n",
            "왕자님은 무도회장에 아가씨들은 쳐다보지도 신데렐라하고만 벽시계의 열두시를 종소리에 신데렐라는 놀랐다.\n",
            "왕자님은 무도회장에 들어가 아가씨들은 쳐다보지도 않고, 신데렐라하고만 벽시계의 열두시를 알리는 종소리에 신데도렐라는 당황해했다.\n",
            "max score:1.0440673029064542 grammar:-3.837083339691162 text:왕자님은 무도회장에 들어가 아가씨들은 쳐다보지도 않고, 신데렐라하고만 벽시계의 열두시를 알리는 종소리에 신데도렐라는 당황해했다.\n",
            "--------------------------------------------------\n",
            "왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고 신데렐라하고만 춤을 추었다. 벽시계의 열두시를 알리는 종소리에 신데렐라는 화들짝 놀랐다.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   310/310 epochs, e 0.00105 gl:0.54134595  sl:-0.1685 ll:0.0070\n",
            "0.6875,0.3086,score:1.0441,[왕자님은 무도회장에 아가씨들은 쳐다보지도 신데렐라하고만 벽시계의 열두시를 종소리에 신데렐라는 놀랐다.]\n",
            "correct_grammar_score:5.1129 best_grammar_score:-3.8371\n",
            "왕자님은 무도회장에 아가씨들은 쳐다보지도 신데렐라하고만 벽시계의 열두시를 종소리에 신데렐라는 놀랐다.\n",
            "왕자님은 무도회장에 들어가 아가씨들은 쳐다보지도 않고, 신데렐라하고만 벽시계의 열두시를 알리는 종소리에 신데도렐라는 당황해했다.\n",
            "max score:1.0440673029064542 grammar:-3.837083339691162 text:왕자님은 무도회장에 들어가 아가씨들은 쳐다보지도 않고, 신데렐라하고만 벽시계의 열두시를 알리는 종소리에 신데도렐라는 당황해했다.\n",
            "--------------------------------------------------\n",
            "왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고 신데렐라하고만 춤을 추었다. 벽시계의 열두시를 알리는 종소리에 신데렐라는 화들짝 놀랐다.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   320/320 epochs, e 0.00105 gl:-0.65071934  sl:-0.2124 ll:0.3687\n",
            "0.8303,0.1728,score:2.1861,[왕자님은 무도회장에 다른 아가씨들은 쳐다보지도 신데렐라하고만 벽시계의 열두시를 알리는 종소리에 신데렐라는 화들짝 놀랐다.]\n",
            "correct_grammar_score:5.2162 best_grammar_score:2.1163\n",
            "왕자님은 무도회장에 다른 아가씨들은 쳐다보지도 신데렐라하고만 벽시계의 열두시를 알리는 종소리에 신데렐라는 화들짝 놀랐다.\n",
            "왕자님은 무도회장에 도착했지만 다른 아가씨들은 쳐다보지도 않고 신데렐라하고만 벽시계의 열두시를 알리는 종소리에 신데도렐라는 화들짝 놀랐다.\n",
            "--------------------------------------------------\n",
            "왕자님은 무도회장에 도착했지만 다른 아가씨들은 쳐다보지도 않고 신데렐라하고만 벽시계의 열두시를 알리는 종소리에 신데도렐라는 화들짝 놀랐다. 2.186143346140309 2.1163315773010254\n",
            "--------------------------------------------------\n",
            "신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리구두 한짝을 주웠다. 드디어 신데렐라의 집에까지 신하들이 도착했다.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   300/300 epochs, e 0.00105 gl:-0.66147012  sl:-0.2199 ll:0.0052\n",
            "0.8474,0.2131,score:2.2034,[신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리구두 신데렐라의 집에까지 신하들이 도착했다.]\n",
            "correct_grammar_score:4.4598 best_grammar_score:1.7731\n",
            "신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리구두 신데렐라의 집에까지 신하들이 도착했다.\n",
            "신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리구두 신데데렐라의 집에까지 도착했고, 신데들이 도착하자 신하들이 도착했다.\n",
            "max score:2.2034324328106942 grammar:1.7731177806854248 text:신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리구두 신데데렐라의 집에까지 도착했고, 신데들이 도착하자 신하들이 도착했다.\n",
            "--------------------------------------------------\n",
            "신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리구두 한짝을 주웠다. 드디어 신데렐라의 집에까지 신하들이 도착했다.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   310/310 epochs, e 0.00105 gl:-0.67747498  sl:-0.2253 ll:0.0028\n",
            "0.8474,0.2131,score:2.2034,[신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리구두 신데렐라의 집에까지 신하들이 도착했다.]\n",
            "correct_grammar_score:4.4598 best_grammar_score:1.7731\n",
            "신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리구두 신데렐라의 집에까지 신하들이 도착했다.\n",
            "신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리구두 신데데렐라의 집에까지 도착했고, 신데들이 도착하자 신하들이 도착했다.\n",
            "max score:2.2034324328106942 grammar:1.7731177806854248 text:신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리구두 신데데렐라의 집에까지 도착했고, 신데들이 도착하자 신하들이 도착했다.\n",
            "--------------------------------------------------\n",
            "신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리구두 한짝을 주웠다. 드디어 신데렐라의 집에까지 신하들이 도착했다.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   320/320 epochs, e 0.00105 gl:-0.66340101  sl:-0.2206 ll:0.0046\n",
            "0.8474,0.2131,score:2.2034,[신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리구두 신데렐라의 집에까지 신하들이 도착했다.]\n",
            "correct_grammar_score:4.4598 best_grammar_score:1.7731\n",
            "신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리구두 신데렐라의 집에까지 신하들이 도착했다.\n",
            "신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리구두 신데데렐라의 집에까지 도착했고, 신데들이 도착하자 신하들이 도착했다.\n",
            "max score:2.2034324328106942 grammar:1.7731177806854248 text:신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리구두 신데데렐라의 집에까지 도착했고, 신데들이 도착하자 신하들이 도착했다.\n",
            "--------------------------------------------------\n",
            "신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리구두 한짝을 주웠다. 드디어 신데렐라의 집에까지 신하들이 도착했다.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   330/330 epochs, e 0.00105 gl:-0.67459357  sl:-0.2243 ll:0.0031\n",
            "0.8474,0.2131,score:2.2034,[신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리구두 신데렐라의 집에까지 신하들이 도착했다.]\n",
            "correct_grammar_score:4.4598 best_grammar_score:1.7731\n",
            "신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리구두 신데렐라의 집에까지 신하들이 도착했다.\n",
            "신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리구두 신데데렐라의 집에까지 도착했고, 신데들이 도착하자 신하들이 도착했다.\n",
            "--------------------------------------------------\n",
            "신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리구두 신데데렐라의 집에까지 도착했고, 신데들이 도착하자 신하들이 도착했다. 2.2034324328106942 1.7731177806854248\n",
            "--------------------------------------------------\n",
            "유리구두는 그녀의 발에 꼭 맞았다. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았다.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   300/300 epochs, e 0.00105 gl:-0.50090134  sl:-0.1458 ll:0.0114\n",
            "0.7556,0.3333,score:2.5892,[유리구두는 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았다.]\n",
            "correct_grammar_score:4.7881 best_grammar_score:4.4677\n",
            "유리구두는 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았다.\n",
            "유리구두는 왕자, 신데렐라는 왕자님과 결혼하여 오래 행복하게 살았다.\n",
            "--------------------------------------------------\n",
            "유리구두는 왕자, 신데렐라는 왕자님과 결혼하여 오래 행복하게 살았다. 2.589245151866114 4.467692852020264\n",
            "==================================================\n",
            "신데렐라는 무럭무럭 자라서 새어머니는 언니들을 데리고 데려 왔다.\n",
            "새어머니는 이 소녀가 자기 딸들보다 훨씬 예쁘고 착한게 못마땅했기에 왕궁에서 무도회가 열렸다.\n",
            "남은 신데렐라는 서러워 했고, 신데데가 고개를 들어보니 할머니와 할머니가 기다리고 있었다.\n",
            "할머니는 무도회에 초대장을 보내줄테니 호박 두마리 도마뱀을 신데렐라의 장식장식 장식장식 장식이 반짝이는 드레스로 바뀌었다.\n",
            "할머니는 신데렐라에게 반짝반짝 빛나는 유리구두를 선물받았고, 신고신데렐라는 황금마차를 타고 왕궁 무도회장으로 가서 멋진 왕자님을 만났다.\n",
            "왕자님은 무도회장에 도착했지만 다른 아가씨들은 쳐다보지도 않고 신데렐라하고만 벽시계의 열두시를 알리는 종소리에 신데도렐라는 화들짝 놀랐다.\n",
            "신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리구두 신데데렐라의 집에까지 도착했고, 신데들이 도착하자 신하들이 도착했다.\n",
            "유리구두는 왕자, 신데렐라는 왕자님과 결혼하여 오래 행복하게 살았다.\n",
            "--------------------------------------------------\n",
            "신데렐라는 무럭무럭 자라서 새어머니는 언니들을 데리고 데려 왔다. 새어머니는 이 소녀가 자기 딸들보다 훨씬 예쁘고 착한게 못마땅했기에 왕궁에서 무도회가 열렸다.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   300/300 epochs, e 0.00105 gl:-0.54627353  sl:-0.1385 ll:0.2452\n",
            "0.7956,0.2584,score:2.4731,[신데렐라는 무럭무럭 자라서 새어머니는 언니들을 새어머니는 딸들보다 예쁘고 착한게 못마땅했기에 왕궁에서 무도회가 열렸다.]\n",
            "correct_grammar_score:5.0138 best_grammar_score:3.7400\n",
            "신데렐라는 무럭무럭 자라서 새어머니는 언니들을 새어머니는 딸들보다 예쁘고 착한게 못마땅했기에 왕궁에서 무도회가 열렸다.\n",
            "신데렐라는 무럭무럭 자라서 새어머니는 언니들을 괴롭혔고, 새고머니는 딸들보다 예쁘고 착한게 못마땅했기에 왕궁에서 무도회가 열렸다.\n",
            "--------------------------------------------------\n",
            "신데렐라는 무럭무럭 자라서 새어머니는 언니들을 괴롭혔고, 새고머니는 딸들보다 예쁘고 착한게 못마땅했기에 왕궁에서 무도회가 열렸다. 2.4730552526829155 3.7400095462799072\n",
            "--------------------------------------------------\n",
            "남은 신데렐라는 서러워 했고 신데데가 고개를 들어보니 할머니와 할머니가 기다리고 있었다. 할머니는 무도회에 초대장을 보내줄테니 호박 두마리 도마뱀을 신데렐라의 장식장식 장식장식 장식이 반짝이는 드레스로 바뀌었다.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   300/300 epochs, e 0.00105 gl:-0.60121024  sl:-0.1903 ll:0.5888\n",
            "0.7943,0.2712,score:2.3794,[남은 신데렐라는 서러워 들어보니 할머니와 할머니가 할머니는 무도회에 초대장을 보내줄테니 호박 두마리 도마뱀을 신데렐라의 장식이 반짝이는 드레스로 바뀌었다.]\n",
            "correct_grammar_score:4.7112 best_grammar_score:3.1179\n",
            "남은 신데렐라는 서러워 들어보니 할머니와 할머니가 할머니는 무도회에 초대장을 보내줄테니 호박 두마리 도마뱀을 신데렐라의 장식이 반짝이는 드레스로 바뀌었다.\n",
            "남은 신데렐라는 서러워 보였고, 들어보니 할머니와 할머니가 할머니는 무도회에 초대장을 보내줄테니 호박 두마리 도마뱀을 선물했고, 신데도렐라의 장식장식 장식이 장식된 장식장식장식장식 장식이 반짝이는 드레스로 바뀌었다.\n",
            "--------------------------------------------------\n",
            "남은 신데렐라는 서러워 보였고, 들어보니 할머니와 할머니가 할머니는 무도회에 초대장을 보내줄테니 호박 두마리 도마뱀을 선물했고, 신데도렐라의 장식장식 장식이 장식된 장식장식장식장식 장식이 반짝이는 드레스로 바뀌었다. 2.379423616748089 3.117887020111084\n",
            "--------------------------------------------------\n",
            "할머니는 신데렐라에게 반짝반짝 빛나는 유리구두를 선물받았고 신고신데렐라는 황금마차를 타고 왕궁 무도회장으로 가서 멋진 왕자님을 만났다. 왕자님은 무도회장에 도착했지만 다른 아가씨들은 쳐다보지도 않고 신데렐라하고만 벽시계의 열두시를 알리는 종소리에 신데도렐라는 화들짝 놀랐다.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   300/300 epochs, e 0.00105 gl:0.54778272  sl:-0.2133 ll:0.0020\n",
            "0.6882,0.3529,score:1.1861,[할머니는 신데렐라에게 반짝반짝 유리구두를 신고신데렐라는 황금마차를 무도회장으로 왕자님을 왕자님은 무도회장에 아가씨들은 쳐다보지도 신데렐라하고만 벽시계의 열두시를 종소리에 놀랐다.]\n",
            "correct_grammar_score:5.2246 best_grammar_score:-3.2596\n",
            "할머니는 신데렐라에게 반짝반짝 유리구두를 신고신데렐라는 황금마차를 무도회장으로 왕자님을 왕자님은 무도회장에 아가씨들은 쳐다보지도 신데렐라하고만 벽시계의 열두시를 종소리에 놀랐다.\n",
            "할머니는 신데렐라에게 반짝반짝 유리구두를 선물받고 신고신데렐라는 황금마차를 무도회장으로 향해 왕자님을 맞이했으나 왕자님은 무도회장에 아가씨들은 쳐다보지도 않고 신데도렐라하고만 벽시계의 열두시를 바라보는 종소리에 깜짝 놀랐다.\n",
            "max score:1.1861257897498865 grammar:-3.2596325874328613 text:할머니는 신데렐라에게 반짝반짝 유리구두를 선물받고 신고신데렐라는 황금마차를 무도회장으로 향해 왕자님을 맞이했으나 왕자님은 무도회장에 아가씨들은 쳐다보지도 않고 신데도렐라하고만 벽시계의 열두시를 바라보는 종소리에 깜짝 놀랐다.\n",
            "--------------------------------------------------\n",
            "할머니는 신데렐라에게 반짝반짝 빛나는 유리구두를 선물받았고 신고신데렐라는 황금마차를 타고 왕궁 무도회장으로 가서 멋진 왕자님을 만났다. 왕자님은 무도회장에 도착했지만 다른 아가씨들은 쳐다보지도 않고 신데렐라하고만 벽시계의 열두시를 알리는 종소리에 신데도렐라는 화들짝 놀랐다.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   310/310 epochs, e 0.00105 gl:-0.50409329  sl:-0.2465 ll:0.2514\n",
            "0.7328,0.2941,score:1.9414,[할머니는 신데렐라에게 반짝반짝 유리구두를 신고신데렐라는 황금마차를 무도회장으로 가서 왕자님을 만났 왕자님은 무도회장에 아가씨들은 쳐다보지도 않고 신데렐라하고만 벽시계의 열두시를 종소리에 놀랐다.]\n",
            "correct_grammar_score:5.2652 best_grammar_score:1.0897\n",
            "할머니는 신데렐라에게 반짝반짝 유리구두를 신고신데렐라는 황금마차를 무도회장으로 가서 왕자님을 만났 왕자님은 무도회장에 아가씨들은 쳐다보지도 않고 신데렐라하고만 벽시계의 열두시를 종소리에 놀랐다.\n",
            "할머니는 신데렐라에게 반짝반짝 유리구두를 선물받고, 신고신데렐라는 황금마차를 타고 무도회장으로 가서 왕자님을 만났고 왕자님은 무도회장에 있던 아가씨들은 쳐다보지도 않고 신데도렐라하고만 벽시계의 열두시를 바라보는 종소리에 깜짝 놀랐다.\n",
            "max score:1.9414183779563872 grammar:1.0897135734558105 text:할머니는 신데렐라에게 반짝반짝 유리구두를 선물받고, 신고신데렐라는 황금마차를 타고 무도회장으로 가서 왕자님을 만났고 왕자님은 무도회장에 있던 아가씨들은 쳐다보지도 않고 신데도렐라하고만 벽시계의 열두시를 바라보는 종소리에 깜짝 놀랐다.\n",
            "--------------------------------------------------\n",
            "할머니는 신데렐라에게 반짝반짝 빛나는 유리구두를 선물받았고 신고신데렐라는 황금마차를 타고 왕궁 무도회장으로 가서 멋진 왕자님을 만났다. 왕자님은 무도회장에 도착했지만 다른 아가씨들은 쳐다보지도 않고 신데렐라하고만 벽시계의 열두시를 알리는 종소리에 신데도렐라는 화들짝 놀랐다.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   320/320 epochs, e 0.00105 gl:0.55154687  sl:-0.2148 ll:0.0012\n",
            "0.6882,0.3529,score:1.1861,[할머니는 신데렐라에게 반짝반짝 유리구두를 신고신데렐라는 황금마차를 무도회장으로 왕자님을 왕자님은 무도회장에 아가씨들은 쳐다보지도 신데렐라하고만 벽시계의 열두시를 종소리에 놀랐다.]\n",
            "correct_grammar_score:5.2246 best_grammar_score:-3.2596\n",
            "할머니는 신데렐라에게 반짝반짝 유리구두를 신고신데렐라는 황금마차를 무도회장으로 왕자님을 왕자님은 무도회장에 아가씨들은 쳐다보지도 신데렐라하고만 벽시계의 열두시를 종소리에 놀랐다.\n",
            "할머니는 신데렐라에게 반짝반짝 유리구두를 선물받고 신고신데렐라는 황금마차를 무도회장으로 향해 왕자님을 맞이했으나 왕자님은 무도회장에 아가씨들은 쳐다보지도 않고 신데도렐라하고만 벽시계의 열두시를 바라보는 종소리에 깜짝 놀랐다.\n",
            "max score:1.1861257897498865 grammar:-3.2596325874328613 text:할머니는 신데렐라에게 반짝반짝 유리구두를 선물받고 신고신데렐라는 황금마차를 무도회장으로 향해 왕자님을 맞이했으나 왕자님은 무도회장에 아가씨들은 쳐다보지도 않고 신데도렐라하고만 벽시계의 열두시를 바라보는 종소리에 깜짝 놀랐다.\n",
            "--------------------------------------------------\n",
            "할머니는 신데렐라에게 반짝반짝 빛나는 유리구두를 선물받았고 신고신데렐라는 황금마차를 타고 왕궁 무도회장으로 가서 멋진 왕자님을 만났다. 왕자님은 무도회장에 도착했지만 다른 아가씨들은 쳐다보지도 않고 신데렐라하고만 벽시계의 열두시를 알리는 종소리에 신데도렐라는 화들짝 놀랐다.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   330/330 epochs, e 0.00105 gl:0.54811746  sl:-0.2135 ll:0.0024\n",
            "0.6882,0.3529,score:1.1861,[할머니는 신데렐라에게 반짝반짝 유리구두를 신고신데렐라는 황금마차를 무도회장으로 왕자님을 왕자님은 무도회장에 아가씨들은 쳐다보지도 신데렐라하고만 벽시계의 열두시를 종소리에 놀랐다.]\n",
            "correct_grammar_score:5.2246 best_grammar_score:-3.2596\n",
            "할머니는 신데렐라에게 반짝반짝 유리구두를 신고신데렐라는 황금마차를 무도회장으로 왕자님을 왕자님은 무도회장에 아가씨들은 쳐다보지도 신데렐라하고만 벽시계의 열두시를 종소리에 놀랐다.\n",
            "할머니는 신데렐라에게 반짝반짝 유리구두를 선물받고 신고신데렐라는 황금마차를 무도회장으로 향해 왕자님을 맞이했으나 왕자님은 무도회장에 아가씨들은 쳐다보지도 않고 신데도렐라하고만 벽시계의 열두시를 바라보는 종소리에 깜짝 놀랐다.\n",
            "max score:1.1861257897498865 grammar:-3.2596325874328613 text:할머니는 신데렐라에게 반짝반짝 유리구두를 선물받고 신고신데렐라는 황금마차를 무도회장으로 향해 왕자님을 맞이했으나 왕자님은 무도회장에 아가씨들은 쳐다보지도 않고 신데도렐라하고만 벽시계의 열두시를 바라보는 종소리에 깜짝 놀랐다.\n",
            "--------------------------------------------------\n",
            "할머니는 신데렐라에게 반짝반짝 빛나는 유리구두를 선물받았고 신고신데렐라는 황금마차를 타고 왕궁 무도회장으로 가서 멋진 왕자님을 만났다. 왕자님은 무도회장에 도착했지만 다른 아가씨들은 쳐다보지도 않고 신데렐라하고만 벽시계의 열두시를 알리는 종소리에 신데도렐라는 화들짝 놀랐다.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   340/340 epochs, e 0.00105 gl:0.55279279  sl:-0.2153 ll:0.0013\n",
            "0.6882,0.3529,score:1.1861,[할머니는 신데렐라에게 반짝반짝 유리구두를 신고신데렐라는 황금마차를 무도회장으로 왕자님을 왕자님은 무도회장에 아가씨들은 쳐다보지도 신데렐라하고만 벽시계의 열두시를 종소리에 놀랐다.]\n",
            "correct_grammar_score:5.2246 best_grammar_score:-3.2596\n",
            "할머니는 신데렐라에게 반짝반짝 유리구두를 신고신데렐라는 황금마차를 무도회장으로 왕자님을 왕자님은 무도회장에 아가씨들은 쳐다보지도 신데렐라하고만 벽시계의 열두시를 종소리에 놀랐다.\n",
            "할머니는 신데렐라에게 반짝반짝 유리구두를 선물받고 신고신데렐라는 황금마차를 무도회장으로 향해 왕자님을 맞이했으나 왕자님은 무도회장에 아가씨들은 쳐다보지도 않고 신데도렐라하고만 벽시계의 열두시를 바라보는 종소리에 깜짝 놀랐다.\n",
            "max score:1.1861257897498865 grammar:-3.2596325874328613 text:할머니는 신데렐라에게 반짝반짝 유리구두를 선물받고 신고신데렐라는 황금마차를 무도회장으로 향해 왕자님을 맞이했으나 왕자님은 무도회장에 아가씨들은 쳐다보지도 않고 신데도렐라하고만 벽시계의 열두시를 바라보는 종소리에 깜짝 놀랐다.\n",
            "--------------------------------------------------\n",
            "할머니는 신데렐라에게 반짝반짝 빛나는 유리구두를 선물받았고 신고신데렐라는 황금마차를 타고 왕궁 무도회장으로 가서 멋진 왕자님을 만났다. 왕자님은 무도회장에 도착했지만 다른 아가씨들은 쳐다보지도 않고 신데렐라하고만 벽시계의 열두시를 알리는 종소리에 신데도렐라는 화들짝 놀랐다.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   350/350 epochs, e 0.00105 gl:0.55398953  sl:-0.2157 ll:0.0010\n",
            "0.6882,0.3529,score:1.1861,[할머니는 신데렐라에게 반짝반짝 유리구두를 신고신데렐라는 황금마차를 무도회장으로 왕자님을 왕자님은 무도회장에 아가씨들은 쳐다보지도 신데렐라하고만 벽시계의 열두시를 종소리에 놀랐다.]\n",
            "correct_grammar_score:5.2246 best_grammar_score:-3.2596\n",
            "할머니는 신데렐라에게 반짝반짝 유리구두를 신고신데렐라는 황금마차를 무도회장으로 왕자님을 왕자님은 무도회장에 아가씨들은 쳐다보지도 신데렐라하고만 벽시계의 열두시를 종소리에 놀랐다.\n",
            "할머니는 신데렐라에게 반짝반짝 유리구두를 선물받고 신고신데렐라는 황금마차를 무도회장으로 향해 왕자님을 맞이했으나 왕자님은 무도회장에 아가씨들은 쳐다보지도 않고 신데도렐라하고만 벽시계의 열두시를 바라보는 종소리에 깜짝 놀랐다.\n",
            "max score:1.1861257897498865 grammar:-3.2596325874328613 text:할머니는 신데렐라에게 반짝반짝 유리구두를 선물받고 신고신데렐라는 황금마차를 무도회장으로 향해 왕자님을 맞이했으나 왕자님은 무도회장에 아가씨들은 쳐다보지도 않고 신데도렐라하고만 벽시계의 열두시를 바라보는 종소리에 깜짝 놀랐다.\n",
            "--------------------------------------------------\n",
            "할머니는 신데렐라에게 반짝반짝 빛나는 유리구두를 선물받았고 신고신데렐라는 황금마차를 타고 왕궁 무도회장으로 가서 멋진 왕자님을 만났다. 왕자님은 무도회장에 도착했지만 다른 아가씨들은 쳐다보지도 않고 신데렐라하고만 벽시계의 열두시를 알리는 종소리에 신데도렐라는 화들짝 놀랐다.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   360/360 epochs, e 0.00105 gl:0.55313176  sl:-0.2154 ll:0.0011\n",
            "0.6882,0.3529,score:1.1861,[할머니는 신데렐라에게 반짝반짝 유리구두를 신고신데렐라는 황금마차를 무도회장으로 왕자님을 왕자님은 무도회장에 아가씨들은 쳐다보지도 신데렐라하고만 벽시계의 열두시를 종소리에 놀랐다.]\n",
            "correct_grammar_score:5.2246 best_grammar_score:-3.2596\n",
            "할머니는 신데렐라에게 반짝반짝 유리구두를 신고신데렐라는 황금마차를 무도회장으로 왕자님을 왕자님은 무도회장에 아가씨들은 쳐다보지도 신데렐라하고만 벽시계의 열두시를 종소리에 놀랐다.\n",
            "할머니는 신데렐라에게 반짝반짝 유리구두를 선물받고 신고신데렐라는 황금마차를 무도회장으로 향해 왕자님을 맞이했으나 왕자님은 무도회장에 아가씨들은 쳐다보지도 않고 신데도렐라하고만 벽시계의 열두시를 바라보는 종소리에 깜짝 놀랐다.\n",
            "max score:1.1861257897498865 grammar:-3.2596325874328613 text:할머니는 신데렐라에게 반짝반짝 유리구두를 선물받고 신고신데렐라는 황금마차를 무도회장으로 향해 왕자님을 맞이했으나 왕자님은 무도회장에 아가씨들은 쳐다보지도 않고 신데도렐라하고만 벽시계의 열두시를 바라보는 종소리에 깜짝 놀랐다.\n",
            "--------------------------------------------------\n",
            "할머니는 신데렐라에게 반짝반짝 빛나는 유리구두를 선물받았고 신고신데렐라는 황금마차를 타고 왕궁 무도회장으로 가서 멋진 왕자님을 만났다. 왕자님은 무도회장에 도착했지만 다른 아가씨들은 쳐다보지도 않고 신데렐라하고만 벽시계의 열두시를 알리는 종소리에 신데도렐라는 화들짝 놀랐다.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   370/370 epochs, e 0.00105 gl:-0.67888945  sl:-0.2657 ll:0.3777\n",
            "0.7628,0.2680,score:2.5833,[할머니는 신데렐라에게 반짝반짝 유리구두를 신고신데렐라는 황금마차를 왕궁 무도회장으로 왕자님을 만났 왕자님은 무도회장에 아가씨들은 쳐다보지도 않고 신데렐라하고만 벽시계의 열두시를 알리는 종소리에 놀랐다.]\n",
            "correct_grammar_score:5.2656 best_grammar_score:4.7381\n",
            "할머니는 신데렐라에게 반짝반짝 유리구두를 신고신데렐라는 황금마차를 왕궁 무도회장으로 왕자님을 만났 왕자님은 무도회장에 아가씨들은 쳐다보지도 않고 신데렐라하고만 벽시계의 열두시를 알리는 종소리에 놀랐다.\n",
            "할머니는 신데렐라에게 반짝반짝 유리구두를 선물받고, 신고신데렐라는 황금마차를 타고 왕궁 무도회장으로 들어가 왕자님을 만났고 왕자님은 무도회장에 있던 아가씨들은 쳐다보지도 않고 신데데렐라하고만 벽시계의 열두시를 알리는 종소리에 깜짝 놀랐다.\n",
            "--------------------------------------------------\n",
            "할머니는 신데렐라에게 반짝반짝 유리구두를 선물받고, 신고신데렐라는 황금마차를 타고 왕궁 무도회장으로 들어가 왕자님을 만났고 왕자님은 무도회장에 있던 아가씨들은 쳐다보지도 않고 신데데렐라하고만 벽시계의 열두시를 알리는 종소리에 깜짝 놀랐다. 2.5832956050204987 4.738136291503906\n",
            "--------------------------------------------------\n",
            "신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리구두 신데데렐라의 집에까지 도착했고 신데들이 도착하자 신하들이 도착했다. 유리구두는 왕자 신데렐라는 왕자님과 결혼하여 오래 행복하게 살았다.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   300/300 epochs, e 0.00105 gl:-0.73586172  sl:-0.2444 ll:0.2265\n",
            "0.8257,0.1667,score:2.2934,[신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리구두 신데데렐라의 집에까지 도착했고 신데들이 신하들이 유리구두는 신데렐라는 왕자님과 결혼하여 행복하게 살았다.]\n",
            "correct_grammar_score:5.2485 best_grammar_score:2.8525\n",
            "신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리구두 신데데렐라의 집에까지 도착했고 신데들이 신하들이 유리구두는 신데렐라는 왕자님과 결혼하여 행복하게 살았다.\n",
            "신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리구두 신데데렐라의 집에까지 도착했고, 신데들이 신하들이 신하고 있던 유리구두는 왕자님과 결혼하여 결혼했고, 그 왕자님과 왕자님이 결혼하여 행복하게 살았다.\n",
            "--------------------------------------------------\n",
            "신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리구두 신데데렐라의 집에까지 도착했고, 신데들이 신하들이 신하고 있던 유리구두는 왕자님과 결혼하여 결혼했고, 그 왕자님과 왕자님이 결혼하여 행복하게 살았다. 2.29343641482474 2.8525190353393555\n",
            "==================================================1==================================================\n",
            "신데렐라는 무럭무럭 자라서 새어머니는 언니들을 괴롭혔고, 새고머니는 딸들보다 예쁘고 착한게 못마땅했기에 왕궁에서 무도회가 열렸다.\n",
            "남은 신데렐라는 서러워 보였고, 들어보니 할머니와 할머니가 할머니는 무도회에 초대장을 보내줄테니 호박 두마리 도마뱀을 선물했고, 신데도렐라의 장식장식 장식이 장식된 장식장식장식장식 장식이 반짝이는 드레스로 바뀌었다.\n",
            "할머니는 신데렐라에게 반짝반짝 유리구두를 선물받고, 신고신데렐라는 황금마차를 타고 왕궁 무도회장으로 들어가 왕자님을 만났고 왕자님은 무도회장에 있던 아가씨들은 쳐다보지도 않고 신데데렐라하고만 벽시계의 열두시를 알리는 종소리에 깜짝 놀랐다.\n",
            "신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리구두 신데데렐라의 집에까지 도착했고, 신데들이 신하들이 신하고 있던 유리구두는 왕자님과 결혼하여 결혼했고, 그 왕자님과 왕자님이 결혼하여 행복하게 살았다.\n",
            "\n",
            "\n",
            "delete model\n",
            "--------------------------------------------------\n",
            "신데렐라는 무럭무럭 자라서 예쁘고 마음씨 고운 소녀가 되었다. 새어머니는 두명의 언니들을 데리고 왔다.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   300/300 epochs, e 0.00105 gl:0.05839734  sl:-0.0721 ll:0.0681\n",
            "0.4642,0.5614,score:1.3996,[신데렐라는 무럭무럭 새어머니는 언니들을 왔다.]\n",
            "0.5338,0.4912,score:1.6820,[신데렐라는 무럭무럭 자라서 새어머니는 언니들을 왔다.]\n",
            "correct_grammar_score:4.2298 best_grammar_score:0.7393\n",
            "신데렐라는 무럭무럭 자라서 새어머니는 언니들을 왔다.\n",
            "신데렐라는 무럭무럭 자라서 새어머니는 언니들을 집으로 데려 왔다.\n",
            "max score:1.681971019450284 grammar:0.7393315434455872 text:신데렐라는 무럭무럭 자라서 새어머니는 언니들을 집으로 데려 왔다.\n",
            "--------------------------------------------------\n",
            "신데렐라는 무럭무럭 자라서 예쁘고 마음씨 고운 소녀가 되었다. 새어머니는 두명의 언니들을 데리고 왔다.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   310/310 epochs, e 0.00105 gl:0.25979835  sl:-0.0684 ll:0.0119\n",
            "0.4642,0.5614,score:1.3996,[신데렐라는 무럭무럭 새어머니는 언니들을 왔다.]\n",
            "correct_grammar_score:3.0224 best_grammar_score:-0.5412\n",
            "신데렐라는 무럭무럭 새어머니는 언니들을 왔다.\n",
            "신데렐라는 무럭무럭 성장하고 새어머니는 언니들을 만나러 왔다.\n",
            "max score:1.3996180742055684 grammar:-0.5411975979804993 text:신데렐라는 무럭무럭 성장하고 새어머니는 언니들을 만나러 왔다.\n",
            "--------------------------------------------------\n",
            "신데렐라는 무럭무럭 자라서 예쁘고 마음씨 고운 소녀가 되었다. 새어머니는 두명의 언니들을 데리고 왔다.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   320/320 epochs, e 0.00105 gl:-0.38591591  sl:-0.0996 ll:0.3808\n",
            "0.6460,0.4211,score:2.1947,[신데렐라는 무럭무럭 자라서 새어머니는 언니들을 데리고 왔다.]\n",
            "correct_grammar_score:4.1468 best_grammar_score:2.8900\n",
            "신데렐라는 무럭무럭 자라서 새어머니는 언니들을 데리고 왔다.\n",
            "신데렐라는 무럭무럭 자라서 새어머니는 언니들을 데리고 데려 왔다.\n",
            "--------------------------------------------------\n",
            "신데렐라는 무럭무럭 자라서 새어머니는 언니들을 데리고 데려 왔다. 2.1946707358766977 2.8900063037872314\n",
            "--------------------------------------------------\n",
            "새어머니는 소녀가 자기 딸들보다 예쁘고 착한게 못마땅했다. 그러던 어느날 왕궁에서 무도회가 열렸다.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   300/300 epochs, e 0.00105 gl:-0.41229075  sl:-0.0570 ll:0.0068\n",
            "0.5338,0.4545,score:1.7597,[새어머니는 딸들보다 못마땅했 왕궁에서 무도회가 열렸다.]\n",
            "correct_grammar_score:5.0943 best_grammar_score:1.4259\n",
            "새어머니는 딸들보다 못마땅했 왕궁에서 무도회가 열렸다.\n",
            "새어머니는 딸들보다 형편이 못마땅했고, 왕궁에서 열린 무도회가 자주 열렸다.\n",
            "max score:1.7597086290432056 grammar:1.42585289478302 text:새어머니는 딸들보다 형편이 못마땅했고, 왕궁에서 열린 무도회가 자주 열렸다.\n",
            "--------------------------------------------------\n",
            "새어머니는 소녀가 자기 딸들보다 예쁘고 착한게 못마땅했다. 그러던 어느날 왕궁에서 무도회가 열렸다.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   310/310 epochs, e 0.00105 gl:-0.50781858  sl:-0.0879 ll:0.3692\n",
            "0.8345,0.1818,score:2.5085,[새어머니는 소녀가 자기 딸들보다 예쁘고 착한게 못마땅했 왕궁에서 무도회가 열렸다.]\n",
            "correct_grammar_score:5.2219 best_grammar_score:3.9457\n",
            "새어머니는 소녀가 자기 딸들보다 예쁘고 착한게 못마땅했 왕궁에서 무도회가 열렸다.\n",
            "새어머니는 이 소녀가 자기 딸들보다 훨씬 예쁘고 착한게 못마땅했기에 왕궁에서 무도회가 열렸다.\n",
            "--------------------------------------------------\n",
            "새어머니는 이 소녀가 자기 딸들보다 훨씬 예쁘고 착한게 못마땅했기에 왕궁에서 무도회가 열렸다. 2.5084819497354776 3.945707082748413\n",
            "--------------------------------------------------\n",
            "혼자 남은 신데렐라는 서러워 울기 시작했다. 신데렐라가 고개를 들어보니 마법사 할머니가 빙그레 웃고 있었다.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   300/300 epochs, e 0.00105 gl:-0.47671169  sl:-0.1585 ll:0.4989\n",
            "0.6647,0.3833,score:2.2735,[남은 신데렐라는 서러워 신데렐라가 고개를 들어보니 할머니가 있었다.]\n",
            "correct_grammar_score:5.0678 best_grammar_score:3.3651\n",
            "남은 신데렐라는 서러워 신데렐라가 고개를 들어보니 할머니가 있었다.\n",
            "남은 신데렐라는 서러워 했고, 신데데가 고개를 들어보니 할머니와 할머니가 기다리고 있었다.\n",
            "--------------------------------------------------\n",
            "남은 신데렐라는 서러워 했고, 신데데가 고개를 들어보니 할머니와 할머니가 기다리고 있었다. 2.2734816298328253 3.3650851249694824\n",
            "--------------------------------------------------\n",
            "할머니는 소녀를 무도회에 보내줄테니 호박 한개와 생쥐 두마리 도마뱀을 가지고 오라 했다. 신데렐라의 낡은 옷은 구슬 장식이 반짝이는 예쁜 드레스로 바뀌었다.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   300/300 epochs, e 0.00105 gl:-0.40344617  sl:-0.0981 ll:0.2095\n",
            "0.6172,0.3908,score:1.9793,[할머니는 무도회에 보내줄테니 호박 두마리 도마뱀을 신데렐라의 장식이 반짝이는 드레스로 바뀌었다.]\n",
            "correct_grammar_score:4.5372 best_grammar_score:2.1243\n",
            "할머니는 무도회에 보내줄테니 호박 두마리 도마뱀을 신데렐라의 장식이 반짝이는 드레스로 바뀌었다.\n",
            "할머니는 무도회에 초대장을 보내줄테니 호박 두마리 도마뱀을 신데렐라의 장식장식 장식장식 장식이 반짝이는 드레스로 바뀌었다.\n",
            "--------------------------------------------------\n",
            "할머니는 무도회에 초대장을 보내줄테니 호박 두마리 도마뱀을 신데렐라의 장식장식 장식장식 장식이 반짝이는 드레스로 바뀌었다. 1.979284020510881 2.1243157386779785\n",
            "--------------------------------------------------\n",
            "할머니는 신데렐라에게 반짝반짝 빛나는 유리구두를 신겨 주었다. 신데렐라는 황금마차를 타고 왕궁 무도회장으로 가서 멋진 왕자님을 만났다.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   300/300 epochs, e 0.00105 gl:-0.45992595  sl:-0.2110 ll:0.0036\n",
            "0.7158,0.3200,score:1.9640,[할머니는 신데렐라에게 반짝반짝 유리구두를 신데렐라는 황금마차를 무도회장으로 왕자님을 만났다.]\n",
            "correct_grammar_score:5.1754 best_grammar_score:1.2741\n",
            "할머니는 신데렐라에게 반짝반짝 유리구두를 신데렐라는 황금마차를 무도회장으로 왕자님을 만났다.\n",
            "할머니는 신데렐라에게 반짝반짝 유리구두를 선물받았고, 신고데렐라는 황금마차를 타고 무도회장으로 향해 왕자님을 만났다.\n",
            "max score:1.9639865353740378 grammar:1.274074912071228 text:할머니는 신데렐라에게 반짝반짝 유리구두를 선물받았고, 신고데렐라는 황금마차를 타고 무도회장으로 향해 왕자님을 만났다.\n",
            "--------------------------------------------------\n",
            "할머니는 신데렐라에게 반짝반짝 빛나는 유리구두를 신겨 주었다. 신데렐라는 황금마차를 타고 왕궁 무도회장으로 가서 멋진 왕자님을 만났다.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   310/310 epochs, e 0.00105 gl:-0.45687255  sl:-0.2096 ll:0.0081\n",
            "0.7158,0.3200,score:1.9640,[할머니는 신데렐라에게 반짝반짝 유리구두를 신데렐라는 황금마차를 무도회장으로 왕자님을 만났다.]\n",
            "correct_grammar_score:5.1754 best_grammar_score:1.2741\n",
            "할머니는 신데렐라에게 반짝반짝 유리구두를 신데렐라는 황금마차를 무도회장으로 왕자님을 만났다.\n",
            "할머니는 신데렐라에게 반짝반짝 유리구두를 선물받았고, 신고데렐라는 황금마차를 타고 무도회장으로 향해 왕자님을 만났다.\n",
            "max score:1.9639865353740378 grammar:1.274074912071228 text:할머니는 신데렐라에게 반짝반짝 유리구두를 선물받았고, 신고데렐라는 황금마차를 타고 무도회장으로 향해 왕자님을 만났다.\n",
            "--------------------------------------------------\n",
            "할머니는 신데렐라에게 반짝반짝 빛나는 유리구두를 신겨 주었다. 신데렐라는 황금마차를 타고 왕궁 무도회장으로 가서 멋진 왕자님을 만났다.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   320/320 epochs, e 0.00105 gl:-0.46805245  sl:-0.2147 ll:0.0021\n",
            "0.7158,0.3200,score:1.9640,[할머니는 신데렐라에게 반짝반짝 유리구두를 신데렐라는 황금마차를 무도회장으로 왕자님을 만났다.]\n",
            "correct_grammar_score:5.1754 best_grammar_score:1.2741\n",
            "할머니는 신데렐라에게 반짝반짝 유리구두를 신데렐라는 황금마차를 무도회장으로 왕자님을 만났다.\n",
            "할머니는 신데렐라에게 반짝반짝 유리구두를 선물받았고, 신고데렐라는 황금마차를 타고 무도회장으로 향해 왕자님을 만났다.\n",
            "max score:1.9639865353740378 grammar:1.274074912071228 text:할머니는 신데렐라에게 반짝반짝 유리구두를 선물받았고, 신고데렐라는 황금마차를 타고 무도회장으로 향해 왕자님을 만났다.\n",
            "--------------------------------------------------\n",
            "할머니는 신데렐라에게 반짝반짝 빛나는 유리구두를 신겨 주었다. 신데렐라는 황금마차를 타고 왕궁 무도회장으로 가서 멋진 왕자님을 만났다.\n",
            "--------------------------------------------------\n",
            "Train... |||||||||||||||||||||| 100.0%   330/330 epochs, e 0.00105 gl:-0.71237689  sl:-0.2791 ll:0.5795\n",
            "0.8821,0.1467,score:2.3836,[할머니는 신데렐라에게 반짝반짝 빛나는 유리구두를 신데렐라는 황금마차를 왕궁 무도회장으로 가서 멋진 왕자님을 만났다.]\n",
            "0.8304,0.1867,score:2.2470,[할머니는 신데렐라에게 반짝반짝 빛나는 유리구두를 신데렐라는 황금마차를 왕궁 무도회장으로 멋진 왕자님을 만났다.]\n",
            "correct_grammar_score:5.2166 best_grammar_score:2.8359\n",
            "할머니는 신데렐라에게 반짝반짝 빛나는 유리구두를 신데렐라는 황금마차를 왕궁 무도회장으로 가서 멋진 왕자님을 만났다.\n",
            "할머니는 신데렐라에게 반짝반짝 빛나는 유리구두를 선물받았고, 신고신데렐라는 황금마차를 타고 왕궁 무도회장으로 가서 멋진 왕자님을 만났다.\n",
            "--------------------------------------------------\n",
            "할머니는 신데렐라에게 반짝반짝 빛나는 유리구두를 선물받았고, 신고신데렐라는 황금마차를 타고 왕궁 무도회장으로 가서 멋진 왕자님을 만났다. 2.383564102515354 2.8359313011169434\n",
            "--------------------------------------------------\n",
            "왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고 신데렐라하고만 춤을 추었다. 벽시계의 열두시를 알리는 종소리에 신데렐라는 화들짝 놀랐다.\n",
            "--------------------------------------------------\n",
            "Train... ||||||||||||||.......| 65.0%   195/300 epochs, e 0.00261 gl:0.52878940  sl:-0.1646 ll:0.0128"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_AzsvMX6KEq"
      },
      "source": [
        "model.save_pretrained(\"/content/drive/MyDrive/GAN_ENDE/sentence_complete_model2\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}