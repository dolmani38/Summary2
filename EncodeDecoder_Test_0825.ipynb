{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "6 - Attention is All You Need.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dolmani38/Summary2/blob/main/EncodeDecoder_Test_0825.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTKaX6slIIAy"
      },
      "source": [
        "# 여기서부터 TEST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTUSxMPHncPU"
      },
      "source": [
        "참조 : https://github.com/kiyoungkim1/LMkor\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1S2PM1n2ePq"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchtext\n",
        "#from torchtext.datasets import Multi30k\n",
        "#from torchtext.data import Field, BucketIterator\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "import spacy\n",
        "import numpy as np\n",
        "\n",
        "import random\n",
        "import math\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBOQ4O8S2oOv"
      },
      "source": [
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8G99UP3gzA-",
        "outputId": "509d6f6f-90f3-4fb9-c50e-462c689430c1"
      },
      "source": [
        "import urllib.request\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "# 간단한 전처리\n",
        "def clean_text(txt):\n",
        "    txt = txt.replace('\\n',' ')\n",
        "    txt = txt.replace('\\r',' ')    \n",
        "    txt = txt.replace('=','')\n",
        "    txt = txt.replace('\\\"','')   \n",
        "    txt = txt.replace('\\'','')\n",
        "    #txt = txt.replace(',','')\n",
        "    txt = txt.replace('..','')\n",
        "    txt = txt.replace('...','')\n",
        "    #txt = txt.replace('.','. ')\n",
        "    txt = txt.replace('.','. ')\n",
        "    txt = txt.replace('  ',' ')\n",
        "    txt = txt.replace('  ',' ')    \n",
        "    txt = txt.replace('  ',' ')   \n",
        "    txt = txt.replace('  ',' ')           \n",
        "    txt = txt.replace('  ',' ')\n",
        "    txt = txt.replace('  ',' ')    \n",
        "    txt = txt.replace('  ',' ')   \n",
        "    txt = txt.replace('  ',' ')             \n",
        "    return txt.strip()\n",
        "\n",
        "def collect_training_dataset_for_s2s_generator(source_urls=[]):\n",
        "    ko_sentences_dataset = []\n",
        "    for url in source_urls:\n",
        "        raw_text = urllib.request.urlopen(url).read().decode('utf-8')\n",
        "        ko_sentences_dataset += nltk.sent_tokenize(clean_text(raw_text))\n",
        "\n",
        "    sentences = []\n",
        "    for txt in ko_sentences_dataset:\n",
        "        txt = txt.strip()\n",
        "        if len(txt) > 40 and txt.endswith('다.'):\n",
        "            #ko_grammar_dataset.append([txt,1])\n",
        "            txt = txt.replace('.','')\n",
        "            sentences.append(txt)\n",
        "\n",
        "    return sentences"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "696xz3yTqbs9",
        "outputId": "09613666-0ae3-4bfd-b67d-534a1678a67d"
      },
      "source": [
        "if True:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "pFoSKILDiVDE",
        "outputId": "aa798b01-13d0-4d71-ecad-3387975183de"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/summary/korean_news_corpus.csv')\n",
        "df"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>contents</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>문 대통령 변창흠 국토장관 사의표명 사실상 수용</td>\n",
              "      <td>정만호 국민소통수석이 12일 오후 청와대 춘추관 대브리핑룸에서 변창흠 국토부 장관 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>계급장 수여하는 문 대통령</td>\n",
              "      <td>(아산뉴스1) 이광호 기자 문재인 대통령이 12일 오후 충남 아산시 경찰대학에서 열...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>계급장 수여하는 문 대통령</td>\n",
              "      <td>(아산뉴스1) 이광호 기자 문재인 대통령이 12일 오후 충남 아산시 경찰대학에서 열...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>수상자 메달 걸어주는 문 대통령</td>\n",
              "      <td>(아산뉴스1) 이광호 기자 문재인 대통령이 12일 오후 충남 아산시 경찰대학에서 열...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>정몽구 서울아산병원에 50억 쾌척</td>\n",
              "      <td>인재 양성·소외 계층 지원 등 계획 “부친 질병·가난 악순환 끊기 원해 국내 최고 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140559</th>\n",
              "      <td>[건축과도시] 북한산을 캔버스 삼아. 미술관 또 하나의 작품이 되다</td>\n",
              "      <td>&lt;은평구 진관동 사비나 미술관&gt; 서울시 은평구 진관동에 자리잡은 사비나미술관. 삼각...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140560</th>\n",
              "      <td>조선후기 문인 김조순 별장 그린 옥호정도 첫 공개</td>\n",
              "      <td>국립중앙박물관 서화실 개편해 32점 새롭게 전시 옥호정도[국립중앙박물관 제공연합뉴스...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140561</th>\n",
              "      <td>안성 청룡사 대웅전에서 목재 곡자 발견</td>\n",
              "      <td>문화재청(청장 정재숙)의 국고보조와 기술지도로 안성시에서 시행하고 있는 안성 청룡사...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140562</th>\n",
              "      <td>156년전 ㄱ자 곡자 찾았다 안성 청룡사 기둥 밑에서</td>\n",
              "      <td>안성 청룡사 대웅전에서 발견된 곡자 【서울뉴시스】 이수지 기자 안성 청룡사 대웅전에...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140563</th>\n",
              "      <td>[김중기의 필름통] 새 영화 도굴 나인스 게이트 앙상블</td>\n",
              "      <td>영화 도굴 스틸컷 ◆도굴 감독: 박정배 출연: 이제훈 조우진 신혜선 도굴을 소재로 ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>140564 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        title                                           contents\n",
              "0                  문 대통령 변창흠 국토장관 사의표명 사실상 수용  정만호 국민소통수석이 12일 오후 청와대 춘추관 대브리핑룸에서 변창흠 국토부 장관 ...\n",
              "1                              계급장 수여하는 문 대통령  (아산뉴스1) 이광호 기자 문재인 대통령이 12일 오후 충남 아산시 경찰대학에서 열...\n",
              "2                              계급장 수여하는 문 대통령  (아산뉴스1) 이광호 기자 문재인 대통령이 12일 오후 충남 아산시 경찰대학에서 열...\n",
              "3                           수상자 메달 걸어주는 문 대통령  (아산뉴스1) 이광호 기자 문재인 대통령이 12일 오후 충남 아산시 경찰대학에서 열...\n",
              "4                          정몽구 서울아산병원에 50억 쾌척  인재 양성·소외 계층 지원 등 계획 “부친 질병·가난 악순환 끊기 원해 국내 최고 ...\n",
              "...                                       ...                                                ...\n",
              "140559  [건축과도시] 북한산을 캔버스 삼아. 미술관 또 하나의 작품이 되다  <은평구 진관동 사비나 미술관> 서울시 은평구 진관동에 자리잡은 사비나미술관. 삼각...\n",
              "140560            조선후기 문인 김조순 별장 그린 옥호정도 첫 공개  국립중앙박물관 서화실 개편해 32점 새롭게 전시 옥호정도[국립중앙박물관 제공연합뉴스...\n",
              "140561                  안성 청룡사 대웅전에서 목재 곡자 발견  문화재청(청장 정재숙)의 국고보조와 기술지도로 안성시에서 시행하고 있는 안성 청룡사...\n",
              "140562          156년전 ㄱ자 곡자 찾았다 안성 청룡사 기둥 밑에서  안성 청룡사 대웅전에서 발견된 곡자 【서울뉴시스】 이수지 기자 안성 청룡사 대웅전에...\n",
              "140563         [김중기의 필름통] 새 영화 도굴 나인스 게이트 앙상블  영화 도굴 스틸컷 ◆도굴 감독: 박정배 출연: 이제훈 조우진 신혜선 도굴을 소재로 ...\n",
              "\n",
              "[140564 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cbf_yNd3quK8",
        "outputId": "fd36becf-d831-45fe-c0b2-38eef6eeb62f"
      },
      "source": [
        "import re\n",
        "import sys\n",
        "# 검사...\n",
        "pattens = [\"[34569][0-9]{3}[\\;.\\;-\\; ][0-9]{4}[\\;.\\;-\\; ][0-9]{4}[\\;.\\;-\\; ][0-9]{4}\",\n",
        "           \"[0-9]{2,3}[\\:\\s\\;.\\;,\\;-;)][0-9]{3,4}[\\:\\s\\;.\\;,\\;-][0-9]{4}\",\n",
        "           \"[0-9]{1}[0-9]{1}[\\W]?[0-1]{1}[0-9]{1}[\\W]?[0-3]{1}[\\W]?[0-9]{1}[\\W]?[1-4]{1}[\\W]?[0-9]{1}[\\W]?[0-9]{1}[\\W]?[0-9]{1}[\\W]?[0-9]{1}[\\W]?[0-9]{1}[\\W]?[0-9]{1}\",\n",
        "           \"[0-9]{2}[\\:\\s\\;.\\;,\\;-][0-9]{2}[\\:\\s\\;.\\;,\\;-][0-9]{6}|[0-9]{3}[\\:\\s\\;.\\;,\\;-]([0-9]{5,6}[\\:\\s\\;.\\;,\\;-][0-9]{3}|[0-9]{6}[\\:\\s\\;.\\;,\\;-][0-9]{5}|[0-9]{2,3}[\\:\\s\\;.\\;,\\;-][0-9]{6}|[0-9]{2}[\\:\\s\\;.\\;,\\;-][0-9]{7}|[0-9]{2}[\\:\\s\\;.\\;,\\;-][0-9]{4,6}[\\:\\s\\;.\\;,\\;-][0-9]|[0-9]{5}[\\:\\s\\;.\\;,\\;-][0-9]{3}[\\:\\s\\;.\\;,\\;-][0-9]{2}|[0-9]{2}[\\:\\s\\;.\\;,\\;-][0-9]{5}[\\:\\s\\;.\\;,\\;-][0-9]{3}|[0-9]{4}[\\:\\s\\;.\\;,\\;-][0-9]{4}[\\:\\s\\;.\\;,\\;-][0-9]{3}|[0-9]{6}[\\:\\s\\;.\\;,\\;-][0-9]{2}[\\:\\s\\;.\\;,\\;-][0-9]{3}|[0-9]{2}[\\:\\s\\;.\\;,\\;-][0-9]{2}[\\:\\s\\;.\\;,\\;-][0-9]{7})|[0-9]{4}[\\:\\s\\;.\\;,\\;-]([0-9]{3}[\\:\\s\\;.\\;,\\;-][0-9]{6}|[0-9]{2}[\\:\\s\\;.\\;,\\;-][0-9]{6}[\\:\\s\\;.\\;,\\;-][0-9])|[0-9]{5}[\\:\\s\\;.\\;,\\;-][0-9]{2}[\\:\\s\\;.\\;,\\;-][0-9]{6}|[0-9]{6}[\\:\\s\\;.\\;,\\;-][0-9]{2}[\\:\\s\\;.\\;,\\;-][0-9]{5,6}\"\n",
        "           ]\n",
        "\n",
        "filters = []\n",
        "for p in pattens:\n",
        "    filters.append(re.compile(p))\n",
        "\n",
        "sentences = []\n",
        "\n",
        "for raw_text in df['contents']:\n",
        "    try:\n",
        "        docs = nltk.sent_tokenize(clean_text(raw_text))\n",
        "        for txt in docs:\n",
        "            if txt.find('▶') > -1 or txt.find('@') > -1 or txt.find('ⓒ') > -1: \n",
        "                pass\n",
        "            else:\n",
        "                txt = txt.strip()\n",
        "                if len(txt) > 40:\n",
        "                    #ok = True\n",
        "                    #for f in filters:\n",
        "                    #    if len(f.findall(txt)) > 0:\n",
        "                    #        ok = False\n",
        "                    #        print('fitered:',txt)\n",
        "                    #if ok:\n",
        "                    if any(chr.isdigit() for chr in txt):\n",
        "                        pass\n",
        "                    else:\n",
        "                        sentences.append(txt)\n",
        "    except KeyboardInterrupt as ki:\n",
        "        raise ki        \n",
        "    except:\n",
        "        print(\"Unexpected error:\", sys.exc_info()[0])      \n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unexpected error: <class 'AttributeError'>\n",
            "Unexpected error: <class 'AttributeError'>\n",
            "Unexpected error: <class 'AttributeError'>\n",
            "Unexpected error: <class 'AttributeError'>\n",
            "Unexpected error: <class 'AttributeError'>\n",
            "Unexpected error: <class 'AttributeError'>\n",
            "Unexpected error: <class 'AttributeError'>\n",
            "Unexpected error: <class 'AttributeError'>\n",
            "Unexpected error: <class 'AttributeError'>\n",
            "Unexpected error: <class 'AttributeError'>\n",
            "Unexpected error: <class 'AttributeError'>\n",
            "Unexpected error: <class 'AttributeError'>\n",
            "Unexpected error: <class 'AttributeError'>\n",
            "Unexpected error: <class 'AttributeError'>\n",
            "Unexpected error: <class 'AttributeError'>\n",
            "Unexpected error: <class 'AttributeError'>\n",
            "Unexpected error: <class 'AttributeError'>\n",
            "Unexpected error: <class 'AttributeError'>\n",
            "Unexpected error: <class 'AttributeError'>\n",
            "Unexpected error: <class 'AttributeError'>\n",
            "Unexpected error: <class 'AttributeError'>\n",
            "Unexpected error: <class 'AttributeError'>\n",
            "Unexpected error: <class 'AttributeError'>\n",
            "Unexpected error: <class 'AttributeError'>\n",
            "Unexpected error: <class 'AttributeError'>\n",
            "Unexpected error: <class 'AttributeError'>\n",
            "Unexpected error: <class 'AttributeError'>\n",
            "Unexpected error: <class 'AttributeError'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYBs7FYFrEze",
        "outputId": "a026f802-56b9-4bf6-af72-f3eea95af0a9"
      },
      "source": [
        "len(sentences)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1544643"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KT_bAT4ix3yn"
      },
      "source": [
        "import re\n",
        "import sys\n",
        "import io\n",
        "\n",
        "#텍스트 정제(전처리)\n",
        "def cleanText(readData):\n",
        "    #텍스트에 포함되어 있는 특수 문자 제거\n",
        "    text = re.sub('[-=+,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》]', '', readData)\n",
        "    return text"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lBwyjW8x55f"
      },
      "source": [
        "c_sentences = []\n",
        "for sentence in sentences:\n",
        "    s = cleanText(sentence)\n",
        "    if len(s.split()) < 10:\n",
        "        c_sentences.append(s)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wW7kLnpyiYF",
        "outputId": "26c2acb5-5aa5-4d7a-e24f-197bb9f448ae"
      },
      "source": [
        "len(c_sentences)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "58552"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAGY99EK5Zqn"
      },
      "source": [
        "c_sentences[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQDZ-X6iiT1U",
        "outputId": "4b65b3c4-1f59-43a0-af48-24adb0a29399"
      },
      "source": [
        "!pip3 install keybert\n",
        "!pip3 install sentence-transformers\n",
        "!pip3 install -q transformers"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keybert in /usr/local/lib/python3.7/dist-packages (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from keybert) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.7/dist-packages (from keybert) (0.22.2.post1)\n",
            "Requirement already satisfied: rich>=10.4.0 in /usr/local/lib/python3.7/dist-packages (from keybert) (10.7.0)\n",
            "Requirement already satisfied: sentence-transformers>=0.3.8 in /usr/local/lib/python3.7/dist-packages (from keybert) (2.0.0)\n",
            "Requirement already satisfied: colorama<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from rich>=10.4.0->keybert) (0.4.4)\n",
            "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from rich>=10.4.0->keybert) (0.9.1)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from rich>=10.4.0->keybert) (2.6.1)\n",
            "Requirement already satisfied: typing-extensions<4.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from rich>=10.4.0->keybert) (3.7.4.3)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.2->keybert) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.2->keybert) (1.0.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.3.8->keybert) (0.1.96)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.3.8->keybert) (1.9.0+cu102)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.3.8->keybert) (4.62.0)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.3.8->keybert) (0.0.12)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.3.8->keybert) (4.9.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.3.8->keybert) (0.10.0+cu102)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.3.8->keybert) (3.2.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (4.6.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (21.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (3.0.12)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (0.0.45)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (2.23.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (0.10.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (5.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (3.5.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers>=0.3.8->keybert) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (2021.5.30)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (7.1.2)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers>=0.3.8->keybert) (7.1.2)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.7/dist-packages (2.0.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.9.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.22.2.post1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.10.0+cu102)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.62.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.9.0+cu102)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.1.96)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.0.12)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.2.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers) (3.7.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.12)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.10.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.0.45)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (4.6.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (21.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (5.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.0.1)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers) (7.1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLXE7zoSieJg"
      },
      "source": [
        "from keybert import KeyBERT\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "sentence_model = SentenceTransformer(\"xlm-r-large-en-ko-nli-ststb\")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7q8egfDPoTU"
      },
      "source": [
        "key_model = KeyBERT(model=sentence_model)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBN_3lM8wrqN"
      },
      "source": [
        "def extract_key(sentence):\n",
        "    #print(s)\n",
        "    top_n= int(len(sentence.split())/3)\n",
        "    keys = key_model.extract_keywords(sentence,top_n=top_n)\n",
        "    x= {}\n",
        "    for k,p in keys:\n",
        "        x[k] = sentence.lower().find(k)\n",
        "        #print(x[k],k)\n",
        "    keys = list(dict(sorted(x.items(), key=lambda item: item[1])).keys())\n",
        "    return keys\n",
        "\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZp15IHCzYTr",
        "outputId": "8eaa6ed0-295f-4c18-fb76-9bc6c2869897"
      },
      "source": [
        "i = 200\n",
        "[' '.join(extract_key(c_sentences[i])),c_sentences[i]]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['가입자 사건에 한해서라도', '가입자 단체에서는 일부 사건에 한해서라도 제도 도입이 필요하다고 주장합니다']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkzG9Nraj0Wz"
      },
      "source": [
        "pretraoned_kobert_model_name='kykim/bert-kor-base'\n",
        "#tokenizer = KoBertTokenizer.from_pretrained(pretraoned_kobert_model_name)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eno9dC3RZpwL"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hv6FBE2scfnY",
        "outputId": "c2d1c204-a972-40d0-8d54-3776b3c3263b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from transformers import EncoderDecoderModel, BertTokenizerFast\n",
        "import torch\n",
        "\n",
        "tokenizer = BertTokenizerFast.from_pretrained(pretraoned_kobert_model_name)\n",
        "model = EncoderDecoderModel.from_encoder_decoder_pretrained(pretraoned_kobert_model_name, pretraoned_kobert_model_name) # initialize Bert2Bert from pre-trained checkpoints\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertLMHeadModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertLMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertLMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertLMHeadModel were not initialized from the model checkpoint at kykim/bert-kor-base and are newly initialized: ['bert.encoder.layer.2.crossattention.output.dense.bias', 'bert.encoder.layer.9.crossattention.output.dense.weight', 'bert.encoder.layer.6.crossattention.output.dense.weight', 'bert.encoder.layer.2.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.self.value.weight', 'bert.encoder.layer.5.crossattention.self.value.bias', 'bert.encoder.layer.4.crossattention.self.key.bias', 'bert.encoder.layer.4.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.7.crossattention.self.query.weight', 'bert.encoder.layer.9.crossattention.self.value.bias', 'bert.encoder.layer.6.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.output.dense.weight', 'bert.encoder.layer.6.crossattention.output.dense.bias', 'bert.encoder.layer.7.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.9.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.self.value.bias', 'bert.encoder.layer.9.crossattention.self.key.weight', 'bert.encoder.layer.9.crossattention.output.dense.bias', 'bert.encoder.layer.11.crossattention.self.value.weight', 'bert.encoder.layer.11.crossattention.output.dense.bias', 'bert.encoder.layer.11.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.8.crossattention.self.query.bias', 'bert.encoder.layer.5.crossattention.self.key.weight', 'bert.encoder.layer.5.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.11.crossattention.self.key.bias', 'bert.encoder.layer.3.crossattention.output.dense.bias', 'bert.encoder.layer.5.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.10.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.self.value.bias', 'bert.encoder.layer.4.crossattention.output.dense.weight', 'bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.9.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.self.query.bias', 'bert.encoder.layer.3.crossattention.self.key.bias', 'bert.encoder.layer.5.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.8.crossattention.self.value.bias', 'bert.encoder.layer.5.crossattention.self.query.bias', 'bert.encoder.layer.6.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.7.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.11.crossattention.output.dense.weight', 'bert.encoder.layer.11.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.1.crossattention.output.dense.bias', 'bert.encoder.layer.5.crossattention.self.value.weight', 'bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.3.crossattention.output.dense.weight', 'bert.encoder.layer.7.crossattention.output.dense.bias', 'bert.encoder.layer.8.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.3.crossattention.self.query.weight', 'bert.encoder.layer.9.crossattention.self.query.bias', 'bert.encoder.layer.6.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.self.query.bias', 'bert.encoder.layer.3.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.8.crossattention.self.value.weight', 'bert.encoder.layer.1.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.self.value.weight', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.self.value.bias', 'bert.encoder.layer.10.crossattention.self.key.bias', 'bert.encoder.layer.3.crossattention.self.key.weight', 'bert.encoder.layer.4.crossattention.self.value.weight', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.3.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.self.value.weight', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.6.crossattention.self.key.weight', 'bert.encoder.layer.7.crossattention.self.key.bias', 'bert.encoder.layer.9.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.3.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.5.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.5.crossattention.output.dense.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.7.crossattention.output.dense.weight', 'bert.encoder.layer.3.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.output.dense.weight', 'bert.encoder.layer.7.crossattention.self.key.weight', 'bert.encoder.layer.9.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.output.dense.weight', 'bert.encoder.layer.8.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.7.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.self.query.bias', 'bert.encoder.layer.11.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.11.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.self.query.weight', 'bert.encoder.layer.8.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.11.crossattention.self.key.weight', 'bert.encoder.layer.10.crossattention.output.dense.weight', 'bert.encoder.layer.7.crossattention.self.query.bias', 'bert.encoder.layer.5.crossattention.self.query.weight', 'bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.8.crossattention.output.dense.bias', 'bert.encoder.layer.11.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.self.value.bias', 'bert.encoder.layer.9.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.output.dense.bias', 'bert.encoder.layer.3.crossattention.self.query.bias', 'bert.encoder.layer.1.crossattention.self.key.bias', 'bert.encoder.layer.10.crossattention.output.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVQbHz1Yde7J",
        "outputId": "49c3eca5-66aa-4f64-81d7-9a364d8a8980",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "op = tokenizer(\"김성수 과학기술정보통신부 과학기술혁신본부장이 간담회 참석자들과 기념촬영 하고 있다\", return_tensors=\"pt\")\n",
        "print(op)\n",
        "print(\"Tokens (str)      : {}\".format([tokenizer.convert_ids_to_tokens(s) for s in op['input_ids'].tolist()[0]]))\n",
        "print(\"Tokens (int)      : {}\".format(op['input_ids'].tolist()[0]))\n",
        "print(\"Tokens (attn_mask): {}\\n\".format(op['attention_mask'].tolist()[0]))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'input_ids': tensor([[    2, 24499,  8069, 35077, 15954, 18931,  8210, 35077, 31246, 22116,\n",
            "         14248, 31650,  8113, 17287, 30246, 16022, 19550, 14042, 13984,     3]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
            "Tokens (str)      : ['[CLS]', '김성', '##수', '과학기술', '##정보', '##통신', '##부', '과학기술', '##혁신', '##본부', '##장이', '간담', '##회', '참석', '##자들과', '기념', '##촬영', '하고', '있다', '[SEP]']\n",
            "Tokens (int)      : [2, 24499, 8069, 35077, 15954, 18931, 8210, 35077, 31246, 22116, 14248, 31650, 8113, 17287, 30246, 16022, 19550, 14042, 13984, 3]\n",
            "Tokens (attn_mask): [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKdA9wbuCqD9",
        "outputId": "7ff50c4c-fbd2-4c50-b272-559ec61526b7"
      },
      "source": [
        "class Batch:\n",
        "  src = []\n",
        "  trg = []\n",
        "max_length = 100\n",
        "batch_size = 8 #4 # 64, 128\n",
        "dataset_iterator = []\n",
        "batch_counter = 0\n",
        "\n",
        "sentences2 = c_sentences[:1000]\n",
        "for i in range(0,len(sentences2),batch_size):\n",
        "#for i in range(0,1,batch_size):\n",
        "    nSRC = []\n",
        "    nTRG = []\n",
        "    src_max = 0\n",
        "    trg_max = 0\n",
        "    batch = Batch()\n",
        "    batch.src = []\n",
        "    batch.trg = []\n",
        "    \n",
        "    percent = (\"{0:.2f}\").format(100 * (i / float(len(sentences2))))\n",
        "    print(f'\\r {percent}% {i}/{str(len(sentences2))}', end=\"\", flush=True)\n",
        "    for j in range(i,i+batch_size):\n",
        "        try:\n",
        "            sentence = sentences2[j]+'.'\n",
        "            keys = extract_key(sentence)\n",
        "            srct = tokenizer((' '.join(keys)).strip(), return_tensors=\"pt\")['input_ids'].tolist()[0]\n",
        "            trgt = tokenizer(sentence, return_tensors=\"pt\")['input_ids'].tolist()[0]\n",
        "            \n",
        "            #srct = tokenizer.convert_tokens_to_ids(['[CLS]'] + tokenizer.tokenize((' '.join(keys)).strip()) + ['[SEP]'])\n",
        "            #trgt = tokenizer.convert_tokens_to_ids(['[CLS]'] + tokenizer.tokenize(sentence ) + ['[SEP]'])\n",
        "            if len(srct) < max_length and len(trgt) < max_length:\n",
        "                if len(trgt) > trg_max:\n",
        "                    trg_max = len(trgt)            \n",
        "                nTRG.append(trgt)\n",
        "                if len(srct) > src_max:\n",
        "                    src_max = len(srct)\n",
        "                nSRC.append(srct)\n",
        "\n",
        "        except Exception as e:\n",
        "            print('Error:',e)\n",
        "            pass\n",
        "\n",
        "    for s in nSRC:\n",
        "        ss = s\n",
        "        if len(s) < src_max:\n",
        "            ss += [1 for i in range(src_max-len(s))]\n",
        "        batch.src.append(ss)\n",
        "\n",
        "    for t in nTRG:\n",
        "        tt = t\n",
        "        if len(t) < trg_max:        \n",
        "            tt += [1 for i in range(trg_max-len(t))]\n",
        "        batch.trg.append(tt)\n",
        "\n",
        "    #print(len(batch.src),len(batch.src[0]))\n",
        "    #print(len(batch.trg),len(batch.trg[0]))\n",
        "\n",
        "    batch.src = torch.tensor(batch.src).to(device)\n",
        "    batch.trg = torch.tensor(batch.trg).to(device)\n",
        "    dataset_iterator.append(batch)\n",
        "\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 99.20% 992/1000"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUFUw0pI4Hfw",
        "outputId": "e5e0427b-d6e4-492c-f387-d6115da03a67"
      },
      "source": [
        "dataset_iterator[0].src"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[    2, 29110,  8269, 18189, 22327,  8061, 25810, 16301,     3,     1,\n",
              "             1,     1,     1],\n",
              "        [    2, 35077, 15954, 18931,  8210, 35077, 31246, 22116, 14248,     3,\n",
              "             1,     1,     1],\n",
              "        [    2, 39009, 21108, 17608,  2784,  8069, 15880, 16207,     3,     1,\n",
              "             1,     1,     1],\n",
              "        [    2, 17497,  8323,  8040, 13973, 40282, 14062,     3,     1,     1,\n",
              "             1,     1,     1],\n",
              "        [    2,  5921,  8146, 25273, 15093,  8159,  5921, 17400, 19913,  8048,\n",
              "          4047, 15804,     3],\n",
              "        [    2,  5921, 17400, 19913, 19974, 14350, 37562,     3,     1,     1,\n",
              "             1,     1,     1],\n",
              "        [    2, 27757,  8273, 16379, 37900,  8048, 16683, 40986,  8048,     3,\n",
              "             1,     1,     1],\n",
              "        [    2, 31179, 14004, 15436, 15534, 17543, 14399,     3,     1,     1,\n",
              "             1,     1,     1]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQntx79IdEGp"
      },
      "source": [
        "# Train 준비"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNBgedENdeRY"
      },
      "source": [
        "SRC_PAD_IDX = tokenizer.pad_token_id\n",
        "TRG_PAD_IDX = tokenizer.pad_token_id\n",
        "\n",
        "LEARNING_RATE = 0.0005\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6G6OgbLfdoJN"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "        \n",
        "        src = batch.src\n",
        "        trg = batch.trg\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        ##print(src.shape)\n",
        "        ##print(trg.shape)\n",
        "        outputs = model(input_ids=src, decoder_input_ids=trg, labels=trg)\n",
        "        #print(outputs)\n",
        "        loss, logits = outputs.loss, outputs.logits\n",
        "\n",
        "        ##print(output.shape)\n",
        "        #output = [batch size, trg len - 1, output dim]\n",
        "        #trg = [batch size, trg len]\n",
        "            \n",
        "        #output_dim = output.shape[-1]\n",
        "            \n",
        "        #output = output.contiguous().view(-1, output_dim)\n",
        "        #trg = trg[:,1:].contiguous().view(-1)\n",
        "                \n",
        "        #output = [batch size * trg len - 1, output dim]\n",
        "        #trg = [batch size * trg len - 1]\n",
        "            \n",
        "        #loss = criterion(output, trg)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        ##print('loss',loss)\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        ##print('epoch_loss',epoch_loss)\n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsdX1KJHd9LI"
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEZ2o1g6dIh-"
      },
      "source": [
        "# Train !!!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8ZsADe2e3av",
        "outputId": "70a65efb-1619-4e21-bb79-07b9621f806e"
      },
      "source": [
        "bcnt = len(dataset_iterator)\n",
        "print(bcnt)\n",
        "train_iterator = dataset_iterator[0:bcnt-int(bcnt/10)]\n",
        "valid_iterator = dataset_iterator[bcnt-int(bcnt/10):bcnt]\n",
        "#train_iterator = dataset_iterator[0:bcnt-1]\n",
        "#valid_iterator = dataset_iterator[bcnt-1:bcnt]\n",
        "print('train',len(train_iterator))\n",
        "print('valid',len(valid_iterator))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "125\n",
            "train 113\n",
            "valid 12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "po1OXs3sgmvI",
        "outputId": "fa8152e7-ce0c-4e6a-9cf4-6c71c601c52a"
      },
      "source": [
        "train_iterator[0].src"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[    2, 29110,  8269, 18189, 22327,  8061, 25810, 16301,     3,     1,\n",
              "             1,     1,     1],\n",
              "        [    2, 35077, 15954, 18931,  8210, 35077, 31246, 22116, 14248,     3,\n",
              "             1,     1,     1],\n",
              "        [    2, 39009, 21108, 17608,  2784,  8069, 15880, 16207,     3,     1,\n",
              "             1,     1,     1],\n",
              "        [    2, 17497,  8323,  8040, 13973, 40282, 14062,     3,     1,     1,\n",
              "             1,     1,     1],\n",
              "        [    2,  5921,  8146, 25273, 15093,  8159,  5921, 17400, 19913,  8048,\n",
              "          4047, 15804,     3],\n",
              "        [    2,  5921, 17400, 19913, 19974, 14350, 37562,     3,     1,     1,\n",
              "             1,     1,     1],\n",
              "        [    2, 27757,  8273, 16379, 37900,  8048, 16683, 40986,  8048,     3,\n",
              "             1,     1,     1],\n",
              "        [    2, 31179, 14004, 15436, 15534, 17543, 14399,     3,     1,     1,\n",
              "             1,     1,     1]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "Y6lxOV5jd_id",
        "outputId": "7cb16bed-ece2-4b4d-c476-86f322bdbe29"
      },
      "source": [
        "\n",
        "N_EPOCHS = 100\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "model.to(device)\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "    #valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    #if valid_loss < best_valid_loss:\n",
        "    #    best_valid_loss = valid_loss\n",
        "    #    torch.save(model.state_dict(), 'tut6-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    #print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Time: 0m 16s\n",
            "\tTrain Loss: 6.398 | Train PPL: 600.532\n",
            "Epoch: 02 | Time: 0m 16s\n",
            "\tTrain Loss: 6.172 | Train PPL: 479.333\n",
            "Epoch: 03 | Time: 0m 16s\n",
            "\tTrain Loss: 6.069 | Train PPL: 432.205\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-ea1a2aed6810>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCLIP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;31m#valid_loss = evaluate(model, valid_iterator, criterion)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-33-8b75cb4979bd>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion, clip)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m##print('loss',loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/utils/clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type, error_if_nonfinite)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mtotal_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mtotal_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtotal_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merror_if_nonfinite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             raise RuntimeError(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXsqseyMlPzB"
      },
      "source": [
        "def complete_sentence(sentence, model, device, max_len = 50):\n",
        "    \n",
        "    model.eval()\n",
        "    '''\n",
        "    if isinstance(sentence, str):\n",
        "        nlp = spacy.load('de_core_news_sm')\n",
        "        tokens = [token.text.lower() for token in nlp(sentence)]\n",
        "    else:\n",
        "        tokens = [token.lower() for token in sentence]\n",
        "    '''\n",
        "    #tokens = tokenizer.tokenize('[CLS] ' + sentence + ' [SEP]')\n",
        "    #tokens = [tokenizer.bos_token] + tokens + [tokenizer.eos_token]\n",
        "    \n",
        "\n",
        "    #src_indexes = [tokenizer.convert_tokens_to_ids(token) for token in tokens]\n",
        "    src_indexes = tokenizer(sentence, return_tensors=\"pt\")['input_ids'].tolist()[0]\n",
        "    print(src_indexes)\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
        "    print(src_tensor)\n",
        "    src_mask = model.make_src_mask(src_tensor)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        enc_src = model.encoder(src_tensor, src_mask)\n",
        "\n",
        "    trg_indexes = [tokenizer.cls_token_id]\n",
        "    \n",
        "\n",
        "    for i in range(max_len):\n",
        "\n",
        "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
        "\n",
        "        trg_mask = model.make_trg_mask(trg_tensor)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            output, attention = model.decoder(trg_tensor, enc_src, trg_mask, src_mask)\n",
        "        \n",
        "        pred_token = output.argmax(2)[:,-1].item()\n",
        "        \n",
        "        trg_indexes.append(pred_token)\n",
        "\n",
        "        if pred_token == tokenizer.sep_token_id: #tk.stoi['<eos>']: #.eos_token_id: # trg_field.vocab.stoi[trg_field.eos_token]:\n",
        "            break\n",
        "    \n",
        "    trg_tokens = tokenizer.convert_ids_to_tokens(trg_indexes) # :[tk.itos[i] for i in trg_indexes]\n",
        "    \n",
        "    return trg_tokens[1:], attention"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guSK6Fasm8rC"
      },
      "source": [
        "trg, _ = complete_sentence('북한 미국 미사일',model,device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7bUE-sNnL97"
      },
      "source": [
        "print(''.join(trg))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1g-rZK5nkEE"
      },
      "source": [
        "extract_key(sentences[101])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alNmLf1bnnDc"
      },
      "source": [
        "trg, _ = complete_sentence('가입자 사건에 한해서라도',model,device)\n",
        "print(' '.join(trg))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbrKiIYt12pn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mXk8B7A12sr",
        "outputId": "95963772-90c8-4e58-e27d-2c2f57cbefac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "keys = '가입자 사건에 한해서라도'\n",
        "input_ids = torch.tensor(tokenizer.encode(keys, add_special_tokens=True)).unsqueeze(0)\n",
        "#input_ids.to(device)\n",
        "print(input_ids)\n",
        "model.eval()\n",
        "model.cpu()\n",
        "generated = model.generate(input_ids, decoder_start_token_id=model.config.decoder.pad_token_id)\n",
        "generated"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[    2, 16704,  8158, 31829, 26980,  8044, 14566,     3]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    }
  ]
}